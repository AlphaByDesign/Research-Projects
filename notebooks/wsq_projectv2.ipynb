{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Time Series Model on BTCUSD\n",
    "\n",
    "* Linear Autoregression (AR) with multiple lags was explored. However there was no significant increase in adding further than 1 lag, as signals diminished.\n",
    "* Next step was to incorporate btc lagged volume, which enhanced sharpe by 0.5.\n",
    "\n",
    "* We will be using a linear model but using Pytorch for the weight and bias"
   ],
   "id": "1344069638934c2e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:24.282411Z",
     "start_time": "2025-11-07T13:51:02.721519Z"
    }
   },
   "source": [
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "client = Client()\n",
    "\n",
    "symbols = [\"BTCUSDT\", \"XRPUSDT\",]\n",
    "interval = \"4h\"\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = datetime.now().strftime(\"%d %b, %Y %H:%M:%S\")\n",
    "\n",
    "def get_data(symbol):\n",
    "    cols = [\n",
    "        \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "        \"close_time\", \"quote_asset_volume\", \"num_trades\",\n",
    "        \"taker_buy_base\", \"taker_buy_quote\", \"ignore\"\n",
    "    ]\n",
    "    klines = client.get_historical_klines(symbol, interval, start_date, end_date)\n",
    "    df = pd.DataFrame(klines, columns=cols)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "    df = df[[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]].astype(float, errors=\"ignore\")\n",
    "    df.set_index(\"timestamp\", inplace=True)\n",
    "    return df\n",
    "\n",
    "# ✅ Loop through symbols and store in a dict\n",
    "data = {}\n",
    "for sym in symbols:\n",
    "    print(f\"Downloading {sym}...\")\n",
    "    data[sym] = get_data(sym)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "\n",
    "# Combine both BTC and XRP close + volume into one DataFrame\n",
    "prices = pd.concat(\n",
    "    [\n",
    "        data[sym][[\"close\", \"volume\"]]\n",
    "        .rename(columns={\n",
    "            \"close\": f\"{sym}_close\",\n",
    "            \"volume\": f\"{sym}_volume\"\n",
    "        })\n",
    "        for sym in symbols\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(prices.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading BTCUSDT...\n",
      "Downloading XRPUSDT...\n",
      "                     BTCUSDT_close  BTCUSDT_volume  XRPUSDT_close  \\\n",
      "timestamp                                                           \n",
      "2021-01-01 00:00:00       29278.40    11560.456553        0.22730   \n",
      "2021-01-01 04:00:00       29092.83     7308.910274        0.22976   \n",
      "2021-01-01 08:00:00       29313.49     8283.705319        0.23732   \n",
      "2021-01-01 12:00:00       29188.67    11794.949515        0.24282   \n",
      "2021-01-01 16:00:00       29029.04     9850.965345        0.23371   \n",
      "\n",
      "                     XRPUSDT_volume  \n",
      "timestamp                            \n",
      "2021-01-01 00:00:00     152869092.2  \n",
      "2021-01-01 04:00:00     410903056.0  \n",
      "2021-01-01 08:00:00     223717854.1  \n",
      "2021-01-01 12:00:00     214552754.0  \n",
      "2021-01-01 16:00:00     362852049.2  \n"
     ]
    }
   ],
   "execution_count": 849
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inspect data",
   "id": "8537a369fcdafa37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:24.361989Z",
     "start_time": "2025-11-07T13:51:24.325428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prices.describe(include=\"all\")\n",
    "prices.value_counts()\n",
    "prices.isna().mean()"
   ],
   "id": "7fe00a8a3b230a69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BTCUSDT_close     0.0\n",
       "BTCUSDT_volume    0.0\n",
       "XRPUSDT_close     0.0\n",
       "XRPUSDT_volume    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 850
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:24.468039Z",
     "start_time": "2025-11-07T13:51:24.451212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts = prices\n",
    "ts"
   ],
   "id": "17ede1e519168225",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     BTCUSDT_close  BTCUSDT_volume  XRPUSDT_close  \\\n",
       "timestamp                                                           \n",
       "2021-01-01 00:00:00       29278.40    11560.456553        0.22730   \n",
       "2021-01-01 04:00:00       29092.83     7308.910274        0.22976   \n",
       "2021-01-01 08:00:00       29313.49     8283.705319        0.23732   \n",
       "2021-01-01 12:00:00       29188.67    11794.949515        0.24282   \n",
       "2021-01-01 16:00:00       29029.04     9850.965345        0.23371   \n",
       "...                            ...             ...            ...   \n",
       "2025-11-06 20:00:00      101346.04     3664.898180        2.21300   \n",
       "2025-11-07 00:00:00      101916.29     3965.613720        2.22910   \n",
       "2025-11-07 04:00:00      102010.00     3062.610990        2.23350   \n",
       "2025-11-07 08:00:00      100411.89     6600.411140        2.18790   \n",
       "2025-11-07 12:00:00      100460.01     3269.295810        2.19190   \n",
       "\n",
       "                     XRPUSDT_volume  \n",
       "timestamp                            \n",
       "2021-01-01 00:00:00     152869092.2  \n",
       "2021-01-01 04:00:00     410903056.0  \n",
       "2021-01-01 08:00:00     223717854.1  \n",
       "2021-01-01 12:00:00     214552754.0  \n",
       "2021-01-01 16:00:00     362852049.2  \n",
       "...                             ...  \n",
       "2025-11-06 20:00:00      27966635.3  \n",
       "2025-11-07 00:00:00      21760263.4  \n",
       "2025-11-07 04:00:00      13482578.9  \n",
       "2025-11-07 08:00:00      23320798.7  \n",
       "2025-11-07 12:00:00      14521560.7  \n",
       "\n",
       "[10630 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCUSDT_close</th>\n",
       "      <th>BTCUSDT_volume</th>\n",
       "      <th>XRPUSDT_close</th>\n",
       "      <th>XRPUSDT_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 00:00:00</th>\n",
       "      <td>29278.40</td>\n",
       "      <td>11560.456553</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>152869092.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 04:00:00</th>\n",
       "      <td>29092.83</td>\n",
       "      <td>7308.910274</td>\n",
       "      <td>0.22976</td>\n",
       "      <td>410903056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 08:00:00</th>\n",
       "      <td>29313.49</td>\n",
       "      <td>8283.705319</td>\n",
       "      <td>0.23732</td>\n",
       "      <td>223717854.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 12:00:00</th>\n",
       "      <td>29188.67</td>\n",
       "      <td>11794.949515</td>\n",
       "      <td>0.24282</td>\n",
       "      <td>214552754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 16:00:00</th>\n",
       "      <td>29029.04</td>\n",
       "      <td>9850.965345</td>\n",
       "      <td>0.23371</td>\n",
       "      <td>362852049.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-06 20:00:00</th>\n",
       "      <td>101346.04</td>\n",
       "      <td>3664.898180</td>\n",
       "      <td>2.21300</td>\n",
       "      <td>27966635.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 00:00:00</th>\n",
       "      <td>101916.29</td>\n",
       "      <td>3965.613720</td>\n",
       "      <td>2.22910</td>\n",
       "      <td>21760263.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 04:00:00</th>\n",
       "      <td>102010.00</td>\n",
       "      <td>3062.610990</td>\n",
       "      <td>2.23350</td>\n",
       "      <td>13482578.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 08:00:00</th>\n",
       "      <td>100411.89</td>\n",
       "      <td>6600.411140</td>\n",
       "      <td>2.18790</td>\n",
       "      <td>23320798.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 12:00:00</th>\n",
       "      <td>100460.01</td>\n",
       "      <td>3269.295810</td>\n",
       "      <td>2.19190</td>\n",
       "      <td>14521560.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10630 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 851
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:25.178764Z",
     "start_time": "2025-11-07T13:51:24.795153Z"
    }
   },
   "cell_type": "code",
   "source": "ts['BTCUSDT_close'].plot(figsize=(10,5),title='btcusdt close')\n",
   "id": "5d88dc99f5a74a37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'btcusdt close'}, xlabel='timestamp'>"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 852
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature Engineering\n",
   "id": "681857bde29a646e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create target and lagged features using log returns",
   "id": "4b345632446ddccc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:25.310870Z",
     "start_time": "2025-11-07T13:51:25.279870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating log return within ts dataframe.\n",
    "max_lags = 4\n",
    "forcast_horizon = 1\n",
    "\n",
    "ts = ts.sort_index()\n",
    "ts['btc_close_log_return']= np.log(ts['BTCUSDT_close']/ts['BTCUSDT_close'].shift(forcast_horizon))\n",
    "ts['xrp_close_log_return']= np.log(ts['XRPUSDT_close']/ts['XRPUSDT_close'].shift(forcast_horizon))\n",
    "#ts['shi_close_log_return']= np.log(ts['SHIBUSDT_close']/ts['SHIBUSDT_close'].shift(forcast_horizon))\n",
    "ts['btc_log_volume'] = np.log(ts['BTCUSDT_volume']/ts['BTCUSDT_volume'].shift(forcast_horizon))\n",
    "ts['xrp_log_volume'] = np.log(ts['XRPUSDT_volume']/ts['XRPUSDT_volume'].shift(forcast_horizon))\n",
    "#ts['shi_log_volume'] = np.log(ts['SHIBUSDT_volume']/ts['SHIBUSDT_volume'].shift(forcast_horizon))\n",
    "ts"
   ],
   "id": "4004e1b2505c135d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     BTCUSDT_close  BTCUSDT_volume  XRPUSDT_close  \\\n",
       "timestamp                                                           \n",
       "2021-01-01 00:00:00       29278.40    11560.456553        0.22730   \n",
       "2021-01-01 04:00:00       29092.83     7308.910274        0.22976   \n",
       "2021-01-01 08:00:00       29313.49     8283.705319        0.23732   \n",
       "2021-01-01 12:00:00       29188.67    11794.949515        0.24282   \n",
       "2021-01-01 16:00:00       29029.04     9850.965345        0.23371   \n",
       "...                            ...             ...            ...   \n",
       "2025-11-06 20:00:00      101346.04     3664.898180        2.21300   \n",
       "2025-11-07 00:00:00      101916.29     3965.613720        2.22910   \n",
       "2025-11-07 04:00:00      102010.00     3062.610990        2.23350   \n",
       "2025-11-07 08:00:00      100411.89     6600.411140        2.18790   \n",
       "2025-11-07 12:00:00      100460.01     3269.295810        2.19190   \n",
       "\n",
       "                     XRPUSDT_volume  btc_close_log_return  \\\n",
       "timestamp                                                   \n",
       "2021-01-01 00:00:00     152869092.2                   NaN   \n",
       "2021-01-01 04:00:00     410903056.0             -0.006358   \n",
       "2021-01-01 08:00:00     223717854.1              0.007556   \n",
       "2021-01-01 12:00:00     214552754.0             -0.004267   \n",
       "2021-01-01 16:00:00     362852049.2             -0.005484   \n",
       "...                             ...                   ...   \n",
       "2025-11-06 20:00:00      27966635.3             -0.000422   \n",
       "2025-11-07 00:00:00      21760263.4              0.005611   \n",
       "2025-11-07 04:00:00      13482578.9              0.000919   \n",
       "2025-11-07 08:00:00      23320798.7             -0.015790   \n",
       "2025-11-07 12:00:00      14521560.7              0.000479   \n",
       "\n",
       "                     xrp_close_log_return  btc_log_volume  xrp_log_volume  \n",
       "timestamp                                                                  \n",
       "2021-01-01 00:00:00                   NaN             NaN             NaN  \n",
       "2021-01-01 04:00:00              0.010765       -0.458496        0.988775  \n",
       "2021-01-01 08:00:00              0.032374        0.125196       -0.607972  \n",
       "2021-01-01 12:00:00              0.022911        0.353381       -0.041830  \n",
       "2021-01-01 16:00:00             -0.038239       -0.180102        0.525440  \n",
       "...                                   ...             ...             ...  \n",
       "2025-11-06 20:00:00              0.000633       -0.502788       -0.284419  \n",
       "2025-11-07 00:00:00              0.007249        0.078860       -0.250927  \n",
       "2025-11-07 04:00:00              0.001972       -0.258393       -0.478687  \n",
       "2025-11-07 08:00:00             -0.020628        0.767864        0.547947  \n",
       "2025-11-07 12:00:00              0.001827       -0.702557       -0.473711  \n",
       "\n",
       "[10630 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCUSDT_close</th>\n",
       "      <th>BTCUSDT_volume</th>\n",
       "      <th>XRPUSDT_close</th>\n",
       "      <th>XRPUSDT_volume</th>\n",
       "      <th>btc_close_log_return</th>\n",
       "      <th>xrp_close_log_return</th>\n",
       "      <th>btc_log_volume</th>\n",
       "      <th>xrp_log_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 00:00:00</th>\n",
       "      <td>29278.40</td>\n",
       "      <td>11560.456553</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>152869092.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 04:00:00</th>\n",
       "      <td>29092.83</td>\n",
       "      <td>7308.910274</td>\n",
       "      <td>0.22976</td>\n",
       "      <td>410903056.0</td>\n",
       "      <td>-0.006358</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>-0.458496</td>\n",
       "      <td>0.988775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 08:00:00</th>\n",
       "      <td>29313.49</td>\n",
       "      <td>8283.705319</td>\n",
       "      <td>0.23732</td>\n",
       "      <td>223717854.1</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.032374</td>\n",
       "      <td>0.125196</td>\n",
       "      <td>-0.607972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 12:00:00</th>\n",
       "      <td>29188.67</td>\n",
       "      <td>11794.949515</td>\n",
       "      <td>0.24282</td>\n",
       "      <td>214552754.0</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.353381</td>\n",
       "      <td>-0.041830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 16:00:00</th>\n",
       "      <td>29029.04</td>\n",
       "      <td>9850.965345</td>\n",
       "      <td>0.23371</td>\n",
       "      <td>362852049.2</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>0.525440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-06 20:00:00</th>\n",
       "      <td>101346.04</td>\n",
       "      <td>3664.898180</td>\n",
       "      <td>2.21300</td>\n",
       "      <td>27966635.3</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.284419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 00:00:00</th>\n",
       "      <td>101916.29</td>\n",
       "      <td>3965.613720</td>\n",
       "      <td>2.22910</td>\n",
       "      <td>21760263.4</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>-0.250927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 04:00:00</th>\n",
       "      <td>102010.00</td>\n",
       "      <td>3062.610990</td>\n",
       "      <td>2.23350</td>\n",
       "      <td>13482578.9</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>-0.258393</td>\n",
       "      <td>-0.478687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 08:00:00</th>\n",
       "      <td>100411.89</td>\n",
       "      <td>6600.411140</td>\n",
       "      <td>2.18790</td>\n",
       "      <td>23320798.7</td>\n",
       "      <td>-0.015790</td>\n",
       "      <td>-0.020628</td>\n",
       "      <td>0.767864</td>\n",
       "      <td>0.547947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 12:00:00</th>\n",
       "      <td>100460.01</td>\n",
       "      <td>3269.295810</td>\n",
       "      <td>2.19190</td>\n",
       "      <td>14521560.7</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>-0.702557</td>\n",
       "      <td>-0.473711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10630 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 853
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:25.606636Z",
     "start_time": "2025-11-07T13:51:25.587665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create lagged features\n",
    "target = 'btc_close_log_return'\n",
    "max_lags = 4\n",
    "forcast_horizon = 1\n",
    "\n",
    "# create 4 lagged features\n",
    "\n",
    "ts = ts.copy() # this is to avoid setting with copy warning\n",
    "\n",
    "ts[f'{target}_lag_1'] = ts[target].shift(forcast_horizon * 1)\n",
    "ts[f'{target}_lag_2'] = ts[target].shift(forcast_horizon * 2)\n",
    "ts[f'{target}_lag_3'] = ts[target].shift(forcast_horizon * 3)\n",
    "ts[f'{target}_lag_4'] = ts[target].shift(forcast_horizon * 4)\n",
    "\n",
    "ts['xrp_close_lag_1'] = ts['xrp_close_log_return'].shift(forcast_horizon * 1)\n",
    "ts['xrp_close_lag_2'] = ts['xrp_close_log_return'].shift(forcast_horizon * 2)\n",
    "ts['xrp_close_lag_3'] = ts['xrp_close_log_return'].shift(forcast_horizon * 3)\n",
    "\n",
    "\n",
    "#ts['shi_close_lag_1'] = ts['shi_close_log_return'].shift(forcast_horizon * 1)\n",
    "#ts['shi_close_lag_2'] = ts['shi_close_log_return'].shift(forcast_horizon * 2)\n",
    "#ts['shi_close_lag_3'] = ts['shi_close_log_return'].shift(forcast_horizon * 3)\n",
    "\n",
    "ts['btc_log_volume_lag_1'] = ts['btc_log_volume'].shift(forcast_horizon * 1)\n",
    "ts['btc_log_volume_lag_2'] = ts['btc_log_volume'].shift(forcast_horizon * 2)\n",
    "ts['btc_log_volume_lag_3'] = ts['btc_log_volume'].shift(forcast_horizon * 3)\n",
    "\n",
    "ts['xrp_log_volume_lag_1'] = ts['xrp_log_volume'].shift(forcast_horizon * 1)\n",
    "ts['xrp_log_volume_lag_2'] = ts['xrp_log_volume'].shift(forcast_horizon * 2)\n",
    "ts['xrp_log_volume_lag_3'] = ts['xrp_log_volume'].shift(forcast_horizon * 3)\n",
    "\n",
    "#ts['shi_log_volume_lag_1'] = ts['shi_log_volume'].shift(forcast_horizon * 1)\n",
    "#ts['shi_log_volume_lag_2'] = ts['shi_log_volume'].shift(forcast_horizon * 2)\n",
    "#ts['shi_log_volume_lag_3'] = ts['shi_log_volume'].shift(forcast_horizon * 3)\n",
    "\n"
   ],
   "id": "39151d4d9ce8b504",
   "outputs": [],
   "execution_count": 854
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:25.919704Z",
     "start_time": "2025-11-07T13:51:25.863493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# better practice would be ts = ts.dropna()\n",
    "ts.dropna(inplace=True)\n",
    "ts"
   ],
   "id": "70780129f756cd25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     BTCUSDT_close  BTCUSDT_volume  XRPUSDT_close  \\\n",
       "timestamp                                                           \n",
       "2021-01-01 20:00:00       29331.69     5383.938005        0.23746   \n",
       "2021-01-02 00:00:00       29351.95     7393.028526        0.23461   \n",
       "2021-01-02 04:00:00       29750.00     9865.642845        0.23337   \n",
       "2021-01-02 08:00:00       29755.00     9226.804608        0.22761   \n",
       "2021-01-02 12:00:00       31691.29    34028.973399        0.22875   \n",
       "...                            ...             ...            ...   \n",
       "2025-11-06 20:00:00      101346.04     3664.898180        2.21300   \n",
       "2025-11-07 00:00:00      101916.29     3965.613720        2.22910   \n",
       "2025-11-07 04:00:00      102010.00     3062.610990        2.23350   \n",
       "2025-11-07 08:00:00      100411.89     6600.411140        2.18790   \n",
       "2025-11-07 12:00:00      100460.01     3269.295810        2.19190   \n",
       "\n",
       "                     XRPUSDT_volume  btc_close_log_return  \\\n",
       "timestamp                                                   \n",
       "2021-01-01 20:00:00     125594921.9              0.010372   \n",
       "2021-01-02 00:00:00     120976606.2              0.000690   \n",
       "2021-01-02 04:00:00      88650190.5              0.013470   \n",
       "2021-01-02 08:00:00     208164332.5              0.000168   \n",
       "2021-01-02 12:00:00     189041528.8              0.063045   \n",
       "...                             ...                   ...   \n",
       "2025-11-06 20:00:00      27966635.3             -0.000422   \n",
       "2025-11-07 00:00:00      21760263.4              0.005611   \n",
       "2025-11-07 04:00:00      13482578.9              0.000919   \n",
       "2025-11-07 08:00:00      23320798.7             -0.015790   \n",
       "2025-11-07 12:00:00      14521560.7              0.000479   \n",
       "\n",
       "                     xrp_close_log_return  btc_log_volume  xrp_log_volume  \\\n",
       "timestamp                                                                   \n",
       "2021-01-01 20:00:00              0.015918       -0.604149       -1.060933   \n",
       "2021-01-02 00:00:00             -0.012075        0.317117       -0.037465   \n",
       "2021-01-02 04:00:00             -0.005299        0.288521       -0.310899   \n",
       "2021-01-02 08:00:00             -0.024992       -0.066946        0.853630   \n",
       "2021-01-02 12:00:00              0.004996        1.305100       -0.096361   \n",
       "...                                   ...             ...             ...   \n",
       "2025-11-06 20:00:00              0.000633       -0.502788       -0.284419   \n",
       "2025-11-07 00:00:00              0.007249        0.078860       -0.250927   \n",
       "2025-11-07 04:00:00              0.001972       -0.258393       -0.478687   \n",
       "2025-11-07 08:00:00             -0.020628        0.767864        0.547947   \n",
       "2025-11-07 12:00:00              0.001827       -0.702557       -0.473711   \n",
       "\n",
       "                     btc_close_log_return_lag_1  btc_close_log_return_lag_2  \\\n",
       "timestamp                                                                     \n",
       "2021-01-01 20:00:00                   -0.005484                   -0.004267   \n",
       "2021-01-02 00:00:00                    0.010372                   -0.005484   \n",
       "2021-01-02 04:00:00                    0.000690                    0.010372   \n",
       "2021-01-02 08:00:00                    0.013470                    0.000690   \n",
       "2021-01-02 12:00:00                    0.000168                    0.013470   \n",
       "...                                         ...                         ...   \n",
       "2025-11-06 20:00:00                   -0.006152                   -0.011821   \n",
       "2025-11-07 00:00:00                   -0.000422                   -0.006152   \n",
       "2025-11-07 04:00:00                    0.005611                   -0.000422   \n",
       "2025-11-07 08:00:00                    0.000919                    0.005611   \n",
       "2025-11-07 12:00:00                   -0.015790                    0.000919   \n",
       "\n",
       "                     ...  btc_close_log_return_lag_4  xrp_close_lag_1  \\\n",
       "timestamp            ...                                                \n",
       "2021-01-01 20:00:00  ...                   -0.006358        -0.038239   \n",
       "2021-01-02 00:00:00  ...                    0.007556         0.015918   \n",
       "2021-01-02 04:00:00  ...                   -0.004267        -0.012075   \n",
       "2021-01-02 08:00:00  ...                   -0.005484        -0.005299   \n",
       "2021-01-02 12:00:00  ...                    0.010372        -0.024992   \n",
       "...                  ...                         ...              ...   \n",
       "2025-11-06 20:00:00  ...                   -0.004357        -0.010212   \n",
       "2025-11-07 00:00:00  ...                    0.000408         0.000633   \n",
       "2025-11-07 04:00:00  ...                   -0.011821         0.007249   \n",
       "2025-11-07 08:00:00  ...                   -0.006152         0.001972   \n",
       "2025-11-07 12:00:00  ...                   -0.000422        -0.020628   \n",
       "\n",
       "                     xrp_close_lag_2  xrp_close_lag_3  btc_log_volume_lag_1  \\\n",
       "timestamp                                                                     \n",
       "2021-01-01 20:00:00         0.022911         0.032374             -0.180102   \n",
       "2021-01-02 00:00:00        -0.038239         0.022911             -0.604149   \n",
       "2021-01-02 04:00:00         0.015918        -0.038239              0.317117   \n",
       "2021-01-02 08:00:00        -0.012075         0.015918              0.288521   \n",
       "2021-01-02 12:00:00        -0.005299        -0.012075             -0.066946   \n",
       "...                              ...              ...                   ...   \n",
       "2025-11-06 20:00:00        -0.029199        -0.011110             -0.097611   \n",
       "2025-11-07 00:00:00        -0.010212        -0.029199             -0.502788   \n",
       "2025-11-07 04:00:00         0.000633        -0.010212              0.078860   \n",
       "2025-11-07 08:00:00         0.007249         0.000633             -0.258393   \n",
       "2025-11-07 12:00:00         0.001972         0.007249              0.767864   \n",
       "\n",
       "                     btc_log_volume_lag_2  btc_log_volume_lag_3  \\\n",
       "timestamp                                                         \n",
       "2021-01-01 20:00:00              0.353381              0.125196   \n",
       "2021-01-02 00:00:00             -0.180102              0.353381   \n",
       "2021-01-02 04:00:00             -0.604149             -0.180102   \n",
       "2021-01-02 08:00:00              0.317117             -0.604149   \n",
       "2021-01-02 12:00:00              0.288521              0.317117   \n",
       "...                                   ...                   ...   \n",
       "2025-11-06 20:00:00              0.921907             -0.111560   \n",
       "2025-11-07 00:00:00             -0.097611              0.921907   \n",
       "2025-11-07 04:00:00             -0.502788             -0.097611   \n",
       "2025-11-07 08:00:00              0.078860             -0.502788   \n",
       "2025-11-07 12:00:00             -0.258393              0.078860   \n",
       "\n",
       "                     xrp_log_volume_lag_1  xrp_log_volume_lag_2  \\\n",
       "timestamp                                                         \n",
       "2021-01-01 20:00:00              0.525440             -0.041830   \n",
       "2021-01-02 00:00:00             -1.060933              0.525440   \n",
       "2021-01-02 04:00:00             -0.037465             -1.060933   \n",
       "2021-01-02 08:00:00             -0.310899             -0.037465   \n",
       "2021-01-02 12:00:00              0.853630             -0.310899   \n",
       "...                                   ...                   ...   \n",
       "2025-11-06 20:00:00              0.076554              0.421566   \n",
       "2025-11-07 00:00:00             -0.284419              0.076554   \n",
       "2025-11-07 04:00:00             -0.250927             -0.284419   \n",
       "2025-11-07 08:00:00             -0.478687             -0.250927   \n",
       "2025-11-07 12:00:00              0.547947             -0.478687   \n",
       "\n",
       "                     xrp_log_volume_lag_3  \n",
       "timestamp                                  \n",
       "2021-01-01 20:00:00             -0.607972  \n",
       "2021-01-02 00:00:00             -0.041830  \n",
       "2021-01-02 04:00:00              0.525440  \n",
       "2021-01-02 08:00:00             -1.060933  \n",
       "2021-01-02 12:00:00             -0.037465  \n",
       "...                                   ...  \n",
       "2025-11-06 20:00:00              0.239795  \n",
       "2025-11-07 00:00:00              0.421566  \n",
       "2025-11-07 04:00:00              0.076554  \n",
       "2025-11-07 08:00:00             -0.284419  \n",
       "2025-11-07 12:00:00             -0.250927  \n",
       "\n",
       "[10625 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCUSDT_close</th>\n",
       "      <th>BTCUSDT_volume</th>\n",
       "      <th>XRPUSDT_close</th>\n",
       "      <th>XRPUSDT_volume</th>\n",
       "      <th>btc_close_log_return</th>\n",
       "      <th>xrp_close_log_return</th>\n",
       "      <th>btc_log_volume</th>\n",
       "      <th>xrp_log_volume</th>\n",
       "      <th>btc_close_log_return_lag_1</th>\n",
       "      <th>btc_close_log_return_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>btc_close_log_return_lag_4</th>\n",
       "      <th>xrp_close_lag_1</th>\n",
       "      <th>xrp_close_lag_2</th>\n",
       "      <th>xrp_close_lag_3</th>\n",
       "      <th>btc_log_volume_lag_1</th>\n",
       "      <th>btc_log_volume_lag_2</th>\n",
       "      <th>btc_log_volume_lag_3</th>\n",
       "      <th>xrp_log_volume_lag_1</th>\n",
       "      <th>xrp_log_volume_lag_2</th>\n",
       "      <th>xrp_log_volume_lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 20:00:00</th>\n",
       "      <td>29331.69</td>\n",
       "      <td>5383.938005</td>\n",
       "      <td>0.23746</td>\n",
       "      <td>125594921.9</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>-0.604149</td>\n",
       "      <td>-1.060933</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006358</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.032374</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>0.353381</td>\n",
       "      <td>0.125196</td>\n",
       "      <td>0.525440</td>\n",
       "      <td>-0.041830</td>\n",
       "      <td>-0.607972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 00:00:00</th>\n",
       "      <td>29351.95</td>\n",
       "      <td>7393.028526</td>\n",
       "      <td>0.23461</td>\n",
       "      <td>120976606.2</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.317117</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>-0.604149</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>0.353381</td>\n",
       "      <td>-1.060933</td>\n",
       "      <td>0.525440</td>\n",
       "      <td>-0.041830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 04:00:00</th>\n",
       "      <td>29750.00</td>\n",
       "      <td>9865.642845</td>\n",
       "      <td>0.23337</td>\n",
       "      <td>88650190.5</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>0.288521</td>\n",
       "      <td>-0.310899</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>0.317117</td>\n",
       "      <td>-0.604149</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>-1.060933</td>\n",
       "      <td>0.525440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 08:00:00</th>\n",
       "      <td>29755.00</td>\n",
       "      <td>9226.804608</td>\n",
       "      <td>0.22761</td>\n",
       "      <td>208164332.5</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-0.024992</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>0.853630</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>0.288521</td>\n",
       "      <td>0.317117</td>\n",
       "      <td>-0.604149</td>\n",
       "      <td>-0.310899</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>-1.060933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 12:00:00</th>\n",
       "      <td>31691.29</td>\n",
       "      <td>34028.973399</td>\n",
       "      <td>0.22875</td>\n",
       "      <td>189041528.8</td>\n",
       "      <td>0.063045</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>1.305100</td>\n",
       "      <td>-0.096361</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>-0.024992</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>0.288521</td>\n",
       "      <td>0.317117</td>\n",
       "      <td>0.853630</td>\n",
       "      <td>-0.310899</td>\n",
       "      <td>-0.037465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-06 20:00:00</th>\n",
       "      <td>101346.04</td>\n",
       "      <td>3664.898180</td>\n",
       "      <td>2.21300</td>\n",
       "      <td>27966635.3</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.284419</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>-0.011821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>-0.010212</td>\n",
       "      <td>-0.029199</td>\n",
       "      <td>-0.011110</td>\n",
       "      <td>-0.097611</td>\n",
       "      <td>0.921907</td>\n",
       "      <td>-0.111560</td>\n",
       "      <td>0.076554</td>\n",
       "      <td>0.421566</td>\n",
       "      <td>0.239795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 00:00:00</th>\n",
       "      <td>101916.29</td>\n",
       "      <td>3965.613720</td>\n",
       "      <td>2.22910</td>\n",
       "      <td>21760263.4</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>-0.250927</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.010212</td>\n",
       "      <td>-0.029199</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.097611</td>\n",
       "      <td>0.921907</td>\n",
       "      <td>-0.284419</td>\n",
       "      <td>0.076554</td>\n",
       "      <td>0.421566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 04:00:00</th>\n",
       "      <td>102010.00</td>\n",
       "      <td>3062.610990</td>\n",
       "      <td>2.23350</td>\n",
       "      <td>13482578.9</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>-0.258393</td>\n",
       "      <td>-0.478687</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011821</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.010212</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.097611</td>\n",
       "      <td>-0.250927</td>\n",
       "      <td>-0.284419</td>\n",
       "      <td>0.076554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 08:00:00</th>\n",
       "      <td>100411.89</td>\n",
       "      <td>6600.411140</td>\n",
       "      <td>2.18790</td>\n",
       "      <td>23320798.7</td>\n",
       "      <td>-0.015790</td>\n",
       "      <td>-0.020628</td>\n",
       "      <td>0.767864</td>\n",
       "      <td>0.547947</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.258393</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.478687</td>\n",
       "      <td>-0.250927</td>\n",
       "      <td>-0.284419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 12:00:00</th>\n",
       "      <td>100460.01</td>\n",
       "      <td>3269.295810</td>\n",
       "      <td>2.19190</td>\n",
       "      <td>14521560.7</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>-0.702557</td>\n",
       "      <td>-0.473711</td>\n",
       "      <td>-0.015790</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.020628</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.767864</td>\n",
       "      <td>-0.258393</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>0.547947</td>\n",
       "      <td>-0.478687</td>\n",
       "      <td>-0.250927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10625 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 855
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:26.513810Z",
     "start_time": "2025-11-07T13:51:26.285995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot distribution\n",
    "\n",
    "ts['xrp_close_log_return'].hist(bins=50, figsize=(10,5))\n",
    "plt.title('Close log return')\n",
    "plt.xlabel('Close log return')\n",
    "plt.ylabel('Number of trades')\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "73d8798594509bd4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 856
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build Model",
   "id": "e111c59fa79b3cb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:26.648755Z",
     "start_time": "2025-11-07T13:51:26.643269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we will use a linear model from torch.\n",
    "# reason for linear model is the simplicity and interpretation\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ],
   "id": "c04f988e3febc490",
   "outputs": [],
   "execution_count": 857
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Split by time\n",
    "* Creating an AR1 model\n",
    "* We are aiming to predict one return by its own lag\n",
    "* splitting your data by scratch ensures no data leackage"
   ],
   "id": "8288476577ed07a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:26.724665Z",
     "start_time": "2025-11-07T13:51:26.719528Z"
    }
   },
   "cell_type": "code",
   "source": [
    " features = ['btc_close_log_return_lag_1','btc_close_log_return_lag_2','btc_close_log_return_lag_3',\n",
    "             'btc_log_volume_lag_1','btc_log_volume_lag_2','xrp_log_volume_lag_1','xrp_log_volume_lag_2']\n",
    " target = 'btc_close_log_return'\n",
    " test_size = 0.25"
   ],
   "id": "9e93e248bd02bb8",
   "outputs": [],
   "execution_count": 858
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:26.802280Z",
     "start_time": "2025-11-07T13:51:26.794462Z"
    }
   },
   "cell_type": "code",
   "source": "len(ts)",
   "id": "52dae32ebe5bc293",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10625"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 859
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:26.893917Z",
     "start_time": "2025-11-07T13:51:26.887988Z"
    }
   },
   "cell_type": "code",
   "source": "len(ts)* test_size",
   "id": "5f2fe3fc83daad85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2656.25"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 860
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:26.990591Z",
     "start_time": "2025-11-07T13:51:26.980604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to split the data by time, we will split it by the index.\n",
    "# this will give us the train size below\n",
    "split_idx = int(len(ts) *(1-test_size))\n",
    "split_idx"
   ],
   "id": "27f4d59037d52114",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7968"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 861
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:27.127106Z",
     "start_time": "2025-11-07T13:51:27.104053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split time series into 2 parts\n",
    "\n",
    "ts_train,ts_test = ts[:split_idx], ts[split_idx:]\n",
    "\n",
    "ts_train.head()"
   ],
   "id": "ce95d1ea4aae1020",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     BTCUSDT_close  BTCUSDT_volume  XRPUSDT_close  \\\n",
       "timestamp                                                           \n",
       "2021-01-01 20:00:00       29331.69     5383.938005        0.23746   \n",
       "2021-01-02 00:00:00       29351.95     7393.028526        0.23461   \n",
       "2021-01-02 04:00:00       29750.00     9865.642845        0.23337   \n",
       "2021-01-02 08:00:00       29755.00     9226.804608        0.22761   \n",
       "2021-01-02 12:00:00       31691.29    34028.973399        0.22875   \n",
       "\n",
       "                     XRPUSDT_volume  btc_close_log_return  \\\n",
       "timestamp                                                   \n",
       "2021-01-01 20:00:00     125594921.9              0.010372   \n",
       "2021-01-02 00:00:00     120976606.2              0.000690   \n",
       "2021-01-02 04:00:00      88650190.5              0.013470   \n",
       "2021-01-02 08:00:00     208164332.5              0.000168   \n",
       "2021-01-02 12:00:00     189041528.8              0.063045   \n",
       "\n",
       "                     xrp_close_log_return  btc_log_volume  xrp_log_volume  \\\n",
       "timestamp                                                                   \n",
       "2021-01-01 20:00:00              0.015918       -0.604149       -1.060933   \n",
       "2021-01-02 00:00:00             -0.012075        0.317117       -0.037465   \n",
       "2021-01-02 04:00:00             -0.005299        0.288521       -0.310899   \n",
       "2021-01-02 08:00:00             -0.024992       -0.066946        0.853630   \n",
       "2021-01-02 12:00:00              0.004996        1.305100       -0.096361   \n",
       "\n",
       "                     btc_close_log_return_lag_1  btc_close_log_return_lag_2  \\\n",
       "timestamp                                                                     \n",
       "2021-01-01 20:00:00                   -0.005484                   -0.004267   \n",
       "2021-01-02 00:00:00                    0.010372                   -0.005484   \n",
       "2021-01-02 04:00:00                    0.000690                    0.010372   \n",
       "2021-01-02 08:00:00                    0.013470                    0.000690   \n",
       "2021-01-02 12:00:00                    0.000168                    0.013470   \n",
       "\n",
       "                     ...  btc_close_log_return_lag_4  xrp_close_lag_1  \\\n",
       "timestamp            ...                                                \n",
       "2021-01-01 20:00:00  ...                   -0.006358        -0.038239   \n",
       "2021-01-02 00:00:00  ...                    0.007556         0.015918   \n",
       "2021-01-02 04:00:00  ...                   -0.004267        -0.012075   \n",
       "2021-01-02 08:00:00  ...                   -0.005484        -0.005299   \n",
       "2021-01-02 12:00:00  ...                    0.010372        -0.024992   \n",
       "\n",
       "                     xrp_close_lag_2  xrp_close_lag_3  btc_log_volume_lag_1  \\\n",
       "timestamp                                                                     \n",
       "2021-01-01 20:00:00         0.022911         0.032374             -0.180102   \n",
       "2021-01-02 00:00:00        -0.038239         0.022911             -0.604149   \n",
       "2021-01-02 04:00:00         0.015918        -0.038239              0.317117   \n",
       "2021-01-02 08:00:00        -0.012075         0.015918              0.288521   \n",
       "2021-01-02 12:00:00        -0.005299        -0.012075             -0.066946   \n",
       "\n",
       "                     btc_log_volume_lag_2  btc_log_volume_lag_3  \\\n",
       "timestamp                                                         \n",
       "2021-01-01 20:00:00              0.353381              0.125196   \n",
       "2021-01-02 00:00:00             -0.180102              0.353381   \n",
       "2021-01-02 04:00:00             -0.604149             -0.180102   \n",
       "2021-01-02 08:00:00              0.317117             -0.604149   \n",
       "2021-01-02 12:00:00              0.288521              0.317117   \n",
       "\n",
       "                     xrp_log_volume_lag_1  xrp_log_volume_lag_2  \\\n",
       "timestamp                                                         \n",
       "2021-01-01 20:00:00              0.525440             -0.041830   \n",
       "2021-01-02 00:00:00             -1.060933              0.525440   \n",
       "2021-01-02 04:00:00             -0.037465             -1.060933   \n",
       "2021-01-02 08:00:00             -0.310899             -0.037465   \n",
       "2021-01-02 12:00:00              0.853630             -0.310899   \n",
       "\n",
       "                     xrp_log_volume_lag_3  \n",
       "timestamp                                  \n",
       "2021-01-01 20:00:00             -0.607972  \n",
       "2021-01-02 00:00:00             -0.041830  \n",
       "2021-01-02 04:00:00              0.525440  \n",
       "2021-01-02 08:00:00             -1.060933  \n",
       "2021-01-02 12:00:00             -0.037465  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCUSDT_close</th>\n",
       "      <th>BTCUSDT_volume</th>\n",
       "      <th>XRPUSDT_close</th>\n",
       "      <th>XRPUSDT_volume</th>\n",
       "      <th>btc_close_log_return</th>\n",
       "      <th>xrp_close_log_return</th>\n",
       "      <th>btc_log_volume</th>\n",
       "      <th>xrp_log_volume</th>\n",
       "      <th>btc_close_log_return_lag_1</th>\n",
       "      <th>btc_close_log_return_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>btc_close_log_return_lag_4</th>\n",
       "      <th>xrp_close_lag_1</th>\n",
       "      <th>xrp_close_lag_2</th>\n",
       "      <th>xrp_close_lag_3</th>\n",
       "      <th>btc_log_volume_lag_1</th>\n",
       "      <th>btc_log_volume_lag_2</th>\n",
       "      <th>btc_log_volume_lag_3</th>\n",
       "      <th>xrp_log_volume_lag_1</th>\n",
       "      <th>xrp_log_volume_lag_2</th>\n",
       "      <th>xrp_log_volume_lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 20:00:00</th>\n",
       "      <td>29331.69</td>\n",
       "      <td>5383.938005</td>\n",
       "      <td>0.23746</td>\n",
       "      <td>125594921.9</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>-0.604149</td>\n",
       "      <td>-1.060933</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006358</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.032374</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>0.353381</td>\n",
       "      <td>0.125196</td>\n",
       "      <td>0.525440</td>\n",
       "      <td>-0.041830</td>\n",
       "      <td>-0.607972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 00:00:00</th>\n",
       "      <td>29351.95</td>\n",
       "      <td>7393.028526</td>\n",
       "      <td>0.23461</td>\n",
       "      <td>120976606.2</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.317117</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>-0.604149</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>0.353381</td>\n",
       "      <td>-1.060933</td>\n",
       "      <td>0.525440</td>\n",
       "      <td>-0.041830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 04:00:00</th>\n",
       "      <td>29750.00</td>\n",
       "      <td>9865.642845</td>\n",
       "      <td>0.23337</td>\n",
       "      <td>88650190.5</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>0.288521</td>\n",
       "      <td>-0.310899</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>0.317117</td>\n",
       "      <td>-0.604149</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>-1.060933</td>\n",
       "      <td>0.525440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 08:00:00</th>\n",
       "      <td>29755.00</td>\n",
       "      <td>9226.804608</td>\n",
       "      <td>0.22761</td>\n",
       "      <td>208164332.5</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-0.024992</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>0.853630</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>0.288521</td>\n",
       "      <td>0.317117</td>\n",
       "      <td>-0.604149</td>\n",
       "      <td>-0.310899</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>-1.060933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 12:00:00</th>\n",
       "      <td>31691.29</td>\n",
       "      <td>34028.973399</td>\n",
       "      <td>0.22875</td>\n",
       "      <td>189041528.8</td>\n",
       "      <td>0.063045</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>1.305100</td>\n",
       "      <td>-0.096361</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>-0.024992</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>0.288521</td>\n",
       "      <td>0.317117</td>\n",
       "      <td>0.853630</td>\n",
       "      <td>-0.310899</td>\n",
       "      <td>-0.037465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 862
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:27.260034Z",
     "start_time": "2025-11-07T13:51:27.234732Z"
    }
   },
   "cell_type": "code",
   "source": "ts_test.tail()",
   "id": "e296efd9cde33cbf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     BTCUSDT_close  BTCUSDT_volume  XRPUSDT_close  \\\n",
       "timestamp                                                           \n",
       "2025-11-06 20:00:00      101346.04      3664.89818         2.2130   \n",
       "2025-11-07 00:00:00      101916.29      3965.61372         2.2291   \n",
       "2025-11-07 04:00:00      102010.00      3062.61099         2.2335   \n",
       "2025-11-07 08:00:00      100411.89      6600.41114         2.1879   \n",
       "2025-11-07 12:00:00      100460.01      3269.29581         2.1919   \n",
       "\n",
       "                     XRPUSDT_volume  btc_close_log_return  \\\n",
       "timestamp                                                   \n",
       "2025-11-06 20:00:00      27966635.3             -0.000422   \n",
       "2025-11-07 00:00:00      21760263.4              0.005611   \n",
       "2025-11-07 04:00:00      13482578.9              0.000919   \n",
       "2025-11-07 08:00:00      23320798.7             -0.015790   \n",
       "2025-11-07 12:00:00      14521560.7              0.000479   \n",
       "\n",
       "                     xrp_close_log_return  btc_log_volume  xrp_log_volume  \\\n",
       "timestamp                                                                   \n",
       "2025-11-06 20:00:00              0.000633       -0.502788       -0.284419   \n",
       "2025-11-07 00:00:00              0.007249        0.078860       -0.250927   \n",
       "2025-11-07 04:00:00              0.001972       -0.258393       -0.478687   \n",
       "2025-11-07 08:00:00             -0.020628        0.767864        0.547947   \n",
       "2025-11-07 12:00:00              0.001827       -0.702557       -0.473711   \n",
       "\n",
       "                     btc_close_log_return_lag_1  btc_close_log_return_lag_2  \\\n",
       "timestamp                                                                     \n",
       "2025-11-06 20:00:00                   -0.006152                   -0.011821   \n",
       "2025-11-07 00:00:00                   -0.000422                   -0.006152   \n",
       "2025-11-07 04:00:00                    0.005611                   -0.000422   \n",
       "2025-11-07 08:00:00                    0.000919                    0.005611   \n",
       "2025-11-07 12:00:00                   -0.015790                    0.000919   \n",
       "\n",
       "                     ...  btc_close_log_return_lag_4  xrp_close_lag_1  \\\n",
       "timestamp            ...                                                \n",
       "2025-11-06 20:00:00  ...                   -0.004357        -0.010212   \n",
       "2025-11-07 00:00:00  ...                    0.000408         0.000633   \n",
       "2025-11-07 04:00:00  ...                   -0.011821         0.007249   \n",
       "2025-11-07 08:00:00  ...                   -0.006152         0.001972   \n",
       "2025-11-07 12:00:00  ...                   -0.000422        -0.020628   \n",
       "\n",
       "                     xrp_close_lag_2  xrp_close_lag_3  btc_log_volume_lag_1  \\\n",
       "timestamp                                                                     \n",
       "2025-11-06 20:00:00        -0.029199        -0.011110             -0.097611   \n",
       "2025-11-07 00:00:00        -0.010212        -0.029199             -0.502788   \n",
       "2025-11-07 04:00:00         0.000633        -0.010212              0.078860   \n",
       "2025-11-07 08:00:00         0.007249         0.000633             -0.258393   \n",
       "2025-11-07 12:00:00         0.001972         0.007249              0.767864   \n",
       "\n",
       "                     btc_log_volume_lag_2  btc_log_volume_lag_3  \\\n",
       "timestamp                                                         \n",
       "2025-11-06 20:00:00              0.921907             -0.111560   \n",
       "2025-11-07 00:00:00             -0.097611              0.921907   \n",
       "2025-11-07 04:00:00             -0.502788             -0.097611   \n",
       "2025-11-07 08:00:00              0.078860             -0.502788   \n",
       "2025-11-07 12:00:00             -0.258393              0.078860   \n",
       "\n",
       "                     xrp_log_volume_lag_1  xrp_log_volume_lag_2  \\\n",
       "timestamp                                                         \n",
       "2025-11-06 20:00:00              0.076554              0.421566   \n",
       "2025-11-07 00:00:00             -0.284419              0.076554   \n",
       "2025-11-07 04:00:00             -0.250927             -0.284419   \n",
       "2025-11-07 08:00:00             -0.478687             -0.250927   \n",
       "2025-11-07 12:00:00              0.547947             -0.478687   \n",
       "\n",
       "                     xrp_log_volume_lag_3  \n",
       "timestamp                                  \n",
       "2025-11-06 20:00:00              0.239795  \n",
       "2025-11-07 00:00:00              0.421566  \n",
       "2025-11-07 04:00:00              0.076554  \n",
       "2025-11-07 08:00:00             -0.284419  \n",
       "2025-11-07 12:00:00             -0.250927  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCUSDT_close</th>\n",
       "      <th>BTCUSDT_volume</th>\n",
       "      <th>XRPUSDT_close</th>\n",
       "      <th>XRPUSDT_volume</th>\n",
       "      <th>btc_close_log_return</th>\n",
       "      <th>xrp_close_log_return</th>\n",
       "      <th>btc_log_volume</th>\n",
       "      <th>xrp_log_volume</th>\n",
       "      <th>btc_close_log_return_lag_1</th>\n",
       "      <th>btc_close_log_return_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>btc_close_log_return_lag_4</th>\n",
       "      <th>xrp_close_lag_1</th>\n",
       "      <th>xrp_close_lag_2</th>\n",
       "      <th>xrp_close_lag_3</th>\n",
       "      <th>btc_log_volume_lag_1</th>\n",
       "      <th>btc_log_volume_lag_2</th>\n",
       "      <th>btc_log_volume_lag_3</th>\n",
       "      <th>xrp_log_volume_lag_1</th>\n",
       "      <th>xrp_log_volume_lag_2</th>\n",
       "      <th>xrp_log_volume_lag_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-11-06 20:00:00</th>\n",
       "      <td>101346.04</td>\n",
       "      <td>3664.89818</td>\n",
       "      <td>2.2130</td>\n",
       "      <td>27966635.3</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.284419</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>-0.011821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>-0.010212</td>\n",
       "      <td>-0.029199</td>\n",
       "      <td>-0.011110</td>\n",
       "      <td>-0.097611</td>\n",
       "      <td>0.921907</td>\n",
       "      <td>-0.111560</td>\n",
       "      <td>0.076554</td>\n",
       "      <td>0.421566</td>\n",
       "      <td>0.239795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 00:00:00</th>\n",
       "      <td>101916.29</td>\n",
       "      <td>3965.61372</td>\n",
       "      <td>2.2291</td>\n",
       "      <td>21760263.4</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>-0.250927</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.010212</td>\n",
       "      <td>-0.029199</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.097611</td>\n",
       "      <td>0.921907</td>\n",
       "      <td>-0.284419</td>\n",
       "      <td>0.076554</td>\n",
       "      <td>0.421566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 04:00:00</th>\n",
       "      <td>102010.00</td>\n",
       "      <td>3062.61099</td>\n",
       "      <td>2.2335</td>\n",
       "      <td>13482578.9</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>-0.258393</td>\n",
       "      <td>-0.478687</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011821</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.010212</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.097611</td>\n",
       "      <td>-0.250927</td>\n",
       "      <td>-0.284419</td>\n",
       "      <td>0.076554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 08:00:00</th>\n",
       "      <td>100411.89</td>\n",
       "      <td>6600.41114</td>\n",
       "      <td>2.1879</td>\n",
       "      <td>23320798.7</td>\n",
       "      <td>-0.015790</td>\n",
       "      <td>-0.020628</td>\n",
       "      <td>0.767864</td>\n",
       "      <td>0.547947</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.258393</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>-0.502788</td>\n",
       "      <td>-0.478687</td>\n",
       "      <td>-0.250927</td>\n",
       "      <td>-0.284419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07 12:00:00</th>\n",
       "      <td>100460.01</td>\n",
       "      <td>3269.29581</td>\n",
       "      <td>2.1919</td>\n",
       "      <td>14521560.7</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>-0.702557</td>\n",
       "      <td>-0.473711</td>\n",
       "      <td>-0.015790</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.020628</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.767864</td>\n",
       "      <td>-0.258393</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>0.547947</td>\n",
       "      <td>-0.478687</td>\n",
       "      <td>-0.250927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 863
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:27.709426Z",
     "start_time": "2025-11-07T13:51:27.694864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# converting into torch tensors\n",
    "# splitting our input and output into separate variables\n",
    "X_train = torch.tensor(ts_train[features].to_numpy(), dtype=torch.float32)\n",
    "X_test = torch.tensor(ts_test[features].to_numpy(), dtype=torch.float32)\n",
    "Y_train = torch.tensor(ts_train[target].to_numpy(), dtype=torch.float32)\n",
    "Y_test = torch.tensor(ts_test[target].to_numpy(), dtype=torch.float32)\n",
    "\n"
   ],
   "id": "9cfe71ea85b7e02a",
   "outputs": [],
   "execution_count": 864
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:27.988393Z",
     "start_time": "2025-11-07T13:51:27.978173Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape # row vector\n",
   "id": "8276b3c4d57bce57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7968, 7])"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 865
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:28.194653Z",
     "start_time": "2025-11-07T13:51:28.185137Z"
    }
   },
   "cell_type": "code",
   "source": "Y_train.shape # one dimensional tensor",
   "id": "1290c3a4fc89890c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7968])"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 866
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:28.287662Z",
     "start_time": "2025-11-07T13:51:28.279057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We need to put it into a 2 dimensional\n",
    "\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_train.shape"
   ],
   "id": "299c41acca5ef0b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7968, 1])"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 867
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:28.406351Z",
     "start_time": "2025-11-07T13:51:28.398600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y_test = Y_test.reshape(-1, 1)\n",
    "Y_test.shape"
   ],
   "id": "ef487b59e8c33154",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2657, 1])"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 868
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:28.530295Z",
     "start_time": "2025-11-07T13:51:28.521837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit scaler on TRAIN only\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_scaler = StandardScaler().fit(ts_train[features].values)\n",
    "X_train_np = x_scaler.transform(ts_train[features].values)\n",
    "X_test_np  = x_scaler.transform(ts_test[features].values)\n",
    "\n",
    "# Replace old torch tensor\n",
    "X_train = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "X_test  = torch.tensor(X_test_np,  dtype=torch.float32)\n"
   ],
   "id": "ccbbacbcd845f55c",
   "outputs": [],
   "execution_count": 869
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Batch Gradient Descent\n",
    "* this trains all the data at once."
   ],
   "id": "e4f3de9490cae570"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.037169Z",
     "start_time": "2025-11-07T13:51:28.592963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# specify hyperparameters which can be tweaked to improve model performance\n",
    "\n",
    "no_epochs = 1000 * 5\n",
    "lr = 0.0005\n",
    "\n",
    "# Create Model\n",
    "model = LinearModel(len(features))\n",
    "\n",
    "#Loss Function L1Loss/MSE / L1Loss has been the strongest performer through testing\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print('\\nTraining...')\n",
    "for epoch in range(no_epochs):\n",
    "    # forward pass\n",
    "    y_hat = model(X_train)\n",
    "    loss = criterion(y_hat, Y_train)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad() # 1. clear old gradients\n",
    "    loss.backward()       # 2. compute new gradients\n",
    "    optimizer.step()      # 3. update weights\n",
    "\n",
    "    # check for improvements by logging\n",
    "    train_loss = loss.item()\n",
    "\n",
    "    # logging\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{no_epochs}], Loss: {train_loss:.6f}')\n",
    "\n",
    "    print('\\nLearned parameters:')\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}:\\n {param.data.numpy()}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(X_test)\n",
    "        test_loss = criterion(y_hat, Y_test)\n",
    "        print(f'\\nTest loss: {test_loss.item():.6f}, Train loss: {train_loss:.6f}')\n",
    "\n",
    "\n"
   ],
   "id": "9207028f35516ec7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14988855 -0.18628149 -0.24905445 -0.01299396 -0.07294779 -0.0742754\n",
      "  -0.25658223]]\n",
      "linear.bias:\n",
      " [-0.24453007]\n",
      "\n",
      "Test loss: 0.374003, Train loss: 0.391925\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14938855 -0.1857815  -0.24855445 -0.01249395 -0.07244779 -0.0737754\n",
      "  -0.25608224]]\n",
      "linear.bias:\n",
      " [-0.24403007]\n",
      "\n",
      "Test loss: 0.373018, Train loss: 0.390951\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14888857 -0.1852815  -0.24805444 -0.0119941  -0.07194779 -0.07327568\n",
      "  -0.25558224]]\n",
      "linear.bias:\n",
      " [-0.24353006]\n",
      "\n",
      "Test loss: 0.372033, Train loss: 0.389977\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14838861 -0.1847815  -0.24755444 -0.01149457 -0.07144778 -0.0727774\n",
      "  -0.25508225]]\n",
      "linear.bias:\n",
      " [-0.24303006]\n",
      "\n",
      "Test loss: 0.371048, Train loss: 0.389003\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14788866 -0.18428145 -0.24705441 -0.01099539 -0.07094774 -0.07228254\n",
      "  -0.25458226]]\n",
      "linear.bias:\n",
      " [-0.24253005]\n",
      "\n",
      "Test loss: 0.370066, Train loss: 0.388030\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14738862 -0.18378137 -0.24655437 -0.0104967  -0.07044766 -0.07179226\n",
      "  -0.25408226]]\n",
      "linear.bias:\n",
      " [-0.24203004]\n",
      "\n",
      "Test loss: 0.369086, Train loss: 0.387058\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14688845 -0.1832813  -0.24605434 -0.0099986  -0.06994757 -0.07131029\n",
      "  -0.25358224]]\n",
      "linear.bias:\n",
      " [-0.24153006]\n",
      "\n",
      "Test loss: 0.368107, Train loss: 0.386086\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14638819 -0.18278125 -0.2455543  -0.00950104 -0.06944747 -0.07083438\n",
      "  -0.25308222]]\n",
      "linear.bias:\n",
      " [-0.24103008]\n",
      "\n",
      "Test loss: 0.367129, Train loss: 0.385114\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14588784 -0.18228121 -0.24505427 -0.0090046  -0.06894739 -0.07036683\n",
      "  -0.25258216]]\n",
      "linear.bias:\n",
      " [-0.24053009]\n",
      "\n",
      "Test loss: 0.366151, Train loss: 0.384143\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14538738 -0.18178123 -0.24455424 -0.00850955 -0.06844728 -0.06990808\n",
      "  -0.25208205]]\n",
      "linear.bias:\n",
      " [-0.24003012]\n",
      "\n",
      "Test loss: 0.365176, Train loss: 0.383173\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14488684 -0.1812813  -0.24405415 -0.00801642 -0.06794712 -0.0694663\n",
      "  -0.2515819 ]]\n",
      "linear.bias:\n",
      " [-0.23953018]\n",
      "\n",
      "Test loss: 0.364202, Train loss: 0.382205\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14438626 -0.18078141 -0.243554   -0.00752542 -0.0674469  -0.0690465\n",
      "  -0.2510817 ]]\n",
      "linear.bias:\n",
      " [-0.23903029]\n",
      "\n",
      "Test loss: 0.363230, Train loss: 0.381237\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14388597 -0.18028165 -0.24305364 -0.00703623 -0.06694665 -0.06864497\n",
      "  -0.25058147]]\n",
      "linear.bias:\n",
      " [-0.23853043]\n",
      "\n",
      "Test loss: 0.362260, Train loss: 0.380270\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14338586 -0.17978212 -0.24255311 -0.00654881 -0.06644636 -0.06826718\n",
      "  -0.25008118]]\n",
      "linear.bias:\n",
      " [-0.2380306]\n",
      "\n",
      "Test loss: 0.361292, Train loss: 0.379304\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.1428859  -0.1792828  -0.2420524  -0.00606293 -0.06594612 -0.06791028\n",
      "  -0.2495809 ]]\n",
      "linear.bias:\n",
      " [-0.23753077]\n",
      "\n",
      "Test loss: 0.360326, Train loss: 0.378338\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14238624 -0.17878342 -0.24155152 -0.00557852 -0.06544595 -0.06757468\n",
      "  -0.24908064]]\n",
      "linear.bias:\n",
      " [-0.23703094]\n",
      "\n",
      "Test loss: 0.359363, Train loss: 0.377374\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14188686 -0.17828394 -0.24105048 -0.00509571 -0.06494588 -0.06726074\n",
      "  -0.24858043]]\n",
      "linear.bias:\n",
      " [-0.2365311]\n",
      "\n",
      "Test loss: 0.358400, Train loss: 0.376409\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14138743 -0.17778449 -0.24054925 -0.00461523 -0.06444601 -0.06697294\n",
      "  -0.24808027]]\n",
      "linear.bias:\n",
      " [-0.23603125]\n",
      "\n",
      "Test loss: 0.357439, Train loss: 0.375446\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14088774 -0.17728513 -0.24004784 -0.00413805 -0.06394631 -0.06671581\n",
      "  -0.24758016]]\n",
      "linear.bias:\n",
      " [-0.23553146]\n",
      "\n",
      "Test loss: 0.356480, Train loss: 0.374483\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.14038794 -0.17678589 -0.23954628 -0.00366428 -0.06344679 -0.06648837\n",
      "  -0.24708009]]\n",
      "linear.bias:\n",
      " [-0.23503166]\n",
      "\n",
      "Test loss: 0.355524, Train loss: 0.373522\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13988791 -0.17628677 -0.23904459 -0.00319433 -0.06294739 -0.06629499\n",
      "  -0.24658003]]\n",
      "linear.bias:\n",
      " [-0.2345319]\n",
      "\n",
      "Test loss: 0.354569, Train loss: 0.372562\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13938779 -0.17578794 -0.2385428  -0.00272794 -0.06244807 -0.06613869\n",
      "  -0.24607997]]\n",
      "linear.bias:\n",
      " [-0.23403211]\n",
      "\n",
      "Test loss: 0.353616, Train loss: 0.371602\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13888748 -0.17528936 -0.23804092 -0.00226504 -0.06194881 -0.06601677\n",
      "  -0.24557988]]\n",
      "linear.bias:\n",
      " [-0.23353232]\n",
      "\n",
      "Test loss: 0.352665, Train loss: 0.370642\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13838704 -0.17479093 -0.23753896 -0.00180544 -0.06144959 -0.06592967\n",
      "  -0.24507979]]\n",
      "linear.bias:\n",
      " [-0.23303255]\n",
      "\n",
      "Test loss: 0.351717, Train loss: 0.369683\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13788651 -0.17429277 -0.23703691 -0.00134904 -0.06095054 -0.06587234\n",
      "  -0.24457969]]\n",
      "linear.bias:\n",
      " [-0.23253275]\n",
      "\n",
      "Test loss: 0.350770, Train loss: 0.368724\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.1373859  -0.17379485 -0.23653477 -0.00089564 -0.06045165 -0.06584285\n",
      "  -0.24407956]]\n",
      "linear.bias:\n",
      " [-0.23203295]\n",
      "\n",
      "Test loss: 0.349825, Train loss: 0.367766\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13688529 -0.17329714 -0.2360326  -0.00044514 -0.05995288 -0.06583644\n",
      "  -0.24357942]]\n",
      "linear.bias:\n",
      " [-0.23153313]\n",
      "\n",
      "Test loss: 0.348881, Train loss: 0.366808\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.3638467e-01 -1.7279956e-01 -2.3553039e-01  2.6847702e-06\n",
      "  -5.9454303e-02 -6.5852471e-02 -2.4307925e-01]]\n",
      "linear.bias:\n",
      " [-0.23103328]\n",
      "\n",
      "Test loss: 0.347938, Train loss: 0.365851\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13588405 -0.17230217 -0.23502813  0.00044779 -0.05895595 -0.06588311\n",
      "  -0.24257906]]\n",
      "linear.bias:\n",
      " [-0.2305334]\n",
      "\n",
      "Test loss: 0.346996, Train loss: 0.364894\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13538347 -0.17180493 -0.23452583  0.00089013 -0.05845783 -0.06592802\n",
      "  -0.24207892]]\n",
      "linear.bias:\n",
      " [-0.23003346]\n",
      "\n",
      "Test loss: 0.346055, Train loss: 0.363938\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13488293 -0.17130789 -0.23402347  0.00133013 -0.05795999 -0.06598678\n",
      "  -0.24157882]]\n",
      "linear.bias:\n",
      " [-0.22953345]\n",
      "\n",
      "Test loss: 0.345116, Train loss: 0.362982\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.1343824  -0.170811   -0.23352104  0.00176816 -0.05746238 -0.06605832\n",
      "  -0.24107875]]\n",
      "linear.bias:\n",
      " [-0.22903337]\n",
      "\n",
      "Test loss: 0.344177, Train loss: 0.362027\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13388187 -0.17031427 -0.2330186   0.00220432 -0.056965   -0.06613935\n",
      "  -0.24057874]]\n",
      "linear.bias:\n",
      " [-0.2285332]\n",
      "\n",
      "Test loss: 0.343240, Train loss: 0.361071\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13338134 -0.16981764 -0.23251618  0.00263881 -0.05646786 -0.0662244\n",
      "  -0.24007878]]\n",
      "linear.bias:\n",
      " [-0.22803295]\n",
      "\n",
      "Test loss: 0.342304, Train loss: 0.360117\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.1328809  -0.1693211  -0.23201376  0.00307171 -0.05597098 -0.0663125\n",
      "  -0.2395789 ]]\n",
      "linear.bias:\n",
      " [-0.22753257]\n",
      "\n",
      "Test loss: 0.341369, Train loss: 0.359162\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13238052 -0.16882448 -0.23151137  0.00350288 -0.05547441 -0.06639531\n",
      "  -0.23907912]]\n",
      "linear.bias:\n",
      " [-0.2270321]\n",
      "\n",
      "Test loss: 0.340433, Train loss: 0.358208\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13188025 -0.16832778 -0.23100902  0.00393285 -0.05497827 -0.06646104\n",
      "  -0.2385795 ]]\n",
      "linear.bias:\n",
      " [-0.22653146]\n",
      "\n",
      "Test loss: 0.339498, Train loss: 0.357256\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13138008 -0.16783102 -0.23050669  0.0043615  -0.05448252 -0.066512\n",
      "  -0.23808002]]\n",
      "linear.bias:\n",
      " [-0.22603068]\n",
      "\n",
      "Test loss: 0.338563, Train loss: 0.356303\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13087998 -0.16733451 -0.23000439  0.00478837 -0.05398711 -0.06655566\n",
      "  -0.23758064]]\n",
      "linear.bias:\n",
      " [-0.22552973]\n",
      "\n",
      "Test loss: 0.337629, Train loss: 0.355351\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.13037996 -0.16683821 -0.22950211  0.00521376 -0.05349199 -0.06659264\n",
      "  -0.23708132]]\n",
      "linear.bias:\n",
      " [-0.22502863]\n",
      "\n",
      "Test loss: 0.336695, Train loss: 0.354400\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12988001 -0.1663421  -0.22899987  0.00563741 -0.05299716 -0.06662443\n",
      "  -0.2365821 ]]\n",
      "linear.bias:\n",
      " [-0.22452737]\n",
      "\n",
      "Test loss: 0.335761, Train loss: 0.353449\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12938003 -0.16584623 -0.22849767  0.00605947 -0.05250261 -0.06664114\n",
      "  -0.23608302]]\n",
      "linear.bias:\n",
      " [-0.22402593]\n",
      "\n",
      "Test loss: 0.334828, Train loss: 0.352498\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12888014 -0.16535054 -0.22799553  0.00648013 -0.05200838 -0.06664346\n",
      "  -0.23558408]]\n",
      "linear.bias:\n",
      " [-0.22352427]\n",
      "\n",
      "Test loss: 0.333895, Train loss: 0.351548\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12838031 -0.16485508 -0.22749344  0.00689934 -0.05151442 -0.0666337\n",
      "  -0.23508525]]\n",
      "linear.bias:\n",
      " [-0.22302245]\n",
      "\n",
      "Test loss: 0.332961, Train loss: 0.350598\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12788072 -0.16435984 -0.22699133  0.00731721 -0.05102091 -0.06661735\n",
      "  -0.23458657]]\n",
      "linear.bias:\n",
      " [-0.22252038]\n",
      "\n",
      "Test loss: 0.332028, Train loss: 0.349649\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12738134 -0.16386482 -0.22648922  0.00773358 -0.0505278  -0.06659501\n",
      "  -0.23408805]]\n",
      "linear.bias:\n",
      " [-0.2220181]\n",
      "\n",
      "Test loss: 0.331094, Train loss: 0.348700\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12688215 -0.1633701  -0.2259871   0.00814797 -0.05003512 -0.06656203\n",
      "  -0.23358974]]\n",
      "linear.bias:\n",
      " [-0.2215155]\n",
      "\n",
      "Test loss: 0.330162, Train loss: 0.347752\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12638298 -0.16287576 -0.225485    0.00855999 -0.04954285 -0.06652897\n",
      "  -0.23309162]]\n",
      "linear.bias:\n",
      " [-0.22101267]\n",
      "\n",
      "Test loss: 0.329231, Train loss: 0.346805\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12588388 -0.16238168 -0.22498284  0.00896855 -0.04905098 -0.06649421\n",
      "  -0.2325937 ]]\n",
      "linear.bias:\n",
      " [-0.2205096]\n",
      "\n",
      "Test loss: 0.328301, Train loss: 0.345859\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12538503 -0.16188805 -0.22448063  0.0093741  -0.04855956 -0.06645267\n",
      "  -0.23209597]]\n",
      "linear.bias:\n",
      " [-0.22000627]\n",
      "\n",
      "Test loss: 0.327371, Train loss: 0.344914\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12488633 -0.161395   -0.22397836  0.00977643 -0.04806861 -0.06640771\n",
      "  -0.23159847]]\n",
      "linear.bias:\n",
      " [-0.21950261]\n",
      "\n",
      "Test loss: 0.326442, Train loss: 0.343969\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12438778 -0.16090247 -0.22347602  0.01017565 -0.04757811 -0.06636184\n",
      "  -0.23110117]]\n",
      "linear.bias:\n",
      " [-0.21899867]\n",
      "\n",
      "Test loss: 0.325513, Train loss: 0.343025\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12388938 -0.16041043 -0.22297366  0.01057171 -0.04708797 -0.06631675\n",
      "  -0.23060404]]\n",
      "linear.bias:\n",
      " [-0.21849447]\n",
      "\n",
      "Test loss: 0.324585, Train loss: 0.342082\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12339111 -0.15991883 -0.22247128  0.01096505 -0.04659814 -0.06627235\n",
      "  -0.23010704]]\n",
      "linear.bias:\n",
      " [-0.21799006]\n",
      "\n",
      "Test loss: 0.323657, Train loss: 0.341139\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12289299 -0.15942758 -0.22196889  0.01135569 -0.04610862 -0.06622853\n",
      "  -0.22961017]]\n",
      "linear.bias:\n",
      " [-0.21748541]\n",
      "\n",
      "Test loss: 0.322731, Train loss: 0.340196\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12239554 -0.15893681 -0.22146638  0.01174402 -0.04561945 -0.06618278\n",
      "  -0.2291135 ]]\n",
      "linear.bias:\n",
      " [-0.21698049]\n",
      "\n",
      "Test loss: 0.321804, Train loss: 0.339254\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.1218987  -0.158447   -0.22096369  0.01212997 -0.04513068 -0.06613523\n",
      "  -0.22861704]]\n",
      "linear.bias:\n",
      " [-0.2164752]\n",
      "\n",
      "Test loss: 0.320878, Train loss: 0.338312\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12140234 -0.15795796 -0.22046086  0.01251308 -0.04464234 -0.06608574\n",
      "  -0.22812082]]\n",
      "linear.bias:\n",
      " [-0.21596958]\n",
      "\n",
      "Test loss: 0.319953, Train loss: 0.337372\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12090629 -0.15746959 -0.21995792  0.01289302 -0.04415447 -0.06603833\n",
      "  -0.22762483]]\n",
      "linear.bias:\n",
      " [-0.21546362]\n",
      "\n",
      "Test loss: 0.319028, Train loss: 0.336432\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.12041028 -0.15698172 -0.21945482  0.01326889 -0.04366712 -0.06599659\n",
      "  -0.22712904]]\n",
      "linear.bias:\n",
      " [-0.21495748]\n",
      "\n",
      "Test loss: 0.318105, Train loss: 0.335494\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11991429 -0.15649438 -0.21895154  0.01364056 -0.04318033 -0.06596363\n",
      "  -0.22663349]]\n",
      "linear.bias:\n",
      " [-0.21445113]\n",
      "\n",
      "Test loss: 0.317183, Train loss: 0.334556\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11941826 -0.15600751 -0.21844806  0.01400872 -0.04269407 -0.06593611\n",
      "  -0.22613816]]\n",
      "linear.bias:\n",
      " [-0.21394461]\n",
      "\n",
      "Test loss: 0.316262, Train loss: 0.333618\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11892227 -0.15552081 -0.21794443  0.01437363 -0.04220828 -0.06591576\n",
      "  -0.22564302]]\n",
      "linear.bias:\n",
      " [-0.21343797]\n",
      "\n",
      "Test loss: 0.315343, Train loss: 0.332681\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11842632 -0.15503424 -0.21744066  0.01473538 -0.0417229  -0.06590348\n",
      "  -0.22514808]]\n",
      "linear.bias:\n",
      " [-0.21293122]\n",
      "\n",
      "Test loss: 0.314425, Train loss: 0.331744\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11793037 -0.15454784 -0.21693678  0.01509373 -0.04123787 -0.06590185\n",
      "  -0.22465333]]\n",
      "linear.bias:\n",
      " [-0.21242432]\n",
      "\n",
      "Test loss: 0.313508, Train loss: 0.330808\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11743444 -0.15406159 -0.21643281  0.01544928 -0.04075317 -0.06590582\n",
      "  -0.22415876]]\n",
      "linear.bias:\n",
      " [-0.2119173]\n",
      "\n",
      "Test loss: 0.312592, Train loss: 0.329872\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11693873 -0.15357554 -0.21592864  0.01580257 -0.04026884 -0.06590825\n",
      "  -0.2236644 ]]\n",
      "linear.bias:\n",
      " [-0.21141014]\n",
      "\n",
      "Test loss: 0.311676, Train loss: 0.328936\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11644316 -0.15308966 -0.21542433  0.01615375 -0.03978489 -0.06590957\n",
      "  -0.22317025]]\n",
      "linear.bias:\n",
      " [-0.21090285]\n",
      "\n",
      "Test loss: 0.310761, Train loss: 0.328001\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11594781 -0.1526038  -0.21491987  0.01650298 -0.03930142 -0.06590179\n",
      "  -0.22267632]]\n",
      "linear.bias:\n",
      " [-0.21039544]\n",
      "\n",
      "Test loss: 0.309848, Train loss: 0.327066\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11545267 -0.15211794 -0.21441531  0.01684977 -0.03881843 -0.06588238\n",
      "  -0.22218257]]\n",
      "linear.bias:\n",
      " [-0.20988792]\n",
      "\n",
      "Test loss: 0.308936, Train loss: 0.326133\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11495776 -0.151632   -0.21391065  0.01719384 -0.0383359  -0.06585\n",
      "  -0.22168902]]\n",
      "linear.bias:\n",
      " [-0.20938031]\n",
      "\n",
      "Test loss: 0.308025, Train loss: 0.325199\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11446311 -0.15114586 -0.21340589  0.01753548 -0.03785376 -0.06580526\n",
      "  -0.2211956 ]]\n",
      "linear.bias:\n",
      " [-0.20887266]\n",
      "\n",
      "Test loss: 0.307113, Train loss: 0.324267\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11396854 -0.1506591  -0.21290098  0.01787448 -0.03737222 -0.06575713\n",
      "  -0.22070242]]\n",
      "linear.bias:\n",
      " [-0.208365]\n",
      "\n",
      "Test loss: 0.306201, Train loss: 0.323334\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11347406 -0.15017177 -0.21239594  0.01821122 -0.0368912  -0.06570587\n",
      "  -0.22020946]]\n",
      "linear.bias:\n",
      " [-0.20785731]\n",
      "\n",
      "Test loss: 0.305290, Train loss: 0.322403\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11297967 -0.14968388 -0.21189073  0.01854484 -0.03641077 -0.06565463\n",
      "  -0.21971677]]\n",
      "linear.bias:\n",
      " [-0.20734958]\n",
      "\n",
      "Test loss: 0.304379, Train loss: 0.321471\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11248541 -0.14919515 -0.21138534  0.01887611 -0.03593105 -0.06559926\n",
      "  -0.21922442]]\n",
      "linear.bias:\n",
      " [-0.2068418]\n",
      "\n",
      "Test loss: 0.303469, Train loss: 0.320541\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.1119913  -0.14870565 -0.21087979  0.01920527 -0.03545203 -0.06553704\n",
      "  -0.2187324 ]]\n",
      "linear.bias:\n",
      " [-0.20633397]\n",
      "\n",
      "Test loss: 0.302558, Train loss: 0.319611\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11149726 -0.14821574 -0.21037407  0.01953208 -0.03497365 -0.06546041\n",
      "  -0.2182407 ]]\n",
      "linear.bias:\n",
      " [-0.20582604]\n",
      "\n",
      "Test loss: 0.301648, Train loss: 0.318682\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11100326 -0.14772552 -0.2098682   0.01985628 -0.03449585 -0.06537034\n",
      "  -0.2177493 ]]\n",
      "linear.bias:\n",
      " [-0.20531803]\n",
      "\n",
      "Test loss: 0.300739, Train loss: 0.317753\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11050929 -0.14723504 -0.20936215  0.0201779  -0.03401867 -0.06527153\n",
      "  -0.21725821]]\n",
      "linear.bias:\n",
      " [-0.20480992]\n",
      "\n",
      "Test loss: 0.299830, Train loss: 0.316825\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.11001536 -0.14674428 -0.20885597  0.02049696 -0.03354204 -0.06517002\n",
      "  -0.2167674 ]]\n",
      "linear.bias:\n",
      " [-0.20430169]\n",
      "\n",
      "Test loss: 0.298923, Train loss: 0.315897\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10952161 -0.14625333 -0.20834966  0.02081443 -0.03306593 -0.06506224\n",
      "  -0.21627682]]\n",
      "linear.bias:\n",
      " [-0.20379335]\n",
      "\n",
      "Test loss: 0.298015, Train loss: 0.314969\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10902819 -0.14576223 -0.2078432   0.02112978 -0.03259032 -0.06495396\n",
      "  -0.21578647]]\n",
      "linear.bias:\n",
      " [-0.2032849]\n",
      "\n",
      "Test loss: 0.297109, Train loss: 0.314042\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10853519 -0.14527126 -0.20733659  0.02144317 -0.03211513 -0.06484812\n",
      "  -0.21529627]]\n",
      "linear.bias:\n",
      " [-0.20277633]\n",
      "\n",
      "Test loss: 0.296203, Train loss: 0.313115\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10804276 -0.14478089 -0.20682971  0.02175453 -0.03164028 -0.06475741\n",
      "  -0.21480617]]\n",
      "linear.bias:\n",
      " [-0.20226762]\n",
      "\n",
      "Test loss: 0.295298, Train loss: 0.312189\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10755083 -0.14429106 -0.20632261  0.02206416 -0.0311657  -0.06468046\n",
      "  -0.21431616]]\n",
      "linear.bias:\n",
      " [-0.2017588]\n",
      "\n",
      "Test loss: 0.294394, Train loss: 0.311264\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10705941 -0.14380156 -0.20581536  0.02237037 -0.03069139 -0.06462461\n",
      "  -0.21382628]]\n",
      "linear.bias:\n",
      " [-0.20124984]\n",
      "\n",
      "Test loss: 0.293492, Train loss: 0.310339\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.1065685  -0.14331228 -0.20530798  0.02267304 -0.03021726 -0.06458645\n",
      "  -0.21333653]]\n",
      "linear.bias:\n",
      " [-0.20074075]\n",
      "\n",
      "Test loss: 0.292590, Train loss: 0.309414\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10607811 -0.14282319 -0.20480046  0.02297299 -0.02974349 -0.06454808\n",
      "  -0.21284693]]\n",
      "linear.bias:\n",
      " [-0.20023154]\n",
      "\n",
      "Test loss: 0.291690, Train loss: 0.308490\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10558819 -0.1423342  -0.20429282  0.02327031 -0.02927011 -0.0645104\n",
      "  -0.21235749]]\n",
      "linear.bias:\n",
      " [-0.1997222]\n",
      "\n",
      "Test loss: 0.290789, Train loss: 0.307567\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10509881 -0.14184523 -0.20378505  0.02356553 -0.02879716 -0.06446752\n",
      "  -0.21186823]]\n",
      "linear.bias:\n",
      " [-0.19921273]\n",
      "\n",
      "Test loss: 0.289889, Train loss: 0.306644\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10461037 -0.14135681 -0.20327705  0.02385793 -0.02832453 -0.06443015\n",
      "  -0.21137908]]\n",
      "linear.bias:\n",
      " [-0.19870308]\n",
      "\n",
      "Test loss: 0.288989, Train loss: 0.305722\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10412277 -0.14086889 -0.20276885  0.02414739 -0.02785225 -0.06440081\n",
      "  -0.2108901 ]]\n",
      "linear.bias:\n",
      " [-0.19819324]\n",
      "\n",
      "Test loss: 0.288089, Train loss: 0.304801\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10363592 -0.14038147 -0.2022604   0.0244334  -0.02738036 -0.06438272\n",
      "  -0.21040131]]\n",
      "linear.bias:\n",
      " [-0.19768319]\n",
      "\n",
      "Test loss: 0.287191, Train loss: 0.303880\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10314997 -0.13989462 -0.20175168  0.02471573 -0.0269089  -0.06437737\n",
      "  -0.20991282]]\n",
      "linear.bias:\n",
      " [-0.19717285]\n",
      "\n",
      "Test loss: 0.286292, Train loss: 0.302961\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10266479 -0.13940825 -0.20124273  0.02499437 -0.02643792 -0.06438107\n",
      "  -0.20942463]]\n",
      "linear.bias:\n",
      " [-0.19666223]\n",
      "\n",
      "Test loss: 0.285395, Train loss: 0.302042\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10218029 -0.13892238 -0.20073356  0.02526911 -0.02596739 -0.06439471\n",
      "  -0.20893674]]\n",
      "linear.bias:\n",
      " [-0.19615136]\n",
      "\n",
      "Test loss: 0.284499, Train loss: 0.301123\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10169651 -0.13843697 -0.2002242   0.02554067 -0.0254973  -0.06441067\n",
      "  -0.20844904]]\n",
      "linear.bias:\n",
      " [-0.19564027]\n",
      "\n",
      "Test loss: 0.283604, Train loss: 0.300205\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10121347 -0.137952   -0.19971472  0.02580863 -0.02502785 -0.06441388\n",
      "  -0.20796171]]\n",
      "linear.bias:\n",
      " [-0.19512881]\n",
      "\n",
      "Test loss: 0.282710, Train loss: 0.299288\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10073121 -0.13746752 -0.19920507  0.02607337 -0.02455904 -0.06440012\n",
      "  -0.20747481]]\n",
      "linear.bias:\n",
      " [-0.19461696]\n",
      "\n",
      "Test loss: 0.281816, Train loss: 0.298372\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.10024971 -0.13698351 -0.19869527  0.02633519 -0.02409081 -0.06437036\n",
      "  -0.20698828]]\n",
      "linear.bias:\n",
      " [-0.19410476]\n",
      "\n",
      "Test loss: 0.280921, Train loss: 0.297457\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09976894 -0.13649988 -0.19818534  0.02659366 -0.02362311 -0.06432834\n",
      "  -0.2065021 ]]\n",
      "linear.bias:\n",
      " [-0.19359222]\n",
      "\n",
      "Test loss: 0.280027, Train loss: 0.296542\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09928882 -0.13601653 -0.19767535  0.02684916 -0.02315594 -0.06426642\n",
      "  -0.20601623]]\n",
      "linear.bias:\n",
      " [-0.19307938]\n",
      "\n",
      "Test loss: 0.279132, Train loss: 0.295627\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09880934 -0.13553339 -0.1971653   0.02710256 -0.02268941 -0.06417271\n",
      "  -0.20553075]]\n",
      "linear.bias:\n",
      " [-0.19256619]\n",
      "\n",
      "Test loss: 0.278237, Train loss: 0.294714\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0983303  -0.1350504  -0.19665521  0.02735401 -0.02222347 -0.06405237\n",
      "  -0.20504563]]\n",
      "linear.bias:\n",
      " [-0.19205266]\n",
      "\n",
      "Test loss: 0.277341, Train loss: 0.293800\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09785163 -0.13456751 -0.19614516  0.02760383 -0.02175817 -0.06390464\n",
      "  -0.20456086]]\n",
      "linear.bias:\n",
      " [-0.1915388]\n",
      "\n",
      "Test loss: 0.276444, Train loss: 0.292887\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0973733  -0.1340846  -0.19563511  0.02785153 -0.02129356 -0.06373337\n",
      "  -0.20407654]]\n",
      "linear.bias:\n",
      " [-0.19102459]\n",
      "\n",
      "Test loss: 0.275547, Train loss: 0.291975\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09689531 -0.13360162 -0.19512504  0.0280965  -0.02082952 -0.06354254\n",
      "  -0.20359261]]\n",
      "linear.bias:\n",
      " [-0.19051006]\n",
      "\n",
      "Test loss: 0.274651, Train loss: 0.291063\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09641788 -0.13311884 -0.1946149   0.02833838 -0.02036618 -0.06332765\n",
      "  -0.20310894]]\n",
      "linear.bias:\n",
      " [-0.18999533]\n",
      "\n",
      "Test loss: 0.273755, Train loss: 0.290152\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09594091 -0.13263625 -0.19410472  0.02857718 -0.01990347 -0.06309325\n",
      "  -0.20262547]]\n",
      "linear.bias:\n",
      " [-0.18948041]\n",
      "\n",
      "Test loss: 0.272860, Train loss: 0.289242\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09546427 -0.13215382 -0.1935945   0.0288131  -0.01944136 -0.06284914\n",
      "  -0.20214218]]\n",
      "linear.bias:\n",
      " [-0.18896532]\n",
      "\n",
      "Test loss: 0.271966, Train loss: 0.288332\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09498791 -0.13167147 -0.1930843   0.02904604 -0.01897976 -0.06260286\n",
      "  -0.20165905]]\n",
      "linear.bias:\n",
      " [-0.18845005]\n",
      "\n",
      "Test loss: 0.271073, Train loss: 0.287423\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09451196 -0.13118939 -0.19257404  0.02927588 -0.01851864 -0.06235146\n",
      "  -0.20117608]]\n",
      "linear.bias:\n",
      " [-0.18793464]\n",
      "\n",
      "Test loss: 0.270181, Train loss: 0.286514\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09403652 -0.13070753 -0.19206369  0.02950298 -0.01805818 -0.0620998\n",
      "  -0.20069337]]\n",
      "linear.bias:\n",
      " [-0.18741898]\n",
      "\n",
      "Test loss: 0.269289, Train loss: 0.285606\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09356154 -0.13022605 -0.19155325  0.0297273  -0.01759825 -0.06185363\n",
      "  -0.20021087]]\n",
      "linear.bias:\n",
      " [-0.18690312]\n",
      "\n",
      "Test loss: 0.268398, Train loss: 0.284699\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09308706 -0.12974498 -0.19104274  0.02994885 -0.01713885 -0.06161793\n",
      "  -0.19972849]]\n",
      "linear.bias:\n",
      " [-0.18638709]\n",
      "\n",
      "Test loss: 0.267509, Train loss: 0.283792\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09261301 -0.12926431 -0.19053215  0.0301671  -0.01667992 -0.06139553\n",
      "  -0.19924617]]\n",
      "linear.bias:\n",
      " [-0.18587095]\n",
      "\n",
      "Test loss: 0.266621, Train loss: 0.282886\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09213927 -0.12878394 -0.19002153  0.03038199 -0.01622144 -0.0611891\n",
      "  -0.19876392]]\n",
      "linear.bias:\n",
      " [-0.18535466]\n",
      "\n",
      "Test loss: 0.265733, Train loss: 0.281980\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0916658  -0.12830386 -0.18951087  0.03059362 -0.01576347 -0.0610041\n",
      "  -0.19828181]]\n",
      "linear.bias:\n",
      " [-0.18483824]\n",
      "\n",
      "Test loss: 0.264848, Train loss: 0.281075\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09119257 -0.12782402 -0.18900016  0.03080235 -0.01530592 -0.06083848\n",
      "  -0.19779979]]\n",
      "linear.bias:\n",
      " [-0.18432169]\n",
      "\n",
      "Test loss: 0.263962, Train loss: 0.280170\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09071963 -0.1273444  -0.18848944  0.03100846 -0.01484878 -0.06068488\n",
      "  -0.1973179 ]]\n",
      "linear.bias:\n",
      " [-0.18380499]\n",
      "\n",
      "Test loss: 0.263078, Train loss: 0.279265\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.09024698 -0.12686491 -0.1879787   0.03121189 -0.01439215 -0.06054329\n",
      "  -0.1968362 ]]\n",
      "linear.bias:\n",
      " [-0.1832881]\n",
      "\n",
      "Test loss: 0.262195, Train loss: 0.278361\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08977462 -0.12638547 -0.18746798  0.03141222 -0.01393597 -0.06042084\n",
      "  -0.1963547 ]]\n",
      "linear.bias:\n",
      " [-0.18277101]\n",
      "\n",
      "Test loss: 0.261313, Train loss: 0.277457\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08930272 -0.12590626 -0.18695717  0.03160741 -0.01348017 -0.06032162\n",
      "  -0.19587334]]\n",
      "linear.bias:\n",
      " [-0.1822538]\n",
      "\n",
      "Test loss: 0.260432, Train loss: 0.276554\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08883125 -0.1254272  -0.18644628  0.03179733 -0.01302475 -0.06024408\n",
      "  -0.19539218]]\n",
      "linear.bias:\n",
      " [-0.18173642]\n",
      "\n",
      "Test loss: 0.259553, Train loss: 0.275652\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08836015 -0.1249483  -0.18593532  0.03198219 -0.01256978 -0.06018669\n",
      "  -0.19491117]]\n",
      "linear.bias:\n",
      " [-0.18121895]\n",
      "\n",
      "Test loss: 0.258675, Train loss: 0.274751\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08788934 -0.1244697  -0.1854243   0.03216181 -0.01211526 -0.06015608\n",
      "  -0.19443034]]\n",
      "linear.bias:\n",
      " [-0.1807013]\n",
      "\n",
      "Test loss: 0.257798, Train loss: 0.273850\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08741868 -0.12399136 -0.18491323  0.03233588 -0.01166119 -0.06014724\n",
      "  -0.19394968]]\n",
      "linear.bias:\n",
      " [-0.18018351]\n",
      "\n",
      "Test loss: 0.256922, Train loss: 0.272949\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08694801 -0.1235133  -0.18440214  0.03250391 -0.01120767 -0.06016086\n",
      "  -0.1934692 ]]\n",
      "linear.bias:\n",
      " [-0.17966563]\n",
      "\n",
      "Test loss: 0.256047, Train loss: 0.272049\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08647734 -0.12303554 -0.18389106  0.03266735 -0.01075474 -0.06018188\n",
      "  -0.19298887]]\n",
      "linear.bias:\n",
      " [-0.17914759]\n",
      "\n",
      "Test loss: 0.255173, Train loss: 0.271149\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08600666 -0.12255803 -0.18338002  0.03282627 -0.01030238 -0.0602096\n",
      "  -0.19250868]]\n",
      "linear.bias:\n",
      " [-0.17862943]\n",
      "\n",
      "Test loss: 0.254300, Train loss: 0.270250\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08553629 -0.1220806  -0.18286899  0.03298137 -0.00985053 -0.060233\n",
      "  -0.19202857]]\n",
      "linear.bias:\n",
      " [-0.17811123]\n",
      "\n",
      "Test loss: 0.253427, Train loss: 0.269352\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08506617 -0.12160324 -0.18235798  0.03313258 -0.00939919 -0.06025226\n",
      "  -0.19154853]]\n",
      "linear.bias:\n",
      " [-0.17759295]\n",
      "\n",
      "Test loss: 0.252556, Train loss: 0.268454\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08459636 -0.12112603 -0.18184699  0.0332803  -0.00894829 -0.06026449\n",
      "  -0.19106856]]\n",
      "linear.bias:\n",
      " [-0.17707461]\n",
      "\n",
      "Test loss: 0.251685, Train loss: 0.267556\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08412694 -0.12064878 -0.181336    0.03342446 -0.00849784 -0.06026514\n",
      "  -0.19058874]]\n",
      "linear.bias:\n",
      " [-0.17655617]\n",
      "\n",
      "Test loss: 0.250814, Train loss: 0.266659\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08365829 -0.12017124 -0.18082502  0.03356638 -0.00804782 -0.06024287\n",
      "  -0.19010912]]\n",
      "linear.bias:\n",
      " [-0.1760376]\n",
      "\n",
      "Test loss: 0.249945, Train loss: 0.265763\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08319046 -0.11969335 -0.18031412  0.03370552 -0.00759821 -0.06019139\n",
      "  -0.1896297 ]]\n",
      "linear.bias:\n",
      " [-0.17551886]\n",
      "\n",
      "Test loss: 0.249077, Train loss: 0.264867\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08272329 -0.11921491 -0.17980327  0.03384241 -0.00714905 -0.06011124\n",
      "  -0.18915051]]\n",
      "linear.bias:\n",
      " [-0.175]\n",
      "\n",
      "Test loss: 0.248208, Train loss: 0.263972\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08225688 -0.11873591 -0.17929251  0.03397703 -0.00670048 -0.06001838\n",
      "  -0.18867148]]\n",
      "linear.bias:\n",
      " [-0.17448097]\n",
      "\n",
      "Test loss: 0.247339, Train loss: 0.263077\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08179116 -0.11825623 -0.17878185  0.03410885 -0.00625276 -0.05992261\n",
      "  -0.18819265]]\n",
      "linear.bias:\n",
      " [-0.1739618]\n",
      "\n",
      "Test loss: 0.246471, Train loss: 0.262183\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08132603 -0.11777593 -0.17827128  0.03423777 -0.00580575 -0.0598249\n",
      "  -0.18771395]]\n",
      "linear.bias:\n",
      " [-0.17344254]\n",
      "\n",
      "Test loss: 0.245604, Train loss: 0.261290\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08086126 -0.11729532 -0.17776081  0.03436309 -0.00535954 -0.05972569\n",
      "  -0.18723541]]\n",
      "linear.bias:\n",
      " [-0.17292315]\n",
      "\n",
      "Test loss: 0.244736, Train loss: 0.260397\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.08039689 -0.11681439 -0.17725047  0.03448622 -0.00491426 -0.05961567\n",
      "  -0.18675709]]\n",
      "linear.bias:\n",
      " [-0.17240354]\n",
      "\n",
      "Test loss: 0.243869, Train loss: 0.259505\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07993291 -0.11633319 -0.17674029  0.03460701 -0.00446984 -0.05949645\n",
      "  -0.18627895]]\n",
      "linear.bias:\n",
      " [-0.17188375]\n",
      "\n",
      "Test loss: 0.243003, Train loss: 0.258614\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07946914 -0.11585182 -0.17623027  0.0347252  -0.00402626 -0.05937038\n",
      "  -0.18580103]]\n",
      "linear.bias:\n",
      " [-0.17136373]\n",
      "\n",
      "Test loss: 0.242138, Train loss: 0.257724\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07900552 -0.11537026 -0.1757204   0.03484048 -0.0035834  -0.05923999\n",
      "  -0.1853233 ]]\n",
      "linear.bias:\n",
      " [-0.17084351]\n",
      "\n",
      "Test loss: 0.241274, Train loss: 0.256833\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07854226 -0.11488894 -0.1752107   0.03495351 -0.00314118 -0.05910911\n",
      "  -0.18484566]]\n",
      "linear.bias:\n",
      " [-0.17032307]\n",
      "\n",
      "Test loss: 0.240410, Train loss: 0.255944\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07807955 -0.11440798 -0.17470112  0.03506413 -0.00269969 -0.05898261\n",
      "  -0.18436816]]\n",
      "linear.bias:\n",
      " [-0.16980232]\n",
      "\n",
      "Test loss: 0.239546, Train loss: 0.255054\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07761751 -0.11392742 -0.17419165  0.03517209 -0.00225898 -0.05885482\n",
      "  -0.18389082]]\n",
      "linear.bias:\n",
      " [-0.16928127]\n",
      "\n",
      "Test loss: 0.238682, Train loss: 0.254166\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0771562  -0.11344709 -0.17368235  0.03527773 -0.00181904 -0.05872765\n",
      "  -0.18341364]]\n",
      "linear.bias:\n",
      " [-0.16875991]\n",
      "\n",
      "Test loss: 0.237820, Train loss: 0.253279\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07669561 -0.1129671  -0.17317316  0.03538135 -0.00137985 -0.05859493\n",
      "  -0.18293665]]\n",
      "linear.bias:\n",
      " [-0.16823822]\n",
      "\n",
      "Test loss: 0.236959, Train loss: 0.252392\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07623565 -0.11248747 -0.17266408  0.0354825  -0.0009413  -0.05845686\n",
      "  -0.1824598 ]]\n",
      "linear.bias:\n",
      " [-0.16771626]\n",
      "\n",
      "Test loss: 0.236099, Train loss: 0.251506\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07577624 -0.11200811 -0.17215511  0.03558176 -0.0005034  -0.05832069\n",
      "  -0.18198308]]\n",
      "linear.bias:\n",
      " [-0.16719405]\n",
      "\n",
      "Test loss: 0.235239, Train loss: 0.250620\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-7.5317398e-02 -1.1152888e-01 -1.7164625e-01  3.5679307e-02\n",
      "  -6.6282286e-05 -5.8183536e-02 -1.8150659e-01]]\n",
      "linear.bias:\n",
      " [-0.16667153]\n",
      "\n",
      "Test loss: 0.234381, Train loss: 0.249735\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07485907 -0.1110497  -0.17113747  0.03577527  0.00037014 -0.0580442\n",
      "  -0.18103027]]\n",
      "linear.bias:\n",
      " [-0.16614877]\n",
      "\n",
      "Test loss: 0.233523, Train loss: 0.248850\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07440139 -0.11057073 -0.17062871  0.03586932  0.000806   -0.05790419\n",
      "  -0.18055405]]\n",
      "linear.bias:\n",
      " [-0.16562584]\n",
      "\n",
      "Test loss: 0.232665, Train loss: 0.247965\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07394444 -0.11009178 -0.17012006  0.03596206  0.0012413  -0.05776041\n",
      "  -0.18007791]]\n",
      "linear.bias:\n",
      " [-0.1651027]\n",
      "\n",
      "Test loss: 0.231807, Train loss: 0.247082\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07348817 -0.10961281 -0.16961151  0.03605289  0.00167606 -0.05762684\n",
      "  -0.1796018 ]]\n",
      "linear.bias:\n",
      " [-0.1645794]\n",
      "\n",
      "Test loss: 0.230950, Train loss: 0.246198\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07303254 -0.1091347  -0.16910297  0.03614093  0.00211034 -0.05750665\n",
      "  -0.17912574]]\n",
      "linear.bias:\n",
      " [-0.16405588]\n",
      "\n",
      "Test loss: 0.230094, Train loss: 0.245315\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0725776  -0.1086575  -0.1685944   0.03622536  0.00254414 -0.05739155\n",
      "  -0.17864971]]\n",
      "linear.bias:\n",
      " [-0.16353218]\n",
      "\n",
      "Test loss: 0.229240, Train loss: 0.244433\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07212334 -0.10818105 -0.16808587  0.0363054   0.0029774  -0.05729209\n",
      "  -0.17817365]]\n",
      "linear.bias:\n",
      " [-0.16300833]\n",
      "\n",
      "Test loss: 0.228386, Train loss: 0.243552\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07166965 -0.10770546 -0.1675774   0.03638079  0.00341015 -0.05721276\n",
      "  -0.17769757]]\n",
      "linear.bias:\n",
      " [-0.1624843]\n",
      "\n",
      "Test loss: 0.227533, Train loss: 0.242672\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07121642 -0.10723066 -0.16706899  0.03645028  0.00384237 -0.05715606\n",
      "  -0.17722149]]\n",
      "linear.bias:\n",
      " [-0.1619601]\n",
      "\n",
      "Test loss: 0.226681, Train loss: 0.241791\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.07076368 -0.10675674 -0.16656058  0.03651323  0.00427392 -0.05712306\n",
      "  -0.17674549]]\n",
      "linear.bias:\n",
      " [-0.16143571]\n",
      "\n",
      "Test loss: 0.225831, Train loss: 0.240912\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0703114  -0.10628368 -0.16605218  0.0365701   0.00470491 -0.05710633\n",
      "  -0.17626953]]\n",
      "linear.bias:\n",
      " [-0.16091116]\n",
      "\n",
      "Test loss: 0.224980, Train loss: 0.240034\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06985947 -0.10581162 -0.16554382  0.03662206  0.00513531 -0.05707378\n",
      "  -0.17579374]]\n",
      "linear.bias:\n",
      " [-0.16038637]\n",
      "\n",
      "Test loss: 0.224130, Train loss: 0.239156\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06940787 -0.10534055 -0.16503547  0.03666936  0.00556479 -0.05703124\n",
      "  -0.17531812]]\n",
      "linear.bias:\n",
      " [-0.15986136]\n",
      "\n",
      "Test loss: 0.223280, Train loss: 0.238278\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06895656 -0.10487041 -0.16452707  0.03671147  0.00599334 -0.05696749\n",
      "  -0.17484272]]\n",
      "linear.bias:\n",
      " [-0.15933616]\n",
      "\n",
      "Test loss: 0.222430, Train loss: 0.237402\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06850561 -0.10440107 -0.16401857  0.03674865  0.00642092 -0.05687502\n",
      "  -0.17436759]]\n",
      "linear.bias:\n",
      " [-0.15881081]\n",
      "\n",
      "Test loss: 0.221580, Train loss: 0.236527\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06805483 -0.1039327  -0.16350995  0.03678117  0.00684734 -0.05675473\n",
      "  -0.17389287]]\n",
      "linear.bias:\n",
      " [-0.1582852]\n",
      "\n",
      "Test loss: 0.220730, Train loss: 0.235653\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06760445 -0.10346518 -0.16300118  0.03681003  0.00727271 -0.05660492\n",
      "  -0.1734185 ]]\n",
      "linear.bias:\n",
      " [-0.15775937]\n",
      "\n",
      "Test loss: 0.219880, Train loss: 0.234779\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06715439 -0.10299813 -0.16249223  0.03683616  0.00769701 -0.05642969\n",
      "  -0.17294456]]\n",
      "linear.bias:\n",
      " [-0.15723336]\n",
      "\n",
      "Test loss: 0.219032, Train loss: 0.233906\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06670492 -0.10253154 -0.16198307  0.03685858  0.00812038 -0.05623875\n",
      "  -0.17247091]]\n",
      "linear.bias:\n",
      " [-0.15670724]\n",
      "\n",
      "Test loss: 0.218183, Train loss: 0.233034\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06625632 -0.10206555 -0.1614737   0.03687907  0.00854275 -0.05600959\n",
      "  -0.17199743]]\n",
      "linear.bias:\n",
      " [-0.1561811]\n",
      "\n",
      "Test loss: 0.217335, Train loss: 0.232162\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06580841 -0.10160015 -0.16096419  0.03689811  0.00896418 -0.05574227\n",
      "  -0.17152411]]\n",
      "linear.bias:\n",
      " [-0.15565489]\n",
      "\n",
      "Test loss: 0.216486, Train loss: 0.231292\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06536124 -0.10113529 -0.16045451  0.03691465  0.00938481 -0.05545393\n",
      "  -0.17105086]]\n",
      "linear.bias:\n",
      " [-0.15512869]\n",
      "\n",
      "Test loss: 0.215638, Train loss: 0.230421\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06491468 -0.10067089 -0.15994471  0.036929    0.00980467 -0.05514447\n",
      "  -0.17057772]]\n",
      "linear.bias:\n",
      " [-0.15460247]\n",
      "\n",
      "Test loss: 0.214790, Train loss: 0.229551\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0644687  -0.10020693 -0.15943481  0.03694233  0.01022359 -0.05480743\n",
      "  -0.1701047 ]]\n",
      "linear.bias:\n",
      " [-0.1540762]\n",
      "\n",
      "Test loss: 0.213943, Train loss: 0.228682\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06402337 -0.09974339 -0.15892479  0.0369544   0.01064168 -0.05445641\n",
      "  -0.16963175]]\n",
      "linear.bias:\n",
      " [-0.15354992]\n",
      "\n",
      "Test loss: 0.213096, Train loss: 0.227814\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06357861 -0.09928019 -0.15841477  0.03696442  0.01105882 -0.05411423\n",
      "  -0.16915889]]\n",
      "linear.bias:\n",
      " [-0.15302353]\n",
      "\n",
      "Test loss: 0.212250, Train loss: 0.226946\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06313433 -0.09881727 -0.15790474  0.03697259  0.01147514 -0.05377996\n",
      "  -0.16868609]]\n",
      "linear.bias:\n",
      " [-0.15249704]\n",
      "\n",
      "Test loss: 0.211405, Train loss: 0.226079\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06269063 -0.09835485 -0.1573947   0.03697731  0.01189066 -0.05347411\n",
      "  -0.16821335]]\n",
      "linear.bias:\n",
      " [-0.15197043]\n",
      "\n",
      "Test loss: 0.210563, Train loss: 0.225213\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06224744 -0.09789296 -0.15688458  0.03697759  0.01230516 -0.05320644\n",
      "  -0.16774076]]\n",
      "linear.bias:\n",
      " [-0.1514437]\n",
      "\n",
      "Test loss: 0.209722, Train loss: 0.224347\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06180477 -0.0974315  -0.15637444  0.03697272  0.01271869 -0.05298205\n",
      "  -0.16726826]]\n",
      "linear.bias:\n",
      " [-0.15091686]\n",
      "\n",
      "Test loss: 0.208882, Train loss: 0.223483\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0613631  -0.09697026 -0.1558643   0.03696447  0.01313127 -0.052797\n",
      "  -0.16679585]]\n",
      "linear.bias:\n",
      " [-0.15038985]\n",
      "\n",
      "Test loss: 0.208044, Train loss: 0.222620\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06092226 -0.09650925 -0.15535417  0.03695196  0.01354298 -0.05265134\n",
      "  -0.16632347]]\n",
      "linear.bias:\n",
      " [-0.14986275]\n",
      "\n",
      "Test loss: 0.207207, Train loss: 0.221757\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0604821  -0.09604841 -0.15484402  0.03693489  0.0139538  -0.05254185\n",
      "  -0.1658512 ]]\n",
      "linear.bias:\n",
      " [-0.14933553]\n",
      "\n",
      "Test loss: 0.206372, Train loss: 0.220895\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.06004263 -0.09558778 -0.15433381  0.03691336  0.01436387 -0.05246644\n",
      "  -0.16537902]]\n",
      "linear.bias:\n",
      " [-0.14880826]\n",
      "\n",
      "Test loss: 0.205537, Train loss: 0.220033\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05960403 -0.09512723 -0.15382354  0.0368886   0.01477319 -0.05240437\n",
      "  -0.16490702]]\n",
      "linear.bias:\n",
      " [-0.14828086]\n",
      "\n",
      "Test loss: 0.204704, Train loss: 0.219171\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05916617 -0.09466679 -0.15331317  0.03686153  0.01518186 -0.05234567\n",
      "  -0.1644352 ]]\n",
      "linear.bias:\n",
      " [-0.14775339]\n",
      "\n",
      "Test loss: 0.203871, Train loss: 0.218311\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05872924 -0.09420636 -0.15280278  0.03683263  0.01558983 -0.05227509\n",
      "  -0.16396351]]\n",
      "linear.bias:\n",
      " [-0.14722581]\n",
      "\n",
      "Test loss: 0.203039, Train loss: 0.217450\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05829341 -0.09374616 -0.15229227  0.03680245  0.01599719 -0.05216195\n",
      "  -0.16349201]]\n",
      "linear.bias:\n",
      " [-0.14669818]\n",
      "\n",
      "Test loss: 0.202207, Train loss: 0.216591\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05785842 -0.09328623 -0.1517816   0.03677073  0.01640387 -0.05201769\n",
      "  -0.16302066]]\n",
      "linear.bias:\n",
      " [-0.14617054]\n",
      "\n",
      "Test loss: 0.201376, Train loss: 0.215732\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05742413 -0.09282656 -0.15127082  0.03673759  0.01680978 -0.05184474\n",
      "  -0.16254939]]\n",
      "linear.bias:\n",
      " [-0.14564294]\n",
      "\n",
      "Test loss: 0.200545, Train loss: 0.214873\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05699044 -0.09236711 -0.15075995  0.03670318  0.01721504 -0.05164594\n",
      "  -0.16207819]]\n",
      "linear.bias:\n",
      " [-0.14511539]\n",
      "\n",
      "Test loss: 0.199715, Train loss: 0.214016\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0565574  -0.09190813 -0.15024899  0.03666829  0.01761943 -0.05141912\n",
      "  -0.16160707]]\n",
      "linear.bias:\n",
      " [-0.14458783]\n",
      "\n",
      "Test loss: 0.198886, Train loss: 0.213159\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05612521 -0.09144896 -0.14973792  0.03663361  0.01802275 -0.0511535\n",
      "  -0.16113615]]\n",
      "linear.bias:\n",
      " [-0.14406028]\n",
      "\n",
      "Test loss: 0.198056, Train loss: 0.212303\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05569375 -0.0909896  -0.14922678  0.03659911  0.01842516 -0.05085307\n",
      "  -0.1606654 ]]\n",
      "linear.bias:\n",
      " [-0.14353277]\n",
      "\n",
      "Test loss: 0.197228, Train loss: 0.211447\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0552628  -0.0905303  -0.14871562  0.03656316  0.01882645 -0.05055119\n",
      "  -0.16019477]]\n",
      "linear.bias:\n",
      " [-0.14300524]\n",
      "\n",
      "Test loss: 0.196400, Train loss: 0.210592\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05483226 -0.0900711  -0.1482044   0.03652622  0.01922663 -0.05025873\n",
      "  -0.15972425]]\n",
      "linear.bias:\n",
      " [-0.1424777]\n",
      "\n",
      "Test loss: 0.195573, Train loss: 0.209739\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05440216 -0.08961188 -0.14769316  0.03648895  0.01962573 -0.04997101\n",
      "  -0.15925387]]\n",
      "linear.bias:\n",
      " [-0.14195016]\n",
      "\n",
      "Test loss: 0.194747, Train loss: 0.208886\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05397274 -0.08915286 -0.14718176  0.03645258  0.02002389 -0.0496945\n",
      "  -0.1587835 ]]\n",
      "linear.bias:\n",
      " [-0.14142267]\n",
      "\n",
      "Test loss: 0.193922, Train loss: 0.208033\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05354412 -0.08869411 -0.1466702   0.0364163   0.02042116 -0.0494386\n",
      "  -0.15831311]]\n",
      "linear.bias:\n",
      " [-0.14089526]\n",
      "\n",
      "Test loss: 0.193098, Train loss: 0.207182\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05311647 -0.08823582 -0.14615838  0.03637975  0.0208176  -0.04919844\n",
      "  -0.1578427 ]]\n",
      "linear.bias:\n",
      " [-0.14036798]\n",
      "\n",
      "Test loss: 0.192275, Train loss: 0.206331\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05269032 -0.08777782 -0.14564636  0.03634319  0.02121308 -0.04897174\n",
      "  -0.15737234]]\n",
      "linear.bias:\n",
      " [-0.1398407]\n",
      "\n",
      "Test loss: 0.191452, Train loss: 0.205481\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05226552 -0.0873201  -0.14513418  0.03630594  0.02160766 -0.04875898\n",
      "  -0.15690205]]\n",
      "linear.bias:\n",
      " [-0.13931341]\n",
      "\n",
      "Test loss: 0.190631, Train loss: 0.204632\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05184187 -0.08686271 -0.14462182  0.03626666  0.02200136 -0.0485611\n",
      "  -0.15643184]]\n",
      "linear.bias:\n",
      " [-0.13878612]\n",
      "\n",
      "Test loss: 0.189811, Train loss: 0.203784\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05141922 -0.08640567 -0.14410928  0.03622681  0.022394   -0.04836954\n",
      "  -0.15596169]]\n",
      "linear.bias:\n",
      " [-0.13825887]\n",
      "\n",
      "Test loss: 0.188992, Train loss: 0.202937\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05099765 -0.08594891 -0.14359654  0.03618658  0.02278551 -0.04818143\n",
      "  -0.15549165]]\n",
      "linear.bias:\n",
      " [-0.13773166]\n",
      "\n",
      "Test loss: 0.188174, Train loss: 0.202091\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05057712 -0.08549239 -0.1430836   0.03614582  0.02317577 -0.0479981\n",
      "  -0.15502182]]\n",
      "linear.bias:\n",
      " [-0.13720442]\n",
      "\n",
      "Test loss: 0.187356, Train loss: 0.201246\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.05015751 -0.08503605 -0.14257059  0.03610367  0.02356476 -0.04779578\n",
      "  -0.15455225]]\n",
      "linear.bias:\n",
      " [-0.13667709]\n",
      "\n",
      "Test loss: 0.186538, Train loss: 0.200401\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04973938 -0.08457956 -0.1420575   0.03605887  0.02395253 -0.04756962\n",
      "  -0.15408301]]\n",
      "linear.bias:\n",
      " [-0.13614962]\n",
      "\n",
      "Test loss: 0.185721, Train loss: 0.199558\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04932242 -0.0841229  -0.14154434  0.03601025  0.02433913 -0.04733302\n",
      "  -0.1536141 ]]\n",
      "linear.bias:\n",
      " [-0.13562204]\n",
      "\n",
      "Test loss: 0.184904, Train loss: 0.198715\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04890705 -0.083666   -0.14103109  0.03595971  0.02472448 -0.04707843\n",
      "  -0.15314554]]\n",
      "linear.bias:\n",
      " [-0.13509431]\n",
      "\n",
      "Test loss: 0.184088, Train loss: 0.197874\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04849314 -0.08320899 -0.14051777  0.03590768  0.02510855 -0.04679945\n",
      "  -0.15267721]]\n",
      "linear.bias:\n",
      " [-0.13456649]\n",
      "\n",
      "Test loss: 0.183272, Train loss: 0.197033\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0480805  -0.08275178 -0.1400045   0.03585619  0.02549111 -0.04648779\n",
      "  -0.15220916]]\n",
      "linear.bias:\n",
      " [-0.13403851]\n",
      "\n",
      "Test loss: 0.182457, Train loss: 0.196194\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04766894 -0.08229437 -0.13949129  0.03580566  0.02587227 -0.0461454\n",
      "  -0.15174139]]\n",
      "linear.bias:\n",
      " [-0.13351038]\n",
      "\n",
      "Test loss: 0.181643, Train loss: 0.195355\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04725893 -0.08183686 -0.13897811  0.03575708  0.02625208 -0.04577314\n",
      "  -0.15127383]]\n",
      "linear.bias:\n",
      " [-0.13298209]\n",
      "\n",
      "Test loss: 0.180829, Train loss: 0.194517\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04685083 -0.08137929 -0.13846487  0.03571017  0.02663043 -0.04536663\n",
      "  -0.15080662]]\n",
      "linear.bias:\n",
      " [-0.13245358]\n",
      "\n",
      "Test loss: 0.180017, Train loss: 0.193680\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04644445 -0.08092163 -0.1379516   0.03566379  0.02700744 -0.04493565\n",
      "  -0.15033977]]\n",
      "linear.bias:\n",
      " [-0.13192484]\n",
      "\n",
      "Test loss: 0.179205, Train loss: 0.192844\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04603946 -0.08046404 -0.1374383   0.03561553  0.02738315 -0.04450663\n",
      "  -0.14987314]]\n",
      "linear.bias:\n",
      " [-0.13139598]\n",
      "\n",
      "Test loss: 0.178395, Train loss: 0.192008\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04563587 -0.08000641 -0.136925    0.03556457  0.0277577  -0.04409503\n",
      "  -0.1494067 ]]\n",
      "linear.bias:\n",
      " [-0.13086699]\n",
      "\n",
      "Test loss: 0.177588, Train loss: 0.191174\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04523392 -0.07954893 -0.13641162  0.03551067  0.02813114 -0.04370189\n",
      "  -0.14894047]]\n",
      "linear.bias:\n",
      " [-0.13033786]\n",
      "\n",
      "Test loss: 0.176781, Train loss: 0.190341\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04483348 -0.07909161 -0.13589814  0.03545278  0.02850355 -0.04333075\n",
      "  -0.14847445]]\n",
      "linear.bias:\n",
      " [-0.12980863]\n",
      "\n",
      "Test loss: 0.175975, Train loss: 0.189509\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04443467 -0.07863405 -0.13538451  0.03538981  0.02887488 -0.04298498\n",
      "  -0.14800866]]\n",
      "linear.bias:\n",
      " [-0.1292794]\n",
      "\n",
      "Test loss: 0.175171, Train loss: 0.188677\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04403732 -0.07817605 -0.13487077  0.0353221   0.02924505 -0.04266058\n",
      "  -0.14754307]]\n",
      "linear.bias:\n",
      " [-0.12875022]\n",
      "\n",
      "Test loss: 0.174368, Train loss: 0.187847\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04364109 -0.07771775 -0.13435693  0.03524794  0.02961417 -0.0423816\n",
      "  -0.14707768]]\n",
      "linear.bias:\n",
      " [-0.12822106]\n",
      "\n",
      "Test loss: 0.173566, Train loss: 0.187017\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04324578 -0.07725935 -0.13384303  0.03516769  0.0299823  -0.04214798\n",
      "  -0.14661248]]\n",
      "linear.bias:\n",
      " [-0.1276919]\n",
      "\n",
      "Test loss: 0.172764, Train loss: 0.186188\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04285128 -0.07680071 -0.1333291   0.0350823   0.03034933 -0.04195021\n",
      "  -0.14614747]]\n",
      "linear.bias:\n",
      " [-0.12716274]\n",
      "\n",
      "Test loss: 0.171963, Train loss: 0.185359\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04245758 -0.07634172 -0.13281508  0.03499208  0.03071525 -0.0417787\n",
      "  -0.1456826 ]]\n",
      "linear.bias:\n",
      " [-0.12663369]\n",
      "\n",
      "Test loss: 0.171162, Train loss: 0.184532\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0420646  -0.07588214 -0.13230103  0.0348998   0.0310798  -0.04160708\n",
      "  -0.14521798]]\n",
      "linear.bias:\n",
      " [-0.12610471]\n",
      "\n",
      "Test loss: 0.170362, Train loss: 0.183705\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04167244 -0.0754228  -0.13178688  0.03480704  0.03144302 -0.04143071\n",
      "  -0.14475358]]\n",
      "linear.bias:\n",
      " [-0.12557574]\n",
      "\n",
      "Test loss: 0.169563, Train loss: 0.182879\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04128122 -0.07496368 -0.1312726   0.03471329  0.03180493 -0.04124334\n",
      "  -0.14428946]]\n",
      "linear.bias:\n",
      " [-0.12504673]\n",
      "\n",
      "Test loss: 0.168765, Train loss: 0.182054\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04089101 -0.07450508 -0.13075806  0.03461975  0.03216557 -0.04103732\n",
      "  -0.14382565]]\n",
      "linear.bias:\n",
      " [-0.12451774]\n",
      "\n",
      "Test loss: 0.167967, Train loss: 0.181230\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04050186 -0.074047   -0.13024333  0.03452661  0.03252503 -0.04081364\n",
      "  -0.14336212]]\n",
      "linear.bias:\n",
      " [-0.12398871]\n",
      "\n",
      "Test loss: 0.167170, Train loss: 0.180407\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.04011361 -0.07358925 -0.1297284   0.03443482  0.03288335 -0.04056428\n",
      "  -0.14289886]]\n",
      "linear.bias:\n",
      " [-0.1234597]\n",
      "\n",
      "Test loss: 0.166374, Train loss: 0.179585\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03972612 -0.07313185 -0.1292133   0.03434516  0.03324062 -0.04029168\n",
      "  -0.14243576]]\n",
      "linear.bias:\n",
      " [-0.12293078]\n",
      "\n",
      "Test loss: 0.165579, Train loss: 0.178763\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03933927 -0.07267476 -0.12869808  0.0342565   0.03359688 -0.04001348\n",
      "  -0.14197281]]\n",
      "linear.bias:\n",
      " [-0.12240189]\n",
      "\n",
      "Test loss: 0.164785, Train loss: 0.177942\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03895295 -0.07221797 -0.12818277  0.03416905  0.03395218 -0.03971873\n",
      "  -0.14150998]]\n",
      "linear.bias:\n",
      " [-0.12187308]\n",
      "\n",
      "Test loss: 0.163991, Train loss: 0.177121\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03856732 -0.07176113 -0.12766746  0.03408178  0.03430644 -0.03941227\n",
      "  -0.1410473 ]]\n",
      "linear.bias:\n",
      " [-0.12134431]\n",
      "\n",
      "Test loss: 0.163200, Train loss: 0.176301\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03818242 -0.07130428 -0.12715217  0.03399464  0.03465975 -0.03909666\n",
      "  -0.14058472]]\n",
      "linear.bias:\n",
      " [-0.12081555]\n",
      "\n",
      "Test loss: 0.162410, Train loss: 0.175481\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03779822 -0.07084715 -0.12663692  0.03390769  0.03501204 -0.03877366\n",
      "  -0.14012223]]\n",
      "linear.bias:\n",
      " [-0.12028688]\n",
      "\n",
      "Test loss: 0.161621, Train loss: 0.174663\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03741506 -0.07039008 -0.12612173  0.03382374  0.03536309 -0.03841984\n",
      "  -0.13965975]]\n",
      "linear.bias:\n",
      " [-0.1197583]\n",
      "\n",
      "Test loss: 0.160833, Train loss: 0.173845\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.037033   -0.0699328  -0.12560654  0.03374119  0.0357129  -0.03804304\n",
      "  -0.1391973 ]]\n",
      "linear.bias:\n",
      " [-0.11922985]\n",
      "\n",
      "Test loss: 0.160045, Train loss: 0.173029\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03665163 -0.06947561 -0.12509139  0.03365698  0.03606144 -0.03767343\n",
      "  -0.13873495]]\n",
      "linear.bias:\n",
      " [-0.11870147]\n",
      "\n",
      "Test loss: 0.159259, Train loss: 0.172213\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03627109 -0.06901804 -0.12457627  0.03357058  0.0364086  -0.03731646\n",
      "  -0.13827275]]\n",
      "linear.bias:\n",
      " [-0.11817319]\n",
      "\n",
      "Test loss: 0.158475, Train loss: 0.171399\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03589135 -0.06856015 -0.12406113  0.03348226  0.03675438 -0.03696145\n",
      "  -0.13781077]]\n",
      "linear.bias:\n",
      " [-0.11764498]\n",
      "\n",
      "Test loss: 0.157691, Train loss: 0.170585\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03551243 -0.06810203 -0.12354595  0.03339177  0.0370989  -0.03663168\n",
      "  -0.13734898]]\n",
      "linear.bias:\n",
      " [-0.11711685]\n",
      "\n",
      "Test loss: 0.156910, Train loss: 0.169772\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03513434 -0.06764381 -0.12303077  0.03329952  0.03744207 -0.03632491\n",
      "  -0.1368874 ]]\n",
      "linear.bias:\n",
      " [-0.11658875]\n",
      "\n",
      "Test loss: 0.156130, Train loss: 0.168961\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03475664 -0.06718585 -0.12251559  0.03320603  0.03778382 -0.03606778\n",
      "  -0.13642593]]\n",
      "linear.bias:\n",
      " [-0.11606073]\n",
      "\n",
      "Test loss: 0.155351, Train loss: 0.168151\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0343799  -0.06672773 -0.12200034  0.03310924  0.03812403 -0.03587183\n",
      "  -0.13596466]]\n",
      "linear.bias:\n",
      " [-0.11553279]\n",
      "\n",
      "Test loss: 0.154572, Train loss: 0.167342\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03400407 -0.06626926 -0.12148508  0.0330096   0.03846254 -0.0357264\n",
      "  -0.13550368]]\n",
      "linear.bias:\n",
      " [-0.11500488]\n",
      "\n",
      "Test loss: 0.153795, Train loss: 0.166534\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03362931 -0.06581046 -0.12096982  0.03290943  0.03879914 -0.03561437\n",
      "  -0.13504301]]\n",
      "linear.bias:\n",
      " [-0.11447701]\n",
      "\n",
      "Test loss: 0.153020, Train loss: 0.165727\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03325569 -0.06535144 -0.12045459  0.03280892  0.03913393 -0.03553518\n",
      "  -0.13458264]]\n",
      "linear.bias:\n",
      " [-0.11394911]\n",
      "\n",
      "Test loss: 0.152246, Train loss: 0.164922\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03288353 -0.06489207 -0.11993938  0.03271047  0.03946675 -0.03546597\n",
      "  -0.13412262]]\n",
      "linear.bias:\n",
      " [-0.11342118]\n",
      "\n",
      "Test loss: 0.151474, Train loss: 0.164118\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03251295 -0.06443239 -0.11942413  0.03261701  0.03979748 -0.03536906\n",
      "  -0.13366307]]\n",
      "linear.bias:\n",
      " [-0.11289319]\n",
      "\n",
      "Test loss: 0.150704, Train loss: 0.163316\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03214372 -0.06397235 -0.1189089   0.03252702  0.04012616 -0.03524561\n",
      "  -0.13320394]]\n",
      "linear.bias:\n",
      " [-0.11236515]\n",
      "\n",
      "Test loss: 0.149936, Train loss: 0.162515\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03177601 -0.06351221 -0.11839373  0.0324407   0.04045267 -0.03508077\n",
      "  -0.13274518]]\n",
      "linear.bias:\n",
      " [-0.11183711]\n",
      "\n",
      "Test loss: 0.149170, Train loss: 0.161715\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03140963 -0.06305191 -0.11787862  0.03235807  0.04077674 -0.03487162\n",
      "  -0.13228683]]\n",
      "linear.bias:\n",
      " [-0.1113091]\n",
      "\n",
      "Test loss: 0.148406, Train loss: 0.160917\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0310444  -0.06259151 -0.11736352  0.03227741  0.04109839 -0.03461564\n",
      "  -0.13182893]]\n",
      "linear.bias:\n",
      " [-0.11078116]\n",
      "\n",
      "Test loss: 0.147645, Train loss: 0.160121\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03068032 -0.06213096 -0.11684842  0.03219884  0.04141757 -0.03431359\n",
      "  -0.13137144]]\n",
      "linear.bias:\n",
      " [-0.11025333]\n",
      "\n",
      "Test loss: 0.146884, Train loss: 0.159326\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.03031764 -0.06167031 -0.11633332  0.03212154  0.04173429 -0.0339766\n",
      "  -0.13091424]]\n",
      "linear.bias:\n",
      " [-0.10972569]\n",
      "\n",
      "Test loss: 0.146126, Train loss: 0.158532\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02995666 -0.06120972 -0.1158182   0.03204338  0.04204833 -0.03360422\n",
      "  -0.13045752]]\n",
      "linear.bias:\n",
      " [-0.10919811]\n",
      "\n",
      "Test loss: 0.145369, Train loss: 0.157740\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02959715 -0.06074911 -0.11530308  0.03196265  0.04235992 -0.03322823\n",
      "  -0.13000116]]\n",
      "linear.bias:\n",
      " [-0.10867064]\n",
      "\n",
      "Test loss: 0.144615, Train loss: 0.156950\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02923845 -0.06028882 -0.11478782  0.03187732  0.04266917 -0.03289764\n",
      "  -0.12954511]]\n",
      "linear.bias:\n",
      " [-0.10814338]\n",
      "\n",
      "Test loss: 0.143863, Train loss: 0.156162\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02888064 -0.05982877 -0.11427253  0.03178649  0.04297617 -0.03262076\n",
      "  -0.12908933]]\n",
      "linear.bias:\n",
      " [-0.10761629]\n",
      "\n",
      "Test loss: 0.143112, Train loss: 0.155374\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02852363 -0.05936937 -0.11375719  0.03168879  0.04328105 -0.03239064\n",
      "  -0.12863372]]\n",
      "linear.bias:\n",
      " [-0.10708939]\n",
      "\n",
      "Test loss: 0.142364, Train loss: 0.154588\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02816738 -0.05891142 -0.11324173  0.03158557  0.04358368 -0.03221809\n",
      "  -0.12817821]]\n",
      "linear.bias:\n",
      " [-0.10656274]\n",
      "\n",
      "Test loss: 0.141616, Train loss: 0.153804\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02781192 -0.05845478 -0.11272617  0.03147762  0.04388421 -0.03207798\n",
      "  -0.12772286]]\n",
      "linear.bias:\n",
      " [-0.10603625]\n",
      "\n",
      "Test loss: 0.140870, Train loss: 0.153021\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02745737 -0.05799903 -0.11221049  0.03136635  0.0441828  -0.03196405\n",
      "  -0.12726775]]\n",
      "linear.bias:\n",
      " [-0.10550993]\n",
      "\n",
      "Test loss: 0.140125, Train loss: 0.152239\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02710414 -0.05754398 -0.11169468  0.03125315  0.04447907 -0.03184871\n",
      "  -0.12681293]]\n",
      "linear.bias:\n",
      " [-0.10498381]\n",
      "\n",
      "Test loss: 0.139382, Train loss: 0.151458\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02675221 -0.05708966 -0.11117878  0.03113985  0.04477293 -0.03170936\n",
      "  -0.12635848]]\n",
      "linear.bias:\n",
      " [-0.10445783]\n",
      "\n",
      "Test loss: 0.138641, Train loss: 0.150679\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02640143 -0.05663639 -0.11066281  0.03102774  0.04506454 -0.03153586\n",
      "  -0.12590435]]\n",
      "linear.bias:\n",
      " [-0.10393193]\n",
      "\n",
      "Test loss: 0.137901, Train loss: 0.149902\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02605174 -0.05618399 -0.11014685  0.03091776  0.04535393 -0.0313144\n",
      "  -0.12545049]]\n",
      "linear.bias:\n",
      " [-0.10340612]\n",
      "\n",
      "Test loss: 0.137163, Train loss: 0.149126\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02570302 -0.05573196 -0.10963088  0.03080855  0.04564093 -0.03105385\n",
      "  -0.124997  ]]\n",
      "linear.bias:\n",
      " [-0.10288047]\n",
      "\n",
      "Test loss: 0.136427, Train loss: 0.148350\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02535516 -0.05528026 -0.10911488  0.03069917  0.04592556 -0.03076686\n",
      "  -0.12454375]]\n",
      "linear.bias:\n",
      " [-0.10235509]\n",
      "\n",
      "Test loss: 0.135694, Train loss: 0.147577\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.025008   -0.05482888 -0.10859889  0.03058888  0.04620782 -0.03045831\n",
      "  -0.12409075]]\n",
      "linear.bias:\n",
      " [-0.10182995]\n",
      "\n",
      "Test loss: 0.134963, Train loss: 0.146804\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02466177 -0.05437799 -0.10808296  0.03047763  0.04648776 -0.0301426\n",
      "  -0.12363803]]\n",
      "linear.bias:\n",
      " [-0.10130496]\n",
      "\n",
      "Test loss: 0.134233, Train loss: 0.146033\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02431671 -0.05392818 -0.10756704  0.03036571  0.04676543 -0.02982082\n",
      "  -0.12318549]]\n",
      "linear.bias:\n",
      " [-0.10078012]\n",
      "\n",
      "Test loss: 0.133507, Train loss: 0.145264\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02397278 -0.05347918 -0.10705113  0.03025448  0.04704101 -0.02948506\n",
      "  -0.12273308]]\n",
      "linear.bias:\n",
      " [-0.10025547]\n",
      "\n",
      "Test loss: 0.132782, Train loss: 0.144495\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02363007 -0.05303109 -0.1065352   0.03014373  0.04731466 -0.02914761\n",
      "  -0.12228075]]\n",
      "linear.bias:\n",
      " [-0.09973103]\n",
      "\n",
      "Test loss: 0.132059, Train loss: 0.143728\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02328864 -0.05258389 -0.10601926  0.0300313   0.04758643 -0.02883533\n",
      "  -0.12182843]]\n",
      "linear.bias:\n",
      " [-0.09920682]\n",
      "\n",
      "Test loss: 0.131337, Train loss: 0.142962\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02294857 -0.05213773 -0.10550334  0.0299177   0.04785606 -0.0285395\n",
      "  -0.1213762 ]]\n",
      "linear.bias:\n",
      " [-0.09868278]\n",
      "\n",
      "Test loss: 0.130616, Train loss: 0.142198\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0226097  -0.05169262 -0.10498747  0.02980422  0.0481234  -0.02824959\n",
      "  -0.12092411]]\n",
      "linear.bias:\n",
      " [-0.0981589]\n",
      "\n",
      "Test loss: 0.129897, Train loss: 0.141436\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02227225 -0.05124817 -0.10447165  0.02968797  0.04838833 -0.02797737\n",
      "  -0.12047221]]\n",
      "linear.bias:\n",
      " [-0.09763517]\n",
      "\n",
      "Test loss: 0.129179, Train loss: 0.140675\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02193613 -0.05080415 -0.103956    0.0295652   0.04865078 -0.02774366\n",
      "  -0.12002043]]\n",
      "linear.bias:\n",
      " [-0.09711165]\n",
      "\n",
      "Test loss: 0.128461, Train loss: 0.139916\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02160155 -0.05036103 -0.10344043  0.02943776  0.04891073 -0.0275347\n",
      "  -0.11956877]]\n",
      "linear.bias:\n",
      " [-0.09658834]\n",
      "\n",
      "Test loss: 0.127744, Train loss: 0.139158\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02126837 -0.04991866 -0.10292501  0.02930497  0.04916788 -0.0273418\n",
      "  -0.11911738]]\n",
      "linear.bias:\n",
      " [-0.09606518]\n",
      "\n",
      "Test loss: 0.127029, Train loss: 0.138402\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02093683 -0.04947736 -0.10240963  0.0291691   0.0494222  -0.0271337\n",
      "  -0.11866623]]\n",
      "linear.bias:\n",
      " [-0.09554226]\n",
      "\n",
      "Test loss: 0.126317, Train loss: 0.137648\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02060732 -0.04903753 -0.10189427  0.02902903  0.04967356 -0.02690401\n",
      "  -0.11821534]]\n",
      "linear.bias:\n",
      " [-0.09501956]\n",
      "\n",
      "Test loss: 0.125608, Train loss: 0.136897\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.02027986 -0.04859905 -0.10137897  0.02888359  0.04992194 -0.02666117\n",
      "  -0.11776469]]\n",
      "linear.bias:\n",
      " [-0.09449709]\n",
      "\n",
      "Test loss: 0.124902, Train loss: 0.136147\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01995443 -0.04816201 -0.10086384  0.02873182  0.05016726 -0.02638747\n",
      "  -0.11731427]]\n",
      "linear.bias:\n",
      " [-0.09397481]\n",
      "\n",
      "Test loss: 0.124199, Train loss: 0.135400\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01963083 -0.04772634 -0.1003489   0.02857374  0.05040982 -0.02609327\n",
      "  -0.11686406]]\n",
      "linear.bias:\n",
      " [-0.09345268]\n",
      "\n",
      "Test loss: 0.123497, Train loss: 0.134653\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01930869 -0.04729189 -0.09983425  0.02841086  0.05064951 -0.02579048\n",
      "  -0.11641406]]\n",
      "linear.bias:\n",
      " [-0.09293063]\n",
      "\n",
      "Test loss: 0.122798, Train loss: 0.133908\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01898782 -0.04685847 -0.09931983  0.02824323  0.05088636 -0.0255089\n",
      "  -0.11596429]]\n",
      "linear.bias:\n",
      " [-0.09240869]\n",
      "\n",
      "Test loss: 0.122101, Train loss: 0.133165\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01866803 -0.04642624 -0.09880565  0.02807059  0.0511204  -0.02526283\n",
      "  -0.11551476]]\n",
      "linear.bias:\n",
      " [-0.09188682]\n",
      "\n",
      "Test loss: 0.121405, Train loss: 0.132423\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01834971 -0.04599504 -0.09829167  0.02789417  0.05135174 -0.02503887\n",
      "  -0.11506541]]\n",
      "linear.bias:\n",
      " [-0.0913651]\n",
      "\n",
      "Test loss: 0.120710, Train loss: 0.131682\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01803279 -0.04556478 -0.09777787  0.02771173  0.05158054 -0.02484551\n",
      "  -0.11461625]]\n",
      "linear.bias:\n",
      " [-0.09084351]\n",
      "\n",
      "Test loss: 0.120015, Train loss: 0.130943\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01771724 -0.04513586 -0.09726409  0.02752651  0.05180664 -0.02467498\n",
      "  -0.11416731]]\n",
      "linear.bias:\n",
      " [-0.09032212]\n",
      "\n",
      "Test loss: 0.119322, Train loss: 0.130206\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01740297 -0.04470835 -0.0967503   0.02733876  0.0520299  -0.02453432\n",
      "  -0.11371852]]\n",
      "linear.bias:\n",
      " [-0.08980107]\n",
      "\n",
      "Test loss: 0.118629, Train loss: 0.129470\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01709007 -0.04428186 -0.0962365   0.02714925  0.05225028 -0.02441329\n",
      "  -0.11326996]]\n",
      "linear.bias:\n",
      " [-0.08928031]\n",
      "\n",
      "Test loss: 0.117938, Train loss: 0.128736\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01677917 -0.04385652 -0.0957227   0.02696068  0.05246784 -0.02427909\n",
      "  -0.11282156]]\n",
      "linear.bias:\n",
      " [-0.08875985]\n",
      "\n",
      "Test loss: 0.117250, Train loss: 0.128003\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01647017 -0.04343219 -0.09520893  0.02677307  0.05268268 -0.0241126\n",
      "  -0.11237331]]\n",
      "linear.bias:\n",
      " [-0.08823972]\n",
      "\n",
      "Test loss: 0.116564, Train loss: 0.127273\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01616324 -0.04300888 -0.09469518  0.02658993  0.05289472 -0.02391146\n",
      "  -0.1119253 ]]\n",
      "linear.bias:\n",
      " [-0.08771982]\n",
      "\n",
      "Test loss: 0.115882, Train loss: 0.126543\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01585847 -0.04258616 -0.09418149  0.02641128  0.05310393 -0.02367067\n",
      "  -0.11147757]]\n",
      "linear.bias:\n",
      " [-0.08720016]\n",
      "\n",
      "Test loss: 0.115201, Train loss: 0.125816\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01555616 -0.04216385 -0.09366779  0.02623508  0.05331023 -0.02341762\n",
      "  -0.11103001]]\n",
      "linear.bias:\n",
      " [-0.08668087]\n",
      "\n",
      "Test loss: 0.114522, Train loss: 0.125090\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01525661 -0.04174167 -0.09315413  0.02606254  0.05351361 -0.02313727\n",
      "  -0.11058265]]\n",
      "linear.bias:\n",
      " [-0.08616194]\n",
      "\n",
      "Test loss: 0.113847, Train loss: 0.124366\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0149596  -0.04131996 -0.09264053  0.02589491  0.05371364 -0.02283312\n",
      "  -0.11013554]]\n",
      "linear.bias:\n",
      " [-0.0856434]\n",
      "\n",
      "Test loss: 0.113174, Train loss: 0.123644\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01466483 -0.04089862 -0.09212694  0.02573237  0.05391051 -0.02249697\n",
      "  -0.10968866]]\n",
      "linear.bias:\n",
      " [-0.08512524]\n",
      "\n",
      "Test loss: 0.112503, Train loss: 0.122924\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01437204 -0.0404772  -0.09161338  0.02557595  0.05410402 -0.02215477\n",
      "  -0.1092421 ]]\n",
      "linear.bias:\n",
      " [-0.08460748]\n",
      "\n",
      "Test loss: 0.111833, Train loss: 0.122206\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01408146 -0.04005563 -0.0910999   0.02541558  0.05429404 -0.02190002\n",
      "  -0.10879585]]\n",
      "linear.bias:\n",
      " [-0.08409016]\n",
      "\n",
      "Test loss: 0.111164, Train loss: 0.121490\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01379352 -0.03963369 -0.09058651  0.0252514   0.05448073 -0.02174128\n",
      "  -0.10834974]]\n",
      "linear.bias:\n",
      " [-0.08357339]\n",
      "\n",
      "Test loss: 0.110496, Train loss: 0.120776\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01350834 -0.0392114  -0.09007317  0.02508522  0.05466384 -0.02166266\n",
      "  -0.10790386]]\n",
      "linear.bias:\n",
      " [-0.08305714]\n",
      "\n",
      "Test loss: 0.109830, Train loss: 0.120064\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01322609 -0.03878883 -0.08955987  0.0249174   0.05484373 -0.02165607\n",
      "  -0.10745812]]\n",
      "linear.bias:\n",
      " [-0.08254138]\n",
      "\n",
      "Test loss: 0.109163, Train loss: 0.119353\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01294662 -0.03836585 -0.08904658  0.0247611   0.05502015 -0.02160375\n",
      "  -0.10701264]]\n",
      "linear.bias:\n",
      " [-0.0820261]\n",
      "\n",
      "Test loss: 0.108499, Train loss: 0.118644\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01267015 -0.03794279 -0.08853327  0.02462416  0.05519281 -0.021441\n",
      "  -0.10656744]]\n",
      "linear.bias:\n",
      " [-0.0815113]\n",
      "\n",
      "Test loss: 0.107839, Train loss: 0.117937\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01239692 -0.03751969 -0.08802001  0.02450937  0.05536146 -0.02114012\n",
      "  -0.10612272]]\n",
      "linear.bias:\n",
      " [-0.0809968]\n",
      "\n",
      "Test loss: 0.107185, Train loss: 0.117233\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01212685 -0.03709656 -0.08750684  0.02440352  0.05552568 -0.02081165\n",
      "  -0.10567851]]\n",
      "linear.bias:\n",
      " [-0.08048274]\n",
      "\n",
      "Test loss: 0.106537, Train loss: 0.116530\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0118597  -0.03667352 -0.08699367  0.02430451  0.05568579 -0.0204632\n",
      "  -0.10523471]]\n",
      "linear.bias:\n",
      " [-0.07996915]\n",
      "\n",
      "Test loss: 0.105891, Train loss: 0.115829\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01159527 -0.03625071 -0.08648051  0.02420852  0.05584219 -0.02011564\n",
      "  -0.10479122]]\n",
      "linear.bias:\n",
      " [-0.07945608]\n",
      "\n",
      "Test loss: 0.105248, Train loss: 0.115131\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01133338 -0.03582903 -0.08596745  0.02411351  0.05599481 -0.0197933\n",
      "  -0.10434784]]\n",
      "linear.bias:\n",
      " [-0.07894354]\n",
      "\n",
      "Test loss: 0.104606, Train loss: 0.114434\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01107374 -0.03540864 -0.08545448  0.02401651  0.0561439  -0.01951018\n",
      "  -0.10390454]]\n",
      "linear.bias:\n",
      " [-0.07843156]\n",
      "\n",
      "Test loss: 0.103966, Train loss: 0.113740\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01081632 -0.03498935 -0.08494164  0.02391411  0.05628945 -0.01930376\n",
      "  -0.10346125]]\n",
      "linear.bias:\n",
      " [-0.07792016]\n",
      "\n",
      "Test loss: 0.103324, Train loss: 0.113047\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01056111 -0.03457145 -0.084429    0.02380762  0.05643133 -0.01918414\n",
      "  -0.1030179 ]]\n",
      "linear.bias:\n",
      " [-0.07740936]\n",
      "\n",
      "Test loss: 0.102682, Train loss: 0.112357\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01030858 -0.03415503 -0.08391649  0.0236994   0.05656961 -0.01914425\n",
      "  -0.10257457]]\n",
      "linear.bias:\n",
      " [-0.0768991]\n",
      "\n",
      "Test loss: 0.102040, Train loss: 0.111668\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.01005876 -0.03374055 -0.08340401  0.02359377  0.05670426 -0.01912828\n",
      "  -0.10213132]]\n",
      "linear.bias:\n",
      " [-0.07638939]\n",
      "\n",
      "Test loss: 0.101400, Train loss: 0.110982\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0098117  -0.03332737 -0.0828917   0.0234942   0.05683507 -0.01911565\n",
      "  -0.10168821]]\n",
      "linear.bias:\n",
      " [-0.07588021]\n",
      "\n",
      "Test loss: 0.100762, Train loss: 0.110297\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00956778 -0.03291562 -0.08237957  0.02340132  0.05696172 -0.01907335\n",
      "  -0.1012453 ]]\n",
      "linear.bias:\n",
      " [-0.07537157]\n",
      "\n",
      "Test loss: 0.100128, Train loss: 0.109615\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00932727 -0.03250621 -0.08186768  0.0233143   0.05708434 -0.01897806\n",
      "  -0.10080252]]\n",
      "linear.bias:\n",
      " [-0.07486343]\n",
      "\n",
      "Test loss: 0.099499, Train loss: 0.108936\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0090902  -0.03209935 -0.08135592  0.02322983  0.05720294 -0.01883652\n",
      "  -0.10035989]]\n",
      "linear.bias:\n",
      " [-0.07435584]\n",
      "\n",
      "Test loss: 0.098874, Train loss: 0.108260\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00885627 -0.03169485 -0.08084431  0.02314634  0.05731756 -0.01866286\n",
      "  -0.09991755]]\n",
      "linear.bias:\n",
      " [-0.07384868]\n",
      "\n",
      "Test loss: 0.098252, Train loss: 0.107584\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00862583 -0.03129307 -0.08033279  0.02306002  0.05742822 -0.01848788\n",
      "  -0.09947543]]\n",
      "linear.bias:\n",
      " [-0.07334201]\n",
      "\n",
      "Test loss: 0.097633, Train loss: 0.106911\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00839844 -0.0308937  -0.07982141  0.0229673   0.05753515 -0.01834773\n",
      "  -0.0990335 ]]\n",
      "linear.bias:\n",
      " [-0.07283579]\n",
      "\n",
      "Test loss: 0.097015, Train loss: 0.106240\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00817413 -0.03049666 -0.07931025  0.02286897  0.05763841 -0.01822872\n",
      "  -0.0985918 ]]\n",
      "linear.bias:\n",
      " [-0.07232992]\n",
      "\n",
      "Test loss: 0.096398, Train loss: 0.105570\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00795255 -0.03010191 -0.07879926  0.02276809  0.05773803 -0.01812052\n",
      "  -0.09815035]]\n",
      "linear.bias:\n",
      " [-0.07182445]\n",
      "\n",
      "Test loss: 0.095782, Train loss: 0.104902\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00773386 -0.0297094  -0.07828832  0.02266984  0.05783346 -0.01800547\n",
      "  -0.0977092 ]]\n",
      "linear.bias:\n",
      " [-0.07131954]\n",
      "\n",
      "Test loss: 0.095169, Train loss: 0.104236\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00751845 -0.02931913 -0.07777744  0.02257676  0.05792481 -0.01785373\n",
      "  -0.09726828]]\n",
      "linear.bias:\n",
      " [-0.07081522]\n",
      "\n",
      "Test loss: 0.094559, Train loss: 0.103573\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00730608 -0.02893077 -0.07726656  0.02248738  0.0580123  -0.01768949\n",
      "  -0.09682754]]\n",
      "linear.bias:\n",
      " [-0.07031155]\n",
      "\n",
      "Test loss: 0.093952, Train loss: 0.102911\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00709715 -0.02854463 -0.07675569  0.02240164  0.05809564 -0.01752882\n",
      "  -0.09638697]]\n",
      "linear.bias:\n",
      " [-0.06980859]\n",
      "\n",
      "Test loss: 0.093348, Train loss: 0.102251\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00689143 -0.02816042 -0.07624488  0.02231817  0.05817512 -0.01738672\n",
      "  -0.09594648]]\n",
      "linear.bias:\n",
      " [-0.06930632]\n",
      "\n",
      "Test loss: 0.092746, Train loss: 0.101594\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00668923 -0.02777785 -0.07573407  0.02223628  0.05825098 -0.01725569\n",
      "  -0.09550609]]\n",
      "linear.bias:\n",
      " [-0.0688047]\n",
      "\n",
      "Test loss: 0.092146, Train loss: 0.100938\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00649044 -0.02739685 -0.07522321  0.02215653  0.05832336 -0.01712561\n",
      "  -0.09506583]]\n",
      "linear.bias:\n",
      " [-0.06830372]\n",
      "\n",
      "Test loss: 0.091549, Train loss: 0.100283\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0062947  -0.02701737 -0.07471231  0.02207718  0.05839233 -0.01700167\n",
      "  -0.09462568]]\n",
      "linear.bias:\n",
      " [-0.0678034]\n",
      "\n",
      "Test loss: 0.090953, Train loss: 0.099629\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.006102   -0.02663957 -0.07420141  0.0219995   0.05845818 -0.0168742\n",
      "  -0.09418555]]\n",
      "linear.bias:\n",
      " [-0.06730368]\n",
      "\n",
      "Test loss: 0.090358, Train loss: 0.098977\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00591255 -0.0262641  -0.07369053  0.0219238   0.05852072 -0.0167274\n",
      "  -0.09374537]]\n",
      "linear.bias:\n",
      " [-0.06680464]\n",
      "\n",
      "Test loss: 0.089767, Train loss: 0.098326\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00572604 -0.02589109 -0.07317971  0.02184873  0.05857984 -0.01658252\n",
      "  -0.09330522]]\n",
      "linear.bias:\n",
      " [-0.0663062]\n",
      "\n",
      "Test loss: 0.089177, Train loss: 0.097678\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00554292 -0.02552051 -0.07266898  0.02176915  0.05863532 -0.01649782\n",
      "  -0.09286508]]\n",
      "linear.bias:\n",
      " [-0.06580847]\n",
      "\n",
      "Test loss: 0.088586, Train loss: 0.097032\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00536314 -0.02515264 -0.0721583   0.02168571  0.05868709 -0.01645833\n",
      "  -0.09242494]]\n",
      "linear.bias:\n",
      " [-0.06531149]\n",
      "\n",
      "Test loss: 0.087995, Train loss: 0.096387\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00518642 -0.02478722 -0.07164766  0.02159713  0.05873545 -0.01645797\n",
      "  -0.09198478]]\n",
      "linear.bias:\n",
      " [-0.06481525]\n",
      "\n",
      "Test loss: 0.087404, Train loss: 0.095745\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00501293 -0.02442401 -0.07113706  0.02150689  0.05878037 -0.01646815\n",
      "  -0.0915447 ]]\n",
      "linear.bias:\n",
      " [-0.06431967]\n",
      "\n",
      "Test loss: 0.086816, Train loss: 0.095104\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00484266 -0.02406332 -0.07062638  0.02141358  0.05882162 -0.01646125\n",
      "  -0.09110479]]\n",
      "linear.bias:\n",
      " [-0.06382485]\n",
      "\n",
      "Test loss: 0.086230, Train loss: 0.094464\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00467554 -0.02370507 -0.0701157   0.0213181   0.05885914 -0.01644064\n",
      "  -0.09066509]]\n",
      "linear.bias:\n",
      " [-0.06333072]\n",
      "\n",
      "Test loss: 0.085647, Train loss: 0.093826\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00451175 -0.02334908 -0.06960502  0.02122425  0.05889277 -0.01636397\n",
      "  -0.09022568]]\n",
      "linear.bias:\n",
      " [-0.0628373]\n",
      "\n",
      "Test loss: 0.085068, Train loss: 0.093191\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00435093 -0.02299591 -0.06909435  0.02113317  0.05892237 -0.01621719\n",
      "  -0.08978662]]\n",
      "linear.bias:\n",
      " [-0.06234454]\n",
      "\n",
      "Test loss: 0.084493, Train loss: 0.092557\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00419322 -0.02264567 -0.0685837   0.02104096  0.05894776 -0.0160282\n",
      "  -0.08934788]]\n",
      "linear.bias:\n",
      " [-0.06185251]\n",
      "\n",
      "Test loss: 0.083923, Train loss: 0.091925\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00403947 -0.02229909 -0.06807311  0.02094656  0.05896868 -0.01581046\n",
      "  -0.08890951]]\n",
      "linear.bias:\n",
      " [-0.06136117]\n",
      "\n",
      "Test loss: 0.083355, Train loss: 0.091295\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00388964 -0.02195599 -0.06756265  0.02084948  0.05898485 -0.01556113\n",
      "  -0.08847155]]\n",
      "linear.bias:\n",
      " [-0.06087054]\n",
      "\n",
      "Test loss: 0.082792, Train loss: 0.090668\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00374343 -0.02161755 -0.06705227  0.02074823  0.05899644 -0.01531786\n",
      "  -0.08803386]]\n",
      "linear.bias:\n",
      " [-0.06038068]\n",
      "\n",
      "Test loss: 0.082231, Train loss: 0.090044\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00360022 -0.02128344 -0.06654203  0.02064383  0.05900349 -0.01508365\n",
      "  -0.08759645]]\n",
      "linear.bias:\n",
      " [-0.05989157]\n",
      "\n",
      "Test loss: 0.081674, Train loss: 0.089422\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00346019 -0.02095407 -0.06603198  0.02053752  0.05900558 -0.01486644\n",
      "  -0.08715929]]\n",
      "linear.bias:\n",
      " [-0.05940329]\n",
      "\n",
      "Test loss: 0.081119, Train loss: 0.088803\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00332322 -0.02063039 -0.06552206  0.02043164  0.05900246 -0.0146615\n",
      "  -0.0867224 ]]\n",
      "linear.bias:\n",
      " [-0.05891589]\n",
      "\n",
      "Test loss: 0.080566, Train loss: 0.088186\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00318901 -0.02031137 -0.06501227  0.02032593  0.05899409 -0.0144782\n",
      "  -0.08628583]]\n",
      "linear.bias:\n",
      " [-0.0584294]\n",
      "\n",
      "Test loss: 0.080015, Train loss: 0.087571\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00305788 -0.01999732 -0.06450254  0.02022151  0.05898035 -0.01432418\n",
      "  -0.08584961]]\n",
      "linear.bias:\n",
      " [-0.05794388]\n",
      "\n",
      "Test loss: 0.079462, Train loss: 0.086959\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00292985 -0.01968783 -0.06399287  0.02011653  0.05896122 -0.01419977\n",
      "  -0.08541376]]\n",
      "linear.bias:\n",
      " [-0.05745934]\n",
      "\n",
      "Test loss: 0.078909, Train loss: 0.086348\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00280553 -0.01938314 -0.06348322  0.02001003  0.0589372  -0.01412611\n",
      "  -0.08497807]]\n",
      "linear.bias:\n",
      " [-0.05697586]\n",
      "\n",
      "Test loss: 0.078355, Train loss: 0.085740\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00268482 -0.01908273 -0.06297361  0.01990266  0.05890832 -0.014094\n",
      "  -0.08454266]]\n",
      "linear.bias:\n",
      " [-0.05649327]\n",
      "\n",
      "Test loss: 0.077800, Train loss: 0.085134\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00256799 -0.01878671 -0.06246402  0.01979353  0.05887444 -0.01408828\n",
      "  -0.08410759]]\n",
      "linear.bias:\n",
      " [-0.05601165]\n",
      "\n",
      "Test loss: 0.077247, Train loss: 0.084529\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00245501 -0.01849501 -0.06195443  0.01968459  0.0588354  -0.01407837\n",
      "  -0.0836729 ]]\n",
      "linear.bias:\n",
      " [-0.05553105]\n",
      "\n",
      "Test loss: 0.076696, Train loss: 0.083926\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00234591 -0.01820768 -0.06144485  0.0195791   0.05879143 -0.01405145\n",
      "  -0.08323848]]\n",
      "linear.bias:\n",
      " [-0.05505144]\n",
      "\n",
      "Test loss: 0.076150, Train loss: 0.083325\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00224055 -0.01792483 -0.06093535  0.01947737  0.05874218 -0.01398189\n",
      "  -0.08280455]]\n",
      "linear.bias:\n",
      " [-0.05457273]\n",
      "\n",
      "Test loss: 0.075609, Train loss: 0.082726\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00213964 -0.01764626 -0.06042596  0.01938018  0.05868753 -0.01382573\n",
      "  -0.08237113]]\n",
      "linear.bias:\n",
      " [-0.05409499]\n",
      "\n",
      "Test loss: 0.075075, Train loss: 0.082129\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00204278 -0.01737177 -0.05991668  0.01928668  0.05862766 -0.01361092\n",
      "  -0.08193811]]\n",
      "linear.bias:\n",
      " [-0.05361826]\n",
      "\n",
      "Test loss: 0.074547, Train loss: 0.081534\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00195012 -0.01710154 -0.05940745  0.01919332  0.05856239 -0.01338216\n",
      "  -0.08150537]]\n",
      "linear.bias:\n",
      " [-0.05314277]\n",
      "\n",
      "Test loss: 0.074023, Train loss: 0.080941\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00186198 -0.01683536 -0.0588984   0.0191007   0.05849199 -0.01316498\n",
      "  -0.08107276]]\n",
      "linear.bias:\n",
      " [-0.0526685]\n",
      "\n",
      "Test loss: 0.073499, Train loss: 0.080350\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00177796 -0.01657368 -0.05838949  0.01900776  0.05841629 -0.01296449\n",
      "  -0.08064027]]\n",
      "linear.bias:\n",
      " [-0.05219553]\n",
      "\n",
      "Test loss: 0.072977, Train loss: 0.079762\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00169762 -0.01631675 -0.05788066  0.01891672  0.0583354  -0.01277477\n",
      "  -0.08020786]]\n",
      "linear.bias:\n",
      " [-0.05172392]\n",
      "\n",
      "Test loss: 0.072455, Train loss: 0.079175\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00162116 -0.0160645  -0.05737199  0.01882217  0.05824938 -0.01263101\n",
      "  -0.07977546]]\n",
      "linear.bias:\n",
      " [-0.05125367]\n",
      "\n",
      "Test loss: 0.071931, Train loss: 0.078591\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00154897 -0.01581681 -0.05686354  0.01872453  0.05815773 -0.01252987\n",
      "  -0.07934324]]\n",
      "linear.bias:\n",
      " [-0.05078477]\n",
      "\n",
      "Test loss: 0.071406, Train loss: 0.078009\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0014807  -0.01557361 -0.0563553   0.01862187  0.05806009 -0.0124889\n",
      "  -0.07891142]]\n",
      "linear.bias:\n",
      " [-0.05031716]\n",
      "\n",
      "Test loss: 0.070879, Train loss: 0.077428\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00141689 -0.0153355  -0.05584736  0.01851566  0.05795614 -0.01254044\n",
      "  -0.07847984]]\n",
      "linear.bias:\n",
      " [-0.04985097]\n",
      "\n",
      "Test loss: 0.070347, Train loss: 0.076850\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00135757 -0.01510224 -0.05533978  0.01840644  0.05784627 -0.01266332\n",
      "  -0.07804852]]\n",
      "linear.bias:\n",
      " [-0.04938602]\n",
      "\n",
      "Test loss: 0.069811, Train loss: 0.076274\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00130287 -0.014873   -0.05483255  0.01829549  0.0577306  -0.01281026\n",
      "  -0.07761744]]\n",
      "linear.bias:\n",
      " [-0.04892234]\n",
      "\n",
      "Test loss: 0.069278, Train loss: 0.075698\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00125245 -0.01464727 -0.0543257   0.01818632  0.05760923 -0.01290453\n",
      "  -0.07718669]]\n",
      "linear.bias:\n",
      " [-0.04845986]\n",
      "\n",
      "Test loss: 0.068750, Train loss: 0.075125\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00120691 -0.01442519 -0.05381937  0.01808158  0.05748164 -0.01291328\n",
      "  -0.07675637]]\n",
      "linear.bias:\n",
      " [-0.0479986]\n",
      "\n",
      "Test loss: 0.068229, Train loss: 0.074553\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00116589 -0.01420622 -0.0533135   0.01798504  0.0573475  -0.0127824\n",
      "  -0.0763266 ]]\n",
      "linear.bias:\n",
      " [-0.04753865]\n",
      "\n",
      "Test loss: 0.067717, Train loss: 0.073984\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00112933 -0.01399074 -0.05280812  0.01789617  0.05720694 -0.0125458\n",
      "  -0.07589728]]\n",
      "linear.bias:\n",
      " [-0.04708002]\n",
      "\n",
      "Test loss: 0.067212, Train loss: 0.073417\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00109682 -0.01377846 -0.0523032   0.01780745  0.05706008 -0.0122681\n",
      "  -0.07546835]]\n",
      "linear.bias:\n",
      " [-0.04662282]\n",
      "\n",
      "Test loss: 0.066712, Train loss: 0.072850\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0010674  -0.01356963 -0.05179875  0.01771635  0.05690726 -0.01199779\n",
      "  -0.07503972]]\n",
      "linear.bias:\n",
      " [-0.04616701]\n",
      "\n",
      "Test loss: 0.066214, Train loss: 0.072285\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00104076 -0.01336368 -0.05129475  0.01761951  0.05674885 -0.01178862\n",
      "  -0.07461126]]\n",
      "linear.bias:\n",
      " [-0.04571263]\n",
      "\n",
      "Test loss: 0.065715, Train loss: 0.071722\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00101658 -0.01316055 -0.05079117  0.01751399  0.05658536 -0.01166441\n",
      "  -0.07418277]]\n",
      "linear.bias:\n",
      " [-0.04525978]\n",
      "\n",
      "Test loss: 0.065209, Train loss: 0.071161\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00099475 -0.01295994 -0.05028801  0.01740091  0.05641716 -0.01161088\n",
      "  -0.07375422]]\n",
      "linear.bias:\n",
      " [-0.04480836]\n",
      "\n",
      "Test loss: 0.064700, Train loss: 0.070600\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00097504 -0.01276189 -0.04978524  0.01728116  0.05624436 -0.01163107\n",
      "  -0.0733256 ]]\n",
      "linear.bias:\n",
      " [-0.0443583]\n",
      "\n",
      "Test loss: 0.064187, Train loss: 0.070041\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00095695 -0.01256694 -0.04928293  0.01715896  0.05606689 -0.01168853\n",
      "  -0.07289682]]\n",
      "linear.bias:\n",
      " [-0.04390963]\n",
      "\n",
      "Test loss: 0.063672, Train loss: 0.069482\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00094035 -0.01237461 -0.04878106  0.01703773  0.05588493 -0.01175439\n",
      "  -0.07246788]]\n",
      "linear.bias:\n",
      " [-0.04346228]\n",
      "\n",
      "Test loss: 0.063157, Train loss: 0.068925\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0009259  -0.01218444 -0.04827966  0.01692165  0.05569835 -0.01177744\n",
      "  -0.07203878]]\n",
      "linear.bias:\n",
      " [-0.04301635]\n",
      "\n",
      "Test loss: 0.062647, Train loss: 0.068369\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00091316 -0.01199675 -0.04777867  0.01681636  0.05550714 -0.01173237\n",
      "  -0.07160949]]\n",
      "linear.bias:\n",
      " [-0.04257184]\n",
      "\n",
      "Test loss: 0.062143, Train loss: 0.067814\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00090208 -0.0118122  -0.04727804  0.01671901  0.05531148 -0.01162867\n",
      "  -0.07118004]]\n",
      "linear.bias:\n",
      " [-0.04212877]\n",
      "\n",
      "Test loss: 0.061645, Train loss: 0.067261\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00089223 -0.01163158 -0.04677763  0.01662439  0.05511147 -0.01148803\n",
      "  -0.07075053]]\n",
      "linear.bias:\n",
      " [-0.0416871]\n",
      "\n",
      "Test loss: 0.061151, Train loss: 0.066709\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00088379 -0.01145545 -0.0462775   0.01653061  0.05490715 -0.01132581\n",
      "  -0.07032092]]\n",
      "linear.bias:\n",
      " [-0.04124683]\n",
      "\n",
      "Test loss: 0.060661, Train loss: 0.066158\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087667 -0.01128453 -0.04577769  0.01643576  0.05469824 -0.01120356\n",
      "  -0.06989113]]\n",
      "linear.bias:\n",
      " [-0.04080806]\n",
      "\n",
      "Test loss: 0.060170, Train loss: 0.065609\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087097 -0.01111795 -0.04527815  0.01633703  0.05448486 -0.01114535\n",
      "  -0.06946106]]\n",
      "linear.bias:\n",
      " [-0.04037095]\n",
      "\n",
      "Test loss: 0.059675, Train loss: 0.065061\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086668 -0.01095546 -0.04477895  0.0162358   0.05426715 -0.01114032\n",
      "  -0.06903074]]\n",
      "linear.bias:\n",
      " [-0.03993536]\n",
      "\n",
      "Test loss: 0.059178, Train loss: 0.064515\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0008638  -0.0107969  -0.04428015  0.01613128  0.05404462 -0.01115244\n",
      "  -0.06860039]]\n",
      "linear.bias:\n",
      " [-0.0395013]\n",
      "\n",
      "Test loss: 0.058680, Train loss: 0.063969\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086235 -0.01064177 -0.0437817   0.01602517  0.05381756 -0.01117428\n",
      "  -0.06817006]]\n",
      "linear.bias:\n",
      " [-0.03906865]\n",
      "\n",
      "Test loss: 0.058183, Train loss: 0.063425\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086233 -0.01049075 -0.04328366  0.0159215   0.05358578 -0.01117178\n",
      "  -0.0677397 ]]\n",
      "linear.bias:\n",
      " [-0.03863743]\n",
      "\n",
      "Test loss: 0.057689, Train loss: 0.062882\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086281 -0.01034348 -0.04278616  0.01581871  0.05334938 -0.01115538\n",
      "  -0.06730935]]\n",
      "linear.bias:\n",
      " [-0.03820753]\n",
      "\n",
      "Test loss: 0.057196, Train loss: 0.062340\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086452 -0.01019974 -0.04228914  0.01571623  0.05310839 -0.01112008\n",
      "  -0.06687906]]\n",
      "linear.bias:\n",
      " [-0.03777891]\n",
      "\n",
      "Test loss: 0.056707, Train loss: 0.061799\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086699 -0.01005968 -0.04179262  0.01561488  0.05286257 -0.0110526\n",
      "  -0.06644884]]\n",
      "linear.bias:\n",
      " [-0.03735168]\n",
      "\n",
      "Test loss: 0.056221, Train loss: 0.061259\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086944 -0.00992336 -0.04129652  0.01551456  0.05261205 -0.01095089\n",
      "  -0.06601869]]\n",
      "linear.bias:\n",
      " [-0.03692589]\n",
      "\n",
      "Test loss: 0.055739, Train loss: 0.060721\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087156 -0.00979054 -0.04080089  0.01541176  0.05235718 -0.01086066\n",
      "  -0.06558844]]\n",
      "linear.bias:\n",
      " [-0.03650151]\n",
      "\n",
      "Test loss: 0.055258, Train loss: 0.060183\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0008728  -0.009661   -0.04030579  0.01530416  0.05209798 -0.01077808\n",
      "  -0.06515821]]\n",
      "linear.bias:\n",
      " [-0.03607845]\n",
      "\n",
      "Test loss: 0.054777, Train loss: 0.059646\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087384 -0.00953459 -0.03981118  0.01518911  0.05183409 -0.01068455\n",
      "  -0.06472822]]\n",
      "linear.bias:\n",
      " [-0.0356569]\n",
      "\n",
      "Test loss: 0.054297, Train loss: 0.059111\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087489 -0.00941149 -0.03931722  0.01506469  0.05156562 -0.01060096\n",
      "  -0.06429823]]\n",
      "linear.bias:\n",
      " [-0.03523695]\n",
      "\n",
      "Test loss: 0.053818, Train loss: 0.058577\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087565 -0.00929205 -0.03882408  0.01493201  0.05129229 -0.01053556\n",
      "  -0.06386828]]\n",
      "linear.bias:\n",
      " [-0.03481854]\n",
      "\n",
      "Test loss: 0.053338, Train loss: 0.058045\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087568 -0.0091754  -0.0383317   0.0147914   0.05101414 -0.01048829\n",
      "  -0.06343847]]\n",
      "linear.bias:\n",
      " [-0.03440162]\n",
      "\n",
      "Test loss: 0.052859, Train loss: 0.057514\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087459 -0.00906149 -0.03784006  0.01464774  0.05073096 -0.01044373\n",
      "  -0.06300879]]\n",
      "linear.bias:\n",
      " [-0.03398624]\n",
      "\n",
      "Test loss: 0.052379, Train loss: 0.056984\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087236 -0.00895028 -0.03734937  0.01450309  0.05044229 -0.01040535\n",
      "  -0.06257927]]\n",
      "linear.bias:\n",
      " [-0.03357254]\n",
      "\n",
      "Test loss: 0.051901, Train loss: 0.056456\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086871 -0.00884088 -0.03685965  0.01435825  0.05014826 -0.01036034\n",
      "  -0.06215001]]\n",
      "linear.bias:\n",
      " [-0.03316041]\n",
      "\n",
      "Test loss: 0.051424, Train loss: 0.055929\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086393 -0.00873327 -0.03637085  0.01421439  0.04984894 -0.01028258\n",
      "  -0.06172107]]\n",
      "linear.bias:\n",
      " [-0.03274976]\n",
      "\n",
      "Test loss: 0.050951, Train loss: 0.055404\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00085837 -0.00862716 -0.03588296  0.01407455  0.04954456 -0.01015035\n",
      "  -0.06129241]]\n",
      "linear.bias:\n",
      " [-0.03234052]\n",
      "\n",
      "Test loss: 0.050483, Train loss: 0.054879\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00085293 -0.00852239 -0.03539592  0.01393702  0.04923544 -0.00998185\n",
      "  -0.06086394]]\n",
      "linear.bias:\n",
      " [-0.03193269]\n",
      "\n",
      "Test loss: 0.050017, Train loss: 0.054355\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00084738 -0.00841867 -0.03490973  0.01380054  0.04892188 -0.00980766\n",
      "  -0.06043551]]\n",
      "linear.bias:\n",
      " [-0.03152628]\n",
      "\n",
      "Test loss: 0.049553, Train loss: 0.053832\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00084191 -0.00831622 -0.03442433  0.01366355  0.04860438 -0.00964316\n",
      "  -0.06000702]]\n",
      "linear.bias:\n",
      " [-0.03112116]\n",
      "\n",
      "Test loss: 0.049089, Train loss: 0.053310\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00083658 -0.0082152  -0.03393983  0.01352555  0.04828326 -0.00950219\n",
      "  -0.05957825]]\n",
      "linear.bias:\n",
      " [-0.03071737]\n",
      "\n",
      "Test loss: 0.048624, Train loss: 0.052789\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00083143 -0.00811539 -0.0334562   0.01338544  0.04795859 -0.00939181\n",
      "  -0.05914921]]\n",
      "linear.bias:\n",
      " [-0.03031489]\n",
      "\n",
      "Test loss: 0.048157, Train loss: 0.052269\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00082611 -0.00801703 -0.03297354  0.01324356  0.04763027 -0.00933423\n",
      "  -0.05871981]]\n",
      "linear.bias:\n",
      " [-0.02991374]\n",
      "\n",
      "Test loss: 0.047688, Train loss: 0.051750\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00082074 -0.00792024 -0.03249181  0.01309821  0.0472986  -0.00933266\n",
      "  -0.05829   ]]\n",
      "linear.bias:\n",
      " [-0.02951384]\n",
      "\n",
      "Test loss: 0.047216, Train loss: 0.051231\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00081562 -0.00782523 -0.03201098  0.01295612  0.04696384 -0.00935366\n",
      "  -0.05785959]]\n",
      "linear.bias:\n",
      " [-0.02911527]\n",
      "\n",
      "Test loss: 0.046744, Train loss: 0.050714\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00081055 -0.00773104 -0.03153127  0.01282197  0.04662599 -0.00935347\n",
      "  -0.05742859]]\n",
      "linear.bias:\n",
      " [-0.02871796]\n",
      "\n",
      "Test loss: 0.046274, Train loss: 0.050198\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00080622 -0.00763779 -0.03105265  0.01269324  0.046285   -0.00934261\n",
      "  -0.05699707]]\n",
      "linear.bias:\n",
      " [-0.02832191]\n",
      "\n",
      "Test loss: 0.045806, Train loss: 0.049682\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00080277 -0.00754512 -0.03057499  0.01257107  0.04594097 -0.00931892\n",
      "  -0.05656505]]\n",
      "linear.bias:\n",
      " [-0.02792719]\n",
      "\n",
      "Test loss: 0.045340, Train loss: 0.049168\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00080011 -0.00745364 -0.03009823  0.01245447  0.04559434 -0.00929107\n",
      "  -0.05613238]]\n",
      "linear.bias:\n",
      " [-0.02753383]\n",
      "\n",
      "Test loss: 0.044876, Train loss: 0.048655\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00079846 -0.00736335 -0.02962238  0.01234477  0.04524517 -0.00924469\n",
      "  -0.05569899]]\n",
      "linear.bias:\n",
      " [-0.02714184]\n",
      "\n",
      "Test loss: 0.044414, Train loss: 0.048143\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00079793 -0.00727424 -0.02914733  0.01224258  0.04489376 -0.00916077\n",
      "  -0.05526482]]\n",
      "linear.bias:\n",
      " [-0.02675124]\n",
      "\n",
      "Test loss: 0.043955, Train loss: 0.047632\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00079856 -0.00718539 -0.02867323  0.01214476  0.04454036 -0.00906694\n",
      "  -0.05482977]]\n",
      "linear.bias:\n",
      " [-0.02636202]\n",
      "\n",
      "Test loss: 0.043499, Train loss: 0.047121\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00080039 -0.00709751 -0.02820003  0.01204852  0.04418515 -0.00897348\n",
      "  -0.05439382]]\n",
      "linear.bias:\n",
      " [-0.02597417]\n",
      "\n",
      "Test loss: 0.043043, Train loss: 0.046612\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00080376 -0.00701073 -0.02772765  0.01195273  0.04382818 -0.008887\n",
      "  -0.05395698]]\n",
      "linear.bias:\n",
      " [-0.02558774]\n",
      "\n",
      "Test loss: 0.042589, Train loss: 0.046104\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00080867 -0.00692484 -0.02725599  0.01185885  0.04346946 -0.00879934\n",
      "  -0.05351933]]\n",
      "linear.bias:\n",
      " [-0.02520267]\n",
      "\n",
      "Test loss: 0.042137, Train loss: 0.045597\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0008151  -0.00683985 -0.026785    0.01176464  0.04310873 -0.00872636\n",
      "  -0.05308099]]\n",
      "linear.bias:\n",
      " [-0.02481901]\n",
      "\n",
      "Test loss: 0.041684, Train loss: 0.045090\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00082209 -0.00675567 -0.0263147   0.01166846  0.04274611 -0.00867417\n",
      "  -0.0526419 ]]\n",
      "linear.bias:\n",
      " [-0.02443684]\n",
      "\n",
      "Test loss: 0.041231, Train loss: 0.044584\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0008303  -0.00667156 -0.02584519  0.01156708  0.04238142 -0.0086468\n",
      "  -0.0522021 ]]\n",
      "linear.bias:\n",
      " [-0.02405621]\n",
      "\n",
      "Test loss: 0.040777, Train loss: 0.044080\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00083982 -0.00658623 -0.02537654  0.01146112  0.04201439 -0.0086323\n",
      "  -0.05176171]]\n",
      "linear.bias:\n",
      " [-0.02367717]\n",
      "\n",
      "Test loss: 0.040323, Train loss: 0.043576\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00085058 -0.00649961 -0.02490878  0.01135315  0.04164502 -0.00861384\n",
      "  -0.05132075]]\n",
      "linear.bias:\n",
      " [-0.02329966]\n",
      "\n",
      "Test loss: 0.039870, Train loss: 0.043074\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086214 -0.00641209 -0.02444202  0.01124726  0.04127344 -0.00855873\n",
      "  -0.05087908]]\n",
      "linear.bias:\n",
      " [-0.02292367]\n",
      "\n",
      "Test loss: 0.039421, Train loss: 0.042573\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087449 -0.00632429 -0.02397637  0.01114189  0.0408998  -0.00846439\n",
      "  -0.05043678]]\n",
      "linear.bias:\n",
      " [-0.02254909]\n",
      "\n",
      "Test loss: 0.038977, Train loss: 0.042073\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00088786 -0.00623701 -0.02351177  0.01103717  0.04052378 -0.00834197\n",
      "  -0.04999391]]\n",
      "linear.bias:\n",
      " [-0.02217605]\n",
      "\n",
      "Test loss: 0.038535, Train loss: 0.041574\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00090192 -0.00615027 -0.02304817  0.01093446  0.04014578 -0.00820376\n",
      "  -0.04955035]]\n",
      "linear.bias:\n",
      " [-0.02180444]\n",
      "\n",
      "Test loss: 0.038095, Train loss: 0.041077\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00091703 -0.00606388 -0.02258568  0.01083238  0.03976602 -0.00809801\n",
      "  -0.04910589]]\n",
      "linear.bias:\n",
      " [-0.02143432]\n",
      "\n",
      "Test loss: 0.037654, Train loss: 0.040580\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00093177 -0.00597895 -0.02212453  0.01072858  0.03938458 -0.00803836\n",
      "  -0.04866036]]\n",
      "linear.bias:\n",
      " [-0.02106584]\n",
      "\n",
      "Test loss: 0.037210, Train loss: 0.040086\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00094647 -0.00589515 -0.02166476  0.01062265  0.03900132 -0.00801144\n",
      "  -0.04821377]]\n",
      "linear.bias:\n",
      " [-0.02069915]\n",
      "\n",
      "Test loss: 0.036764, Train loss: 0.039593\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00096093 -0.00581273 -0.02120646  0.01051078  0.0386161  -0.00801433\n",
      "  -0.04776626]]\n",
      "linear.bias:\n",
      " [-0.02033421]\n",
      "\n",
      "Test loss: 0.036316, Train loss: 0.039102\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00097513 -0.00573102 -0.02074966  0.01039609  0.03822867 -0.00802458\n",
      "  -0.04731797]]\n",
      "linear.bias:\n",
      " [-0.01997096]\n",
      "\n",
      "Test loss: 0.035869, Train loss: 0.038612\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00098892 -0.00564964 -0.02029436  0.01028269  0.03783859 -0.00800217\n",
      "  -0.04686916]]\n",
      "linear.bias:\n",
      " [-0.01960943]\n",
      "\n",
      "Test loss: 0.035426, Train loss: 0.038124\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00100236 -0.00556932 -0.01984072  0.01017     0.0374462  -0.0079502\n",
      "  -0.04641964]]\n",
      "linear.bias:\n",
      " [-0.01924961]\n",
      "\n",
      "Test loss: 0.034986, Train loss: 0.037638\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00101544 -0.00549001 -0.01938876  0.0100594   0.03705095 -0.00780419\n",
      "  -0.04596967]]\n",
      "linear.bias:\n",
      " [-0.01889167]\n",
      "\n",
      "Test loss: 0.034554, Train loss: 0.037153\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00102809 -0.00541178 -0.01893858  0.00994298  0.03665344 -0.00763929\n",
      "  -0.04551895]]\n",
      "linear.bias:\n",
      " [-0.01853555]\n",
      "\n",
      "Test loss: 0.034125, Train loss: 0.036671\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00103958 -0.00533444 -0.01849017  0.00981794  0.03625398 -0.00748533\n",
      "  -0.0450674 ]]\n",
      "linear.bias:\n",
      " [-0.01818121]\n",
      "\n",
      "Test loss: 0.033697, Train loss: 0.036190\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00104936 -0.0052583  -0.01804348  0.00968101  0.03585296 -0.00740112\n",
      "  -0.04461483]]\n",
      "linear.bias:\n",
      " [-0.01782871]\n",
      "\n",
      "Test loss: 0.033264, Train loss: 0.035711\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0010567  -0.00518263 -0.01759863  0.00953453  0.0354505  -0.00739446\n",
      "  -0.04416116]]\n",
      "linear.bias:\n",
      " [-0.01747818]\n",
      "\n",
      "Test loss: 0.032827, Train loss: 0.035233\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00106271 -0.00510747 -0.01715571  0.00938233  0.03504645 -0.00742093\n",
      "  -0.04370641]]\n",
      "linear.bias:\n",
      " [-0.01712956]\n",
      "\n",
      "Test loss: 0.032388, Train loss: 0.034758\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00106778 -0.00503265 -0.01671478  0.00922722  0.0346407  -0.00743786\n",
      "  -0.04325059]]\n",
      "linear.bias:\n",
      " [-0.01678298]\n",
      "\n",
      "Test loss: 0.031951, Train loss: 0.034285\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00107299 -0.00495847 -0.01627594  0.00907421  0.03423323 -0.00743261\n",
      "  -0.0427936 ]]\n",
      "linear.bias:\n",
      " [-0.01643849]\n",
      "\n",
      "Test loss: 0.031517, Train loss: 0.033813\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00107767 -0.00488492 -0.01583914  0.00892789  0.03382447 -0.0073695\n",
      "  -0.04233532]]\n",
      "linear.bias:\n",
      " [-0.01609614]\n",
      "\n",
      "Test loss: 0.031090, Train loss: 0.033344\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0010816  -0.00481174 -0.01540443  0.00878834  0.03341452 -0.00726963\n",
      "  -0.04187577]]\n",
      "linear.bias:\n",
      " [-0.01575598]\n",
      "\n",
      "Test loss: 0.030666, Train loss: 0.032877\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0010853  -0.00473934 -0.01497192  0.0086601   0.03300309 -0.00712396\n",
      "  -0.04141501]]\n",
      "linear.bias:\n",
      " [-0.01541803]\n",
      "\n",
      "Test loss: 0.030246, Train loss: 0.032413\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00108829 -0.00466693 -0.01454172  0.00854089  0.03259059 -0.00695732\n",
      "  -0.04095289]]\n",
      "linear.bias:\n",
      " [-0.01508237]\n",
      "\n",
      "Test loss: 0.029830, Train loss: 0.031951\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00109088 -0.00459414 -0.01411428  0.00842957  0.03217669 -0.00680701\n",
      "  -0.0404895 ]]\n",
      "linear.bias:\n",
      " [-0.01474903]\n",
      "\n",
      "Test loss: 0.029415, Train loss: 0.031492\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00109326 -0.00452101 -0.0136895   0.00832013  0.03176148 -0.0067258\n",
      "  -0.0400249 ]]\n",
      "linear.bias:\n",
      " [-0.01441805]\n",
      "\n",
      "Test loss: 0.028998, Train loss: 0.031037\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00109617 -0.00444819 -0.01326727  0.00821306  0.03134496 -0.00670644\n",
      "  -0.0395592 ]]\n",
      "linear.bias:\n",
      " [-0.0140895]\n",
      "\n",
      "Test loss: 0.028577, Train loss: 0.030583\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00109966 -0.00437443 -0.01284795  0.00811123  0.03092765 -0.00671637\n",
      "  -0.03909224]]\n",
      "linear.bias:\n",
      " [-0.01376341]\n",
      "\n",
      "Test loss: 0.028156, Train loss: 0.030133\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00110406 -0.00429958 -0.01243152  0.00802093  0.03050922 -0.00668275\n",
      "  -0.03862422]]\n",
      "linear.bias:\n",
      " [-0.01343971]\n",
      "\n",
      "Test loss: 0.027740, Train loss: 0.029685\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00110816 -0.00422311 -0.01201806  0.00793691  0.03008964 -0.00661596\n",
      "  -0.03815532]]\n",
      "linear.bias:\n",
      " [-0.01311824]\n",
      "\n",
      "Test loss: 0.027329, Train loss: 0.029241\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00111221 -0.00414379 -0.01160769  0.00786126  0.02966942 -0.00649599\n",
      "  -0.03768531]]\n",
      "linear.bias:\n",
      " [-0.01279908]\n",
      "\n",
      "Test loss: 0.026923, Train loss: 0.028799\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00111712 -0.00406208 -0.01120045  0.00778305  0.02924865 -0.00637608\n",
      "  -0.03721416]]\n",
      "linear.bias:\n",
      " [-0.01248246]\n",
      "\n",
      "Test loss: 0.026519, Train loss: 0.028360\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00112292 -0.00397917 -0.01079639  0.00770289  0.02882723 -0.00623499\n",
      "  -0.03674192]]\n",
      "linear.bias:\n",
      " [-0.01216839]\n",
      "\n",
      "Test loss: 0.026119, Train loss: 0.027924\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00112921 -0.00389571 -0.01039607  0.00761569  0.0284053  -0.00611712\n",
      "  -0.03626849]]\n",
      "linear.bias:\n",
      " [-0.01185696]\n",
      "\n",
      "Test loss: 0.025721, Train loss: 0.027493\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00113563 -0.00381234 -0.00999947  0.00751391  0.0279835  -0.00604878\n",
      "  -0.03579356]]\n",
      "linear.bias:\n",
      " [-0.01154842]\n",
      "\n",
      "Test loss: 0.025320, Train loss: 0.027065\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00114352 -0.00372982 -0.0096073   0.0073992   0.02756248 -0.00600761\n",
      "  -0.03531687]]\n",
      "linear.bias:\n",
      " [-0.01124276]\n",
      "\n",
      "Test loss: 0.024918, Train loss: 0.026642\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00115258 -0.00364793 -0.00921981  0.00727448  0.02714166 -0.00599548\n",
      "  -0.03483877]]\n",
      "linear.bias:\n",
      " [-0.01093988]\n",
      "\n",
      "Test loss: 0.024518, Train loss: 0.026224\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00116194 -0.00356548 -0.00883729  0.00714444  0.02672096 -0.00599647\n",
      "  -0.03435936]]\n",
      "linear.bias:\n",
      " [-0.0106396]\n",
      "\n",
      "Test loss: 0.024118, Train loss: 0.025809\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00117103 -0.00348259 -0.00846006  0.007017    0.0263005  -0.00596922\n",
      "  -0.03387848]]\n",
      "linear.bias:\n",
      " [-0.01034219]\n",
      "\n",
      "Test loss: 0.023723, Train loss: 0.025400\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00118066 -0.00340009 -0.00808809  0.00689176  0.02588053 -0.00591446\n",
      "  -0.03339605]]\n",
      "linear.bias:\n",
      " [-0.0100478]\n",
      "\n",
      "Test loss: 0.023333, Train loss: 0.024995\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00118918 -0.00331865 -0.00772141  0.00677353  0.02546108 -0.00582129\n",
      "  -0.03291203]]\n",
      "linear.bias:\n",
      " [-0.00975664]\n",
      "\n",
      "Test loss: 0.022950, Train loss: 0.024594\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00119577 -0.00323835 -0.00736011  0.00665739  0.02504246 -0.00574478\n",
      "  -0.03242632]]\n",
      "linear.bias:\n",
      " [-0.00946884]\n",
      "\n",
      "Test loss: 0.022568, Train loss: 0.024198\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00120055 -0.0031605  -0.00700403  0.00654056  0.02462441 -0.00570667\n",
      "  -0.0319392 ]]\n",
      "linear.bias:\n",
      " [-0.00918414]\n",
      "\n",
      "Test loss: 0.022188, Train loss: 0.023807\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00120397 -0.00308472 -0.00665321  0.006427    0.02420697 -0.00567269\n",
      "  -0.03145074]]\n",
      "linear.bias:\n",
      " [-0.00890254]\n",
      "\n",
      "Test loss: 0.021810, Train loss: 0.023419\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00120633 -0.00301063 -0.00630749  0.00631551  0.02378979 -0.00563924\n",
      "  -0.03096114]]\n",
      "linear.bias:\n",
      " [-0.00862397]\n",
      "\n",
      "Test loss: 0.021434, Train loss: 0.023035\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00120889 -0.0029371  -0.00596718  0.00620199  0.02337334 -0.00563297\n",
      "  -0.03047029]]\n",
      "linear.bias:\n",
      " [-0.00834867]\n",
      "\n",
      "Test loss: 0.021059, Train loss: 0.022655\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00121137 -0.002864   -0.00563202  0.00610033  0.0229576  -0.00552477\n",
      "  -0.02997822]]\n",
      "linear.bias:\n",
      " [-0.00807669]\n",
      "\n",
      "Test loss: 0.020695, Train loss: 0.022280\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00121357 -0.00279208 -0.00530251  0.00600351  0.02254247 -0.00543361\n",
      "  -0.02948485]]\n",
      "linear.bias:\n",
      " [-0.00780806]\n",
      "\n",
      "Test loss: 0.020334, Train loss: 0.021908\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00121467 -0.00272162 -0.00497897  0.00590498  0.02212825 -0.00535343\n",
      "  -0.02899014]]\n",
      "linear.bias:\n",
      " [-0.00754269]\n",
      "\n",
      "Test loss: 0.019975, Train loss: 0.021541\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00121554 -0.00265325 -0.00466134  0.00579853  0.02171505 -0.00533204\n",
      "  -0.0284941 ]]\n",
      "linear.bias:\n",
      " [-0.00728058]\n",
      "\n",
      "Test loss: 0.019616, Train loss: 0.021179\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00121528 -0.00258748 -0.00434995  0.00570003  0.02130324 -0.00522328\n",
      "  -0.02799664]]\n",
      "linear.bias:\n",
      " [-0.00702169]\n",
      "\n",
      "Test loss: 0.019267, Train loss: 0.020821\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00121256 -0.00252373 -0.00404499  0.00560419  0.02089238 -0.00511127\n",
      "  -0.02749795]]\n",
      "linear.bias:\n",
      " [-0.00676598]\n",
      "\n",
      "Test loss: 0.018922, Train loss: 0.020467\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00120805 -0.00246141 -0.00374695  0.00550564  0.02048349 -0.00504535\n",
      "  -0.02699757]]\n",
      "linear.bias:\n",
      " [-0.00651379]\n",
      "\n",
      "Test loss: 0.018579, Train loss: 0.020118\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00120114 -0.00240149 -0.00345646  0.00540485  0.02007629 -0.00504975\n",
      "  -0.02649587]]\n",
      "linear.bias:\n",
      " [-0.00626529]\n",
      "\n",
      "Test loss: 0.018236, Train loss: 0.019776\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00119279 -0.0023425  -0.00317331  0.00530065  0.0196706  -0.00509348\n",
      "  -0.02599316]]\n",
      "linear.bias:\n",
      " [-0.00602044]\n",
      "\n",
      "Test loss: 0.017893, Train loss: 0.019439\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00118287 -0.00228466 -0.0028975   0.00520009  0.019267   -0.00510267\n",
      "  -0.02548937]]\n",
      "linear.bias:\n",
      " [-0.00577927]\n",
      "\n",
      "Test loss: 0.017558, Train loss: 0.019107\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00117167 -0.00222745 -0.00262908  0.00510951  0.01886529 -0.00500339\n",
      "  -0.02498474]]\n",
      "linear.bias:\n",
      " [-0.00554197]\n",
      "\n",
      "Test loss: 0.017233, Train loss: 0.018780\n",
      "Epoch [500/5000], Loss: 0.018457\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00115908 -0.00217052 -0.00236815  0.00502424  0.01846536 -0.00486011\n",
      "  -0.02447933]]\n",
      "linear.bias:\n",
      " [-0.00530861]\n",
      "\n",
      "Test loss: 0.016913, Train loss: 0.018457\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0011451  -0.00211311 -0.00211477  0.00494082  0.01806704 -0.00471782\n",
      "  -0.02397327]]\n",
      "linear.bias:\n",
      " [-0.00507941]\n",
      "\n",
      "Test loss: 0.016597, Train loss: 0.018140\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00112981 -0.00205625 -0.00186894  0.00485198  0.01767038 -0.00461811\n",
      "  -0.0234667 ]]\n",
      "linear.bias:\n",
      " [-0.00485446]\n",
      "\n",
      "Test loss: 0.016283, Train loss: 0.017828\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00111251 -0.00200071 -0.00163078  0.00475311  0.01727586 -0.00459384\n",
      "  -0.02295959]]\n",
      "linear.bias:\n",
      " [-0.00463376]\n",
      "\n",
      "Test loss: 0.015969, Train loss: 0.017521\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00109409 -0.00194667 -0.00140054  0.00464639  0.0168838  -0.00466419\n",
      "  -0.02245187]]\n",
      "linear.bias:\n",
      " [-0.00441756]\n",
      "\n",
      "Test loss: 0.015655, Train loss: 0.017219\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00107442 -0.00189433 -0.00117906  0.00454358  0.01649343 -0.0047122\n",
      "  -0.02194392]]\n",
      "linear.bias:\n",
      " [-0.00420564]\n",
      "\n",
      "Test loss: 0.015350, Train loss: 0.016923\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00105414 -0.0018437  -0.00096651  0.00445167  0.01610471 -0.00469582\n",
      "  -0.02143601]]\n",
      "linear.bias:\n",
      " [-0.0039979]\n",
      "\n",
      "Test loss: 0.015051, Train loss: 0.016633\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00103366 -0.00179422 -0.00076335  0.00437637  0.01571756 -0.00454199\n",
      "  -0.02092833]]\n",
      "linear.bias:\n",
      " [-0.00379446]\n",
      "\n",
      "Test loss: 0.014760, Train loss: 0.016349\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00101413 -0.00174504 -0.00057028  0.00430916  0.01533226 -0.00431422\n",
      "  -0.02042099]]\n",
      "linear.bias:\n",
      " [-0.00359514]\n",
      "\n",
      "Test loss: 0.014476, Train loss: 0.016069\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00099417 -0.00169714 -0.00038705  0.00423556  0.01494939 -0.0041443\n",
      "  -0.01991389]]\n",
      "linear.bias:\n",
      " [-0.00340005]\n",
      "\n",
      "Test loss: 0.014194, Train loss: 0.015796\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00097488 -0.00165126 -0.0002138   0.00414296  0.01456982 -0.00418334\n",
      "  -0.0194067 ]]\n",
      "linear.bias:\n",
      " [-0.00320955]\n",
      "\n",
      "Test loss: 0.013905, Train loss: 0.015528\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.5729780e-04 -1.6071748e-03 -5.0427130e-05  4.0431158e-03\n",
      "   1.4192592e-02 -4.2514992e-03 -1.8899919e-02]]\n",
      "linear.bias:\n",
      " [-0.00302376]\n",
      "\n",
      "Test loss: 0.013621, Train loss: 0.015265\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00094188 -0.00156472  0.00010294  0.00395283  0.01381667 -0.00415051\n",
      "  -0.01839419]]\n",
      "linear.bias:\n",
      " [-0.00284272]\n",
      "\n",
      "Test loss: 0.013346, Train loss: 0.015007\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00092761 -0.00152468  0.00024614  0.00386999  0.01344203 -0.00390645\n",
      "  -0.01788975]]\n",
      "linear.bias:\n",
      " [-0.00266639]\n",
      "\n",
      "Test loss: 0.013080, Train loss: 0.014753\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00091496 -0.00148626  0.00037952  0.0037835   0.01306883 -0.00370341\n",
      "  -0.01738659]]\n",
      "linear.bias:\n",
      " [-0.00249505]\n",
      "\n",
      "Test loss: 0.012817, Train loss: 0.014504\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00090395 -0.00144828  0.00050224  0.00368274  0.01269764 -0.00360923\n",
      "  -0.0168849 ]]\n",
      "linear.bias:\n",
      " [-0.00232899]\n",
      "\n",
      "Test loss: 0.012553, Train loss: 0.014262\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00089455 -0.00141215  0.00061499  0.00356843  0.01232859 -0.00367133\n",
      "  -0.01638461]]\n",
      "linear.bias:\n",
      " [-0.00216813]\n",
      "\n",
      "Test loss: 0.012287, Train loss: 0.014025\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00088736 -0.00137793  0.00071848  0.00344971  0.01196141 -0.00378005\n",
      "  -0.0158858 ]]\n",
      "linear.bias:\n",
      " [-0.0020123]\n",
      "\n",
      "Test loss: 0.012027, Train loss: 0.013790\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.000883   -0.00134516  0.00081302  0.00334197  0.01159552 -0.00371936\n",
      "  -0.01538901]]\n",
      "linear.bias:\n",
      " [-0.00186131]\n",
      "\n",
      "Test loss: 0.011776, Train loss: 0.013560\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00088098 -0.00131415  0.00089921  0.00325076  0.0112311  -0.00346454\n",
      "  -0.01489417]]\n",
      "linear.bias:\n",
      " [-0.00171533]\n",
      "\n",
      "Test loss: 0.011532, Train loss: 0.013333\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00088004 -0.00128374  0.00097668  0.00315578  0.0108686  -0.00323655\n",
      "  -0.01440143]]\n",
      "linear.bias:\n",
      " [-0.00157437]\n",
      "\n",
      "Test loss: 0.011292, Train loss: 0.013109\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0008796  -0.00125392  0.00104543  0.00304115  0.01050877 -0.00318955\n",
      "  -0.01391063]]\n",
      "linear.bias:\n",
      " [-0.0014385]\n",
      "\n",
      "Test loss: 0.011050, Train loss: 0.012892\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00088032 -0.00122442  0.00110527  0.00292359  0.01015126 -0.00319406\n",
      "  -0.01342222]]\n",
      "linear.bias:\n",
      " [-0.00130787]\n",
      "\n",
      "Test loss: 0.010811, Train loss: 0.012678\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00088046 -0.00119322  0.00115585  0.00283432  0.00979589 -0.00304928\n",
      "  -0.01293673]]\n",
      "linear.bias:\n",
      " [-0.00118259]\n",
      "\n",
      "Test loss: 0.010579, Train loss: 0.012470\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087937 -0.00116071  0.00119771  0.00275952  0.0094428  -0.00281421\n",
      "  -0.01245419]]\n",
      "linear.bias:\n",
      " [-0.00106293]\n",
      "\n",
      "Test loss: 0.010355, Train loss: 0.012266\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087754 -0.00112761  0.00123115  0.00268218  0.00909228 -0.00270974\n",
      "  -0.01197471]]\n",
      "linear.bias:\n",
      " [-0.00094899]\n",
      "\n",
      "Test loss: 0.010134, Train loss: 0.012067\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087452 -0.00109323  0.0012566   0.00259977  0.00874449 -0.0027545\n",
      "  -0.01149861]]\n",
      "linear.bias:\n",
      " [-0.00084066]\n",
      "\n",
      "Test loss: 0.009912, Train loss: 0.011873\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00087188 -0.00105834  0.00127406  0.00252766  0.00839928 -0.00273964\n",
      "  -0.01102666]]\n",
      "linear.bias:\n",
      " [-0.00073787]\n",
      "\n",
      "Test loss: 0.009699, Train loss: 0.011683\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0008701  -0.00102196  0.00128387  0.00247522  0.00805659 -0.00256479\n",
      "  -0.01055954]]\n",
      "linear.bias:\n",
      " [-0.00064062]\n",
      "\n",
      "Test loss: 0.009493, Train loss: 0.011500\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086831 -0.00098494  0.00128665  0.00241405  0.00771711 -0.00243088\n",
      "  -0.01009699]]\n",
      "linear.bias:\n",
      " [-0.0005486]\n",
      "\n",
      "Test loss: 0.009292, Train loss: 0.011321\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086443 -0.00094698  0.00128282  0.00234102  0.00738009 -0.00234506\n",
      "  -0.00963969]]\n",
      "linear.bias:\n",
      " [-0.00046184]\n",
      "\n",
      "Test loss: 0.009096, Train loss: 0.011147\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0008577  -0.00090719  0.00127294  0.00225914  0.00704511 -0.0022581\n",
      "  -0.00918811]]\n",
      "linear.bias:\n",
      " [-0.00038029]\n",
      "\n",
      "Test loss: 0.008906, Train loss: 0.010978\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00084915 -0.00086558  0.00125735  0.00217078  0.0067121  -0.0021308\n",
      "  -0.00874249]]\n",
      "linear.bias:\n",
      " [-0.00030352]\n",
      "\n",
      "Test loss: 0.008722, Train loss: 0.010814\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00084013 -0.00082265  0.00123654  0.0020738   0.00638178 -0.00200266\n",
      "  -0.00830282]]\n",
      "linear.bias:\n",
      " [-0.0002318]\n",
      "\n",
      "Test loss: 0.008544, Train loss: 0.010654\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00083123 -0.00077986  0.00121113  0.00196374  0.00605486 -0.00192671\n",
      "  -0.00786908]]\n",
      "linear.bias:\n",
      " [-0.00016516]\n",
      "\n",
      "Test loss: 0.008371, Train loss: 0.010500\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00082262 -0.00073706  0.0011814   0.00184053  0.00573199 -0.00188671\n",
      "  -0.00744163]]\n",
      "linear.bias:\n",
      " [-0.0001033]\n",
      "\n",
      "Test loss: 0.008201, Train loss: 0.010352\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00081483 -0.00069512  0.00114767  0.00172118  0.00541351 -0.00176391\n",
      "  -0.0070205 ]]\n",
      "linear.bias:\n",
      " [-4.5898843e-05]\n",
      "\n",
      "Test loss: 0.008038, Train loss: 0.010209\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00080803 -0.00065284  0.00110991  0.00160475  0.00509891 -0.00160837\n",
      "  -0.00660638]]\n",
      "linear.bias:\n",
      " [7.13774e-06]\n",
      "\n",
      "Test loss: 0.007882, Train loss: 0.010071\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00080095 -0.00061132  0.00106846  0.00149404  0.00478898 -0.00148691\n",
      "  -0.00619927]]\n",
      "linear.bias:\n",
      " [5.5766803e-05]\n",
      "\n",
      "Test loss: 0.007730, Train loss: 0.009939\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0007932  -0.00057041  0.00102382  0.00138508  0.00448384 -0.00145444\n",
      "  -0.00579954]]\n",
      "linear.bias:\n",
      " [0.00010011]\n",
      "\n",
      "Test loss: 0.007586, Train loss: 0.009813\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00078422 -0.00053099  0.00097657  0.00129188  0.00418317 -0.00137805\n",
      "  -0.00540759]]\n",
      "linear.bias:\n",
      " [0.00014049]\n",
      "\n",
      "Test loss: 0.007449, Train loss: 0.009693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00077576 -0.00049394  0.00092761  0.00122356  0.00388728 -0.00120626\n",
      "  -0.00502384]]\n",
      "linear.bias:\n",
      " [0.00017703]\n",
      "\n",
      "Test loss: 0.007320, Train loss: 0.009580\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00077043 -0.00046032  0.00087688  0.00114935  0.00359775 -0.00111924\n",
      "  -0.00464832]]\n",
      "linear.bias:\n",
      " [0.00020998]\n",
      "\n",
      "Test loss: 0.007197, Train loss: 0.009472\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00076916 -0.0004304   0.00082545  0.00107171  0.00331494 -0.0011254\n",
      "  -0.00428137]]\n",
      "linear.bias:\n",
      " [0.0002396]\n",
      "\n",
      "Test loss: 0.007083, Train loss: 0.009372\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00077227 -0.00040419  0.00077406  0.00101281  0.00304008 -0.00101174\n",
      "  -0.00392364]]\n",
      "linear.bias:\n",
      " [0.00026604]\n",
      "\n",
      "Test loss: 0.006979, Train loss: 0.009279\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00077926 -0.00037994  0.00072271  0.00095505  0.00277385 -0.0008711\n",
      "  -0.00357568]]\n",
      "linear.bias:\n",
      " [0.00028926]\n",
      "\n",
      "Test loss: 0.006885, Train loss: 0.009193\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00079071 -0.0003575   0.00067106  0.00086985  0.00251753 -0.00092015\n",
      "  -0.00323759]]\n",
      "linear.bias:\n",
      " [0.00030895]\n",
      "\n",
      "Test loss: 0.006799, Train loss: 0.009116\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.0008064  -0.00033562  0.00061937  0.00081409  0.00226949 -0.00076121\n",
      "  -0.00291118]]\n",
      "linear.bias:\n",
      " [0.00032528]\n",
      "\n",
      "Test loss: 0.006722, Train loss: 0.009045\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00082476 -0.00031486  0.00056753  0.00076307  0.00203134 -0.00061187\n",
      "  -0.00259665]]\n",
      "linear.bias:\n",
      " [0.00033797]\n",
      "\n",
      "Test loss: 0.006657, Train loss: 0.008982\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00084588 -0.00029504  0.00051576  0.00069413  0.00180305 -0.00060684\n",
      "  -0.00229408]]\n",
      "linear.bias:\n",
      " [0.00034788]\n",
      "\n",
      "Test loss: 0.006599, Train loss: 0.008926\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00086966 -0.00027584  0.0004645   0.00061806  0.00158465 -0.00060264\n",
      "  -0.00200442]]\n",
      "linear.bias:\n",
      " [0.00035496]\n",
      "\n",
      "Test loss: 0.006551, Train loss: 0.008876\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00089485 -0.00025662  0.0004147   0.0005467   0.00137523 -0.00041238\n",
      "  -0.00172874]]\n",
      "linear.bias:\n",
      " [0.00035946]\n",
      "\n",
      "Test loss: 0.006511, Train loss: 0.008833\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00092038 -0.00023748  0.00036632  0.00046463  0.00117703 -0.00038137\n",
      "  -0.00146655]]\n",
      "linear.bias:\n",
      " [0.00036181]\n",
      "\n",
      "Test loss: 0.006477, Train loss: 0.008796\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00094678 -0.00021752  0.00031958  0.00037935  0.00099005 -0.0004062\n",
      "  -0.00121879]]\n",
      "linear.bias:\n",
      " [0.00036232]\n",
      "\n",
      "Test loss: 0.006451, Train loss: 0.008765\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00097468 -0.00019759  0.00027467  0.00031604  0.00081445 -0.00023156\n",
      "  -0.00098628]]\n",
      "linear.bias:\n",
      " [0.00036121]\n",
      "\n",
      "Test loss: 0.006429, Train loss: 0.008742\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00100307 -0.00017937  0.00023158  0.00024055  0.0006508  -0.00015479\n",
      "  -0.00076903]]\n",
      "linear.bias:\n",
      " [0.00035873]\n",
      "\n",
      "Test loss: 0.006413, Train loss: 0.008723\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-0.00102939 -0.00016264  0.0001907   0.00015187  0.00049992 -0.0002829\n",
      "  -0.00056707]]\n",
      "linear.bias:\n",
      " [0.00035479]\n",
      "\n",
      "Test loss: 0.006403, Train loss: 0.008709\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0553995e-03 -1.4628618e-04  1.5214839e-04  1.3136124e-04\n",
      "   3.6082463e-04  4.0118466e-06 -3.8227654e-04]]\n",
      "linear.bias:\n",
      " [0.00034915]\n",
      "\n",
      "Test loss: 0.006395, Train loss: 0.008702\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.07783056e-03 -1.30098051e-04  1.15680159e-04  1.01471436e-04\n",
      "   2.34460342e-04  3.84845225e-05 -2.13335938e-04]]\n",
      "linear.bias:\n",
      " [0.00034226]\n",
      "\n",
      "Test loss: 0.006391, Train loss: 0.008696\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.09599798e-03 -1.13628055e-04  8.14392115e-05  6.51879091e-05\n",
      "   1.20400633e-04 -1.08208900e-04 -6.03692897e-05]]\n",
      "linear.bias:\n",
      " [0.00033418]\n",
      "\n",
      "Test loss: 0.006390, Train loss: 0.008694\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.1111117e-03 -9.5426120e-05  4.9599679e-05  7.8061799e-05\n",
      "   1.6872887e-05  3.2373136e-06  7.6356126e-05]]\n",
      "linear.bias:\n",
      " [0.00032509]\n",
      "\n",
      "Test loss: 0.006391, Train loss: 0.008694\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.1220736e-03 -7.7577904e-05  2.0612937e-05  9.4795265e-05\n",
      "  -7.5480413e-05  8.0669044e-05  1.9778693e-04]]\n",
      "linear.bias:\n",
      " [0.00031526]\n",
      "\n",
      "Test loss: 0.006395, Train loss: 0.008694\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.1272971e-03 -5.9979189e-05 -5.7447287e-06  7.9180987e-05\n",
      "  -1.5693950e-04 -4.5601504e-05  3.0419277e-04]]\n",
      "linear.bias:\n",
      " [0.00030519]\n",
      "\n",
      "Test loss: 0.006398, Train loss: 0.008697\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.1292176e-03 -4.3661217e-05 -2.9919478e-05  6.8693684e-05\n",
      "  -2.2917477e-04 -2.4203486e-05  3.9465551e-04]]\n",
      "linear.bias:\n",
      " [0.00029493]\n",
      "\n",
      "Test loss: 0.006402, Train loss: 0.008700\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.1273087e-03 -2.7560216e-05 -5.2054911e-05  6.0000450e-05\n",
      "  -2.9234911e-04  1.4619538e-04  4.7019264e-04]]\n",
      "linear.bias:\n",
      " [0.00028471]\n",
      "\n",
      "Test loss: 0.006406, Train loss: 0.008704\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.12176721e-03 -1.09124485e-05 -7.20330791e-05  7.60871990e-06\n",
      "  -3.45984241e-04  8.66330665e-05  5.32698934e-04]]\n",
      "linear.bias:\n",
      " [0.00027488]\n",
      "\n",
      "Test loss: 0.006408, Train loss: 0.008707\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.1131769e-03  5.5206765e-06 -8.9939662e-05 -3.4561788e-05\n",
      "  -3.9072317e-04  8.0328537e-05  5.8249629e-04]]\n",
      "linear.bias:\n",
      " [0.00026527]\n",
      "\n",
      "Test loss: 0.006410, Train loss: 0.008710\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.1022254e-03  2.1092921e-05 -1.0577774e-04 -5.1702511e-05\n",
      "  -4.2723364e-04  1.7191052e-04  6.2040344e-04]]\n",
      "linear.bias:\n",
      " [0.00025576]\n",
      "\n",
      "Test loss: 0.006412, Train loss: 0.008713\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0883335e-03  3.4825774e-05 -1.1945488e-04 -5.2730426e-05\n",
      "  -4.5570853e-04  2.3117362e-04  6.4778101e-04]]\n",
      "linear.bias:\n",
      " [0.00024655]\n",
      "\n",
      "Test loss: 0.006415, Train loss: 0.008715\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0720373e-03  4.6140227e-05 -1.3099083e-04 -6.0532366e-05\n",
      "  -4.7492166e-04  1.3051780e-04  6.6610490e-04]]\n",
      "linear.bias:\n",
      " [0.00023762]\n",
      "\n",
      "Test loss: 0.006416, Train loss: 0.008717\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0550991e-03  5.4352673e-05 -1.4046322e-04 -5.0506813e-05\n",
      "  -4.8671008e-04  7.4172087e-05  6.7557284e-04]]\n",
      "linear.bias:\n",
      " [0.00022897]\n",
      "\n",
      "Test loss: 0.006418, Train loss: 0.008717\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386348e-03  5.9402610e-05 -1.4786763e-04 -1.1673037e-05\n",
      "  -4.9241388e-04  1.8297110e-04  6.7657401e-04]]\n",
      "linear.bias:\n",
      " [0.00022058]\n",
      "\n",
      "Test loss: 0.006418, Train loss: 0.008718\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0213790e-03  6.1494022e-05 -1.5329929e-04  6.3173884e-06\n",
      "  -4.9061654e-04  1.8430040e-04  6.7070365e-04]]\n",
      "linear.bias:\n",
      " [0.00021294]\n",
      "\n",
      "Test loss: 0.006418, Train loss: 0.008718\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0035395e-03  6.1123705e-05 -1.5700579e-04 -2.5892559e-06\n",
      "  -4.8190760e-04  7.0878661e-05  6.5881870e-04]]\n",
      "linear.bias:\n",
      " [0.0002062]\n",
      "\n",
      "Test loss: 0.006417, Train loss: 0.008718\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.8708633e-04  5.8931506e-05 -1.5881799e-04 -7.5743214e-06\n",
      "  -4.6817656e-04  7.5665157e-05  6.4088590e-04]]\n",
      "linear.bias:\n",
      " [0.00020017]\n",
      "\n",
      "Test loss: 0.006415, Train loss: 0.008717\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.7194762e-04  5.4511751e-05 -1.5888037e-04 -5.5938608e-06\n",
      "  -4.5050218e-04  1.9389435e-04  6.1744498e-04]]\n",
      "linear.bias:\n",
      " [0.00019485]\n",
      "\n",
      "Test loss: 0.006414, Train loss: 0.008716\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.5811539e-04  4.8519916e-05 -1.5774225e-04 -3.1308045e-05\n",
      "  -4.2809077e-04  1.4729262e-04  5.9050589e-04]]\n",
      "linear.bias:\n",
      " [0.0001905]\n",
      "\n",
      "Test loss: 0.006411, Train loss: 0.008715\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.4656507e-04  4.1245243e-05 -1.5536499e-04 -5.8512756e-05\n",
      "  -4.0299870e-04  8.8909539e-05  5.5965799e-04]]\n",
      "linear.bias:\n",
      " [0.00018693]\n",
      "\n",
      "Test loss: 0.006408, Train loss: 0.008713\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.3744858e-04  3.4060526e-05 -1.5173583e-04 -5.1466039e-05\n",
      "  -3.7663788e-04  1.8575427e-04  5.2499800e-04]]\n",
      "linear.bias:\n",
      " [0.00018383]\n",
      "\n",
      "Test loss: 0.006405, Train loss: 0.008712\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.3023008e-04  2.5552799e-05 -1.4741295e-04 -5.3029980e-05\n",
      "  -3.4773405e-04  1.6899691e-04  4.8837432e-04]]\n",
      "linear.bias:\n",
      " [0.00018147]\n",
      "\n",
      "Test loss: 0.006403, Train loss: 0.008710\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.2521671e-04  1.8217510e-05 -1.4227681e-04 -5.2781215e-05\n",
      "  -3.1758027e-04  9.0677997e-05  4.4991515e-04]]\n",
      "linear.bias:\n",
      " [0.00017954]\n",
      "\n",
      "Test loss: 0.006401, Train loss: 0.008708\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.2306611e-04  1.1994092e-05 -1.3627604e-04 -2.9854680e-05\n",
      "  -2.8677646e-04  7.8240133e-05  4.0955297e-04]]\n",
      "linear.bias:\n",
      " [0.00017813]\n",
      "\n",
      "Test loss: 0.006399, Train loss: 0.008706\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.2338916e-04  7.3890433e-06 -1.2968913e-04  8.6858199e-07\n",
      "  -2.5537590e-04  1.1275853e-04  3.6785257e-04]]\n",
      "linear.bias:\n",
      " [0.00017714]\n",
      "\n",
      "Test loss: 0.006397, Train loss: 0.008704\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.2615542e-04  3.5525836e-06 -1.2289884e-04  1.8405353e-05\n",
      "  -2.2317431e-04  6.7698849e-05  3.2574779e-04]]\n",
      "linear.bias:\n",
      " [0.00017666]\n",
      "\n",
      "Test loss: 0.006396, Train loss: 0.008702\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.3141274e-04  4.4179615e-08 -1.1597623e-04  2.8063714e-05\n",
      "  -1.9091205e-04  2.9341449e-05  2.8356383e-04]]\n",
      "linear.bias:\n",
      " [0.00017675]\n",
      "\n",
      "Test loss: 0.006394, Train loss: 0.008701\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.39494115e-04 -4.44977695e-06 -1.08939304e-04  3.75317977e-05\n",
      "  -1.58594572e-04  4.68978615e-05  2.41744652e-04]]\n",
      "linear.bias:\n",
      " [0.00017736]\n",
      "\n",
      "Test loss: 0.006392, Train loss: 0.008699\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.4992272e-04 -1.0610187e-05 -1.0191363e-04  3.8445225e-05\n",
      "  -1.2658958e-04  4.3456275e-05  2.0080134e-04]]\n",
      "linear.bias:\n",
      " [0.00017855]\n",
      "\n",
      "Test loss: 0.006390, Train loss: 0.008698\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.6177636e-04 -1.7508462e-05 -9.4891599e-05  3.5770216e-05\n",
      "  -9.4638584e-05  1.9241234e-06  1.6170822e-04]]\n",
      "linear.bias:\n",
      " [0.00018014]\n",
      "\n",
      "Test loss: 0.006389, Train loss: 0.008696\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.7499875e-04 -2.5085885e-05 -8.7734690e-05  4.4021792e-05\n",
      "  -6.3392930e-05  3.8180700e-05  1.2427989e-04]]\n",
      "linear.bias:\n",
      " [0.00018216]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008696\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.8919787e-04 -3.4045355e-05 -8.0448051e-05  4.3485612e-05\n",
      "  -3.2629916e-05  1.3927944e-05  8.9161163e-05]]\n",
      "linear.bias:\n",
      " [0.00018468]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008695\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0028665e-03 -4.3311415e-05 -7.3107920e-05  4.5924520e-05\n",
      "  -2.9455969e-06  1.0504709e-06  5.6239129e-05]]\n",
      "linear.bias:\n",
      " [0.00018778]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008694\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0155684e-03 -5.3594420e-05 -6.5732071e-05  5.2872820e-05\n",
      "   2.5229787e-05  8.2605147e-06  2.5600006e-05]]\n",
      "linear.bias:\n",
      " [0.0001913]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008694\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0273653e-03 -6.4491076e-05 -5.8444162e-05  5.8122871e-05\n",
      "   5.1796480e-05 -8.3383929e-06 -2.7750011e-06]]\n",
      "linear.bias:\n",
      " [0.00019514]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03809009e-03 -7.50114632e-05 -5.11201506e-05  6.38546626e-05\n",
      "   7.64933502e-05 -1.47965275e-05 -2.91039232e-05]]\n",
      "linear.bias:\n",
      " [0.00019911]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477892e-03 -8.4813648e-05 -4.3872733e-05  7.1824368e-05\n",
      "   9.9221012e-05 -4.6626419e-06 -5.3617281e-05]]\n",
      "linear.bias:\n",
      " [0.0002031]\n",
      "\n",
      "Test loss: 0.006384, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0565571e-03 -9.3527269e-05 -3.6669124e-05  7.8862475e-05\n",
      "   1.2021235e-04 -1.3572061e-05 -7.6195291e-05]]\n",
      "linear.bias:\n",
      " [0.00020703]\n",
      "\n",
      "Test loss: 0.006384, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06428179e-03 -1.01301914e-04 -2.95889295e-05  8.63454552e-05\n",
      "   1.39400407e-04 -4.03498234e-05 -9.69389293e-05]]\n",
      "linear.bias:\n",
      " [0.00021077]\n",
      "\n",
      "Test loss: 0.006384, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0710830e-03 -1.0785156e-04 -2.2573588e-05  1.0300953e-04\n",
      "   1.5666921e-04  5.7575817e-06 -1.1602155e-04]]\n",
      "linear.bias:\n",
      " [0.0002143]\n",
      "\n",
      "Test loss: 0.006384, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.07613427e-03 -1.13849484e-04 -1.55781509e-05  1.02255384e-04\n",
      "   1.72832311e-04 -4.24187165e-05 -1.33281952e-04]]\n",
      "linear.bias:\n",
      " [0.0002176]\n",
      "\n",
      "Test loss: 0.006384, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0802165e-03 -1.1877865e-04 -8.8610686e-06  1.0763774e-04\n",
      "   1.8707820e-04 -3.4613258e-05 -1.4897838e-04]]\n",
      "linear.bias:\n",
      " [0.00022066]\n",
      "\n",
      "Test loss: 0.006384, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0830611e-03 -1.2201044e-04 -2.3674056e-06  1.1534155e-04\n",
      "   1.9971585e-04 -1.2229761e-05 -1.6308419e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.08439941e-03 -1.24223938e-04  3.88687158e-06  1.12860514e-04\n",
      "   2.11044826e-04 -5.95291713e-05 -1.75591078e-04]]\n",
      "linear.bias:\n",
      " [0.00022575]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0847929e-03 -1.2473982e-04  9.7404809e-06  1.2315529e-04\n",
      "   2.2025718e-04 -3.7221784e-05 -1.8696960e-04]]\n",
      "linear.bias:\n",
      " [0.00022786]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.08433014e-03 -1.23581471e-04  1.52495295e-05  1.31164677e-04\n",
      "   2.28163306e-04 -1.17530562e-05 -1.96944326e-04]]\n",
      "linear.bias:\n",
      " [0.00022971]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.08242081e-03 -1.21653764e-04  2.04017360e-05  1.23282996e-04\n",
      "   2.34590450e-04 -5.71616620e-05 -2.05667660e-04]]\n",
      "linear.bias:\n",
      " [0.00023126]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0797529e-03 -1.1862632e-04  2.5138315e-05  1.2265758e-04\n",
      "   2.3955155e-04 -6.0226339e-05 -2.1330849e-04]]\n",
      "linear.bias:\n",
      " [0.00023257]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.07640086e-03 -1.14635623e-04  2.95090449e-05  1.31848938e-04\n",
      "   2.43198010e-04 -1.11607515e-05 -2.19825524e-04]]\n",
      "linear.bias:\n",
      " [0.00023369]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.07245939e-03 -1.10331144e-04  3.34386641e-05  1.29867694e-04\n",
      "   2.46039068e-04 -1.33098629e-05 -2.25178956e-04]]\n",
      "linear.bias:\n",
      " [0.00023462]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06827111e-03 -1.05978484e-04  3.68532747e-05  1.20726923e-04\n",
      "   2.48254975e-04 -5.64863258e-05 -2.29361875e-04]]\n",
      "linear.bias:\n",
      " [0.00023531]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06379786e-03 -1.01794954e-04  3.97607946e-05  1.24546394e-04\n",
      "   2.49631499e-04 -4.78329530e-05 -2.32422128e-04]]\n",
      "linear.bias:\n",
      " [0.00023582]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0598082e-03 -9.7787182e-05  4.2091935e-05  1.2933224e-04\n",
      "   2.5050252e-04 -2.5212315e-05 -2.3444125e-04]]\n",
      "linear.bias:\n",
      " [0.00023617]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0560977e-03 -9.4118521e-05  4.3916236e-05  1.2685562e-04\n",
      "   2.5099222e-04 -3.0554605e-05 -2.3542554e-04]]\n",
      "linear.bias:\n",
      " [0.00023622]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0527885e-03 -9.1009359e-05  4.5186061e-05  1.1966473e-04\n",
      "   2.5120008e-04 -6.0315331e-05 -2.3541013e-04]]\n",
      "linear.bias:\n",
      " [0.00023602]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496452e-03 -8.8585846e-05  4.5849371e-05  1.2621163e-04\n",
      "   2.5084658e-04 -3.0796749e-05 -2.3468428e-04]]\n",
      "linear.bias:\n",
      " [0.00023566]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468471e-03 -8.6598979e-05  4.6072342e-05  1.2714026e-04\n",
      "   2.5029425e-04 -2.9170109e-05 -2.3312609e-04]]\n",
      "linear.bias:\n",
      " [0.00023508]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443599e-03 -8.5005733e-05  4.5898167e-05  1.2300162e-04\n",
      "   2.4956252e-04 -5.2687203e-05 -2.3081699e-04]]\n",
      "linear.bias:\n",
      " [0.0002343]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423434e-03 -8.3845443e-05  4.5303190e-05  1.2338662e-04\n",
      "   2.4869043e-04 -5.4191922e-05 -2.2791598e-04]]\n",
      "linear.bias:\n",
      " [0.00023342]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405676e-03 -8.3390361e-05  4.4341770e-05  1.3022078e-04\n",
      "   2.4746309e-04 -2.5305604e-05 -2.2462560e-04]]\n",
      "linear.bias:\n",
      " [0.00023247]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391392e-03 -8.3278450e-05  4.3180076e-05  1.2833373e-04\n",
      "   2.4602166e-04 -2.9601242e-05 -2.2089746e-04]]\n",
      "linear.bias:\n",
      " [0.00023134]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381944e-03 -8.3624203e-05  4.1938565e-05  1.2058495e-04\n",
      "   2.4428012e-04 -6.1849212e-05 -2.1691491e-04]]\n",
      "linear.bias:\n",
      " [0.00023016]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374589e-03 -8.4306455e-05  4.0500392e-05  1.2442206e-04\n",
      "   2.4210988e-04 -3.4898003e-05 -2.1277688e-04]]\n",
      "linear.bias:\n",
      " [0.00022895]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0373339e-03 -8.5180705e-05  3.9007493e-05  1.2371731e-04\n",
      "   2.3961344e-04 -2.0695741e-05 -2.0862433e-04]]\n",
      "linear.bias:\n",
      " [0.00022777]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03757076e-03 -8.59077263e-05  3.74808187e-05  1.17186755e-04\n",
      "   2.36865526e-04 -3.57439785e-05 -2.04433702e-04]]\n",
      "linear.bias:\n",
      " [0.00022659]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0382436e-03 -8.6876993e-05  3.5968063e-05  1.1240799e-04\n",
      "   2.3387109e-04 -5.1056108e-05 -2.0025384e-04]]\n",
      "linear.bias:\n",
      " [0.00022548]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0390470e-03 -8.8222652e-05  3.4381555e-05  1.1783654e-04\n",
      "   2.3040804e-04 -2.5602511e-05 -1.9622603e-04]]\n",
      "linear.bias:\n",
      " [0.00022438]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399861e-03 -8.9492183e-05  3.2858778e-05  1.1825872e-04\n",
      "   2.2675988e-04 -2.6499893e-05 -1.9222022e-04]]\n",
      "linear.bias:\n",
      " [0.00022331]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409510e-03 -9.0772075e-05  3.1389434e-05  1.1530797e-04\n",
      "   2.2308432e-04 -5.0700408e-05 -1.8821318e-04]]\n",
      "linear.bias:\n",
      " [0.00022232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418931e-03 -9.2315982e-05  2.9913755e-05  1.1613972e-04\n",
      "   2.1931989e-04 -4.4028493e-05 -1.8436446e-04]]\n",
      "linear.bias:\n",
      " [0.00022139]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428805e-03 -9.4066498e-05  2.8454124e-05  1.1978204e-04\n",
      "   2.1548859e-04 -1.0700300e-05 -1.8071466e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04400504e-03 -9.56800213e-05  2.70564615e-05  1.14319526e-04\n",
      "   2.11617633e-04 -2.27562050e-05 -1.77128328e-04]]\n",
      "linear.bias:\n",
      " [0.00021983]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451591e-03 -9.7284727e-05  2.5743540e-05  1.0689014e-04\n",
      "   2.0784611e-04 -4.9675065e-05 -1.7359736e-04]]\n",
      "linear.bias:\n",
      " [0.00021921]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458146e-03 -9.8942357e-05  2.4580948e-05  1.0842465e-04\n",
      "   2.0401794e-04 -3.5794576e-05 -1.7029658e-04]]\n",
      "linear.bias:\n",
      " [0.0002188]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460912e-03 -1.0063187e-04  2.3539531e-05  1.1488422e-04\n",
      "   2.0029025e-04  5.8630067e-06 -1.6722119e-04]]\n",
      "linear.bias:\n",
      " [0.00021854]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464594e-03 -1.0227247e-04  2.2668552e-05  1.0956309e-04\n",
      "   1.9680015e-04 -2.2661512e-05 -1.6425157e-04]]\n",
      "linear.bias:\n",
      " [0.00021831]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465134e-03 -1.0369195e-04  2.1937696e-05  1.0221255e-04\n",
      "   1.9353708e-04 -6.5405184e-05 -1.6134814e-04]]\n",
      "linear.bias:\n",
      " [0.00021819]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461921e-03 -1.0433293e-04  2.1337853e-05  1.0860272e-04\n",
      "   1.8993761e-04 -3.1105890e-05 -1.5887529e-04]]\n",
      "linear.bias:\n",
      " [0.00021817]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456543e-03 -1.0489741e-04  2.0810743e-05  1.1410352e-04\n",
      "   1.8677363e-04  1.6765051e-05 -1.5650892e-04]]\n",
      "linear.bias:\n",
      " [0.00021833]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450020e-03 -1.0546724e-04  2.0503536e-05  1.0433657e-04\n",
      "   1.8366014e-04 -4.0579260e-05 -1.5431599e-04]]\n",
      "linear.bias:\n",
      " [0.0002185]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04423240e-03 -1.06161227e-04  2.02632600e-05  1.00768884e-04\n",
      "   1.80884585e-04 -5.81823042e-05 -1.52277906e-04]]\n",
      "linear.bias:\n",
      " [0.00021868]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04335346e-03 -1.06265135e-04  2.01569364e-05  1.09010274e-04\n",
      "   1.78041984e-04 -2.10553189e-05 -1.50589476e-04]]\n",
      "linear.bias:\n",
      " [0.00021884]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04253658e-03 -1.06576525e-04  2.02768970e-05  1.11761517e-04\n",
      "   1.75998648e-04 -1.18822263e-05 -1.48770545e-04]]\n",
      "linear.bias:\n",
      " [0.00021902]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417375e-03 -1.0707123e-04  2.0603380e-05  1.0905656e-04\n",
      "   1.7471999e-04 -3.4673245e-05 -1.4680656e-04]]\n",
      "linear.bias:\n",
      " [0.00021918]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04090455e-03 -1.07747233e-04  2.10359503e-05  1.03965576e-04\n",
      "   1.74075103e-04 -4.23178681e-05 -1.44802121e-04]]\n",
      "linear.bias:\n",
      " [0.00021944]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04011910e-03 -1.07799613e-04  2.14962656e-05  1.05154395e-04\n",
      "   1.73293345e-04 -1.14557406e-06 -1.43145444e-04]]\n",
      "linear.bias:\n",
      " [0.00021971]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03934435e-03 -1.07980988e-04  2.20695129e-05  1.00078076e-04\n",
      "   1.72943546e-04 -2.99552676e-06 -1.41358643e-04]]\n",
      "linear.bias:\n",
      " [0.00021992]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0385498e-03 -1.0832267e-04  2.2754737e-05  9.1349903e-05\n",
      "   1.7300480e-04 -3.7041686e-05 -1.3945645e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0378654e-03 -1.0826897e-04  2.3474855e-05  9.6278221e-05\n",
      "   1.7280722e-04 -1.5431244e-05 -1.3788289e-04]]\n",
      "linear.bias:\n",
      " [0.00022028]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03745353e-03 -1.08130866e-04  2.42097321e-05  1.02080565e-04\n",
      "   1.72822402e-04 -7.48058119e-06 -1.36358038e-04]]\n",
      "linear.bias:\n",
      " [0.00022043]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03740313e-03 -1.08412176e-04  2.49279565e-05  1.00572513e-04\n",
      "   1.73231296e-04 -3.58568141e-05 -1.34710819e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03748764e-03 -1.07930144e-04  2.55143514e-05  1.06330473e-04\n",
      "   1.73195658e-04 -1.09780522e-05 -1.33513371e-04]]\n",
      "linear.bias:\n",
      " [0.00022075]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03788846e-03 -1.07677195e-04  2.60321758e-05  1.04768180e-04\n",
      "   1.73405526e-04 -1.48898971e-05 -1.32233356e-04]]\n",
      "linear.bias:\n",
      " [0.00022098]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383825e-03 -1.0713754e-04  2.6482099e-05  1.0066933e-04\n",
      "   1.7361053e-04 -2.2522294e-05 -1.3108339e-04]]\n",
      "linear.bias:\n",
      " [0.0002213]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03889569e-03 -1.05896404e-04  2.68393942e-05  1.02264006e-04\n",
      "   1.73389562e-04  5.80290725e-06 -1.30328466e-04]]\n",
      "linear.bias:\n",
      " [0.00022165]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0398226e-03 -1.0474283e-04  2.7127377e-05  9.0980800e-05\n",
      "   1.7314214e-04 -3.8758739e-05 -1.2976452e-04]]\n",
      "linear.bias:\n",
      " [0.00022209]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406843e-03 -1.0307384e-04  2.7396627e-05  9.3833762e-05\n",
      "   1.7224278e-04 -2.0887843e-05 -1.2964547e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414365e-03 -1.0178842e-04  2.7604521e-05  1.0395276e-04\n",
      "   1.7130467e-04  2.4426818e-05 -1.2969176e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04196637e-03 -1.00873156e-04  2.77747440e-05  9.36966535e-05\n",
      "   1.70318424e-04 -5.02574767e-05 -1.30102519e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424576e-03 -9.9435711e-05  2.7900798e-05  9.6967677e-05\n",
      "   1.6884475e-04 -5.8662128e-05 -1.3084779e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429478e-03 -9.7564473e-05  2.8038290e-05  1.1137291e-04\n",
      "   1.6712215e-04 -6.2052750e-06 -1.3186017e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435497e-03 -9.6310039e-05  2.8227141e-05  1.1270389e-04\n",
      "   1.6599607e-04 -7.6653450e-06 -1.3262089e-04]]\n",
      "linear.bias:\n",
      " [0.00022404]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442525e-03 -9.5611758e-05  2.8462331e-05  1.0224510e-04\n",
      "   1.6540784e-04 -5.7655921e-05 -1.3315471e-04]]\n",
      "linear.bias:\n",
      " [0.00022424]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450279e-03 -9.4363379e-05  2.8665165e-05  1.0168531e-04\n",
      "   1.6465351e-04 -4.8211426e-05 -1.3391138e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04578456e-03 -9.35415956e-05  2.88552474e-05  1.09134955e-04\n",
      "   1.64077734e-04  3.07874870e-06 -1.34689428e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04661984e-03 -9.34903946e-05  2.91397864e-05  1.03599064e-04\n",
      "   1.64293509e-04 -2.15515411e-06 -1.35144233e-04]]\n",
      "linear.bias:\n",
      " [0.00022444]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476727e-03 -9.4155657e-05  2.9501454e-05  9.2693052e-05\n",
      "   1.6519146e-04 -4.5514236e-05 -1.3513859e-04]]\n",
      "linear.bias:\n",
      " [0.00022445]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485217e-03 -9.5112577e-05  2.9851291e-05  9.4372430e-05\n",
      "   1.6604135e-04 -3.9034130e-05 -1.3519831e-04]]\n",
      "linear.bias:\n",
      " [0.00022439]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493266e-03 -9.6298449e-05  3.0178773e-05  1.0477504e-04\n",
      "   1.6690185e-04  6.2163053e-06 -1.3522500e-04]]\n",
      "linear.bias:\n",
      " [0.00022431]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501720e-03 -9.8021192e-05  3.0535826e-05  1.0292473e-04\n",
      "   1.6822202e-04 -5.7611996e-06 -1.3503688e-04]]\n",
      "linear.bias:\n",
      " [0.00022424]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512426e-03 -1.0003032e-04  3.0914973e-05  9.5872820e-05\n",
      "   1.6980937e-04 -5.2511212e-05 -1.3454494e-04]]\n",
      "linear.bias:\n",
      " [0.00022415]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05219183e-03 -1.01269914e-04  3.12641278e-05  1.01993777e-04\n",
      "   1.70949716e-04 -3.73758157e-05 -1.34347778e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528713e-03 -1.0239771e-04  3.1541622e-05  1.1256686e-04\n",
      "   1.7180129e-04  1.5790174e-05 -1.3429079e-04]]\n",
      "linear.bias:\n",
      " [0.00022393]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528724e-03 -1.0335007e-04  3.1711083e-05  9.9348610e-05\n",
      "   1.7239572e-04 -4.8642869e-05 -1.3466939e-04]]\n",
      "linear.bias:\n",
      " [0.00022387]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528438e-03 -1.0354622e-04  3.1829521e-05  9.9413555e-05\n",
      "   1.7243491e-04 -5.1798528e-05 -1.3532644e-04]]\n",
      "linear.bias:\n",
      " [0.00022381]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0527871e-03 -1.0306922e-04  3.1891621e-05  1.1158013e-04\n",
      "   1.7199104e-04  1.5681289e-06 -1.3624418e-04]]\n",
      "linear.bias:\n",
      " [0.00022373]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528633e-03 -1.0293172e-04  3.2005326e-05  1.1041666e-04\n",
      "   1.7189179e-04  2.1996575e-06 -1.3686973e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0531234e-03 -1.0318074e-04  3.2159722e-05  9.7839322e-05\n",
      "   1.7218220e-04 -4.3392371e-05 -1.3722037e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05332665e-03 -1.02725986e-04  3.22589149e-05  9.80677505e-05\n",
      "   1.71959196e-04 -3.10976902e-05 -1.37781622e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05330907e-03 -1.02393460e-04  3.23167733e-05  1.05552346e-04\n",
      "   1.71570413e-04  1.93913766e-05 -1.38347867e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05257914e-03 -1.02318634e-04  3.24373941e-05  9.35663265e-05\n",
      "   1.71291089e-04 -4.04318198e-05 -1.39003605e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05178438e-03 -1.02354395e-04  3.25090114e-05  9.33178380e-05\n",
      "   1.70963991e-04 -4.95335262e-05 -1.39625146e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510528e-03 -1.0178624e-04  3.2586046e-05  1.0511225e-04\n",
      "   1.7037230e-04 -3.8180369e-06 -1.4035213e-04]]\n",
      "linear.bias:\n",
      " [0.00022274]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05055433e-03 -1.01675716e-04  3.26994814e-05  1.06741260e-04\n",
      "   1.70205589e-04 -7.06578703e-06 -1.40704622e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05041859e-03 -1.02039776e-04  3.28599708e-05  1.02751364e-04\n",
      "   1.70459098e-04 -4.57116075e-05 -1.40695091e-04]]\n",
      "linear.bias:\n",
      " [0.00022229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503005e-03 -1.0246013e-04  3.2950560e-05  1.0766640e-04\n",
      "   1.7067054e-04 -3.8905218e-05 -1.4070584e-04]]\n",
      "linear.bias:\n",
      " [0.00022208]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05005340e-03 -1.02897233e-04  3.30244875e-05  1.13070804e-04\n",
      "   1.70878804e-04  1.05323488e-06 -1.40786680e-04]]\n",
      "linear.bias:\n",
      " [0.00022199]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05002406e-03 -1.03667720e-04  3.31435767e-05  1.06298015e-04\n",
      "   1.71450127e-04 -9.07063259e-06 -1.40644406e-04]]\n",
      "linear.bias:\n",
      " [0.00022187]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503312e-03 -1.0478375e-04  3.3309243e-05  9.3205876e-05\n",
      "   1.7237579e-04 -5.3456024e-05 -1.4023193e-04]]\n",
      "linear.bias:\n",
      " [0.00022177]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505765e-03 -1.0510248e-04  3.3418139e-05  9.3094561e-05\n",
      "   1.7271965e-04 -4.0127681e-05 -1.4010843e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05076598e-03 -1.04702231e-04  3.34758515e-05  1.04688224e-04\n",
      "   1.72538887e-04  2.51287238e-05 -1.40245509e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05063093e-03 -1.04498635e-04  3.35666991e-05  9.78939715e-05\n",
      "   1.72258297e-04 -3.33542012e-05 -1.40574761e-04]]\n",
      "linear.bias:\n",
      " [0.00022175]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504978e-03 -1.0432592e-04  3.3541055e-05  9.9920573e-05\n",
      "   1.7179691e-04 -4.5288500e-05 -1.4097099e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503663e-03 -1.0418103e-04  3.3410353e-05  1.0990165e-04\n",
      "   1.7117245e-04 -1.5301110e-05 -1.4142766e-04]]\n",
      "linear.bias:\n",
      " [0.00022196]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05048483e-03 -1.04254585e-04  3.32352975e-05  1.10161775e-04\n",
      "   1.70831074e-04 -1.51589120e-05 -1.41648299e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05082884e-03 -1.04525141e-04  3.30202238e-05  1.01656056e-04\n",
      "   1.70744956e-04 -4.19156713e-05 -1.41656099e-04]]\n",
      "linear.bias:\n",
      " [0.00022234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05114304e-03 -1.04862280e-04  3.27718699e-05  1.02593665e-04\n",
      "   1.70650237e-04 -2.44545317e-05 -1.41682685e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05116400e-03 -1.05346669e-04  3.25316287e-05  1.04069375e-04\n",
      "   1.70577550e-04  5.63168032e-06 -1.41670578e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0513457e-03 -1.0619049e-04  3.2359902e-05  9.6270560e-05\n",
      "   1.7088398e-04 -1.1719339e-05 -1.4135262e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05141185e-03 -1.07075495e-04  3.23680033e-05  8.88719296e-05\n",
      "   1.71482665e-04 -5.14109779e-05 -1.40801494e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0513136e-03 -1.0719871e-04  3.2367967e-05  9.6004231e-05\n",
      "   1.7170658e-04 -3.0031200e-05 -1.4043374e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05101988e-03 -1.07388616e-04  3.23357235e-05  1.09864457e-04\n",
      "   1.71716223e-04  2.85730403e-05 -1.40164382e-04]]\n",
      "linear.bias:\n",
      " [0.00022306]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498752e-03 -1.0703671e-04  3.2207987e-05  1.0038310e-04\n",
      "   1.7179624e-04 -4.6427966e-05 -1.4020185e-04]]\n",
      "linear.bias:\n",
      " [0.00022315]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489566e-03 -1.0601187e-04  3.2034888e-05  1.0156362e-04\n",
      "   1.7143125e-04 -6.4140964e-05 -1.4047543e-04]]\n",
      "linear.bias:\n",
      " [0.00022323]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04814954e-03 -1.04360974e-04  3.19079008e-05  1.12319736e-04\n",
      "   1.70892381e-04 -1.82011281e-05 -1.40941149e-04]]\n",
      "linear.bias:\n",
      " [0.00022333]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474749e-03 -1.0306346e-04  3.1731728e-05  1.1168120e-04\n",
      "   1.7061562e-04 -5.8077712e-06 -1.4119495e-04]]\n",
      "linear.bias:\n",
      " [0.00022346]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470506e-03 -1.0226083e-04  3.1617925e-05  1.0037134e-04\n",
      "   1.7074689e-04 -3.8391823e-05 -1.4115902e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466727e-03 -1.0163216e-04  3.1460204e-05  9.8872952e-05\n",
      "   1.7084782e-04 -2.6295136e-05 -1.4114643e-04]]\n",
      "linear.bias:\n",
      " [0.00022355]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04603788e-03 -1.01586535e-04  3.14088866e-05  1.02822392e-04\n",
      "   1.71115782e-04  2.11587030e-06 -1.40993579e-04]]\n",
      "linear.bias:\n",
      " [0.00022356]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458187e-03 -1.0197397e-04  3.1411695e-05  9.8667384e-05\n",
      "   1.7174818e-04 -1.4434565e-05 -1.4051823e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459340e-03 -1.0300980e-04  3.1418851e-05  9.6199205e-05\n",
      "   1.7248694e-04 -4.0525640e-05 -1.3993069e-04]]\n",
      "linear.bias:\n",
      " [0.00022336]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460424e-03 -1.0403776e-04  3.1369884e-05  1.0269976e-04\n",
      "   1.7313508e-04 -2.2483970e-05 -1.3942124e-04]]\n",
      "linear.bias:\n",
      " [0.00022323]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458700e-03 -1.0511353e-04  3.1300155e-05  1.1021621e-04\n",
      "   1.7373091e-04  9.5657324e-06 -1.3895014e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457047e-03 -1.0608475e-04  3.1306870e-05  1.0072910e-04\n",
      "   1.7405674e-04 -3.9894614e-05 -1.3857748e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04566978e-03 -1.06244166e-04  3.12542652e-05  1.02007107e-04\n",
      "   1.73908411e-04 -3.44945256e-05 -1.38484189e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04563171e-03 -1.06375024e-04  3.10910218e-05  1.10774490e-04\n",
      "   1.73566819e-04  1.05955078e-05 -1.38519856e-04]]\n",
      "linear.bias:\n",
      " [0.00022291]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455600e-03 -1.0639388e-04  3.1015712e-05  1.0114715e-04\n",
      "   1.7302104e-04 -3.4830926e-05 -1.3868533e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04548875e-03 -1.06398089e-04  3.08317831e-05  1.00104175e-04\n",
      "   1.72320972e-04 -3.55638949e-05 -1.38954347e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454127e-03 -1.0641287e-04  3.0555791e-05  1.0751592e-04\n",
      "   1.7147626e-04  4.5017005e-06 -1.3929891e-04]]\n",
      "linear.bias:\n",
      " [0.00022292]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04553008e-03 -1.06797175e-04  3.03526431e-05  1.03325176e-04\n",
      "   1.71100779e-04 -3.23723361e-06 -1.39341326e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459606e-03 -1.0762390e-04  3.0230045e-05  9.3901879e-05\n",
      "   1.7118092e-04 -4.5854031e-05 -1.3904054e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463323e-03 -1.0774457e-04  3.0132605e-05  9.7887038e-05\n",
      "   1.7094436e-04 -3.0377800e-05 -1.3894319e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04665523e-03 -1.07864304e-04  2.99340973e-05  1.09859844e-04\n",
      "   1.70516374e-04  2.43166869e-05 -1.38958087e-04]]\n",
      "linear.bias:\n",
      " [0.00022278]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465811e-03 -1.0781991e-04  2.9845825e-05  9.8161545e-05\n",
      "   1.7000883e-04 -4.7770591e-05 -1.3929118e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04664569e-03 -1.07142325e-04  2.97618917e-05  9.79707402e-05\n",
      "   1.69303079e-04 -6.22296720e-05 -1.39753378e-04]]\n",
      "linear.bias:\n",
      " [0.00022291]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467517e-03 -1.0587582e-04  2.9679786e-05  1.1085030e-04\n",
      "   1.6846135e-04 -1.6914779e-05 -1.4035335e-04]]\n",
      "linear.bias:\n",
      " [0.00022295]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471297e-03 -1.0519235e-04  2.9615945e-05  1.1400212e-04\n",
      "   1.6804946e-04 -5.2568103e-06 -1.4064810e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476575e-03 -1.0495052e-04  2.9604274e-05  1.0589413e-04\n",
      "   1.6806691e-04 -3.8410653e-05 -1.4064355e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04803848e-03 -1.04807288e-04  2.96214130e-05  1.02346945e-04\n",
      "   1.68238083e-04 -3.13414930e-05 -1.40665928e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04829692e-03 -1.05042847e-04  2.97431088e-05  1.03705046e-04\n",
      "   1.68690705e-04  4.36346454e-06 -1.40593707e-04]]\n",
      "linear.bias:\n",
      " [0.00022299]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04888971e-03 -1.05692474e-04  2.99027997e-05  9.70630426e-05\n",
      "   1.69497565e-04 -5.52743859e-06 -1.40183998e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493587e-03 -1.0643426e-04  3.0219933e-05  8.7850865e-05\n",
      "   1.7057327e-04 -4.5304918e-05 -1.3950725e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497649e-03 -1.0647171e-04  3.0518775e-05  9.2153721e-05\n",
      "   1.7123029e-04 -2.7388065e-05 -1.3907308e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05011882e-03 -1.06516585e-04  3.06760812e-05  1.04498227e-04\n",
      "   1.71605003e-04  2.94172278e-05 -1.38785646e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498858e-03 -1.0660000e-04  3.0852429e-05  9.5690739e-05\n",
      "   1.7179978e-04 -4.4779088e-05 -1.3878058e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04964292e-03 -1.05956635e-04  3.09690731e-05  9.99549375e-05\n",
      "   1.71462496e-04 -5.88396106e-05 -1.39035605e-04]]\n",
      "linear.bias:\n",
      " [0.00022259]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04940648e-03 -1.04753162e-04  3.10763753e-05  1.16573385e-04\n",
      "   1.70864136e-04 -1.66696191e-05 -1.39451629e-04]]\n",
      "linear.bias:\n",
      " [0.00022257]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04927982e-03 -1.03816667e-04  3.10982905e-05  1.18724456e-04\n",
      "   1.70516869e-04 -1.39997264e-05 -1.39653057e-04]]\n",
      "linear.bias:\n",
      " [0.00022255]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04926608e-03 -1.03139013e-04  3.10520736e-05  1.06678686e-04\n",
      "   1.70406754e-04 -4.90225284e-05 -1.39707801e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490825e-03 -1.0262651e-04  3.1026444e-05  1.0165349e-04\n",
      "   1.7032027e-04 -4.0862218e-05 -1.3980213e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04872056e-03 -1.02333055e-04  3.10255673e-05  1.05274019e-04\n",
      "   1.70243598e-04  6.23346205e-06 -1.39867479e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485644e-03 -1.0249361e-04  3.1071402e-05  9.9034907e-05\n",
      "   1.7056239e-04  4.5410816e-06 -1.3960614e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487880e-03 -1.0308074e-04  3.1163330e-05  8.5462503e-05\n",
      "   1.7125331e-04 -3.8911487e-05 -1.3902207e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489728e-03 -1.0297216e-04  3.1259431e-05  8.5963948e-05\n",
      "   1.7156037e-04 -2.4468452e-05 -1.3867326e-04]]\n",
      "linear.bias:\n",
      " [0.00022224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04902079e-03 -1.03113285e-04  3.13774908e-05  9.82795900e-05\n",
      "   1.71725958e-04  1.36515737e-05 -1.38393385e-04]]\n",
      "linear.bias:\n",
      " [0.00022209]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04933849e-03 -1.03364495e-04  3.15182915e-05  1.00530611e-04\n",
      "   1.71971376e-04 -1.67174912e-05 -1.37936935e-04]]\n",
      "linear.bias:\n",
      " [0.00022186]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493628e-03 -1.0407601e-04  3.1701285e-05  1.0291510e-04\n",
      "   1.7232366e-04 -4.1684732e-05 -1.3742206e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493980e-03 -1.0465763e-04  3.1746484e-05  1.1130934e-04\n",
      "   1.7243247e-04 -2.3615086e-05 -1.3712845e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491080e-03 -1.0540741e-04  3.1783107e-05  1.1577537e-04\n",
      "   1.7260906e-04 -3.1601176e-06 -1.3684607e-04]]\n",
      "linear.bias:\n",
      " [0.00022181]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489294e-03 -1.0622227e-04  3.1658114e-05  1.0251031e-04\n",
      "   1.7269215e-04 -2.8140326e-05 -1.3667667e-04]]\n",
      "linear.bias:\n",
      " [0.00022203]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04851020e-03 -1.06949374e-04  3.15195866e-05  9.39758684e-05\n",
      "   1.72576736e-04 -2.66338557e-05 -1.36647315e-04]]\n",
      "linear.bias:\n",
      " [0.00022229]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480605e-03 -1.0760000e-04  3.1285916e-05  9.4221148e-05\n",
      "   1.7222053e-04  5.0063118e-06 -1.3674381e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476204e-03 -1.0817454e-04  3.1232175e-05  9.2373361e-05\n",
      "   1.7214805e-04 -4.8920938e-06 -1.3659535e-04]]\n",
      "linear.bias:\n",
      " [0.00022264]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470443e-03 -1.0884650e-04  3.1343239e-05  9.2374670e-05\n",
      "   1.7227641e-04 -3.4911180e-05 -1.3620117e-04]]\n",
      "linear.bias:\n",
      " [0.00022271]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04649190e-03 -1.08720189e-04  3.14002973e-05  1.04788895e-04\n",
      "   1.71869906e-04 -8.86258931e-06 -1.36110408e-04]]\n",
      "linear.bias:\n",
      " [0.00022281]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04586792e-03 -1.08504544e-04  3.15682373e-05  1.09196299e-04\n",
      "   1.71807405e-04 -1.45564054e-05 -1.35800408e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04555755e-03 -1.08527034e-04  3.16586593e-05  1.03916303e-04\n",
      "   1.71986045e-04 -4.65678022e-05 -1.35318522e-04]]\n",
      "linear.bias:\n",
      " [0.00022317]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454223e-03 -1.0773021e-04  3.1672695e-05  1.0702878e-04\n",
      "   1.7169814e-04 -2.5474743e-05 -1.3520282e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451173e-03 -1.0698240e-04  3.1671370e-05  1.1120627e-04\n",
      "   1.7139409e-04  1.4734869e-05 -1.3520420e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446415e-03 -1.0592594e-04  3.1584295e-05  9.2410221e-05\n",
      "   1.7066202e-04 -4.7031725e-05 -1.3571129e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04418071e-03 -1.04254206e-04  3.14686113e-05  8.84550609e-05\n",
      "   1.69462583e-04 -4.81073221e-05 -1.36511851e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437489e-03 -1.0212512e-04  3.1372670e-05  9.8460980e-05\n",
      "   1.6806558e-04  7.5505523e-06 -1.3750177e-04]]\n",
      "linear.bias:\n",
      " [0.00022432]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437667e-03 -1.0052052e-04  3.1326948e-05  9.9542354e-05\n",
      "   1.6711099e-04  6.6322723e-06 -1.3809183e-04]]\n",
      "linear.bias:\n",
      " [0.00022436]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441712e-03 -9.9614597e-05  3.1394313e-05  9.2859264e-05\n",
      "   1.6686809e-04 -3.5545414e-05 -1.3818189e-04]]\n",
      "linear.bias:\n",
      " [0.00022429]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445794e-03 -9.9154226e-05  3.1468520e-05  9.6564167e-05\n",
      "   1.6675344e-04 -3.4470020e-05 -1.3823323e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449911e-03 -9.9095560e-05  3.1548901e-05  1.0963548e-04\n",
      "   1.6675443e-04  5.5616656e-06 -1.3824966e-04]]\n",
      "linear.bias:\n",
      " [0.00022408]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04554556e-03 -9.96436211e-05  3.16739715e-05  1.07824795e-04\n",
      "   1.67302700e-04 -7.77597870e-06 -1.38014322e-04]]\n",
      "linear.bias:\n",
      " [0.00022397]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04643824e-03 -1.00543344e-04  3.18383281e-05  9.64331048e-05\n",
      "   1.68216066e-04 -6.14190067e-05 -1.37492971e-04]]\n",
      "linear.bias:\n",
      " [0.00022384]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472256e-03 -1.0072664e-04  3.1994714e-05  9.9825724e-05\n",
      "   1.6872030e-04 -5.3000615e-05 -1.3729383e-04]]\n",
      "linear.bias:\n",
      " [0.00022366]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480706e-03 -1.0023587e-04  3.2119660e-05  1.1379728e-04\n",
      "   1.6893449e-04  6.5901731e-06 -1.3729409e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04877190e-03 -1.00318284e-04  3.23274216e-05  1.09451219e-04\n",
      "   1.69586579e-04 -1.11577920e-05 -1.37244904e-04]]\n",
      "linear.bias:\n",
      " [0.00022322]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494990e-03 -1.0085236e-04  3.2521068e-05  9.5134354e-05\n",
      "   1.7051963e-04 -5.8569858e-05 -1.3697299e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501372e-03 -1.0070392e-04  3.2703869e-05  9.5939540e-05\n",
      "   1.7104042e-04 -4.4587425e-05 -1.3699956e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505450e-03 -1.0059399e-04  3.2770600e-05  1.0770145e-04\n",
      "   1.7121994e-04  1.1891614e-05 -1.3714380e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508844e-03 -1.0080227e-04  3.2903110e-05  9.9767989e-05\n",
      "   1.7146600e-04 -2.5873112e-05 -1.3741948e-04]]\n",
      "linear.bias:\n",
      " [0.00022255]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05082500e-03 -1.01172205e-04  3.29829199e-05  9.64773280e-05\n",
      "   1.71550957e-04 -4.12784902e-05 -1.37673807e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05060393e-03 -1.01529324e-04  3.29565992e-05  1.04578547e-04\n",
      "   1.71337058e-04 -1.12968792e-05 -1.38023548e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507477e-03 -1.0235830e-04  3.2996668e-05  1.0592953e-04\n",
      "   1.7158609e-04 -1.9894920e-05 -1.3798071e-04]]\n",
      "linear.bias:\n",
      " [0.00022259]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505463e-03 -1.0333735e-04  3.3028551e-05  1.0396661e-04\n",
      "   1.7189122e-04 -2.3453022e-05 -1.3792374e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05010183e-03 -1.04367165e-04  3.30392577e-05  1.01234858e-04\n",
      "   1.72185915e-04 -1.18233220e-05 -1.37881565e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496334e-03 -1.0545883e-04  3.3230386e-05  9.5399671e-05\n",
      "   1.7281676e-04 -3.2311633e-05 -1.3752133e-04]]\n",
      "linear.bias:\n",
      " [0.00022322]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04919879e-03 -1.06453896e-04  3.32854615e-05  9.89854743e-05\n",
      "   1.73157779e-04 -9.95710616e-06 -1.37305324e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04869506e-03 -1.07218264e-04  3.34343713e-05  9.93462018e-05\n",
      "   1.73705543e-04 -1.69468221e-05 -1.36865579e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480565e-03 -1.0806245e-04  3.3449131e-05  1.0350987e-04\n",
      "   1.7403878e-04 -1.2549523e-05 -1.3650057e-04]]\n",
      "linear.bias:\n",
      " [0.00022388]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04732625e-03 -1.08699423e-04  3.35179102e-05  1.00375226e-04\n",
      "   1.74502289e-04 -3.08131821e-05 -1.36000555e-04]]\n",
      "linear.bias:\n",
      " [0.00022419]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467959e-03 -1.0848241e-04  3.3510834e-05  1.0727141e-04\n",
      "   1.7445294e-04  2.2750064e-06 -1.3582851e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04631891e-03 -1.07999374e-04  3.34597753e-05  9.98272662e-05\n",
      "   1.74371991e-04 -2.97310617e-05 -1.35546157e-04]]\n",
      "linear.bias:\n",
      " [0.00022467]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459550e-03 -1.0675570e-04  3.3349763e-05  1.0216136e-04\n",
      "   1.7379897e-04 -1.9486293e-05 -1.3558874e-04]]\n",
      "linear.bias:\n",
      " [0.00022481]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04560202e-03 -1.05624349e-04  3.31565643e-05  1.07285916e-04\n",
      "   1.73208071e-04  2.48129800e-06 -1.35712355e-04]]\n",
      "linear.bias:\n",
      " [0.000225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04551925e-03 -1.04860526e-04  3.30199473e-05  1.00493460e-04\n",
      "   1.72977365e-04 -3.07286573e-05 -1.35592330e-04]]\n",
      "linear.bias:\n",
      " [0.00022507]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04543206e-03 -1.04184212e-04  3.27788039e-05  1.03288425e-04\n",
      "   1.72540400e-04 -1.96956480e-05 -1.35593611e-04]]\n",
      "linear.bias:\n",
      " [0.00022517]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455889e-03 -1.0404941e-04  3.2432927e-05  1.0455667e-04\n",
      "   1.7212424e-04 -1.3217016e-05 -1.3554639e-04]]\n",
      "linear.bias:\n",
      " [0.00022526]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460730e-03 -1.0437515e-04  3.2121130e-05  9.8076576e-05\n",
      "   1.7205361e-04 -3.5693261e-05 -1.3525347e-04]]\n",
      "linear.bias:\n",
      " [0.00022534]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04663195e-03 -1.03897459e-04  3.17770428e-05  1.02792794e-04\n",
      "   1.71513791e-04 -5.72363933e-06 -1.35250884e-04]]\n",
      "linear.bias:\n",
      " [0.00022541]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475263e-03 -1.0394268e-04  3.1520849e-05  1.0235280e-04\n",
      "   1.7141168e-04 -1.3473151e-05 -1.3489620e-04]]\n",
      "linear.bias:\n",
      " [0.00022541]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04820041e-03 -1.04406718e-04  3.14240751e-05  1.02110615e-04\n",
      "   1.71555876e-04 -4.04091406e-05 -1.34388232e-04]]\n",
      "linear.bias:\n",
      " [0.0002253]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04895176e-03 -1.04003135e-04  3.12733500e-05  1.10805435e-04\n",
      "   1.71214502e-04 -1.38836458e-05 -1.34241549e-04]]\n",
      "linear.bias:\n",
      " [0.00022524]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496858e-03 -1.0384666e-04  3.1070165e-05  1.0740726e-04\n",
      "   1.7113473e-04 -1.9263733e-05 -1.3392854e-04]]\n",
      "linear.bias:\n",
      " [0.00022522]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05010485e-03 -1.03900573e-04  3.09087154e-05  1.00235295e-04\n",
      "   1.71098043e-04 -2.60628494e-05 -1.33635171e-04]]\n",
      "linear.bias:\n",
      " [0.00022534]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502003e-03 -1.0399364e-04  3.0726755e-05  1.0043037e-04\n",
      "   1.7082735e-04 -3.6658803e-06 -1.3347642e-04]]\n",
      "linear.bias:\n",
      " [0.00022545]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502128e-03 -1.0420789e-04  3.0738047e-05  9.8275486e-05\n",
      "   1.7095466e-04 -1.3277068e-05 -1.3303179e-04]]\n",
      "linear.bias:\n",
      " [0.00022547]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05010788e-03 -1.04812265e-04  3.08777817e-05  9.82287893e-05\n",
      "   1.71245309e-04 -3.01669825e-05 -1.32503075e-04]]\n",
      "linear.bias:\n",
      " [0.00022546]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499379e-03 -1.0535210e-04  3.0889500e-05  1.0649027e-04\n",
      "   1.7124267e-04 -1.4704392e-05 -1.3215568e-04]]\n",
      "linear.bias:\n",
      " [0.00022546]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04936468e-03 -1.06034735e-04  3.09198986e-05  1.07001724e-04\n",
      "   1.71269363e-04 -9.95780465e-06 -1.31831403e-04]]\n",
      "linear.bias:\n",
      " [0.00022552]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484419e-03 -1.0654580e-04  3.1010703e-05  9.7444550e-05\n",
      "   1.7150841e-04 -3.1474461e-05 -1.3138344e-04]]\n",
      "linear.bias:\n",
      " [0.00022564]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04773627e-03 -1.06243024e-04  3.10348441e-05  1.00019592e-04\n",
      "   1.71226828e-04  1.20905315e-06 -1.31325243e-04]]\n",
      "linear.bias:\n",
      " [0.00022572]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473571e-03 -1.0620143e-04  3.1073931e-05  9.4915420e-05\n",
      "   1.7120701e-04 -2.0714642e-05 -1.3102649e-04]]\n",
      "linear.bias:\n",
      " [0.00022558]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04693975e-03 -1.06159336e-04  3.09944662e-05  9.86576779e-05\n",
      "   1.70923478e-04 -9.72412727e-06 -1.30886838e-04]]\n",
      "linear.bias:\n",
      " [0.00022546]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464023e-03 -1.0653090e-04  3.1056115e-05  1.0334583e-04\n",
      "   1.7089686e-04 -1.4896517e-05 -1.3060014e-04]]\n",
      "linear.bias:\n",
      " [0.00022528]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457950e-03 -1.0683874e-04  3.1126157e-05  1.0721288e-04\n",
      "   1.7077583e-04 -1.3929894e-05 -1.3044299e-04]]\n",
      "linear.bias:\n",
      " [0.00022515]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453508e-03 -1.0733011e-04  3.1118194e-05  9.9925572e-05\n",
      "   1.7084545e-04 -3.5738027e-05 -1.3015037e-04]]\n",
      "linear.bias:\n",
      " [0.0002251]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451038e-03 -1.0693048e-04  3.1046442e-05  1.0213674e-04\n",
      "   1.7042081e-04 -3.2110729e-06 -1.3030309e-04]]\n",
      "linear.bias:\n",
      " [0.00022509]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452954e-03 -1.0696780e-04  3.1026542e-05  9.8788238e-05\n",
      "   1.7043413e-04 -7.0151900e-06 -1.3015901e-04]]\n",
      "linear.bias:\n",
      " [0.00022502]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455495e-03 -1.0735598e-04  3.1060074e-05  9.6796401e-05\n",
      "   1.7066572e-04 -2.9044266e-05 -1.2988051e-04]]\n",
      "linear.bias:\n",
      " [0.00022488]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458474e-03 -1.0689361e-04  3.1030970e-05  1.0478289e-04\n",
      "   1.7034617e-04 -7.7595960e-06 -1.3001583e-04]]\n",
      "linear.bias:\n",
      " [0.00022472]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04645093e-03 -1.06684834e-04  3.09953430e-05  1.03534490e-04\n",
      "   1.70393629e-04 -2.19036119e-05 -1.29870081e-04]]\n",
      "linear.bias:\n",
      " [0.00022461]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04701705e-03 -1.06389234e-04  3.08635281e-05  1.04726249e-04\n",
      "   1.70368730e-04 -1.15217354e-05 -1.29893146e-04]]\n",
      "linear.bias:\n",
      " [0.00022459]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472602e-03 -1.0629850e-04  3.0762218e-05  1.0097638e-04\n",
      "   1.7044348e-04 -1.4566169e-05 -1.2986713e-04]]\n",
      "linear.bias:\n",
      " [0.0002246]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473552e-03 -1.0618969e-04  3.0685584e-05  9.7239521e-05\n",
      "   1.7041297e-04 -1.1653631e-05 -1.2994563e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476226e-03 -1.0628584e-04  3.0676736e-05  9.7995748e-05\n",
      "   1.7047694e-04 -1.0788008e-05 -1.3000432e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04782893e-03 -1.06642976e-04  3.08142990e-05  1.01929763e-04\n",
      "   1.70646701e-04 -1.33245021e-05 -1.30002038e-04]]\n",
      "linear.bias:\n",
      " [0.00022458]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478904e-03 -1.0693753e-04  3.0952880e-05  1.0511364e-04\n",
      "   1.7070152e-04 -9.9392910e-06 -1.3010220e-04]]\n",
      "linear.bias:\n",
      " [0.00022455]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475328e-03 -1.0709730e-04  3.1142172e-05  9.7803000e-05\n",
      "   1.7096940e-04 -3.2957396e-05 -1.3003401e-04]]\n",
      "linear.bias:\n",
      " [0.0002246]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04734406e-03 -1.06439395e-04  3.12475822e-05  1.01796162e-04\n",
      "   1.70711719e-04 -1.62989818e-06 -1.30343280e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474183e-03 -1.0617769e-04  3.1371528e-05  9.5964744e-05\n",
      "   1.7083748e-04 -1.5660920e-05 -1.3036496e-04]]\n",
      "linear.bias:\n",
      " [0.00022454]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475444e-03 -1.0589093e-04  3.1454816e-05  9.6451120e-05\n",
      "   1.7075689e-04 -2.4637788e-05 -1.3044574e-04]]\n",
      "linear.bias:\n",
      " [0.00022449]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475881e-03 -1.0561838e-04  3.1413034e-05  1.0510996e-04\n",
      "   1.7040431e-04 -6.6289613e-07 -1.3075273e-04]]\n",
      "linear.bias:\n",
      " [0.00022444]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478481e-03 -1.0580288e-04  3.1435313e-05  9.9686855e-05\n",
      "   1.7052470e-04 -2.6201964e-05 -1.3078372e-04]]\n",
      "linear.bias:\n",
      " [0.00022436]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480324e-03 -1.0588825e-04  3.1331816e-05  1.0079217e-04\n",
      "   1.7037489e-04 -1.8126737e-05 -1.3101373e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04797562e-03 -1.05980689e-04  3.12267475e-05  1.02322934e-04\n",
      "   1.70189596e-04  1.12841008e-06 -1.31316323e-04]]\n",
      "linear.bias:\n",
      " [0.00022442]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04813045e-03 -1.06475316e-04  3.11825388e-05  9.16966674e-05\n",
      "   1.70450119e-04 -2.65494873e-05 -1.31291759e-04]]\n",
      "linear.bias:\n",
      " [0.00022441]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483342e-03 -1.0612280e-04  3.1089054e-05  9.2842034e-05\n",
      "   1.7014249e-04 -9.3836043e-06 -1.3164189e-04]]\n",
      "linear.bias:\n",
      " [0.00022433]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04856747e-03 -1.06048086e-04  3.10621908e-05  1.00439102e-04\n",
      "   1.69847350e-04  9.25921086e-07 -1.31912529e-04]]\n",
      "linear.bias:\n",
      " [0.00022419]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487414e-03 -1.0610026e-04  3.1216357e-05  1.0137244e-04\n",
      "   1.6993910e-04 -2.8297520e-05 -1.3181569e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488478e-03 -1.0606601e-04  3.1231004e-05  1.0823476e-04\n",
      "   1.6976212e-04 -2.3445124e-05 -1.3193161e-04]]\n",
      "linear.bias:\n",
      " [0.00022389]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487031e-03 -1.0604421e-04  3.1240645e-05  1.1448697e-04\n",
      "   1.6962169e-04  1.5682326e-06 -1.3213773e-04]]\n",
      "linear.bias:\n",
      " [0.00022386]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04833837e-03 -1.06300206e-04  3.12719058e-05  9.83298596e-05\n",
      "   1.69518549e-04 -4.73502660e-05 -1.32567046e-04]]\n",
      "linear.bias:\n",
      " [0.00022384]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04816072e-03 -1.05695326e-04  3.12405646e-05  9.35460848e-05\n",
      "   1.68920757e-04 -3.79833109e-05 -1.33359907e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04796619e-03 -1.04377417e-04  3.11723488e-05  1.03137354e-04\n",
      "   1.67802544e-04  2.65751478e-05 -1.34443166e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04738679e-03 -1.03323815e-04  3.11606309e-05  9.03786713e-05\n",
      "   1.66675425e-04 -3.61951861e-05 -1.35738970e-04]]\n",
      "linear.bias:\n",
      " [0.00022385]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467476e-03 -1.0276888e-04  3.1183994e-05  9.1677161e-05\n",
      "   1.6570369e-04 -4.9404112e-05 -1.3688768e-04]]\n",
      "linear.bias:\n",
      " [0.0002239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461538e-03 -1.0159887e-04  3.1213935e-05  1.0740315e-04\n",
      "   1.6448800e-04 -3.2122771e-06 -1.3821146e-04]]\n",
      "linear.bias:\n",
      " [0.00022387]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04605802e-03 -1.01074249e-04  3.13573619e-05  1.11625115e-04\n",
      "   1.64062338e-04 -3.52226698e-06 -1.38980569e-04]]\n",
      "linear.bias:\n",
      " [0.00022378]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463389e-03 -1.0123586e-04  3.1535918e-05  1.0230008e-04\n",
      "   1.6461959e-04 -5.2361513e-05 -1.3919800e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466173e-03 -1.0144853e-04  3.1621767e-05  1.0212753e-04\n",
      "   1.6512908e-04 -5.1860847e-05 -1.3947856e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468730e-03 -1.0174745e-04  3.1636344e-05  1.1180317e-04\n",
      "   1.6556833e-04 -8.8796260e-06 -1.3975377e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04733068e-03 -1.02529004e-04  3.17619742e-05  1.08834618e-04\n",
      "   1.66618745e-04 -1.43477655e-05 -1.39607771e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480769e-03 -1.0383961e-04  3.1947864e-05  9.7234908e-05\n",
      "   1.6817360e-04 -4.8534079e-05 -1.3910889e-04]]\n",
      "linear.bias:\n",
      " [0.00022278]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04873092e-03 -1.04318482e-04  3.21299340e-05  1.00747406e-04\n",
      "   1.69227074e-04 -2.40941481e-05 -1.38854710e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04901358e-03 -1.04919789e-04  3.22648557e-05  1.05786734e-04\n",
      "   1.70189582e-04  1.41048185e-05 -1.38611969e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493111e-03 -1.0575406e-04  3.2418629e-05  9.5847354e-05\n",
      "   1.7133183e-04 -3.2212178e-05 -1.3829266e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495658e-03 -1.0651797e-04  3.2432446e-05  9.6291042e-05\n",
      "   1.7211877e-04 -3.2133470e-05 -1.3812058e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497819e-03 -1.0721852e-04  3.2320084e-05  1.0609531e-04\n",
      "   1.7258542e-04  9.7234151e-06 -1.3808122e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05010229e-03 -1.07936794e-04  3.22621454e-05  1.00457430e-04\n",
      "   1.73113338e-04 -2.31199629e-05 -1.37954892e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05008495e-03 -1.08627064e-04  3.21816369e-05  1.00874335e-04\n",
      "   1.73373192e-04 -2.85557744e-05 -1.37925046e-04]]\n",
      "linear.bias:\n",
      " [0.00022157]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04998634e-03 -1.09213586e-04  3.19927967e-05  1.07649343e-04\n",
      "   1.73370150e-04 -7.73037027e-06 -1.38026662e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494492e-03 -1.0909952e-04  3.1888434e-05  1.0205500e-04\n",
      "   1.7372378e-04 -2.7874154e-05 -1.3787295e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487736e-03 -1.0845191e-04  3.1632411e-05  1.0151082e-04\n",
      "   1.7387840e-04 -1.9824691e-05 -1.3789114e-04]]\n",
      "linear.bias:\n",
      " [0.00022166]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04774360e-03 -1.08113745e-04  3.13623168e-05  1.04215062e-04\n",
      "   1.73867666e-04 -3.17911326e-06 -1.37896233e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472002e-03 -1.0797134e-04  3.1096923e-05  9.5461866e-05\n",
      "   1.7418028e-04 -2.8518292e-05 -1.3761995e-04]]\n",
      "linear.bias:\n",
      " [0.0002221]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468410e-03 -1.0702451e-04  3.0790761e-05  9.8757264e-05\n",
      "   1.7395640e-04 -2.4927431e-08 -1.3764841e-04]]\n",
      "linear.bias:\n",
      " [0.00022229]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464443e-03 -1.0634793e-04  3.0710111e-05  9.8106131e-05\n",
      "   1.7414759e-04 -6.1834189e-06 -1.3732757e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460137e-03 -1.0591493e-04  3.0832765e-05  9.3896924e-05\n",
      "   1.7471299e-04 -4.3561115e-05 -1.3669180e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04558887e-03 -1.04717466e-04  3.08958042e-05  1.03754865e-04\n",
      "   1.74646062e-04 -2.25793538e-05 -1.36410818e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04500470e-03 -1.03605809e-04  3.09372190e-05  1.14140814e-04\n",
      "   1.74536617e-04  1.81197156e-05 -1.36273928e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440013e-03 -1.0258796e-04  3.0933421e-05  9.7250522e-05\n",
      "   1.7414283e-04 -5.8394995e-05 -1.3665254e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431143e-03 -1.0092614e-04  3.0896808e-05  9.7120479e-05\n",
      "   1.7307683e-04 -6.7419620e-05 -1.3744968e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424582e-03 -9.8748540e-05  3.0887179e-05  1.1486580e-04\n",
      "   1.7163732e-04  5.0276576e-06 -1.3851811e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420060e-03 -9.7455639e-05  3.0965548e-05  1.1274462e-04\n",
      "   1.7068259e-04  1.1247632e-05 -1.3934444e-04]]\n",
      "linear.bias:\n",
      " [0.00022313]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416021e-03 -9.6547003e-05  3.1098094e-05  9.1083195e-05\n",
      "   1.6985087e-04 -7.1447525e-05 -1.4017681e-04]]\n",
      "linear.bias:\n",
      " [0.00022322]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414388e-03 -9.5087933e-05  3.1182703e-05  9.2040966e-05\n",
      "   1.6879920e-04 -4.5316592e-05 -1.4134149e-04]]\n",
      "linear.bias:\n",
      " [0.00022333]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04117114e-03 -9.41785693e-05  3.12937627e-05  1.06022184e-04\n",
      "   1.67896651e-04  2.12920204e-05 -1.42371558e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408260e-03 -9.4050687e-05  3.1560456e-05  1.0200668e-04\n",
      "   1.6785972e-04 -1.8745774e-05 -1.4312322e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407546e-03 -9.4956726e-05  3.1863310e-05  9.8665347e-05\n",
      "   1.6836985e-04 -6.1814593e-05 -1.4347237e-04]]\n",
      "linear.bias:\n",
      " [0.00022337]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405681e-03 -9.5983611e-05  3.2053005e-05  1.0841757e-04\n",
      "   1.6901875e-04 -4.7355366e-05 -1.4377474e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410611e-03 -9.7568271e-05  3.2115880e-05  1.2047169e-04\n",
      "   1.6991080e-04 -2.6375928e-06 -1.4401038e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418802e-03 -9.9571334e-05  3.2170385e-05  1.1604955e-04\n",
      "   1.7146750e-04 -1.3571609e-05 -1.4388147e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429786e-03 -1.0184593e-04  3.2218588e-05  9.9966463e-05\n",
      "   1.7324048e-04 -5.9852566e-05 -1.4348069e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04394788e-03 -1.03185266e-04  3.22645319e-05  9.99326512e-05\n",
      "   1.74502580e-04 -4.52670356e-05 -1.43331548e-04]]\n",
      "linear.bias:\n",
      " [0.00022335]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04497233e-03 -1.03657476e-04  3.23008389e-05  1.11745998e-04\n",
      "   1.75353256e-04  1.94271415e-05 -1.43383892e-04]]\n",
      "linear.bias:\n",
      " [0.00022327]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455922e-03 -1.0437774e-04  3.2470976e-05  1.0063445e-04\n",
      "   1.7605463e-04 -2.2270273e-05 -1.4353055e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04574335e-03 -1.05254476e-04  3.25876063e-05  9.56696895e-05\n",
      "   1.76529837e-04 -4.03148333e-05 -1.43648489e-04]]\n",
      "linear.bias:\n",
      " [0.0002231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04601227e-03 -1.05210005e-04  3.26242807e-05  1.02573533e-04\n",
      "   1.76442743e-04 -5.84079680e-06 -1.44037374e-04]]\n",
      "linear.bias:\n",
      " [0.00022304]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04667724e-03 -1.05684354e-04  3.27154776e-05  1.03738792e-04\n",
      "   1.76779853e-04 -9.89105683e-06 -1.44006510e-04]]\n",
      "linear.bias:\n",
      " [0.00022292]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04769925e-03 -1.06626474e-04  3.28558344e-05  9.97306779e-05\n",
      "   1.77499445e-04 -4.86434219e-05 -1.43597223e-04]]\n",
      "linear.bias:\n",
      " [0.00022274]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04858226e-03 -1.06652267e-04  3.29339127e-05  1.10008354e-04\n",
      "   1.77560403e-04 -2.95287264e-05 -1.43525831e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490422e-03 -1.0688118e-04  3.2996384e-05  1.1675216e-04\n",
      "   1.7770706e-04  1.6297327e-06 -1.4345946e-04]]\n",
      "linear.bias:\n",
      " [0.00022264]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04944059e-03 -1.06797284e-04  3.30118019e-05  1.03882689e-04\n",
      "   1.77667127e-04 -3.24911744e-05 -1.43380006e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04955200e-03 -1.06784035e-04  3.29909017e-05  9.86971936e-05\n",
      "   1.77444439e-04 -2.86353716e-05 -1.43375175e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494087e-03 -1.0686583e-04  3.2933807e-05  1.0279139e-04\n",
      "   1.7701567e-04  1.4774701e-05 -1.4344444e-04]]\n",
      "linear.bias:\n",
      " [0.00022285]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04929262e-03 -1.06963336e-04  3.29242175e-05  9.39607417e-05\n",
      "   1.76625326e-04 -1.57918985e-05 -1.43320140e-04]]\n",
      "linear.bias:\n",
      " [0.00022275]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488225e-03 -1.0730865e-04  3.2940497e-05  9.1506707e-05\n",
      "   1.7620620e-04 -3.9432147e-05 -1.4311826e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04836118e-03 -1.06791951e-04  3.29065188e-05  1.03262995e-04\n",
      "   1.75237947e-04 -6.66571214e-06 -1.43235477e-04]]\n",
      "linear.bias:\n",
      " [0.00022268]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483257e-03 -1.0688868e-04  3.2946591e-05  1.0729074e-04\n",
      "   1.7485527e-04 -1.3466388e-05 -1.4294444e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04857830e-03 -1.07220993e-04  3.29138384e-05  1.00512654e-04\n",
      "   1.74776331e-04 -4.69609367e-05 -1.42453078e-04]]\n",
      "linear.bias:\n",
      " [0.00022266]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04894023e-03 -1.06676845e-04  3.28151946e-05  1.05904284e-04\n",
      "   1.74184359e-04 -2.62559533e-05 -1.42296267e-04]]\n",
      "linear.bias:\n",
      " [0.00022268]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489745e-03 -1.0635067e-04  3.2706361e-05  1.0969709e-04\n",
      "   1.7367309e-04  7.5163061e-06 -1.4216517e-04]]\n",
      "linear.bias:\n",
      " [0.00022282]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04912871e-03 -1.06126354e-04  3.26327172e-05  9.94900620e-05\n",
      "   1.73406763e-04 -2.60700745e-05 -1.41835553e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489438e-03 -1.0599721e-04  3.2543918e-05  9.6824602e-05\n",
      "   1.7293646e-04 -3.1740808e-05 -1.4160480e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04876340e-03 -1.05893821e-04  3.23339846e-05  1.04192186e-04\n",
      "   1.72260639e-04  4.72654210e-06 -1.41517361e-04]]\n",
      "linear.bias:\n",
      " [0.00022278]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487968e-03 -1.0629071e-04  3.2198652e-05  9.9939010e-05\n",
      "   1.7209920e-04 -7.6763490e-06 -1.4106931e-04]]\n",
      "linear.bias:\n",
      " [0.00022268]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487512e-03 -1.0683065e-04  3.2278676e-05  9.2370639e-05\n",
      "   1.7236029e-04 -5.0422557e-05 -1.4030719e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04869111e-03 -1.06581996e-04  3.23660752e-05  1.00138641e-04\n",
      "   1.72231856e-04 -3.39464241e-05 -1.39825192e-04]]\n",
      "linear.bias:\n",
      " [0.00022244]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486292e-03 -1.0634289e-04  3.2307438e-05  1.1609758e-04\n",
      "   1.7186960e-04  2.1931137e-05 -1.3953296e-04]]\n",
      "linear.bias:\n",
      " [0.00022242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479309e-03 -1.0586322e-04  3.2228163e-05  9.9293116e-05\n",
      "   1.7127131e-04 -5.2536667e-05 -1.3980249e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472829e-03 -1.0469427e-04  3.2172113e-05  9.8772907e-05\n",
      "   1.7036787e-04 -6.4841035e-05 -1.4025027e-04]]\n",
      "linear.bias:\n",
      " [0.00022244]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04675570e-03 -1.02869075e-04  3.21139814e-05  1.13553775e-04\n",
      "   1.69311679e-04 -1.63693585e-05 -1.40869728e-04]]\n",
      "linear.bias:\n",
      " [0.00022245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04638829e-03 -1.01743535e-04  3.20689360e-05  1.15201779e-04\n",
      "   1.68750048e-04 -4.69749557e-06 -1.41171040e-04]]\n",
      "linear.bias:\n",
      " [0.00022246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04629400e-03 -1.01190875e-04  3.20926192e-05  1.02565689e-04\n",
      "   1.68713887e-04 -4.08988672e-05 -1.41179116e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462144e-03 -1.0080647e-04  3.2047661e-05  1.0153423e-04\n",
      "   1.6866050e-04 -3.1294570e-05 -1.4121014e-04]]\n",
      "linear.bias:\n",
      " [0.0002224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459527e-03 -1.0104910e-04  3.2117328e-05  1.0449530e-04\n",
      "   1.6903577e-04  2.3067769e-06 -1.4104805e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461403e-03 -1.0178221e-04  3.2238968e-05  9.7978998e-05\n",
      "   1.6984329e-04 -1.0334808e-05 -1.4049663e-04]]\n",
      "linear.bias:\n",
      " [0.00022228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467425e-03 -1.0296972e-04  3.2408141e-05  8.6937755e-05\n",
      "   1.7099654e-04 -5.6853954e-05 -1.3960933e-04]]\n",
      "linear.bias:\n",
      " [0.00022212]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471495e-03 -1.0328860e-04  3.2566586e-05  9.5042793e-05\n",
      "   1.7151356e-04 -3.5439654e-05 -1.3913662e-04]]\n",
      "linear.bias:\n",
      " [0.0002219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04750204e-03 -1.03588936e-04  3.25777110e-05  1.12226102e-04\n",
      "   1.71723892e-04  2.53157887e-05 -1.38832766e-04]]\n",
      "linear.bias:\n",
      " [0.00022174]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473053e-03 -1.0390628e-04  3.2566299e-05  1.0060161e-04\n",
      "   1.7157546e-04 -4.1753385e-05 -1.3912040e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471139e-03 -1.0420525e-04  3.2424203e-05  1.0002785e-04\n",
      "   1.7118597e-04 -6.0813727e-05 -1.3950162e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469208e-03 -1.0374122e-04  3.2298820e-05  1.1441577e-04\n",
      "   1.7048894e-04 -2.1986059e-05 -1.4006396e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469812e-03 -1.0362469e-04  3.2083775e-05  1.1838201e-04\n",
      "   1.7012774e-04 -1.2345881e-06 -1.4036358e-04]]\n",
      "linear.bias:\n",
      " [0.00022181]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472457e-03 -1.0420737e-04  3.1950334e-05  1.0650955e-04\n",
      "   1.7042877e-04 -3.2660912e-05 -1.4034723e-04]]\n",
      "linear.bias:\n",
      " [0.00022192]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472083e-03 -1.0496214e-04  3.1816267e-05  9.4011804e-05\n",
      "   1.7083068e-04 -3.6476511e-05 -1.4031012e-04]]\n",
      "linear.bias:\n",
      " [0.00022221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471800e-03 -1.0575655e-04  3.1628548e-05  9.3202201e-05\n",
      "   1.7117169e-04  2.2231143e-06 -1.4030069e-04]]\n",
      "linear.bias:\n",
      " [0.00022247]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475852e-03 -1.0703226e-04  3.1526652e-05  8.8111607e-05\n",
      "   1.7190175e-04  2.5657869e-06 -1.3987685e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477727e-03 -1.0838161e-04  3.1622851e-05  8.4172811e-05\n",
      "   1.7279567e-04 -2.3615165e-05 -1.3915947e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479093e-03 -1.0870521e-04  3.1725602e-05  9.5593248e-05\n",
      "   1.7305343e-04 -9.7755410e-06 -1.3878180e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478293e-03 -1.0914779e-04  3.1996715e-05  1.0695318e-04\n",
      "   1.7351763e-04 -1.9346531e-05 -1.3815993e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475519e-03 -1.0943536e-04  3.2310305e-05  1.0986042e-04\n",
      "   1.7412443e-04 -3.9789680e-05 -1.3746176e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04755932e-03 -1.08718472e-04  3.25285546e-05  1.19173135e-04\n",
      "   1.74320201e-04 -1.03493130e-05 -1.37181225e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04758237e-03 -1.08135013e-04  3.25474175e-05  1.06703366e-04\n",
      "   1.74308356e-04 -2.94347701e-05 -1.37042502e-04]]\n",
      "linear.bias:\n",
      " [0.00022327]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473903e-03 -1.0757460e-04  3.2548171e-05  9.7056552e-05\n",
      "   1.7424574e-04 -2.5042089e-05 -1.3704033e-04]]\n",
      "linear.bias:\n",
      " [0.00022354]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471329e-03 -1.0706467e-04  3.2421318e-05  9.7590251e-05\n",
      "   1.7389389e-04  9.8372766e-06 -1.3718236e-04]]\n",
      "linear.bias:\n",
      " [0.00022379]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472725e-03 -1.0670688e-04  3.2335258e-05  8.9236419e-05\n",
      "   1.7361778e-04 -2.3870147e-05 -1.3708200e-04]]\n",
      "linear.bias:\n",
      " [0.00022385]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04731368e-03 -1.06379455e-04  3.21299995e-05  9.09494993e-05\n",
      "   1.73073146e-04 -2.33003757e-05 -1.37135823e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472662e-03 -1.0607938e-04  3.1817268e-05  1.0173740e-04\n",
      "   1.7228640e-04  8.1503877e-06 -1.3732865e-04]]\n",
      "linear.bias:\n",
      " [0.00022397]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04731775e-03 -1.05935374e-04  3.15715806e-05  9.92519708e-05\n",
      "   1.71673120e-04 -3.20435429e-05 -1.37294177e-04]]\n",
      "linear.bias:\n",
      " [0.00022387]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04734988e-03 -1.05819003e-04  3.12163684e-05  1.07060485e-04\n",
      "   1.70860847e-04 -2.66753341e-05 -1.37387207e-04]]\n",
      "linear.bias:\n",
      " [0.00022381]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470292e-03 -1.0592866e-04  3.0888219e-05  1.1147870e-04\n",
      "   1.7022487e-04 -7.8628564e-06 -1.3746884e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469659e-03 -1.0647816e-04  3.0647905e-05  1.0237520e-04\n",
      "   1.7012036e-04 -3.5655197e-05 -1.3721680e-04]]\n",
      "linear.bias:\n",
      " [0.00022393]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04692462e-03 -1.06902873e-04  3.02898297e-05  1.01509875e-04\n",
      "   1.69779407e-04 -1.91175750e-05 -1.37191237e-04]]\n",
      "linear.bias:\n",
      " [0.00022406]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04657223e-03 -1.07819447e-04  3.00230022e-05  1.02388025e-04\n",
      "   1.69626743e-04 -2.91389370e-07 -1.37075258e-04]]\n",
      "linear.bias:\n",
      " [0.00022422]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466885e-03 -1.0917212e-04  2.9842980e-05  9.3783266e-05\n",
      "   1.6997015e-04 -2.6413523e-05 -1.3655549e-04]]\n",
      "linear.bias:\n",
      " [0.00022429]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468622e-03 -1.0949548e-04  2.9614863e-05  9.7161945e-05\n",
      "   1.6970126e-04 -9.5765208e-06 -1.3640488e-04]]\n",
      "linear.bias:\n",
      " [0.0002243]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469034e-03 -1.0991299e-04  2.9604756e-05  9.8882243e-05\n",
      "   1.6986714e-04 -1.9509545e-05 -1.3596172e-04]]\n",
      "linear.bias:\n",
      " [0.00022428]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467789e-03 -1.1028511e-04  2.9640634e-05  1.0536684e-04\n",
      "   1.7005428e-04 -1.3301318e-05 -1.3557127e-04]]\n",
      "linear.bias:\n",
      " [0.00022422]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465176e-03 -1.1050006e-04  2.9810510e-05  1.0327151e-04\n",
      "   1.7058132e-04 -3.7559708e-05 -1.3495018e-04]]\n",
      "linear.bias:\n",
      " [0.00022425]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04645255e-03 -1.09730245e-04  2.98840259e-05  1.10591020e-04\n",
      "   1.70526793e-04 -8.33199192e-06 -1.34766189e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465753e-03 -1.0919082e-04  2.9921710e-05  1.0334660e-04\n",
      "   1.7080593e-04 -2.4436014e-05 -1.3433187e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04646967e-03 -1.08669556e-04  2.99391722e-05  9.84294820e-05\n",
      "   1.71004634e-04 -1.72340988e-05 -1.34065296e-04]]\n",
      "linear.bias:\n",
      " [0.00022449]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04628992e-03 -1.08201224e-04  3.00329066e-05  9.69469475e-05\n",
      "   1.71164909e-04 -1.15965313e-05 -1.33823152e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460895e-03 -1.0808140e-04  3.0279820e-05  9.9221790e-05\n",
      "   1.7143447e-04 -9.8494565e-06 -1.3354348e-04]]\n",
      "linear.bias:\n",
      " [0.00022448]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458252e-03 -1.0812185e-04  3.0701558e-05  9.8635748e-05\n",
      "   1.7209955e-04 -3.8566985e-05 -1.3294839e-04]]\n",
      "linear.bias:\n",
      " [0.00022436]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457296e-03 -1.0729326e-04  3.1016079e-05  1.1070675e-04\n",
      "   1.7213535e-04 -1.1630487e-05 -1.3280383e-04]]\n",
      "linear.bias:\n",
      " [0.00022422]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04574778e-03 -1.06725405e-04  3.12090342e-05  1.06216547e-04\n",
      "   1.72399392e-04 -2.38981065e-05 -1.32464091e-04]]\n",
      "linear.bias:\n",
      " [0.00022409]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04578957e-03 -1.06093044e-04  3.12707343e-05  1.04760191e-04\n",
      "   1.72561180e-04 -1.16082383e-05 -1.32331596e-04]]\n",
      "linear.bias:\n",
      " [0.00022405]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04617514e-03 -1.05735555e-04  3.12412958e-05  9.40773825e-05\n",
      "   1.72912216e-04 -2.70077653e-05 -1.31984169e-04]]\n",
      "linear.bias:\n",
      " [0.00022405]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465921e-03 -1.0450820e-04  3.1148054e-05  9.5708820e-05\n",
      "   1.7264353e-04 -2.4692963e-07 -1.3199245e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04741217e-03 -1.03907514e-04  3.11148542e-05  9.30786991e-05\n",
      "   1.72842032e-04 -1.01948917e-05 -1.31625231e-04]]\n",
      "linear.bias:\n",
      " [0.00022386]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04825699e-03 -1.03641556e-04  3.11454787e-05  9.86318191e-05\n",
      "   1.72942047e-04 -1.73988283e-05 -1.31280962e-04]]\n",
      "linear.bias:\n",
      " [0.00022369]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488970e-03 -1.0341658e-04  3.1049647e-05  1.0955035e-04\n",
      "   1.7277060e-04 -7.8387520e-06 -1.3109169e-04]]\n",
      "linear.bias:\n",
      " [0.00022365]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04956795e-03 -1.03475555e-04  3.07985974e-05  1.00720055e-04\n",
      "   1.72739194e-04 -3.95010575e-05 -1.30924134e-04]]\n",
      "linear.bias:\n",
      " [0.00022369]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05034630e-03 -1.02572158e-04  3.04991299e-05  1.02668986e-04\n",
      "   1.72157452e-04 -1.50448068e-05 -1.31246008e-04]]\n",
      "linear.bias:\n",
      " [0.00022377]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05081312e-03 -1.01894679e-04  3.02304270e-05  1.02535756e-04\n",
      "   1.71598338e-04  7.64651304e-06 -1.31566238e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512739e-03 -1.0146069e-04  3.0046809e-05  8.7449633e-05\n",
      "   1.7130801e-04 -5.1964053e-05 -1.3184166e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05172256e-03 -1.00248515e-04  2.98809719e-05  9.10140661e-05\n",
      "   1.70174899e-04 -4.51513915e-05 -1.32616537e-04]]\n",
      "linear.bias:\n",
      " [0.00022391]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0521465e-03 -9.8336706e-05  2.9708983e-05  1.1036168e-04\n",
      "   1.6835937e-04  1.9623207e-05 -1.3379716e-04]]\n",
      "linear.bias:\n",
      " [0.00022385]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516047e-03 -9.6843665e-05  2.9567316e-05  9.9325749e-05\n",
      "   1.6663215e-04 -3.2837423e-05 -1.3529763e-04]]\n",
      "linear.bias:\n",
      " [0.00022376]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509240e-03 -9.6008931e-05  2.9552377e-05  9.9895864e-05\n",
      "   1.6522381e-04 -4.1487721e-05 -1.3656483e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501178e-03 -9.5767573e-05  2.9651676e-05  1.1092762e-04\n",
      "   1.6410284e-04 -1.0683201e-05 -1.3762187e-04]]\n",
      "linear.bias:\n",
      " [0.00022336]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495739e-03 -9.6408003e-05  2.9874476e-05  1.0938548e-04\n",
      "   1.6400598e-04 -2.4082121e-05 -1.3811907e-04]]\n",
      "linear.bias:\n",
      " [0.00022312]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487611e-03 -9.7669887e-05  3.0224015e-05  1.0547870e-04\n",
      "   1.6440562e-04 -3.3559310e-05 -1.3838208e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478041e-03 -9.9415236e-05  3.0667205e-05  1.0255572e-04\n",
      "   1.6529259e-04 -1.7497772e-05 -1.3846310e-04]]\n",
      "linear.bias:\n",
      " [0.00022301]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466737e-03 -1.0170550e-04  3.1278316e-05  1.0080593e-04\n",
      "   1.6667151e-04 -6.9974303e-06 -1.3823283e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04608154e-03 -1.04474144e-04  3.19723986e-05  9.27817455e-05\n",
      "   1.68681945e-04 -3.35068762e-05 -1.37499184e-04]]\n",
      "linear.bias:\n",
      " [0.00022298]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455536e-03 -1.0708746e-04  3.2527703e-05  9.6436299e-05\n",
      "   1.7047087e-04 -1.4598905e-05 -1.3686340e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450800e-03 -1.0987980e-04  3.3050797e-05  1.0390324e-04\n",
      "   1.7231746e-04  1.9202798e-06 -1.3618276e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451198e-03 -1.1240818e-04  3.3484499e-05  9.8566576e-05\n",
      "   1.7420643e-04 -3.2894946e-05 -1.3532472e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451615e-03 -1.1324759e-04  3.3743767e-05  1.0494968e-04\n",
      "   1.7543194e-04 -1.3392473e-05 -1.3485360e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04517047e-03 -1.13269365e-04  3.38919817e-05  1.04130930e-04\n",
      "   1.76719375e-04 -1.02581553e-05 -1.34287082e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04522798e-03 -1.12233705e-04  3.38240679e-05  9.53587660e-05\n",
      "   1.77988157e-04 -3.28015485e-05 -1.33721449e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454238e-03 -1.1039696e-04  3.3688801e-05  9.9734891e-05\n",
      "   1.7857279e-04 -1.5494006e-06 -1.3351823e-04]]\n",
      "linear.bias:\n",
      " [0.00022395]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464173e-03 -1.0837992e-04  3.3312928e-05  9.9177960e-05\n",
      "   1.7901130e-04 -2.0771933e-05 -1.3331998e-04]]\n",
      "linear.bias:\n",
      " [0.00022428]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473790e-03 -1.0560476e-04  3.2909953e-05  1.0762727e-04\n",
      "   1.7885356e-04 -2.7154201e-06 -1.3346208e-04]]\n",
      "linear.bias:\n",
      " [0.00022462]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483151e-03 -1.0312348e-04  3.2424581e-05  9.6339165e-05\n",
      "   1.7850020e-04 -4.0621540e-05 -1.3365713e-04]]\n",
      "linear.bias:\n",
      " [0.00022497]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04917854e-03 -1.00055942e-04  3.19644350e-05  1.02544815e-04\n",
      "   1.77374764e-04 -1.59238261e-05 -1.34322923e-04]]\n",
      "linear.bias:\n",
      " [0.00022525]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495993e-03 -9.7516408e-05  3.1536445e-05  1.1064615e-04\n",
      "   1.7613922e-04  9.4398092e-06 -1.3491866e-04]]\n",
      "linear.bias:\n",
      " [0.00022557]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499002e-03 -9.5231750e-05  3.1145300e-05  9.4922667e-05\n",
      "   1.7466709e-04 -5.6078014e-05 -1.3574903e-04]]\n",
      "linear.bias:\n",
      " [0.00022583]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501898e-03 -9.2350936e-05  3.0756320e-05  9.7330034e-05\n",
      "   1.7255534e-04 -5.4857639e-05 -1.3700081e-04]]\n",
      "linear.bias:\n",
      " [0.00022597]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503301e-03 -8.9963083e-05  3.0373172e-05  1.1472644e-04\n",
      "   1.7040645e-04 -2.2658824e-06 -1.3834967e-04]]\n",
      "linear.bias:\n",
      " [0.00022603]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506047e-03 -8.8647146e-05  3.0149924e-05  1.1249090e-04\n",
      "   1.6906801e-04 -9.7271168e-06 -1.3931276e-04]]\n",
      "linear.bias:\n",
      " [0.00022611]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510776e-03 -8.8274362e-05  3.0070745e-05  9.6130025e-05\n",
      "   1.6876149e-04 -6.4422835e-05 -1.3971467e-04]]\n",
      "linear.bias:\n",
      " [0.00022611]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512837e-03 -8.9101624e-05  3.0121648e-05  9.6807664e-05\n",
      "   1.6854897e-04 -6.2699954e-05 -1.4014015e-04]]\n",
      "linear.bias:\n",
      " [0.00022595]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05118938e-03 -9.09700102e-05  3.02674780e-05  1.12057984e-04\n",
      "   1.68574581e-04 -1.26358646e-05 -1.40513119e-04]]\n",
      "linear.bias:\n",
      " [0.00022568]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512404e-03 -9.3316099e-05  3.0475963e-05  1.1387541e-04\n",
      "   1.6926530e-04  7.5073604e-07 -1.4046939e-04]]\n",
      "linear.bias:\n",
      " [0.0002254]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0514559e-03 -9.6374912e-05  3.0855444e-05  9.8084609e-05\n",
      "   1.7073701e-04 -4.1242380e-05 -1.4007253e-04]]\n",
      "linear.bias:\n",
      " [0.00022515]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0514528e-03 -9.9651697e-05  3.1312469e-05  9.4596151e-05\n",
      "   1.7221337e-04 -4.0283252e-05 -1.3962886e-04]]\n",
      "linear.bias:\n",
      " [0.00022484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05101790e-03 -1.02827835e-04  3.17739468e-05  1.04216917e-04\n",
      "   1.73467241e-04  5.13063787e-06 -1.39219977e-04]]\n",
      "linear.bias:\n",
      " [0.00022456]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05088181e-03 -1.06050422e-04  3.22344313e-05  1.01356876e-04\n",
      "   1.74948917e-04 -8.98119379e-06 -1.38517789e-04]]\n",
      "linear.bias:\n",
      " [0.00022415]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506293e-03 -1.0883771e-04  3.2779870e-05  9.4070929e-05\n",
      "   1.7657358e-04 -5.1137391e-05 -1.3755943e-04]]\n",
      "linear.bias:\n",
      " [0.00022378]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504207e-03 -1.1048630e-04  3.3240558e-05  1.0345780e-04\n",
      "   1.7723834e-04 -3.1826130e-05 -1.3709662e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05026341e-03 -1.10449175e-04  3.35214936e-05  1.21329154e-04\n",
      "   1.77359747e-04  3.69508707e-05 -1.37045194e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490209e-03 -1.0909279e-04  3.3517350e-05  9.6588774e-05\n",
      "   1.7750177e-04 -7.1629132e-05 -1.3754454e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479337e-03 -1.0669798e-04  3.3458164e-05  9.7594486e-05\n",
      "   1.7649071e-04 -6.9491849e-05 -1.3853720e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "Epoch [1000/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04694057e-03 -1.03586688e-04  3.34162796e-05  1.15768904e-04\n",
      "   1.74698347e-04  1.73076987e-05 -1.39907963e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04554917e-03 -1.00678066e-04  3.33136486e-05  1.03340077e-04\n",
      "   1.72682165e-04 -1.43995530e-05 -1.41626224e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447649e-03 -9.8679135e-05  3.3295251e-05  8.5690917e-05\n",
      "   1.7134119e-04 -7.2377487e-05 -1.4277722e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439446e-03 -9.6070667e-05  3.3190772e-05  9.9017423e-05\n",
      "   1.6945736e-04 -1.4595724e-05 -1.4425168e-04]]\n",
      "linear.bias:\n",
      " [0.00022251]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435578e-03 -9.4835246e-05  3.3156153e-05  1.1156700e-04\n",
      "   1.6830166e-04  2.6584868e-05 -1.4519208e-04]]\n",
      "linear.bias:\n",
      " [0.00022226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04305975e-03 -9.44724306e-05  3.33047283e-05  1.02186124e-04\n",
      "   1.67854465e-04 -5.02013972e-05 -1.45945814e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04318094e-03 -9.50900139e-05  3.32810414e-05  1.03662926e-04\n",
      "   1.67776117e-04 -8.05358140e-05 -1.46490347e-04]]\n",
      "linear.bias:\n",
      " [0.00022164]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432861e-03 -9.4708921e-05  3.3302331e-05  1.2139224e-04\n",
      "   1.6779607e-04 -1.0803364e-05 -1.4711959e-04]]\n",
      "linear.bias:\n",
      " [0.00022143]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04373868e-03 -9.51420661e-05  3.33248063e-05  1.19452714e-04\n",
      "   1.68805534e-04  7.87902536e-06 -1.47262705e-04]]\n",
      "linear.bias:\n",
      " [0.00022121]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445110e-03 -9.6393705e-05  3.3472192e-05  9.9675781e-05\n",
      "   1.7074314e-04 -2.9081941e-05 -1.4695623e-04]]\n",
      "linear.bias:\n",
      " [0.00022096]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454552e-03 -9.8635777e-05  3.3572280e-05  8.6693595e-05\n",
      "   1.7277650e-04 -3.9204635e-05 -1.4641081e-04]]\n",
      "linear.bias:\n",
      " [0.00022074]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461704e-03 -1.0111027e-04  3.3701588e-05  8.9629430e-05\n",
      "   1.7465827e-04 -5.6084391e-06 -1.4589813e-04]]\n",
      "linear.bias:\n",
      " [0.00022054]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471432e-03 -1.0390477e-04  3.3860928e-05  9.2817419e-05\n",
      "   1.7661238e-04 -3.1766604e-07 -1.4507934e-04]]\n",
      "linear.bias:\n",
      " [0.00022028]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04838761e-03 -1.07054235e-04  3.40617335e-05  9.35558128e-05\n",
      "   1.78645118e-04 -2.70016972e-05 -1.43917248e-04]]\n",
      "linear.bias:\n",
      " [0.00021997]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494931e-03 -1.0990521e-04  3.4099681e-05  1.0489397e-04\n",
      "   1.8019867e-04 -9.7886023e-06 -1.4300298e-04]]\n",
      "linear.bias:\n",
      " [0.00021972]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05007435e-03 -1.11905763e-04  3.41632403e-05  1.07011896e-04\n",
      "   1.81943731e-04 -1.84411601e-05 -1.41871438e-04]]\n",
      "linear.bias:\n",
      " [0.00021963]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501825e-03 -1.1304517e-04  3.4214972e-05  1.0505740e-04\n",
      "   1.8353372e-04 -3.4007266e-05 -1.4071322e-04]]\n",
      "linear.bias:\n",
      " [0.00021979]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05031102e-03 -1.12525246e-04  3.41254308e-05  1.12844587e-04\n",
      "   1.84480901e-04  2.42893293e-06 -1.40041258e-04]]\n",
      "linear.bias:\n",
      " [0.00022006]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05024106e-03 -1.10910325e-04  3.37275378e-05  9.29708985e-05\n",
      "   1.84541073e-04 -4.28684143e-05 -1.39932177e-04]]\n",
      "linear.bias:\n",
      " [0.0002205]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502130e-03 -1.0856404e-04  3.3375232e-05  9.2179987e-05\n",
      "   1.8367710e-04 -2.7185102e-05 -1.4027534e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500862e-03 -1.0549677e-04  3.3047374e-05  1.0694563e-04\n",
      "   1.8209776e-04  3.0445011e-05 -1.4097255e-04]]\n",
      "linear.bias:\n",
      " [0.00022139]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492735e-03 -1.0276321e-04  3.2688316e-05  9.3511851e-05\n",
      "   1.8029040e-04 -4.3833399e-05 -1.4201109e-04]]\n",
      "linear.bias:\n",
      " [0.00022183]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484994e-03 -9.9379540e-05  3.2310760e-05  9.6845491e-05\n",
      "   1.7800483e-04 -5.7183446e-05 -1.4327945e-04]]\n",
      "linear.bias:\n",
      " [0.00022227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477599e-03 -9.5409596e-05  3.1916497e-05  1.1529139e-04\n",
      "   1.7528803e-04 -1.5710211e-05 -1.4475507e-04]]\n",
      "linear.bias:\n",
      " [0.0002227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472535e-03 -9.2343085e-05  3.1555312e-05  1.1639213e-04\n",
      "   1.7323994e-04 -1.6631311e-05 -1.4579856e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469784e-03 -9.0201094e-05  3.1295142e-05  1.0241385e-04\n",
      "   1.7205132e-04 -5.4980377e-05 -1.4634516e-04]]\n",
      "linear.bias:\n",
      " [0.00022329]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464923e-03 -8.8944966e-05  3.1160576e-05  1.0039592e-04\n",
      "   1.7131768e-04 -4.8761642e-05 -1.4668131e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458517e-03 -8.8349800e-05  3.1157811e-05  1.0957749e-04\n",
      "   1.7081187e-04 -5.2715695e-06 -1.4689547e-04]]\n",
      "linear.bias:\n",
      " [0.00022352]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04573066e-03 -8.87337519e-05  3.12865122e-05  1.07054424e-04\n",
      "   1.71297084e-04 -1.13693804e-05 -1.46512000e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460679e-03 -8.9819056e-05  3.1552940e-05  9.8055665e-05\n",
      "   1.7253926e-04 -5.2087424e-05 -1.4561521e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462342e-03 -9.1258436e-05  3.1832657e-05  1.0478050e-04\n",
      "   1.7370915e-04 -4.6071480e-05 -1.4478575e-04]]\n",
      "linear.bias:\n",
      " [0.00022331]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461806e-03 -9.3092793e-05  3.2203403e-05  1.2186895e-04\n",
      "   1.7491833e-04 -2.7232381e-06 -1.4394976e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462028e-03 -9.5635958e-05  3.2597862e-05  1.1721728e-04\n",
      "   1.7652189e-04 -1.1435233e-05 -1.4300007e-04]]\n",
      "linear.bias:\n",
      " [0.00022307]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463836e-03 -9.8439392e-05  3.2947035e-05  9.7414304e-05\n",
      "   1.7836795e-04 -5.7629528e-05 -1.4185708e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465658e-03 -1.0007641e-04  3.3230011e-05  9.5954791e-05\n",
      "   1.7920793e-04 -4.3187876e-05 -1.4124010e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466874e-03 -1.0061996e-04  3.3430184e-05  1.1021728e-04\n",
      "   1.7930014e-04  2.3423989e-05 -1.4102072e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462763e-03 -1.0105621e-04  3.3563745e-05  9.3568800e-05\n",
      "   1.7887699e-04 -3.0615000e-05 -1.4135691e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458905e-03 -1.0146363e-04  3.3538538e-05  8.9420173e-05\n",
      "   1.7821348e-04 -3.8225808e-05 -1.4179455e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04550039e-03 -1.00897509e-04  3.34610013e-05  1.01291065e-04\n",
      "   1.76949965e-04  8.37453626e-06 -1.42525838e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456541e-03 -1.0078469e-04  3.3454337e-05  1.0202105e-04\n",
      "   1.7609024e-04 -5.0597009e-06 -1.4287326e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462734e-03 -1.0126830e-04  3.3514501e-05  9.6981552e-05\n",
      "   1.7578868e-04 -5.1914230e-05 -1.4275254e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467884e-03 -1.0076864e-04  3.3513734e-05  1.0808456e-04\n",
      "   1.7484961e-04 -4.0623243e-05 -1.4298171e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470138e-03 -1.0037872e-04  3.3473458e-05  1.2363707e-04\n",
      "   1.7376122e-04  7.5585485e-06 -1.4332283e-04]]\n",
      "linear.bias:\n",
      " [0.00022292]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04691286e-03 -1.00190526e-04  3.34484321e-05  1.07415464e-04\n",
      "   1.72587665e-04 -2.86084105e-05 -1.43826852e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469819e-03 -1.0069672e-04  3.3256580e-05  9.0450609e-05\n",
      "   1.7164477e-04 -5.1502975e-05 -1.4418617e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470228e-03 -1.0032663e-04  3.3100994e-05  9.1417409e-05\n",
      "   1.7038688e-04 -1.7911916e-05 -1.4473961e-04]]\n",
      "linear.bias:\n",
      " [0.0002233]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467161e-03 -1.0072320e-04  3.3152854e-05  9.9746678e-05\n",
      "   1.6959402e-04  1.4512963e-05 -1.4496238e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467282e-03 -1.0172274e-04  3.3297660e-05  9.4442730e-05\n",
      "   1.6978741e-04 -3.0235300e-05 -1.4457920e-04]]\n",
      "linear.bias:\n",
      " [0.00022321]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04679505e-03 -1.03075916e-04  3.34452998e-05  1.01871126e-04\n",
      "   1.70094223e-04 -3.11695039e-05 -1.44196150e-04]]\n",
      "linear.bias:\n",
      " [0.00022301]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04658550e-03 -1.04659615e-04  3.36179728e-05  1.13104950e-04\n",
      "   1.70681320e-04 -4.31733133e-06 -1.43679121e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466441e-03 -1.0657992e-04  3.3834051e-05  1.0899015e-04\n",
      "   1.7172330e-04 -2.4303876e-05 -1.4285669e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469558e-03 -1.0856506e-04  3.3908327e-05  9.7849945e-05\n",
      "   1.7294954e-04 -4.1858504e-05 -1.4194273e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04738935e-03 -1.09394357e-04  3.38966383e-05  1.00762016e-04\n",
      "   1.73461987e-04 -7.33803608e-06 -1.41444354e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480618e-03 -1.0986647e-04  3.3807890e-05  9.6738855e-05\n",
      "   1.7432336e-04 -8.7085282e-06 -1.4059436e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482733e-03 -1.0961598e-04  3.3783919e-05  9.1993192e-05\n",
      "   1.7529147e-04 -3.4436322e-05 -1.3951640e-04]]\n",
      "linear.bias:\n",
      " [0.00022244]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484206e-03 -1.0844498e-04  3.3706772e-05  1.0351911e-04\n",
      "   1.7548876e-04 -4.0113773e-06 -1.3888704e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489792e-03 -1.0764114e-04  3.3611512e-05  1.0294272e-04\n",
      "   1.7603766e-04 -1.6731870e-05 -1.3792909e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04920857e-03 -1.07169872e-04  3.35389959e-05  1.01094905e-04\n",
      "   1.76487563e-04 -2.95105074e-05 -1.37005161e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493286e-03 -1.0670783e-04  3.3324352e-05  1.0863779e-04\n",
      "   1.7657249e-04 -1.0914160e-05 -1.3635661e-04]]\n",
      "linear.bias:\n",
      " [0.00022268]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495079e-03 -1.0654956e-04  3.3047072e-05  1.0163355e-04\n",
      "   1.7693262e-04 -2.3540388e-05 -1.3554719e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04957120e-03 -1.06365274e-04  3.26596601e-05  1.02810482e-04\n",
      "   1.76976348e-04 -9.53877043e-06 -1.34970236e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04943244e-03 -1.06043415e-04  3.23807581e-05  9.53000053e-05\n",
      "   1.77221867e-04 -1.93548512e-05 -1.34234462e-04]]\n",
      "linear.bias:\n",
      " [0.00022333]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492022e-03 -1.0574369e-04  3.1999611e-05  9.6976582e-05\n",
      "   1.7715459e-04 -2.2381573e-06 -1.3370006e-04]]\n",
      "linear.bias:\n",
      " [0.00022363]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487527e-03 -1.0533627e-04  3.1766333e-05  9.7540120e-05\n",
      "   1.7720823e-04 -1.1349053e-05 -1.3293228e-04]]\n",
      "linear.bias:\n",
      " [0.0002239]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04815490e-03 -1.05000392e-04  3.16260885e-05  1.03897175e-04\n",
      "   1.77045426e-04 -1.74748457e-05 -1.32262634e-04]]\n",
      "linear.bias:\n",
      " [0.00022414]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474643e-03 -1.0466463e-04  3.1517728e-05  1.0918808e-04\n",
      "   1.7677866e-04 -1.7365595e-05 -1.3178463e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462537e-03 -1.0464872e-04  3.1349693e-05  1.0488096e-04\n",
      "   1.7642777e-04 -2.2850902e-05 -1.3154777e-04]]\n",
      "linear.bias:\n",
      " [0.0002248]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04519108e-03 -1.04501953e-04  3.10755204e-05  1.03816776e-04\n",
      "   1.76028407e-04 -4.71500789e-06 -1.31524546e-04]]\n",
      "linear.bias:\n",
      " [0.00022526]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447436e-03 -1.0451227e-04  3.0788498e-05  9.1410700e-05\n",
      "   1.7597004e-04 -2.7125314e-05 -1.3118438e-04]]\n",
      "linear.bias:\n",
      " [0.00022562]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444822e-03 -1.0359353e-04  3.0488438e-05  9.3942064e-05\n",
      "   1.7509414e-04 -3.2326097e-06 -1.3140962e-04]]\n",
      "linear.bias:\n",
      " [0.00022582]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448192e-03 -1.0365667e-04  3.0110226e-05  9.9494900e-05\n",
      "   1.7439593e-04 -4.8656511e-07 -1.3139576e-04]]\n",
      "linear.bias:\n",
      " [0.00022587]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456564e-03 -1.0408836e-04  2.9811097e-05  1.0024615e-04\n",
      "   1.7411035e-04 -4.0775125e-05 -1.3104211e-04]]\n",
      "linear.bias:\n",
      " [0.00022574]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04665733e-03 -1.03506776e-04  2.94932961e-05  1.13458198e-04\n",
      "   1.73076842e-04 -2.18098266e-05 -1.31295121e-04]]\n",
      "linear.bias:\n",
      " [0.00022558]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469973e-03 -1.0320527e-04  2.9228941e-05  1.1822762e-04\n",
      "   1.7216968e-04 -8.9227533e-06 -1.3154594e-04]]\n",
      "linear.bias:\n",
      " [0.00022557]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472427e-03 -1.0311876e-04  2.8853248e-05  9.7551034e-05\n",
      "   1.7107085e-04 -4.6716515e-05 -1.3195453e-04]]\n",
      "linear.bias:\n",
      " [0.00022569]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474838e-03 -1.0215747e-04  2.8475508e-05  9.6605843e-05\n",
      "   1.6923771e-04 -2.1331272e-05 -1.3286338e-04]]\n",
      "linear.bias:\n",
      " [0.00022571]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474757e-03 -1.0168673e-04  2.8258830e-05  1.0729735e-04\n",
      "   1.6754751e-04  2.2440296e-05 -1.3365800e-04]]\n",
      "linear.bias:\n",
      " [0.0002256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04677235e-03 -1.01591126e-04  2.82613255e-05  8.91724776e-05\n",
      "   1.65920937e-04 -5.47224190e-05 -1.34706905e-04]]\n",
      "linear.bias:\n",
      " [0.00022554]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461811e-03 -1.0073463e-04  2.8298315e-05  9.1134134e-05\n",
      "   1.6387810e-04 -6.4181622e-05 -1.3608178e-04]]\n",
      "linear.bias:\n",
      " [0.00022536]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04581821e-03 -9.91543202e-05  2.83593818e-05  1.13870985e-04\n",
      "   1.61468590e-04  7.07344589e-06 -1.37736497e-04]]\n",
      "linear.bias:\n",
      " [0.00022515]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04579597e-03 -9.86683226e-05  2.85605402e-05  1.14182716e-04\n",
      "   1.60497366e-04  8.77136063e-06 -1.38924021e-04]]\n",
      "linear.bias:\n",
      " [0.00022492]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458082e-03 -9.9398087e-05  2.8956878e-05  9.3864517e-05\n",
      "   1.6089808e-04 -6.0930255e-05 -1.3964866e-04]]\n",
      "linear.bias:\n",
      " [0.00022463]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459196e-03 -9.9493904e-05  2.9402609e-05  9.2824754e-05\n",
      "   1.6156107e-04 -6.0474918e-05 -1.4037149e-04]]\n",
      "linear.bias:\n",
      " [0.00022432]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460988e-03 -9.9167992e-05  2.9869778e-05  1.0958350e-04\n",
      "   1.6222906e-04 -3.2805474e-07 -1.4113481e-04]]\n",
      "linear.bias:\n",
      " [0.00022404]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04670739e-03 -9.96469316e-05  3.03506713e-05  1.08904416e-04\n",
      "   1.63976525e-04  5.83713881e-06 -1.41243261e-04]]\n",
      "linear.bias:\n",
      " [0.00022366]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04770320e-03 -1.00851365e-04  3.08439703e-05  9.25098575e-05\n",
      "   1.66697137e-04 -3.65869710e-05 -1.40761447e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486576e-03 -1.0240237e-04  3.1305994e-05  9.0282847e-05\n",
      "   1.6928406e-04 -3.5215344e-05 -1.4028845e-04]]\n",
      "linear.bias:\n",
      " [0.00022272]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493736e-03 -1.0428179e-04  3.1763648e-05  1.0371429e-04\n",
      "   1.7166737e-04  8.8136476e-06 -1.3983973e-04]]\n",
      "linear.bias:\n",
      " [0.0002223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501253e-03 -1.0611733e-04  3.2216558e-05  1.0214332e-04\n",
      "   1.7392181e-04 -1.9562574e-05 -1.3920020e-04]]\n",
      "linear.bias:\n",
      " [0.00022175]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504010e-03 -1.0808261e-04  3.2605160e-05  1.0046430e-04\n",
      "   1.7596676e-04 -4.0241786e-05 -1.3855225e-04]]\n",
      "linear.bias:\n",
      " [0.00022138]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508136e-03 -1.0883323e-04  3.2866163e-05  1.1128660e-04\n",
      "   1.7720672e-04 -8.8740053e-06 -1.3832755e-04]]\n",
      "linear.bias:\n",
      " [0.00022109]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504636e-03 -1.0864299e-04  3.3120359e-05  1.0459869e-04\n",
      "   1.7853253e-04 -1.4345502e-05 -1.3791207e-04]]\n",
      "linear.bias:\n",
      " [0.00022087]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499685e-03 -1.0829394e-04  3.3414413e-05  9.1996648e-05\n",
      "   1.7985945e-04 -2.9896268e-05 -1.3739460e-04]]\n",
      "linear.bias:\n",
      " [0.00022085]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494950e-03 -1.0699166e-04  3.3661483e-05  9.7827819e-05\n",
      "   1.8024903e-04  1.0258334e-05 -1.3731574e-04]]\n",
      "linear.bias:\n",
      " [0.00022092]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04958727e-03 -1.05146755e-04  3.36626981e-05  8.93905308e-05\n",
      "   1.80099159e-04 -2.43099803e-05 -1.37297669e-04]]\n",
      "linear.bias:\n",
      " [0.00022094]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495628e-03 -1.0247470e-04  3.3652635e-05  9.8109878e-05\n",
      "   1.7911564e-04 -1.1870071e-05 -1.3769248e-04]]\n",
      "linear.bias:\n",
      " [0.000221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04915095e-03 -1.00312136e-04  3.36287994e-05  1.08684886e-04\n",
      "   1.77987487e-04  2.39236033e-06 -1.38043746e-04]]\n",
      "linear.bias:\n",
      " [0.00022114]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490501e-03 -9.8796052e-05  3.3666198e-05  9.9765457e-05\n",
      "   1.7716730e-04 -3.9850711e-05 -1.3823860e-04]]\n",
      "linear.bias:\n",
      " [0.00022132]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489430e-03 -9.7445729e-05  3.3547447e-05  1.0305647e-04\n",
      "   1.7613276e-04 -3.6559133e-05 -1.3855533e-04]]\n",
      "linear.bias:\n",
      " [0.00022151]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488374e-03 -9.6211836e-05  3.3279783e-05  1.1638381e-04\n",
      "   1.7491249e-04  7.1784852e-06 -1.3900668e-04]]\n",
      "linear.bias:\n",
      " [0.00022178]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486197e-03 -9.5536481e-05  3.3061075e-05  1.0172044e-04\n",
      "   1.7362650e-04 -3.0468469e-05 -1.3960432e-04]]\n",
      "linear.bias:\n",
      " [0.00022215]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480887e-03 -9.5532007e-05  3.2888460e-05  9.6902579e-05\n",
      "   1.7245178e-04 -3.2574499e-05 -1.4009270e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476460e-03 -9.5882737e-05  3.2675376e-05  1.0465721e-04\n",
      "   1.7125950e-04  4.3976397e-06 -1.4060702e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477409e-03 -9.6798380e-05  3.2552096e-05  1.0105782e-04\n",
      "   1.7073286e-04 -5.0615936e-06 -1.4059769e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482763e-03 -9.8288830e-05  3.2524771e-05  9.0140289e-05\n",
      "   1.7083825e-04 -4.9739589e-05 -1.4011959e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487363e-03 -9.8766723e-05  3.2518175e-05  9.7255965e-05\n",
      "   1.7050549e-04 -3.5343048e-05 -1.3992949e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492089e-03 -9.9670404e-05  3.2530221e-05  1.1637848e-04\n",
      "   1.7034437e-04  1.7269536e-05 -1.3971863e-04]]\n",
      "linear.bias:\n",
      " [0.00022347]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486324e-03 -1.0067295e-04  3.2650987e-05  1.0410793e-04\n",
      "   1.7023487e-04 -4.3071577e-05 -1.3984123e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04787247e-03 -1.01742684e-04  3.27898160e-05  1.01833066e-04\n",
      "   1.70145970e-04 -5.64230031e-05 -1.39988188e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04736828e-03 -1.01835685e-04  3.28937094e-05  1.14018389e-04\n",
      "   1.69747305e-04 -1.57727663e-05 -1.40358985e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470846e-03 -1.0246319e-04  3.2980799e-05  1.0851533e-04\n",
      "   1.6981422e-04 -1.7602566e-05 -1.4038800e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472775e-03 -1.0366764e-04  3.3069613e-05  9.2826376e-05\n",
      "   1.7028785e-04 -4.2100892e-05 -1.4011475e-04]]\n",
      "linear.bias:\n",
      " [0.00022317]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474288e-03 -1.0388340e-04  3.3167718e-05  9.5723663e-05\n",
      "   1.7028452e-04 -9.6285075e-06 -1.4011041e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474260e-03 -1.0425546e-04  3.3487937e-05  9.7813427e-05\n",
      "   1.7074094e-04 -4.6952323e-06 -1.3972957e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479322e-03 -1.0520957e-04  3.3846340e-05  9.3695475e-05\n",
      "   1.7165211e-04 -3.5241210e-05 -1.3892789e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483715e-03 -1.0608428e-04  3.4014760e-05  1.0144319e-04\n",
      "   1.7217318e-04 -2.1417980e-05 -1.3834889e-04]]\n",
      "linear.bias:\n",
      " [0.0002227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04866258e-03 -1.06986030e-04  3.40217412e-05  1.11806825e-04\n",
      "   1.72633096e-04  8.57833766e-06 -1.37865180e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04901684e-03 -1.07307744e-04  3.39957805e-05  9.61536862e-05\n",
      "   1.72563203e-04 -5.55349761e-05 -1.37754861e-04]]\n",
      "linear.bias:\n",
      " [0.00022264]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492887e-03 -1.0661896e-04  3.3899003e-05  9.8740158e-05\n",
      "   1.7181857e-04 -5.8057991e-05 -1.3802764e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494863e-03 -1.0501932e-04  3.3738390e-05  1.1776414e-04\n",
      "   1.7046570e-04 -5.1676070e-06 -1.3864573e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498028e-03 -1.0380731e-04  3.3502838e-05  1.1600051e-04\n",
      "   1.6952657e-04  4.2974243e-06 -1.3902780e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500907e-03 -1.0338922e-04  3.3405831e-05  9.3405164e-05\n",
      "   1.6917878e-04 -5.1087543e-05 -1.3914386e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503273e-03 -1.0213713e-04  3.3336706e-05  9.0197238e-05\n",
      "   1.6843241e-04 -4.6437228e-05 -1.3949195e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505179e-03 -1.0013323e-04  3.3292708e-05  1.0446064e-04\n",
      "   1.6732673e-04  1.2229739e-05 -1.4004925e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05045305e-03 -9.89050386e-05  3.33398166e-05  1.00718564e-04\n",
      "   1.66851110e-04 -1.73350127e-05 -1.40242060e-04]]\n",
      "linear.bias:\n",
      " [0.00022244]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500918e-03 -9.8608856e-05  3.3621265e-05  9.8333679e-05\n",
      "   1.6707691e-04 -4.7858281e-05 -1.4007367e-04]]\n",
      "linear.bias:\n",
      " [0.00022226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497727e-03 -9.8476790e-05  3.3796019e-05  1.0831996e-04\n",
      "   1.6725557e-04 -3.3347951e-05 -1.3995021e-04]]\n",
      "linear.bias:\n",
      " [0.0002221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491837e-03 -9.8747907e-05  3.4014047e-05  1.1581069e-04\n",
      "   1.6784800e-04  4.8937836e-06 -1.3969657e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04881846e-03 -9.99229960e-05  3.43463034e-05  1.02787955e-04\n",
      "   1.69047416e-04 -1.44633068e-05 -1.39187279e-04]]\n",
      "linear.bias:\n",
      " [0.0002222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04862021e-03 -1.02103026e-04  3.45698390e-05  8.73990357e-05\n",
      "   1.70478903e-04 -4.10415450e-05 -1.38495525e-04]]\n",
      "linear.bias:\n",
      " [0.00022231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04841893e-03 -1.03185776e-04  3.47895257e-05  9.07757494e-05\n",
      "   1.71332504e-04 -1.04383726e-05 -1.38117510e-04]]\n",
      "linear.bias:\n",
      " [0.00022241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04812719e-03 -1.04721476e-04  3.50050759e-05  1.02238235e-04\n",
      "   1.72159052e-04  2.00946743e-05 -1.37655050e-04]]\n",
      "linear.bias:\n",
      " [0.00022255]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477793e-03 -1.0608123e-04  3.5174209e-05  9.2157323e-05\n",
      "   1.7282878e-04 -4.8285561e-05 -1.3743332e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04742020e-03 -1.06303414e-04  3.52676325e-05  9.97517418e-05\n",
      "   1.72716536e-04 -5.61290872e-05 -1.37595824e-04]]\n",
      "linear.bias:\n",
      " [0.00022266]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470491e-03 -1.0551333e-04  3.5277506e-05  1.2345436e-04\n",
      "   1.7192564e-04 -8.0955724e-06 -1.3811875e-04]]\n",
      "linear.bias:\n",
      " [0.00022272]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467340e-03 -1.0487502e-04  3.5077243e-05  1.2056439e-04\n",
      "   1.7099183e-04 -1.0130330e-05 -1.3872384e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04655873e-03 -1.04600476e-04  3.47077330e-05  9.67898377e-05\n",
      "   1.70292042e-04 -5.14629428e-05 -1.39272190e-04]]\n",
      "linear.bias:\n",
      " [0.0002231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463779e-03 -1.0346792e-04  3.4393379e-05  9.2691662e-05\n",
      "   1.6922380e-04 -3.4204506e-05 -1.4001236e-04]]\n",
      "linear.bias:\n",
      " [0.0002233]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04622147e-03 -1.02583763e-04  3.40308106e-05  1.01231184e-04\n",
      "   1.68236744e-04  2.33182582e-05 -1.40707460e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458790e-03 -1.0238825e-04  3.3743916e-05  9.0467714e-05\n",
      "   1.6812650e-04 -2.3533696e-05 -1.4114607e-04]]\n",
      "linear.bias:\n",
      " [0.00022356]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456380e-03 -1.0264827e-04  3.3582262e-05  9.4534123e-05\n",
      "   1.6823968e-04 -4.2700223e-05 -1.4145463e-04]]\n",
      "linear.bias:\n",
      " [0.00022349]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04542729e-03 -1.03018654e-04  3.33570533e-05  1.10451423e-04\n",
      "   1.68316634e-04 -1.80228199e-05 -1.41761062e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456608e-03 -1.0412102e-04  3.3246386e-05  1.1367144e-04\n",
      "   1.6915737e-04 -2.4643896e-05 -1.4157144e-04]]\n",
      "linear.bias:\n",
      " [0.00022337]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461509e-03 -1.0547370e-04  3.3024829e-05  1.0598207e-04\n",
      "   1.7023286e-04 -4.4787303e-05 -1.4115367e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466339e-03 -1.0673026e-04  3.2736829e-05  1.0816370e-04\n",
      "   1.7119254e-04 -2.0974754e-05 -1.4089653e-04]]\n",
      "linear.bias:\n",
      " [0.00022371]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04731158e-03 -1.08197550e-04  3.23522545e-05  1.01022386e-04\n",
      "   1.72362226e-04 -8.70692656e-06 -1.40456759e-04]]\n",
      "linear.bias:\n",
      " [0.00022413]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478300e-03 -1.0974046e-04  3.2250919e-05  9.0122936e-05\n",
      "   1.7390902e-04 -2.8997434e-05 -1.3962560e-04]]\n",
      "linear.bias:\n",
      " [0.00022446]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482506e-03 -1.1011723e-04  3.2100128e-05  9.7137134e-05\n",
      "   1.7457931e-04  6.5115601e-06 -1.3924294e-04]]\n",
      "linear.bias:\n",
      " [0.0002248]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04908063e-03 -1.10576766e-04  3.19851388e-05  9.31788963e-05\n",
      "   1.75347130e-04 -2.22417093e-05 -1.38550706e-04]]\n",
      "linear.bias:\n",
      " [0.00022488]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04990928e-03 -1.09937784e-04  3.18039747e-05  1.02534257e-04\n",
      "   1.75358495e-04 -8.14314990e-06 -1.38300806e-04]]\n",
      "linear.bias:\n",
      " [0.0002249]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05050951e-03 -1.09232496e-04  3.17878403e-05  1.05716834e-04\n",
      "   1.75695153e-04 -2.43454051e-05 -1.37709023e-04]]\n",
      "linear.bias:\n",
      " [0.00022493]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507968e-03 -1.0855579e-04  3.1753985e-05  1.1044403e-04\n",
      "   1.7593657e-04 -1.7465863e-05 -1.3732212e-04]]\n",
      "linear.bias:\n",
      " [0.00022499]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05057564e-03 -1.07814485e-04  3.18038728e-05  1.02429054e-04\n",
      "   1.76370886e-04 -3.02887020e-05 -1.36809060e-04]]\n",
      "linear.bias:\n",
      " [0.00022519]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501818e-03 -1.0615633e-04  3.1874100e-05  1.0604123e-04\n",
      "   1.7611470e-04 -3.8698709e-06 -1.3669093e-04]]\n",
      "linear.bias:\n",
      " [0.00022532]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499443e-03 -1.0472335e-04  3.1912590e-05  9.2350128e-05\n",
      "   1.7615159e-04 -2.3382521e-05 -1.3628590e-04]]\n",
      "linear.bias:\n",
      " [0.00022535]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496299e-03 -1.0342660e-04  3.1795204e-05  9.0866117e-05\n",
      "   1.7583257e-04 -1.0154190e-05 -1.3609279e-04]]\n",
      "linear.bias:\n",
      " [0.00022538]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04918669e-03 -1.02679616e-04  3.18719794e-05  9.75315415e-05\n",
      "   1.75480309e-04  1.94486165e-06 -1.35846538e-04]]\n",
      "linear.bias:\n",
      " [0.00022531]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493564e-03 -1.0240644e-04  3.1985397e-05  9.9029705e-05\n",
      "   1.7552903e-04 -2.9860550e-05 -1.3526103e-04]]\n",
      "linear.bias:\n",
      " [0.00022506]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494086e-03 -1.0215426e-04  3.1935160e-05  1.1124867e-04\n",
      "   1.7521989e-04 -2.7658167e-05 -1.3490573e-04]]\n",
      "linear.bias:\n",
      " [0.00022484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487653e-03 -1.0215807e-04  3.1874551e-05  1.1703074e-04\n",
      "   1.7503339e-04 -1.3956501e-05 -1.3462288e-04]]\n",
      "linear.bias:\n",
      " [0.00022478]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481998e-03 -1.0234606e-04  3.1636297e-05  9.9820660e-05\n",
      "   1.7489033e-04 -4.2629305e-05 -1.3438881e-04]]\n",
      "linear.bias:\n",
      " [0.00022477]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478582e-03 -1.0149724e-04  3.1344789e-05  9.8951918e-05\n",
      "   1.7409852e-04 -1.6132653e-05 -1.3463874e-04]]\n",
      "linear.bias:\n",
      " [0.00022471]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471955e-03 -1.0134393e-04  3.1166321e-05  1.0178549e-04\n",
      "   1.7330074e-04  8.3428822e-06 -1.3478905e-04]]\n",
      "linear.bias:\n",
      " [0.00022471]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467115e-03 -1.0135681e-04  3.1048618e-05  8.9953683e-05\n",
      "   1.7269622e-04 -3.8020946e-05 -1.3467560e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462307e-03 -1.0036488e-04  3.0890700e-05  9.7004107e-05\n",
      "   1.7139917e-04 -2.4206332e-05 -1.3505253e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457508e-03 -9.9821009e-05  3.0695119e-05  1.1504587e-04\n",
      "   1.7004632e-04  1.6652230e-05 -1.3549451e-04]]\n",
      "linear.bias:\n",
      " [0.00022416]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445627e-03 -9.9674486e-05  3.0604679e-05  9.9459372e-05\n",
      "   1.6860830e-04 -5.4616052e-05 -1.3638681e-04]]\n",
      "linear.bias:\n",
      " [0.00022398]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436827e-03 -9.8656114e-05  3.0509533e-05  1.0090249e-04\n",
      "   1.6695987e-04 -6.4401618e-05 -1.3754811e-04]]\n",
      "linear.bias:\n",
      " [0.00022368]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430168e-03 -9.6631346e-05  3.0462390e-05  1.1741233e-04\n",
      "   1.6526802e-04 -5.2989599e-06 -1.3902543e-04]]\n",
      "linear.bias:\n",
      " [0.00022346]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429135e-03 -9.5656345e-05  3.0496611e-05  1.1396398e-04\n",
      "   1.6497987e-04 -2.3612754e-06 -1.3980619e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433173e-03 -9.5627431e-05  3.0604166e-05  9.2530463e-05\n",
      "   1.6595684e-04 -4.9971321e-05 -1.3995919e-04]]\n",
      "linear.bias:\n",
      " [0.00022281]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435281e-03 -9.6114753e-05  3.0745214e-05  8.9566063e-05\n",
      "   1.6689350e-04 -4.9934748e-05 -1.4007284e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435651e-03 -9.7067394e-05  3.0916461e-05  1.0324523e-04\n",
      "   1.6779389e-04 -6.9997950e-06 -1.4015102e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440956e-03 -9.8749180e-05  3.1238364e-05  1.0813926e-04\n",
      "   1.6950177e-04 -3.7841460e-06 -1.3960719e-04]]\n",
      "linear.bias:\n",
      " [0.00022184]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451218e-03 -1.0083014e-04  3.1600379e-05  9.9227400e-05\n",
      "   1.7162501e-04 -4.3184304e-05 -1.3868591e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04602880e-03 -1.02720427e-04  3.17650993e-05  1.03126724e-04\n",
      "   1.73224238e-04 -3.72525865e-05 -1.38005649e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468644e-03 -1.0433843e-04  3.1743140e-05  1.1532945e-04\n",
      "   1.7436774e-04  9.4528623e-06 -1.3763524e-04]]\n",
      "linear.bias:\n",
      " [0.00022108]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476455e-03 -1.0562584e-04  3.1583935e-05  9.6730655e-05\n",
      "   1.7493228e-04 -4.4658525e-05 -1.3780208e-04]]\n",
      "linear.bias:\n",
      " [0.00022107]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483015e-03 -1.0574938e-04  3.1379670e-05  9.7160628e-05\n",
      "   1.7470140e-04 -3.9523671e-05 -1.3832664e-04]]\n",
      "linear.bias:\n",
      " [0.00022111]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488449e-03 -1.0482392e-04  3.1134776e-05  1.1473837e-04\n",
      "   1.7375359e-04  1.8920480e-05 -1.3917363e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487222e-03 -1.0396925e-04  3.0861487e-05  9.7548320e-05\n",
      "   1.7252129e-04 -4.0003404e-05 -1.4058029e-04]]\n",
      "linear.bias:\n",
      " [0.00022131]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485944e-03 -1.0321563e-04  3.0453319e-05  9.4034440e-05\n",
      "   1.7109698e-04 -5.1836931e-05 -1.4199734e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04845560e-03 -1.01622085e-04  3.01047658e-05  1.08706488e-04\n",
      "   1.69361621e-04 -8.05694435e-06 -1.43528116e-04]]\n",
      "linear.bias:\n",
      " [0.0002216]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04885991e-03 -1.00950536e-04  2.99594976e-05  1.12216527e-04\n",
      "   1.68710641e-04 -3.43102874e-06 -1.44354955e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494858e-03 -1.0128875e-04  2.9970155e-05  9.8950375e-05\n",
      "   1.6916782e-04 -4.6324534e-05 -1.4455929e-04]]\n",
      "linear.bias:\n",
      " [0.00022165]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497660e-03 -1.0183600e-04  3.0011788e-05  9.8475197e-05\n",
      "   1.6958136e-04 -4.4490480e-05 -1.4471504e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497348e-03 -1.0257169e-04  3.0081341e-05  1.0952759e-04\n",
      "   1.6995559e-04 -2.3815228e-06 -1.4482699e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500045e-03 -1.0390574e-04  3.0291440e-05  1.0447862e-04\n",
      "   1.7115081e-04 -8.0830778e-06 -1.4441152e-04]]\n",
      "linear.bias:\n",
      " [0.00022124]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05009426e-03 -1.05390085e-04  3.07484333e-05  9.35239805e-05\n",
      "   1.72824497e-04 -4.56897324e-05 -1.43573416e-04]]\n",
      "linear.bias:\n",
      " [0.00022103]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501513e-03 -1.0580754e-04  3.1179185e-05  1.0157904e-04\n",
      "   1.7387705e-04 -2.5025847e-05 -1.4307437e-04]]\n",
      "linear.bias:\n",
      " [0.00022083]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04969705e-03 -1.06488922e-04  3.15249345e-05  1.12634356e-04\n",
      "   1.74634915e-04  1.10145502e-05 -1.42596909e-04]]\n",
      "linear.bias:\n",
      " [0.0002208]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492761e-03 -1.0702736e-04  3.1951582e-05  9.8102311e-05\n",
      "   1.7492412e-04 -3.7639380e-05 -1.4228513e-04]]\n",
      "linear.bias:\n",
      " [0.00022077]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488795e-03 -1.0752856e-04  3.2172524e-05  9.7069511e-05\n",
      "   1.7486766e-04 -4.0188097e-05 -1.4215567e-04]]\n",
      "linear.bias:\n",
      " [0.00022079]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484743e-03 -1.0693275e-04  3.2309974e-05  1.1348496e-04\n",
      "   1.7406944e-04  1.1245396e-05 -1.4241743e-04]]\n",
      "linear.bias:\n",
      " [0.00022086]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04806188e-03 -1.06595740e-04  3.25435831e-05  1.02270176e-04\n",
      "   1.73144843e-04 -2.69575321e-05 -1.42746328e-04]]\n",
      "linear.bias:\n",
      " [0.00022096]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04718306e-03 -1.06598716e-04  3.27116250e-05  9.59820172e-05\n",
      "   1.72121305e-04 -4.39612631e-05 -1.43014462e-04]]\n",
      "linear.bias:\n",
      " [0.0002212]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463676e-03 -1.0567735e-04  3.2882228e-05  1.0831913e-04\n",
      "   1.7074232e-04 -4.8257134e-06 -1.4351304e-04]]\n",
      "linear.bias:\n",
      " [0.00022141]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04619062e-03 -1.05423227e-04  3.31091796e-05  1.05914114e-04\n",
      "   1.70095154e-04 -1.17164600e-05 -1.43523401e-04]]\n",
      "linear.bias:\n",
      " [0.00022156]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465133e-03 -1.0590751e-04  3.3403252e-05  9.5579402e-05\n",
      "   1.7013328e-04 -5.3987955e-05 -1.4302957e-04]]\n",
      "linear.bias:\n",
      " [0.00022164]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467800e-03 -1.0541764e-04  3.3687404e-05  1.0430811e-04\n",
      "   1.6970950e-04 -3.7567566e-05 -1.4284244e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04717410e-03 -1.04983366e-04  3.38686295e-05  1.18726799e-04\n",
      "   1.69529201e-04  1.62530341e-05 -1.42771343e-04]]\n",
      "linear.bias:\n",
      " [0.00022183]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468278e-03 -1.0417383e-04  3.4051078e-05  9.5816431e-05\n",
      "   1.6965301e-04 -4.7877133e-05 -1.4282392e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464919e-03 -1.0251669e-04  3.4234738e-05  9.3250208e-05\n",
      "   1.6930541e-04 -5.1277413e-05 -1.4312947e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04616536e-03 -1.00095516e-04  3.44195032e-05  1.09016328e-04\n",
      "   1.68532919e-04 -3.47972673e-08 -1.43663026e-04]]\n",
      "linear.bias:\n",
      " [0.00022147]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466186e-03 -9.8657445e-05  3.4575976e-05  1.0772418e-04\n",
      "   1.6881764e-04 -2.8495779e-07 -1.4359294e-04]]\n",
      "linear.bias:\n",
      " [0.00022132]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475225e-03 -9.8285600e-05  3.4785124e-05  9.3766743e-05\n",
      "   1.6985367e-04 -4.6506655e-05 -1.4299515e-04]]\n",
      "linear.bias:\n",
      " [0.00022115]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481238e-03 -9.8110802e-05  3.4915993e-05  9.7111020e-05\n",
      "   1.7066966e-04 -4.3024240e-05 -1.4250452e-04]]\n",
      "linear.bias:\n",
      " [0.00022103]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04867201e-03 -9.80962286e-05  3.49503462e-05  1.12917965e-04\n",
      "   1.71378371e-04  1.99576971e-06 -1.42092555e-04]]\n",
      "linear.bias:\n",
      " [0.00022093]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494284e-03 -9.8942721e-05  3.5056619e-05  1.0819494e-04\n",
      "   1.7279973e-04 -7.3359461e-06 -1.4136368e-04]]\n",
      "linear.bias:\n",
      " [0.00022084]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05067191e-03 -1.00285775e-04  3.52262614e-05  9.03237524e-05\n",
      "   1.74679793e-04 -5.77759274e-05 -1.40264761e-04]]\n",
      "linear.bias:\n",
      " [0.00022071]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0515265e-03 -1.0033956e-04  3.5286106e-05  9.4088275e-05\n",
      "   1.7559668e-04 -4.6454257e-05 -1.3959492e-04]]\n",
      "linear.bias:\n",
      " [0.00022069]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05224771e-03 -9.93272115e-05  3.52776660e-05  1.15020404e-04\n",
      "   1.75665424e-04  1.73085464e-05 -1.39374897e-04]]\n",
      "linear.bias:\n",
      " [0.00022072]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0519370e-03 -9.8315366e-05  3.5143516e-05  9.9173834e-05\n",
      "   1.7545588e-04 -3.7720631e-05 -1.3985226e-04]]\n",
      "linear.bias:\n",
      " [0.00022074]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516394e-03 -9.7420569e-05  3.4856905e-05  9.7114127e-05\n",
      "   1.7494542e-04 -4.6239402e-05 -1.4043580e-04]]\n",
      "linear.bias:\n",
      " [0.00022081]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05113303e-03 -9.66486477e-05  3.44589716e-05  1.10621506e-04\n",
      "   1.74072324e-04 -9.67851520e-06 -1.41133074e-04]]\n",
      "linear.bias:\n",
      " [0.00022097]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508610e-03 -9.6540352e-05  3.4093577e-05  1.0513742e-04\n",
      "   1.7374578e-04 -1.4988881e-05 -1.4143188e-04]]\n",
      "linear.bias:\n",
      " [0.00022107]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508565e-03 -9.7669807e-05  3.3683194e-05  9.5553216e-05\n",
      "   1.7376829e-04 -2.7091060e-05 -1.4145573e-04]]\n",
      "linear.bias:\n",
      " [0.0002212]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504803e-03 -9.9379962e-05  3.3349006e-05  9.7020893e-05\n",
      "   1.7376243e-04 -5.8154656e-06 -1.4139598e-04]]\n",
      "linear.bias:\n",
      " [0.00022132]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505780e-03 -1.0162113e-04  3.3105862e-05  9.4844378e-05\n",
      "   1.7408306e-04 -1.8565079e-05 -1.4087444e-04]]\n",
      "linear.bias:\n",
      " [0.00022138]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501555e-03 -1.0437063e-04  3.2947159e-05  9.8874436e-05\n",
      "   1.7434142e-04 -2.2707343e-05 -1.4028956e-04]]\n",
      "linear.bias:\n",
      " [0.00022149]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492526e-03 -1.0710778e-04  3.2747623e-05  1.0788429e-04\n",
      "   1.7437850e-04 -7.6035212e-06 -1.3977135e-04]]\n",
      "linear.bias:\n",
      " [0.00022167]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486632e-03 -1.0976296e-04  3.2532706e-05  9.9236968e-05\n",
      "   1.7481692e-04 -3.5833131e-05 -1.3897322e-04]]\n",
      "linear.bias:\n",
      " [0.0002218]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481393e-03 -1.1042145e-04  3.2180815e-05  1.0470233e-04\n",
      "   1.7463822e-04 -1.1459770e-05 -1.3861802e-04]]\n",
      "linear.bias:\n",
      " [0.000222]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472130e-03 -1.1028425e-04  3.1897951e-05  9.8018441e-05\n",
      "   1.7488968e-04 -1.3112255e-05 -1.3800731e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463449e-03 -1.1029450e-04  3.1585394e-05  9.7895885e-05\n",
      "   1.7494244e-04 -1.5942100e-05 -1.3743763e-04]]\n",
      "linear.bias:\n",
      " [0.00022282]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04564417e-03 -1.10233734e-04  3.12649790e-05  1.05470273e-04\n",
      "   1.74723973e-04 -1.48740482e-05 -1.37008581e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04485452e-03 -1.10009336e-04  3.10515024e-05  1.03526210e-04\n",
      "   1.74687841e-04 -2.95395530e-05 -1.36422692e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442535e-03 -1.0858467e-04  3.0781404e-05  1.1007595e-04\n",
      "   1.7399831e-04 -7.5609933e-06 -1.3635030e-04]]\n",
      "linear.bias:\n",
      " [0.00022438]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04393705e-03 -1.07492495e-04  3.05027570e-05  9.91337729e-05\n",
      "   1.73784341e-04 -2.97351307e-05 -1.35952039e-04]]\n",
      "linear.bias:\n",
      " [0.00022486]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04382599e-03 -1.05416795e-04  3.01622749e-05  1.03854967e-04\n",
      "   1.72917251e-04  8.73371391e-07 -1.35963375e-04]]\n",
      "linear.bias:\n",
      " [0.00022529]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442672e-03 -1.0420507e-04  2.9930901e-05  9.6601871e-05\n",
      "   1.7273646e-04 -1.4288441e-05 -1.3545534e-04]]\n",
      "linear.bias:\n",
      " [0.00022558]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446088e-03 -1.0352433e-04  2.9932924e-05  9.5518517e-05\n",
      "   1.7272051e-04 -3.0678737e-05 -1.3489425e-04]]\n",
      "linear.bias:\n",
      " [0.0002257]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04509073e-03 -1.01816862e-04  2.98450341e-05  1.09147775e-04\n",
      "   1.72030326e-04  5.17957233e-06 -1.34759714e-04]]\n",
      "linear.bias:\n",
      " [0.0002258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458811e-03 -1.0067019e-04  2.9832463e-05  1.0388909e-04\n",
      "   1.7185473e-04 -1.8208453e-05 -1.3437872e-04]]\n",
      "linear.bias:\n",
      " [0.0002258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470148e-03 -1.0061812e-04  2.9742587e-05  9.5917945e-05\n",
      "   1.7185214e-04 -4.4704691e-05 -1.3396205e-04]]\n",
      "linear.bias:\n",
      " [0.0002258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480605e-03 -9.9564277e-05  2.9633869e-05  1.0819574e-04\n",
      "   1.7087362e-04 -1.0790231e-05 -1.3417954e-04]]\n",
      "linear.bias:\n",
      " [0.00022575]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04923744e-03 -9.92535352e-05  2.96219096e-05  1.06310625e-04\n",
      "   1.70616026e-04 -1.81335490e-05 -1.33969908e-04]]\n",
      "linear.bias:\n",
      " [0.00022566]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500116e-03 -9.9624442e-05  2.9746829e-05  9.9738361e-05\n",
      "   1.7061306e-04 -2.9166669e-05 -1.3369080e-04]]\n",
      "linear.bias:\n",
      " [0.00022572]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503585e-03 -1.0043268e-04  2.9921754e-05  1.0488710e-04\n",
      "   1.7044449e-04 -1.2290839e-05 -1.3348747e-04]]\n",
      "linear.bias:\n",
      " [0.00022568]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501686e-03 -1.0177722e-04  3.0293273e-05  1.0175536e-04\n",
      "   1.7070786e-04 -2.1562177e-05 -1.3309410e-04]]\n",
      "linear.bias:\n",
      " [0.00022559]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04975549e-03 -1.03388054e-04  3.07128284e-05  1.04031380e-04\n",
      "   1.71049876e-04 -1.13431779e-05 -1.32751593e-04]]\n",
      "linear.bias:\n",
      " [0.00022546]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489351e-03 -1.0534767e-04  3.1275566e-05  1.0170796e-04\n",
      "   1.7168027e-04 -2.4013565e-05 -1.3228625e-04]]\n",
      "linear.bias:\n",
      " [0.0002252]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04792579e-03 -1.07068292e-04  3.17617632e-05  1.01589554e-04\n",
      "   1.72182044e-04 -1.38596288e-05 -1.32023095e-04]]\n",
      "linear.bias:\n",
      " [0.00022502]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04684348e-03 -1.08580076e-04  3.22200976e-05  1.00993449e-04\n",
      "   1.72497137e-04  9.32941475e-07 -1.31928638e-04]]\n",
      "linear.bias:\n",
      " [0.0002249]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464709e-03 -1.0997006e-04  3.2571483e-05  9.0150017e-05\n",
      "   1.7295625e-04 -3.4195647e-05 -1.3148964e-04]]\n",
      "linear.bias:\n",
      " [0.00022465]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04608794e-03 -1.10158624e-04  3.28329515e-05  9.90407279e-05\n",
      "   1.72572312e-04 -1.02053509e-05 -1.31601904e-04]]\n",
      "linear.bias:\n",
      " [0.00022442]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458764e-03 -1.1021702e-04  3.3050965e-05  1.1105064e-04\n",
      "   1.7224737e-04  5.2609885e-06 -1.3171566e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454661e-03 -1.0909002e-04  3.2921136e-05  9.0940521e-05\n",
      "   1.7109051e-04 -7.1892675e-05 -1.3248499e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04513532e-03 -1.06592284e-04  3.27145062e-05  1.03231941e-04\n",
      "   1.68733488e-04 -2.78039115e-05 -1.33942085e-04]]\n",
      "linear.bias:\n",
      " [0.00022373]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448692e-03 -1.0419149e-04  3.2388129e-05  1.1747741e-04\n",
      "   1.6651551e-04  3.4949564e-05 -1.3547154e-04]]\n",
      "linear.bias:\n",
      " [0.00022364]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04387128e-03 -1.01034966e-04  3.18582206e-05  8.65440161e-05\n",
      "   1.64671845e-04 -5.21793663e-05 -1.37478346e-04]]\n",
      "linear.bias:\n",
      " [0.00022352]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431061e-03 -9.7587625e-05  3.1486034e-05  7.9652389e-05\n",
      "   1.6285446e-04 -7.2312338e-05 -1.3960796e-04]]\n",
      "linear.bias:\n",
      " [0.0002233]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425824e-03 -9.3808208e-05  3.1186897e-05  1.1131352e-04\n",
      "   1.6071953e-04  2.4566085e-05 -1.4203689e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419665e-03 -9.1288006e-05  3.1141204e-05  1.1540151e-04\n",
      "   1.5989627e-04  8.8490979e-06 -1.4401565e-04]]\n",
      "linear.bias:\n",
      " [0.00022251]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414941e-03 -9.0416957e-05  3.1353313e-05  9.6890537e-05\n",
      "   1.6055886e-04 -6.9952053e-05 -1.4532356e-04]]\n",
      "linear.bias:\n",
      " [0.00022205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410395e-03 -9.0053800e-05  3.1611416e-05  9.8137818e-05\n",
      "   1.6189285e-04 -5.8435398e-05 -1.4639068e-04]]\n",
      "linear.bias:\n",
      " [0.00022179]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407512e-03 -9.0371374e-05  3.1811829e-05  1.1357887e-04\n",
      "   1.6362444e-04 -1.2185883e-06 -1.4724181e-04]]\n",
      "linear.bias:\n",
      " [0.00022155]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04129268e-03 -9.15592245e-05  3.20665131e-05  1.12115755e-04\n",
      "   1.66506550e-04  4.91202127e-06 -1.47309242e-04]]\n",
      "linear.bias:\n",
      " [0.00022124]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425517e-03 -9.3601200e-05  3.2370364e-05  9.7759068e-05\n",
      "   1.7041680e-04 -3.5452016e-05 -1.4659985e-04]]\n",
      "linear.bias:\n",
      " [0.00022081]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442974e-03 -9.6624761e-05  3.2456763e-05  9.5258874e-05\n",
      "   1.7420795e-04 -4.1073912e-05 -1.4577300e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457068e-03 -9.9894758e-05  3.2581640e-05  1.1028917e-04\n",
      "   1.7768281e-04 -3.6975034e-06 -1.4500259e-04]]\n",
      "linear.bias:\n",
      " [0.00021998]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04755943e-03 -1.03442166e-04  3.27708003e-05  1.09755943e-04\n",
      "   1.81434720e-04 -1.18732441e-05 -1.43849757e-04]]\n",
      "linear.bias:\n",
      " [0.00021958]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04960555e-03 -1.06962216e-04  3.28498536e-05  9.58025266e-05\n",
      "   1.85166238e-04 -4.62237876e-05 -1.42507502e-04]]\n",
      "linear.bias:\n",
      " [0.00021931]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0514171e-03 -1.0901534e-04  3.2900949e-05  1.0242543e-04\n",
      "   1.8761602e-04 -2.3466735e-05 -1.4173651e-04]]\n",
      "linear.bias:\n",
      " [0.00021917]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05259567e-03 -1.11043460e-04  3.29262512e-05  1.12930546e-04\n",
      "   1.89523562e-04  9.69161556e-06 -1.41094904e-04]]\n",
      "linear.bias:\n",
      " [0.0002192]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0532102e-03 -1.1125413e-04  3.2637403e-05  8.9883906e-05\n",
      "   1.9033515e-04 -4.8147438e-05 -1.4113879e-04]]\n",
      "linear.bias:\n",
      " [0.00021937]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05344655e-03 -1.09940716e-04  3.23306158e-05  9.75886142e-05\n",
      "   1.89110127e-04 -3.35161349e-05 -1.41841374e-04]]\n",
      "linear.bias:\n",
      " [0.00021957]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05361547e-03 -1.07546715e-04  3.20605286e-05  1.24680912e-04\n",
      "   1.86932855e-04  3.40165607e-05 -1.42960751e-04]]\n",
      "linear.bias:\n",
      " [0.0002199]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05257647e-03 -1.04293904e-04  3.15878387e-05  9.68238019e-05\n",
      "   1.84428209e-04 -7.43189303e-05 -1.44798600e-04]]\n",
      "linear.bias:\n",
      " [0.0002205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0514749e-03 -9.9986675e-05  3.1177293e-05  9.8326789e-05\n",
      "   1.8057683e-04 -8.2029088e-05 -1.4698657e-04]]\n",
      "linear.bias:\n",
      " [0.00022103]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503824e-03 -9.4909476e-05  3.0804164e-05  1.2885306e-04\n",
      "   1.7635188e-04  2.1015607e-05 -1.4935185e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488098e-03 -9.0253227e-05  3.0612966e-05  1.1659142e-04\n",
      "   1.7218749e-04 -7.7488603e-06 -1.5189490e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476721e-03 -8.7063287e-05  3.0591349e-05  8.8215202e-05\n",
      "   1.6954743e-04 -7.9622878e-05 -1.5361018e-04]]\n",
      "linear.bias:\n",
      " [0.00022224]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463753e-03 -8.5043350e-05  3.0406349e-05  9.3103372e-05\n",
      "   1.6761012e-04 -4.9197020e-05 -1.5490185e-04]]\n",
      "linear.bias:\n",
      " [0.00022251]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447424e-03 -8.4784166e-05  3.0351513e-05  1.1243073e-04\n",
      "   1.6622222e-04  1.6939455e-05 -1.5581214e-04]]\n",
      "linear.bias:\n",
      " [0.00022274]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433146e-03 -8.5930442e-05  3.0522831e-05  1.1161727e-04\n",
      "   1.6633362e-04  1.2369450e-05 -1.5586763e-04]]\n",
      "linear.bias:\n",
      " [0.00022271]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424961e-03 -8.8211396e-05  3.0831867e-05  9.7244585e-05\n",
      "   1.6785209e-04 -4.5488276e-05 -1.5508957e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420257e-03 -9.1739064e-05  3.1020154e-05  9.3123708e-05\n",
      "   1.6974082e-04 -6.6084060e-05 -1.5405563e-04]]\n",
      "linear.bias:\n",
      " [0.00022222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04131212e-03 -9.55053620e-05  3.11578187e-05  1.12020265e-04\n",
      "   1.71740248e-04 -1.63746408e-05 -1.52950233e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04144041e-03 -9.96661911e-05  3.13804449e-05  1.20651166e-04\n",
      "   1.74711080e-04 -6.92345930e-06 -1.51203771e-04]]\n",
      "linear.bias:\n",
      " [0.00022191]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420835e-03 -1.0387819e-04  3.1570391e-05  1.1142929e-04\n",
      "   1.7819680e-04 -4.2530461e-05 -1.4912021e-04]]\n",
      "linear.bias:\n",
      " [0.00022156]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430946e-03 -1.0821588e-04  3.1552045e-05  1.0084716e-04\n",
      "   1.8143284e-04 -4.9475380e-05 -1.4728408e-04]]\n",
      "linear.bias:\n",
      " [0.00022139]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441857e-03 -1.1098922e-04  3.1442618e-05  1.0635009e-04\n",
      "   1.8364744e-04 -6.4592714e-06 -1.4601441e-04]]\n",
      "linear.bias:\n",
      " [0.00022124]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04562799e-03 -1.13592236e-04  3.13071105e-05  9.95715818e-05\n",
      "   1.85855257e-04 -7.07998970e-06 -1.44444930e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04636187e-03 -1.15059156e-04  3.12749617e-05  8.96354904e-05\n",
      "   1.87942584e-04 -3.42712628e-05 -1.42642166e-04]]\n",
      "linear.bias:\n",
      " [0.00022075]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468026e-03 -1.1443425e-04  3.1159409e-05  1.0358444e-04\n",
      "   1.8844816e-04 -3.5025550e-06 -1.4164581e-04]]\n",
      "linear.bias:\n",
      " [0.00022076]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04689843e-03 -1.12109112e-04  3.09560382e-05  1.04857354e-04\n",
      "   1.88147053e-04 -3.16091173e-05 -1.40848017e-04]]\n",
      "linear.bias:\n",
      " [0.00022092]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04719133e-03 -1.08764230e-04  3.06840811e-05  1.15604678e-04\n",
      "   1.87238722e-04 -1.23058835e-05 -1.40577555e-04]]\n",
      "linear.bias:\n",
      " [0.00022122]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04745792e-03 -1.05721374e-04  3.02048265e-05  9.93570284e-05\n",
      "   1.86071615e-04 -3.88794433e-05 -1.40455042e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04774069e-03 -1.01894235e-04  2.97806037e-05  1.05147541e-04\n",
      "   1.83901560e-04 -7.68942482e-06 -1.40882636e-04]]\n",
      "linear.bias:\n",
      " [0.00022197]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485128e-03 -9.8760953e-05  2.9368884e-05  1.0282412e-04\n",
      "   1.8232847e-04 -1.1327311e-05 -1.4082441e-04]]\n",
      "linear.bias:\n",
      " [0.00022227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488670e-03 -9.6689961e-05  2.9107834e-05  1.0143247e-04\n",
      "   1.8083528e-04 -2.0337662e-05 -1.4060752e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486633e-03 -9.5610121e-05  2.8940969e-05  1.0376920e-04\n",
      "   1.7946857e-04 -2.3227502e-05 -1.4028027e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479568e-03 -9.5423471e-05  2.8858976e-05  1.0946622e-04\n",
      "   1.7821575e-04 -2.0601556e-05 -1.3985357e-04]]\n",
      "linear.bias:\n",
      " [0.00022356]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477455e-03 -9.6418175e-05  2.8737208e-05  1.0608925e-04\n",
      "   1.7736148e-04 -3.1004005e-05 -1.3929336e-04]]\n",
      "linear.bias:\n",
      " [0.0002241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472548e-03 -9.7381431e-05  2.8594053e-05  1.0757598e-04\n",
      "   1.7634810e-04 -7.6239485e-06 -1.3891305e-04]]\n",
      "linear.bias:\n",
      " [0.00022479]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470776e-03 -9.8910925e-05  2.8537765e-05  9.4605901e-05\n",
      "   1.7603970e-04 -3.0529158e-05 -1.3807164e-04]]\n",
      "linear.bias:\n",
      " [0.00022526]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466453e-03 -1.0080676e-04  2.8544422e-05  9.5390475e-05\n",
      "   1.7563741e-04 -1.4640429e-05 -1.3733699e-04]]\n",
      "linear.bias:\n",
      " [0.00022563]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460792e-03 -1.0297964e-04  2.8752222e-05  1.0483659e-04\n",
      "   1.7520330e-04 -1.5019486e-07 -1.3659538e-04]]\n",
      "linear.bias:\n",
      " [0.00022586]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458346e-03 -1.0559991e-04  2.9012159e-05  9.9006633e-05\n",
      "   1.7541785e-04 -3.1108735e-05 -1.3542756e-04]]\n",
      "linear.bias:\n",
      " [0.00022592]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04579702e-03 -1.06812331e-04  2.91521992e-05  1.08964334e-04\n",
      "   1.74902496e-04 -9.43753003e-06 -1.34764574e-04]]\n",
      "linear.bias:\n",
      " [0.00022597]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459998e-03 -1.0810517e-04  2.9241091e-05  1.0033837e-04\n",
      "   1.7486664e-04 -3.1041331e-05 -1.3381704e-04]]\n",
      "linear.bias:\n",
      " [0.00022597]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04636548e-03 -1.08120505e-04  2.92269560e-05  1.07796754e-04\n",
      "   1.74124783e-04 -9.39102392e-07 -1.33353009e-04]]\n",
      "linear.bias:\n",
      " [0.00022596]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468852e-03 -1.0859356e-04  2.9296734e-05  9.6764008e-05\n",
      "   1.7394162e-04 -1.8596769e-05 -1.3252563e-04]]\n",
      "linear.bias:\n",
      " [0.00022581]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472557e-03 -1.0788868e-04  2.9449797e-05  9.6542382e-05\n",
      "   1.7302543e-04 -7.5507378e-06 -1.3210754e-04]]\n",
      "linear.bias:\n",
      " [0.00022557]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475152e-03 -1.0766913e-04  2.9807403e-05  9.8437005e-05\n",
      "   1.7245485e-04 -1.2428906e-05 -1.3155976e-04]]\n",
      "linear.bias:\n",
      " [0.00022515]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04763824e-03 -1.07472966e-04  3.02314329e-05  1.03895771e-04\n",
      "   1.71916516e-04 -1.76460217e-05 -1.31063789e-04]]\n",
      "linear.bias:\n",
      " [0.00022472]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475678e-03 -1.0725671e-04  3.0634703e-05  1.0830383e-04\n",
      "   1.7128864e-04 -1.6827522e-05 -1.3076613e-04]]\n",
      "linear.bias:\n",
      " [0.00022438]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04683929e-03 -1.07325235e-04  3.10238102e-05  1.03983621e-04\n",
      "   1.70751242e-04 -2.01926414e-05 -1.30525208e-04]]\n",
      "linear.bias:\n",
      " [0.00022423]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462162e-03 -1.0722927e-04  3.1228010e-05  1.0338254e-04\n",
      "   1.7016804e-04 -5.9936792e-07 -1.3053458e-04]]\n",
      "linear.bias:\n",
      " [0.00022419]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04595360e-03 -1.07738946e-04  3.14850076e-05  8.59877255e-05\n",
      "   1.70262225e-04 -2.66487950e-05 -1.30112414e-04]]\n",
      "linear.bias:\n",
      " [0.00022406]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04566722e-03 -1.07084896e-04  3.16588885e-05  8.97175632e-05\n",
      "   1.69512292e-04  4.30003274e-06 -1.30263608e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04565942e-03 -1.06366446e-04  3.19491155e-05  9.11366733e-05\n",
      "   1.69063977e-04 -8.53277834e-06 -1.30182481e-04]]\n",
      "linear.bias:\n",
      " [0.00022379]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04579097e-03 -1.06078063e-04  3.22894193e-05  1.02478174e-04\n",
      "   1.68557512e-04 -1.83894335e-05 -1.30091794e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459028e-03 -1.0572926e-04  3.2453627e-05  1.1468612e-04\n",
      "   1.6799796e-04 -1.4098382e-05 -1.3021211e-04]]\n",
      "linear.bias:\n",
      " [0.00022357]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461267e-03 -1.0575611e-04  3.2386790e-05  1.0197720e-04\n",
      "   1.6765438e-04 -4.9222257e-05 -1.3032428e-04]]\n",
      "linear.bias:\n",
      " [0.00022365]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04655290e-03 -1.04548555e-04  3.22135893e-05  1.03306353e-04\n",
      "   1.66653394e-04 -2.81758403e-05 -1.31057532e-04]]\n",
      "linear.bias:\n",
      " [0.00022373]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469700e-03 -1.0330247e-04  3.1910564e-05  1.0780986e-04\n",
      "   1.6565216e-04  1.3452394e-05 -1.3194552e-04]]\n",
      "linear.bias:\n",
      " [0.0002239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472963e-03 -1.0277420e-04  3.1781467e-05  8.6858978e-05\n",
      "   1.6515970e-04 -3.3224143e-05 -1.3283915e-04]]\n",
      "linear.bias:\n",
      " [0.00022405]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474229e-03 -1.0289257e-04  3.1723543e-05  8.6645872e-05\n",
      "   1.6475601e-04 -3.1582011e-05 -1.3373827e-04]]\n",
      "linear.bias:\n",
      " [0.00022414]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04736944e-03 -1.03593724e-04  3.17297563e-05  1.05118699e-04\n",
      "   1.64432320e-04  1.35610608e-05 -1.34642411e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470428e-03 -1.0495551e-04  3.1886972e-05  9.8218406e-05\n",
      "   1.6472446e-04 -3.4880224e-05 -1.3543593e-04]]\n",
      "linear.bias:\n",
      " [0.00022409]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467558e-03 -1.0633672e-04  3.1938078e-05  1.0573488e-04\n",
      "   1.6495917e-04 -3.7121103e-05 -1.3618299e-04]]\n",
      "linear.bias:\n",
      " [0.00022402]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466650e-03 -1.0758821e-04  3.1902713e-05  1.1957545e-04\n",
      "   1.6538998e-04 -6.7445580e-07 -1.3696199e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466068e-03 -1.0840911e-04  3.1607069e-05  1.0894843e-04\n",
      "   1.6720658e-04 -2.0256148e-05 -1.3715769e-04]]\n",
      "linear.bias:\n",
      " [0.00022384]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462776e-03 -1.0899864e-04  3.1434371e-05  8.9771856e-05\n",
      "   1.6909704e-04 -4.9474686e-05 -1.3714784e-04]]\n",
      "linear.bias:\n",
      " [0.00022395]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04595500e-03 -1.08557324e-04  3.12917473e-05  9.29516027e-05\n",
      "   1.70305793e-04 -1.92013249e-05 -1.37558323e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457013e-03 -1.0851514e-04  3.1199430e-05  1.0855510e-04\n",
      "   1.7136575e-04  2.5366106e-05 -1.3792454e-04]]\n",
      "linear.bias:\n",
      " [0.00022389]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448077e-03 -1.0846207e-04  3.1198353e-05  8.9036228e-05\n",
      "   1.7202162e-04 -5.2564938e-05 -1.3881354e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440535e-03 -1.0749222e-04  3.1238964e-05  9.2920367e-05\n",
      "   1.7192074e-04 -6.3926767e-05 -1.4012904e-04]]\n",
      "linear.bias:\n",
      " [0.00022383]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04357733e-03 -1.05650724e-04  3.13087548e-05  1.21028053e-04\n",
      "   1.71148233e-04  4.02639853e-06 -1.41812125e-04]]\n",
      "linear.bias:\n",
      " [0.00022368]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433920e-03 -1.0421062e-04  3.1421539e-05  1.1450506e-04\n",
      "   1.7067068e-04 -8.5300908e-06 -1.4316368e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435282e-03 -1.0351877e-04  3.1597308e-05  9.1559916e-05\n",
      "   1.7086937e-04 -6.3355074e-05 -1.4394378e-04]]\n",
      "linear.bias:\n",
      " [0.00022323]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435391e-03 -1.0174423e-04  3.1717369e-05  9.6319694e-05\n",
      "   1.7056426e-04 -3.5347519e-05 -1.4485981e-04]]\n",
      "linear.bias:\n",
      " [0.00022308]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436177e-03 -1.0070256e-04  3.1846648e-05  1.1528387e-04\n",
      "   1.7045243e-04  2.8652059e-05 -1.4563819e-04]]\n",
      "linear.bias:\n",
      " [0.00022291]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432287e-03 -9.9736048e-05  3.2192125e-05  9.4390874e-05\n",
      "   1.7052410e-04 -3.8375525e-05 -1.4655804e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429469e-03 -9.9422861e-05  3.2524447e-05  9.0266563e-05\n",
      "   1.7075184e-04 -6.0057355e-05 -1.4733982e-04]]\n",
      "linear.bias:\n",
      " [0.00022245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04253436e-03 -9.79686884e-05  3.27796988e-05  1.09508284e-04\n",
      "   1.70600135e-04 -1.85422432e-05 -1.48273713e-04]]\n",
      "linear.bias:\n",
      " [0.00022228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04286161e-03 -9.74912036e-05  3.30301700e-05  1.16254436e-04\n",
      "   1.71551306e-04 -1.07592823e-05 -1.48413266e-04]]\n",
      "linear.bias:\n",
      " [0.00022203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04404334e-03 -9.77110903e-05  3.33405296e-05  1.07794636e-04\n",
      "   1.73598717e-04 -4.50938787e-05 -1.47827304e-04]]\n",
      "linear.bias:\n",
      " [0.00022164]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455091e-03 -9.8668803e-05  3.3461965e-05  1.0816362e-04\n",
      "   1.7547655e-04 -4.1952149e-05 -1.4721736e-04]]\n",
      "linear.bias:\n",
      " [0.00022129]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471115e-03 -1.0029994e-04  3.3302855e-05  1.1143954e-04\n",
      "   1.7698824e-04 -1.0145766e-05 -1.4668312e-04]]\n",
      "linear.bias:\n",
      " [0.00022114]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490671e-03 -1.0243750e-04  3.3158296e-05  9.7737007e-05\n",
      "   1.7887668e-04 -1.6952465e-05 -1.4579733e-04]]\n",
      "linear.bias:\n",
      " [0.000221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502168e-03 -1.0481198e-04  3.2995409e-05  8.9369423e-05\n",
      "   1.8035300e-04 -1.4910436e-05 -1.4491339e-04]]\n",
      "linear.bias:\n",
      " [0.00022103]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508206e-03 -1.0721775e-04  3.2784694e-05  9.3990682e-05\n",
      "   1.8145677e-04 -4.6112764e-06 -1.4407502e-04]]\n",
      "linear.bias:\n",
      " [0.00022121]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510659e-03 -1.0931113e-04  3.2753986e-05  9.6525604e-05\n",
      "   1.8258311e-04 -2.0239926e-05 -1.4289947e-04]]\n",
      "linear.bias:\n",
      " [0.00022138]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507926e-03 -1.1136919e-04  3.2699438e-05  1.0633416e-04\n",
      "   1.8327092e-04 -1.9826068e-05 -1.4190769e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498194e-03 -1.1269277e-04  3.2591412e-05  1.1304166e-04\n",
      "   1.8357357e-04 -1.8698829e-05 -1.4102894e-04]]\n",
      "linear.bias:\n",
      " [0.00022197]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04809226e-03 -1.12929556e-04  3.25306137e-05  1.04007820e-04\n",
      "   1.84056786e-04 -3.76315766e-05 -1.40033895e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465765e-03 -1.1117672e-04  3.2302742e-05  1.0771301e-04\n",
      "   1.8387532e-04 -5.1663774e-06 -1.3960982e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453132e-03 -1.0951266e-04  3.1935833e-05  8.9512687e-05\n",
      "   1.8350196e-04 -1.5848300e-05 -1.3911595e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444985e-03 -1.0675804e-04  3.1690415e-05  8.8162305e-05\n",
      "   1.8230396e-04 -7.2438297e-06 -1.3904880e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04386511e-03 -1.04222316e-04  3.14840399e-05  9.75017902e-05\n",
      "   1.80792078e-04  4.94189408e-06 -1.39093361e-04]]\n",
      "linear.bias:\n",
      " [0.00022441]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439933e-03 -1.0237506e-04  3.1360370e-05  9.5722113e-05\n",
      "   1.7967989e-04 -3.7727710e-05 -1.3876060e-04]]\n",
      "linear.bias:\n",
      " [0.00022462]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442983e-03 -9.9521014e-05  3.1151409e-05  1.0983325e-04\n",
      "   1.7794312e-04 -2.6441838e-05 -1.3886427e-04]]\n",
      "linear.bias:\n",
      " [0.00022482]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448708e-03 -9.7659584e-05  3.0734263e-05  1.1919525e-04\n",
      "   1.7643168e-04 -5.0681374e-06 -1.3893192e-04]]\n",
      "linear.bias:\n",
      " [0.00022509]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453744e-03 -9.6615877e-05  3.0304411e-05  9.8632197e-05\n",
      "   1.7492045e-04 -3.6554084e-05 -1.3913574e-04]]\n",
      "linear.bias:\n",
      " [0.00022545]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455439e-03 -9.6215859e-05  2.9977027e-05  9.3041002e-05\n",
      "   1.7342970e-04 -2.8210732e-05 -1.3934339e-04]]\n",
      "linear.bias:\n",
      " [0.00022572]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04543939e-03 -9.65362633e-05  2.98325285e-05  1.01627724e-04\n",
      "   1.72283850e-04  1.67447797e-05 -1.39417898e-04]]\n",
      "linear.bias:\n",
      " [0.00022586]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450534e-03 -9.7505450e-05  2.9819355e-05  9.0084002e-05\n",
      "   1.7173160e-04 -2.7808965e-05 -1.3920951e-04]]\n",
      "linear.bias:\n",
      " [0.00022571]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448809e-03 -9.8912569e-05  2.9912369e-05  9.6513730e-05\n",
      "   1.7153264e-04 -3.4837456e-05 -1.3889281e-04]]\n",
      "linear.bias:\n",
      " [0.00022548]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04479562e-03 -1.00746576e-04  3.00176798e-05  1.17225019e-04\n",
      "   1.71519408e-04 -2.22676681e-06 -1.38560121e-04]]\n",
      "linear.bias:\n",
      " [0.00022522]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04505103e-03 -1.03045524e-04  3.02027129e-05  1.16679803e-04\n",
      "   1.72166750e-04 -1.86584421e-05 -1.37890907e-04]]\n",
      "linear.bias:\n",
      " [0.00022493]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454908e-03 -1.0536460e-04  3.0242643e-05  9.6878066e-05\n",
      "   1.7298444e-04 -6.2189509e-05 -1.3705336e-04]]\n",
      "linear.bias:\n",
      " [0.00022472]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459116e-03 -1.0636813e-04  3.0230256e-05  1.0026907e-04\n",
      "   1.7268484e-04 -4.3229673e-05 -1.3696340e-04]]\n",
      "linear.bias:\n",
      " [0.00022443]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464814e-03 -1.0607267e-04  3.0120789e-05  1.1913839e-04\n",
      "   1.7167444e-04  2.3569235e-05 -1.3728872e-04]]\n",
      "linear.bias:\n",
      " [0.00022416]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04610785e-03 -1.05344465e-04  2.99667190e-05  9.16506106e-05\n",
      "   1.70500440e-04 -5.02724579e-05 -1.38314193e-04]]\n",
      "linear.bias:\n",
      " [0.00022403]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457445e-03 -1.0364838e-04  2.9849643e-05  8.6861495e-05\n",
      "   1.6892850e-04 -6.3300780e-05 -1.3952717e-04]]\n",
      "linear.bias:\n",
      " [0.00022391]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453839e-03 -1.0102084e-04  2.9744095e-05  1.1026765e-04\n",
      "   1.6679127e-04  6.0399980e-06 -1.4106049e-04]]\n",
      "linear.bias:\n",
      " [0.00022381]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453798e-03 -9.9756602e-05  2.9824467e-05  1.1114527e-04\n",
      "   1.6607066e-04  2.0225762e-05 -1.4190385e-04]]\n",
      "linear.bias:\n",
      " [0.00022366]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452571e-03 -9.9548415e-05  3.0139056e-05  8.6106804e-05\n",
      "   1.6656045e-04 -6.3687272e-05 -1.4248314e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449881e-03 -9.8824145e-05  3.0431078e-05  9.3170966e-05\n",
      "   1.6684970e-04 -6.0174418e-05 -1.4305106e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448425e-03 -9.7665892e-05  3.0774732e-05  1.2074979e-04\n",
      "   1.6719717e-04  1.3303434e-06 -1.4370035e-04]]\n",
      "linear.bias:\n",
      " [0.0002231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451857e-03 -9.7743068e-05  3.1249572e-05  1.2278560e-04\n",
      "   1.6884741e-04  4.0482037e-06 -1.4371891e-04]]\n",
      "linear.bias:\n",
      " [0.00022292]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04594196e-03 -9.87917520e-05  3.17511294e-05  1.01116115e-04\n",
      "   1.71341744e-04 -4.68708167e-05 -1.43307116e-04]]\n",
      "linear.bias:\n",
      " [0.00022275]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466306e-03 -9.9896621e-05  3.2109052e-05  9.5753967e-05\n",
      "   1.7355871e-04 -5.1691874e-05 -1.4296986e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472236e-03 -9.9845121e-05  3.2453208e-05  1.1098389e-04\n",
      "   1.7503758e-04 -2.8297982e-06 -1.4295730e-04]]\n",
      "linear.bias:\n",
      " [0.00022246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480700e-03 -1.0042249e-04  3.2839638e-05  1.0718023e-04\n",
      "   1.7701760e-04 -2.1656090e-06 -1.4249541e-04]]\n",
      "linear.bias:\n",
      " [0.00022223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491123e-03 -1.0164229e-04  3.3264452e-05  8.8736604e-05\n",
      "   1.7943965e-04 -4.5392251e-05 -1.4155199e-04]]\n",
      "linear.bias:\n",
      " [0.00022187]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500962e-03 -1.0158569e-04  3.3654909e-05  9.3675553e-05\n",
      "   1.8043151e-04 -2.9152916e-05 -1.4127418e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05071510e-03 -1.01572798e-04  3.38498212e-05  1.15093346e-04\n",
      "   1.80861345e-04  2.88997380e-05 -1.41216486e-04]]\n",
      "linear.bias:\n",
      " [0.00022145]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505182e-03 -1.0140663e-04  3.3955916e-05  9.2931397e-05\n",
      "   1.8077598e-04 -4.9635644e-05 -1.4189362e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503657e-03 -1.0011769e-04  3.4011020e-05  9.3410075e-05\n",
      "   1.7964354e-04 -6.5712666e-05 -1.4303270e-04]]\n",
      "linear.bias:\n",
      " [0.00022151]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499167e-03 -9.7670905e-05  3.3987155e-05  1.2209812e-04\n",
      "   1.7710707e-04 -1.8216815e-07 -1.4455941e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494628e-03 -9.6336124e-05  3.3917531e-05  1.1582589e-04\n",
      "   1.7479375e-04  3.5187775e-06 -1.4609827e-04]]\n",
      "linear.bias:\n",
      " [0.00022167]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492520e-03 -9.6248499e-05  3.4017517e-05  8.7036598e-05\n",
      "   1.7350752e-04 -4.5390923e-05 -1.4714793e-04]]\n",
      "linear.bias:\n",
      " [0.0002219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486399e-03 -9.6657401e-05  3.4124256e-05  8.2289174e-05\n",
      "   1.7239258e-04 -4.4798162e-05 -1.4799401e-04]]\n",
      "linear.bias:\n",
      " [0.00022216]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04760448e-03 -9.75723888e-05  3.41931373e-05  1.02500024e-04\n",
      "   1.71346022e-04  1.86702164e-06 -1.48651729e-04]]\n",
      "linear.bias:\n",
      " [0.00022239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473026e-03 -9.9272591e-05  3.4431461e-05  1.0877787e-04\n",
      "   1.7140547e-04  3.1420880e-06 -1.4852715e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475527e-03 -1.0183828e-04  3.4720946e-05  9.7886921e-05\n",
      "   1.7287066e-04 -4.2847460e-05 -1.4761949e-04]]\n",
      "linear.bias:\n",
      " [0.00022226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04778551e-03 -1.04310981e-04  3.48869326e-05  1.02343976e-04\n",
      "   1.74160465e-04 -4.34062677e-05 -1.46835984e-04]]\n",
      "linear.bias:\n",
      " [0.0002221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480027e-03 -1.0670003e-04  3.4941630e-05  1.2063142e-04\n",
      "   1.7529231e-04 -3.0592892e-06 -1.4616431e-04]]\n",
      "linear.bias:\n",
      " [0.00022196]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04805699e-03 -1.08300323e-04  3.48235008e-05  1.13519374e-04\n",
      "   1.76610294e-04 -5.12138104e-06 -1.45332902e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481621e-03 -1.0926916e-04  3.4609664e-05  8.8337714e-05\n",
      "   1.7835337e-04 -4.7830174e-05 -1.4417569e-04]]\n",
      "linear.bias:\n",
      " [0.00022182]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479556e-03 -1.0883002e-04  3.4311604e-05  8.7809603e-05\n",
      "   1.7904211e-04 -3.0936859e-05 -1.4349655e-04]]\n",
      "linear.bias:\n",
      " [0.00022187]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477145e-03 -1.0723078e-04  3.3972432e-05  1.0689702e-04\n",
      "   1.7880330e-04  3.6536385e-05 -1.4331983e-04]]\n",
      "linear.bias:\n",
      " [0.00022197]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466899e-03 -1.0560622e-04  3.3675937e-05  9.0258720e-05\n",
      "   1.7825665e-04 -3.9438044e-05 -1.4338949e-04]]\n",
      "linear.bias:\n",
      " [0.00022206]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457122e-03 -1.0293779e-04  3.3338078e-05  9.4856878e-05\n",
      "   1.7690411e-04 -5.5768563e-05 -1.4388772e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447763e-03 -9.9328448e-05  3.2962918e-05  1.1858962e-04\n",
      "   1.7482521e-04 -1.8425431e-05 -1.4477222e-04]]\n",
      "linear.bias:\n",
      " [0.00022237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440781e-03 -9.6325479e-05  3.2499720e-05  1.1939725e-04\n",
      "   1.7327450e-04 -1.9660223e-05 -1.4527813e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04365835e-03 -9.42873594e-05  3.20746149e-05  1.00437166e-04\n",
      "   1.72399974e-04 -5.80075102e-05 -1.45360013e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432878e-03 -9.2615053e-05  3.1596348e-05  9.7713557e-05\n",
      "   1.7158243e-04 -5.1811261e-05 -1.4546794e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04302599e-03 -9.16914578e-05  3.11877593e-05  1.10509216e-04\n",
      "   1.71016727e-04 -7.87689351e-06 -1.45516358e-04]]\n",
      "linear.bias:\n",
      " [0.00022271]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04342727e-03 -9.17446087e-05  3.09978423e-05  1.10008106e-04\n",
      "   1.71519263e-04 -8.96822985e-06 -1.44835853e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444260e-03 -9.2678005e-05  3.1004976e-05  9.7524913e-05\n",
      "   1.7298454e-04 -5.0600964e-05 -1.4349840e-04]]\n",
      "linear.bias:\n",
      " [0.00022226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451459e-03 -9.4122144e-05  3.1063340e-05  1.0507838e-04\n",
      "   1.7437087e-04 -4.6571538e-05 -1.4226550e-04]]\n",
      "linear.bias:\n",
      " [0.000222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454642e-03 -9.5705305e-05  3.1153209e-05  1.2496933e-04\n",
      "   1.7562146e-04 -3.6754063e-06 -1.4112220e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457005e-03 -9.8013268e-05  3.1185275e-05  1.1036158e-04\n",
      "   1.7671833e-04 -2.0269394e-05 -1.4025898e-04]]\n",
      "linear.bias:\n",
      " [0.00022165]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463079e-03 -1.0092681e-04  3.1044299e-05  8.7226828e-05\n",
      "   1.7780077e-04 -4.5501602e-05 -1.3937493e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469011e-03 -1.0237230e-04  3.0925366e-05  8.8293906e-05\n",
      "   1.7756219e-04 -1.3393150e-05 -1.3916210e-04]]\n",
      "linear.bias:\n",
      " [0.00022183]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04743184e-03 -1.04123472e-04  3.08612143e-05  1.01219535e-04\n",
      "   1.77312904e-04  2.32226848e-05 -1.38939926e-04]]\n",
      "linear.bias:\n",
      " [0.00022194]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476221e-03 -1.0555734e-04  3.0881958e-05  8.5279600e-05\n",
      "   1.7653622e-04 -5.0733597e-05 -1.3906255e-04]]\n",
      "linear.bias:\n",
      " [0.00022203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04751473e-03 -1.05614025e-04  3.08406597e-05  1.02089864e-04\n",
      "   1.74245113e-04 -5.38380555e-05 -1.39869517e-04]]\n",
      "linear.bias:\n",
      " [0.00022206]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476487e-03 -1.0434945e-04  3.0701693e-05  1.3089344e-04\n",
      "   1.7142709e-04 -7.2029034e-06 -1.4109416e-04]]\n",
      "linear.bias:\n",
      " [0.00022214]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473928e-03 -1.0342022e-04  3.0302910e-05  1.1445375e-04\n",
      "   1.6856461e-04 -2.3973136e-05 -1.4252606e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475932e-03 -1.0358653e-04  3.0009254e-05  8.8775232e-05\n",
      "   1.6691259e-04 -5.4464239e-05 -1.4329168e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04774360e-03 -1.02677426e-04  2.97485549e-05  8.63571113e-05\n",
      "   1.64924932e-04 -2.77382042e-05 -1.44297373e-04]]\n",
      "linear.bias:\n",
      " [0.00022308]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04746735e-03 -1.02553364e-04  2.97867191e-05  1.03750266e-04\n",
      "   1.63372111e-04  3.05426875e-05 -1.45021986e-04]]\n",
      "linear.bias:\n",
      " [0.00022323]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468707e-03 -1.0319233e-04  3.0058309e-05  9.3741750e-05\n",
      "   1.6333147e-04 -2.9005474e-05 -1.4532937e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460437e-03 -1.0467607e-04  3.0524570e-05  9.8779841e-05\n",
      "   1.6374281e-04 -5.6392717e-05 -1.4528580e-04]]\n",
      "linear.bias:\n",
      " [0.00022315]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04547548e-03 -1.05112405e-04  3.08936105e-05  1.19985161e-04\n",
      "   1.63958379e-04 -2.73140613e-05 -1.45453378e-04]]\n",
      "linear.bias:\n",
      " [0.00022301]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456550e-03 -1.0638134e-04  3.1201351e-05  1.2766694e-04\n",
      "   1.6530580e-04 -1.7359122e-05 -1.4498054e-04]]\n",
      "linear.bias:\n",
      " [0.00022294]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04619737e-03 -1.07671593e-04  3.12595766e-05  1.07572545e-04\n",
      "   1.68055572e-04 -5.04034469e-05 -1.43907033e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467425e-03 -1.0769635e-04  3.1448741e-05  9.8130724e-05\n",
      "   1.7040080e-04 -3.4874938e-05 -1.4323073e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04724127e-03 -1.07884371e-04  3.15222169e-05  1.04161205e-04\n",
      "   1.72482498e-04  1.97741138e-05 -1.42656369e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04742730e-03 -1.08442655e-04  3.17172671e-05  9.12965916e-05\n",
      "   1.74637622e-04 -1.12664056e-05 -1.41880941e-04]]\n",
      "linear.bias:\n",
      " [0.00022224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476123e-03 -1.0956621e-04  3.1956355e-05  8.8428395e-05\n",
      "   1.7657339e-04 -4.2351483e-05 -1.4104466e-04]]\n",
      "linear.bias:\n",
      " [0.00022187]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04772253e-03 -1.09348570e-04  3.20994222e-05  1.05755935e-04\n",
      "   1.77439273e-04 -1.83236953e-05 -1.40735734e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04759412e-03 -1.08927707e-04  3.23106506e-05  1.13278686e-04\n",
      "   1.78387112e-04 -6.95633480e-06 -1.40276257e-04]]\n",
      "linear.bias:\n",
      " [0.00022154]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475168e-03 -1.0852305e-04  3.2348325e-05  9.5470663e-05\n",
      "   1.7912404e-04 -3.7175632e-05 -1.3972631e-04]]\n",
      "linear.bias:\n",
      " [0.00022151]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473909e-03 -1.0692668e-04  3.2309857e-05  9.9378653e-05\n",
      "   1.7890851e-04 -1.2326891e-05 -1.3967614e-04]]\n",
      "linear.bias:\n",
      " [0.00022153]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469019e-03 -1.0582296e-04  3.2359483e-05  1.0652209e-04\n",
      "   1.7854861e-04  5.8379737e-06 -1.3949705e-04]]\n",
      "linear.bias:\n",
      " [0.00022167]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465218e-03 -1.0465351e-04  3.2430948e-05  8.9812856e-05\n",
      "   1.7792628e-04 -4.8794365e-05 -1.3927624e-04]]\n",
      "linear.bias:\n",
      " [0.00022162]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462265e-03 -1.0240309e-04  3.2503463e-05  9.6956901e-05\n",
      "   1.7613305e-04 -4.3276927e-05 -1.3967004e-04]]\n",
      "linear.bias:\n",
      " [0.00022163]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04590401e-03 -9.91412162e-05  3.24961838e-05  1.23379097e-04\n",
      "   1.73636581e-04  1.37227835e-05 -1.40470976e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448062e-03 -9.6517280e-05  3.2605065e-05  1.0676263e-04\n",
      "   1.7105322e-04 -4.1617386e-05 -1.4178356e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446240e-03 -9.4764262e-05  3.2398621e-05  9.8960045e-05\n",
      "   1.6874020e-04 -5.5801909e-05 -1.4302615e-04]]\n",
      "linear.bias:\n",
      " [0.00022182]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441628e-03 -9.3556861e-05  3.2120508e-05  1.0960951e-04\n",
      "   1.6676377e-04 -2.2079086e-05 -1.4411063e-04]]\n",
      "linear.bias:\n",
      " [0.00022204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441848e-03 -9.3487950e-05  3.1936524e-05  1.0818539e-04\n",
      "   1.6592385e-04 -7.0675633e-06 -1.4455536e-04]]\n",
      "linear.bias:\n",
      " [0.00022235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450210e-03 -9.4607363e-05  3.1873973e-05  9.6011296e-05\n",
      "   1.6669356e-04 -3.1960488e-05 -1.4408956e-04]]\n",
      "linear.bias:\n",
      " [0.00022251]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453692e-03 -9.6570264e-05  3.1954496e-05  9.7269593e-05\n",
      "   1.6770116e-04 -2.2381377e-05 -1.4343124e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04615383e-03 -9.96942763e-05  3.20839026e-05  1.04028615e-04\n",
      "   1.69333740e-04 -8.65405855e-06 -1.42427569e-04]]\n",
      "linear.bias:\n",
      " [0.00022246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474585e-03 -1.0349867e-04  3.2402142e-05  1.0140800e-04\n",
      "   1.7188299e-04 -3.0516174e-05 -1.4078474e-04]]\n",
      "linear.bias:\n",
      " [0.00022222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04826083e-03 -1.07018743e-04  3.26363443e-05  1.08295215e-04\n",
      "   1.73897570e-04 -1.68740189e-05 -1.39405762e-04]]\n",
      "linear.bias:\n",
      " [0.00022212]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487299e-03 -1.1005719e-04  3.2952401e-05  1.0243872e-04\n",
      "   1.7600378e-04 -2.0845520e-05 -1.3791423e-04]]\n",
      "linear.bias:\n",
      " [0.00022225]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487777e-03 -1.1210421e-04  3.2991222e-05  1.0502274e-04\n",
      "   1.7763232e-04 -9.2070140e-06 -1.3670615e-04]]\n",
      "linear.bias:\n",
      " [0.00022259]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483616e-03 -1.1303282e-04  3.3047756e-05  9.6246309e-05\n",
      "   1.7947308e-04 -2.0559099e-05 -1.3529809e-04]]\n",
      "linear.bias:\n",
      " [0.00022307]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04789285e-03 -1.11823116e-04  3.29226750e-05  1.02355545e-04\n",
      "   1.80409101e-04  7.41329859e-06 -1.34483489e-04]]\n",
      "linear.bias:\n",
      " [0.00022355]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04768644e-03 -1.09602865e-04  3.25447618e-05  8.61748413e-05\n",
      "   1.80344447e-04 -4.11406181e-05 -1.33936395e-04]]\n",
      "linear.bias:\n",
      " [0.00022388]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475346e-03 -1.0638999e-04  3.2224809e-05  9.7335891e-05\n",
      "   1.7876827e-04 -2.5868221e-05 -1.3423675e-04]]\n",
      "linear.bias:\n",
      " [0.00022411]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474976e-03 -1.0220095e-04  3.1841169e-05  1.2285408e-04\n",
      "   1.7651181e-04  2.6651634e-05 -1.3496693e-04]]\n",
      "linear.bias:\n",
      " [0.00022427]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465260e-03 -9.7939490e-05  3.1436975e-05  9.9238205e-05\n",
      "   1.7420034e-04 -5.8056125e-05 -1.3639942e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456771e-03 -9.2951545e-05  3.1021711e-05  1.0023110e-04\n",
      "   1.7102048e-04 -7.7232486e-05 -1.3839372e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449649e-03 -8.7449655e-05  3.0717631e-05  1.2520672e-04\n",
      "   1.6774236e-04 -2.0070729e-07 -1.4067003e-04]]\n",
      "linear.bias:\n",
      " [0.0002248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445594e-03 -8.3810657e-05  3.0710555e-05  1.2437825e-04\n",
      "   1.6597238e-04  1.7986429e-05 -1.4222256e-04]]\n",
      "linear.bias:\n",
      " [0.00022494]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441645e-03 -8.1290607e-05  3.0916501e-05  9.0266789e-05\n",
      "   1.6532188e-04 -6.4018735e-05 -1.4341825e-04]]\n",
      "linear.bias:\n",
      " [0.00022479]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439310e-03 -8.0389749e-05  3.1084684e-05  8.3086357e-05\n",
      "   1.6504238e-04 -7.2849565e-05 -1.4439919e-04]]\n",
      "linear.bias:\n",
      " [0.00022471]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436078e-03 -8.0897633e-05  3.1151525e-05  1.1133663e-04\n",
      "   1.6480782e-04  6.0340972e-06 -1.4547055e-04]]\n",
      "linear.bias:\n",
      " [0.00022458]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04350841e-03 -8.27361364e-05  3.13796954e-05  1.19066375e-04\n",
      "   1.66172220e-04  2.18974437e-05 -1.45548474e-04]]\n",
      "linear.bias:\n",
      " [0.00022419]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433571e-03 -8.5306128e-05  3.1854721e-05  9.5454518e-05\n",
      "   1.6859242e-04 -6.5630054e-05 -1.4537513e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433431e-03 -8.8992863e-05  3.2265187e-05  9.7771488e-05\n",
      "   1.7107915e-04 -7.9685546e-05 -1.4512289e-04]]\n",
      "linear.bias:\n",
      " [0.00022313]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435740e-03 -9.1864393e-05  3.2677257e-05  1.2440229e-04\n",
      "   1.7287390e-04  3.2555545e-07 -1.4527133e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439900e-03 -9.5622920e-05  3.3219520e-05  1.2425173e-04\n",
      "   1.7532884e-04  2.0873074e-05 -1.4505128e-04]]\n",
      "linear.bias:\n",
      " [0.00022249]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438807e-03 -9.9031226e-05  3.3709039e-05  8.0929130e-05\n",
      "   1.7725032e-04 -7.6969503e-05 -1.4526736e-04]]\n",
      "linear.bias:\n",
      " [0.00022214]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439004e-03 -1.0091310e-04  3.4214292e-05  9.0048161e-05\n",
      "   1.7689783e-04 -4.7976973e-05 -1.4642259e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04388944e-03 -1.01498095e-04  3.46924462e-05  1.19284872e-04\n",
      "   1.76031346e-04  2.99585008e-05 -1.47771760e-04]]\n",
      "linear.bias:\n",
      " [0.00022109]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435214e-03 -1.0126392e-04  3.5123212e-05  1.0313136e-04\n",
      "   1.7517134e-04 -2.7641516e-05 -1.4927625e-04]]\n",
      "linear.bias:\n",
      " [0.0002207]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437985e-03 -1.0183971e-04  3.5096891e-05  9.3490642e-05\n",
      "   1.7421128e-04 -5.4955301e-05 -1.5059407e-04]]\n",
      "linear.bias:\n",
      " [0.00022058]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04353542e-03 -1.02435406e-04  3.49679685e-05  1.06005929e-04\n",
      "   1.73183100e-04 -3.36619305e-05 -1.51762797e-04]]\n",
      "linear.bias:\n",
      " [0.00022058]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04364683e-03 -1.04061059e-04  3.47124369e-05  1.16059186e-04\n",
      "   1.72816595e-04  5.48044045e-06 -1.52510504e-04]]\n",
      "linear.bias:\n",
      " [0.00022069]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04430330e-03 -1.06384665e-04  3.44634573e-05  1.04478873e-04\n",
      "   1.73634093e-04 -5.54950111e-06 -1.52573324e-04]]\n",
      "linear.bias:\n",
      " [0.00022069]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04556535e-03 -1.08629334e-04  3.42800195e-05  8.44682072e-05\n",
      "   1.75806621e-04 -4.99414309e-05 -1.51738510e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04634126e-03 -1.08688895e-04  3.39756043e-05  9.57906450e-05\n",
      "   1.77247028e-04 -3.44312575e-05 -1.51108135e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468127e-03 -1.0803903e-04  3.3432221e-05  1.1992771e-04\n",
      "   1.7826626e-04  1.8635033e-05 -1.5068623e-04]]\n",
      "linear.bias:\n",
      " [0.00022068]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466446e-03 -1.0645120e-04  3.3063712e-05  1.0109049e-04\n",
      "   1.7936848e-04 -3.8496779e-05 -1.5039118e-04]]\n",
      "linear.bias:\n",
      " [0.00022067]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464721e-03 -1.0504095e-04  3.2533833e-05  9.8313903e-05\n",
      "   1.7997689e-04 -5.0832317e-05 -1.5030892e-04]]\n",
      "linear.bias:\n",
      " [0.00022072]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04625861e-03 -1.02501428e-04  3.19820283e-05  1.16225216e-04\n",
      "   1.79618830e-04 -1.10078290e-05 -1.50693508e-04]]\n",
      "linear.bias:\n",
      " [0.00022083]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04621856e-03 -1.00474965e-04  3.13531709e-05  1.10930632e-04\n",
      "   1.79634779e-04 -9.26277789e-06 -1.50733948e-04]]\n",
      "linear.bias:\n",
      " [0.00022092]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468224e-03 -9.9427562e-05  3.0875832e-05  9.2926457e-05\n",
      "   1.8035866e-04 -4.8148249e-05 -1.5015765e-04]]\n",
      "linear.bias:\n",
      " [0.00022088]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471101e-03 -9.8676945e-05  3.0376757e-05  9.5321120e-05\n",
      "   1.8086968e-04 -4.0255542e-05 -1.4969612e-04]]\n",
      "linear.bias:\n",
      " [0.00022091]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467292e-03 -9.8166325e-05  2.9899560e-05  1.1400626e-04\n",
      "   1.8086868e-04  7.5754870e-06 -1.4941547e-04]]\n",
      "linear.bias:\n",
      " [0.000221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462954e-03 -9.7915603e-05  2.9583089e-05  1.0471837e-04\n",
      "   1.8079802e-04 -1.0125934e-05 -1.4898433e-04]]\n",
      "linear.bias:\n",
      " [0.00022096]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464892e-03 -9.8554570e-05  2.9406818e-05  8.6740125e-05\n",
      "   1.8148740e-04 -6.0293823e-05 -1.4798589e-04]]\n",
      "linear.bias:\n",
      " [0.00022086]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463189e-03 -9.7935561e-05  2.9292243e-05  1.0552877e-04\n",
      "   1.8057297e-04 -2.6216545e-05 -1.4749677e-04]]\n",
      "linear.bias:\n",
      " [0.00022072]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456159e-03 -9.8193290e-05  2.9261631e-05  1.2787741e-04\n",
      "   1.7972889e-04  1.8666939e-05 -1.4693452e-04]]\n",
      "linear.bias:\n",
      " [0.00022071]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04434392e-03 -9.82998536e-05  2.94010388e-05  1.03550425e-04\n",
      "   1.78497547e-04 -5.40852889e-05 -1.46954160e-04]]\n",
      "linear.bias:\n",
      " [0.00022076]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432064e-03 -9.8568387e-05  2.9425704e-05  9.6644304e-05\n",
      "   1.7735695e-04 -7.9839207e-05 -1.4700800e-04]]\n",
      "linear.bias:\n",
      " [0.0002208]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04211050e-03 -9.75945222e-05  2.94330584e-05  1.17949414e-04\n",
      "   1.75871508e-04 -6.40833605e-06 -1.47399274e-04]]\n",
      "linear.bias:\n",
      " [0.00022106]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414596e-03 -9.7388409e-05  2.9521949e-05  1.1856817e-04\n",
      "   1.7523092e-04  1.7791674e-05 -1.4726698e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405062e-03 -9.7560536e-05  2.9829476e-05  8.3665480e-05\n",
      "   1.7447928e-04 -5.6740209e-05 -1.4729967e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0394657e-03 -9.7017073e-05  3.0254223e-05  8.2941144e-05\n",
      "   1.7297575e-04 -6.7749861e-05 -1.4762572e-04]]\n",
      "linear.bias:\n",
      " [0.00022113]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0385875e-03 -9.5913791e-05  3.0692969e-05  1.1981043e-04\n",
      "   1.7080161e-04  6.4431370e-06 -1.4824890e-04]]\n",
      "linear.bias:\n",
      " [0.00022113]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383094e-03 -9.6131582e-05  3.1266889e-05  1.2875551e-04\n",
      "   1.7028967e-04  2.2454895e-05 -1.4819787e-04]]\n",
      "linear.bias:\n",
      " [0.00022108]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0376142e-03 -9.6206189e-05  3.1938671e-05  8.8952336e-05\n",
      "   1.7018330e-04 -8.7508568e-05 -1.4839511e-04]]\n",
      "linear.bias:\n",
      " [0.00022103]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0370135e-03 -9.4816540e-05  3.2513250e-05  9.2605471e-05\n",
      "   1.6933546e-04 -6.8955764e-05 -1.4909565e-04]]\n",
      "linear.bias:\n",
      " [0.00022093]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363667e-03 -9.2919829e-05  3.3087312e-05  1.2396509e-04\n",
      "   1.6849938e-04  2.1868815e-05 -1.4978195e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0359420e-03 -9.1383641e-05  3.3878521e-05  1.1425222e-04\n",
      "   1.6855657e-04 -5.2322575e-06 -1.5021102e-04]]\n",
      "linear.bias:\n",
      " [0.00022092]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0365002e-03 -9.1059243e-05  3.4678193e-05  8.7971173e-05\n",
      "   1.7016126e-04 -7.2328839e-05 -1.4977642e-04]]\n",
      "linear.bias:\n",
      " [0.00022077]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371685e-03 -9.0750684e-05  3.5350567e-05  9.8253731e-05\n",
      "   1.7134969e-04 -5.4051699e-05 -1.4952553e-04]]\n",
      "linear.bias:\n",
      " [0.00022069]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0385772e-03 -9.1809881e-05  3.5733068e-05  1.2092726e-04\n",
      "   1.7287934e-04 -1.4142242e-06 -1.4910936e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "Epoch [1500/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04043807e-03 -9.36727083e-05  3.60741687e-05  1.18483236e-04\n",
      "   1.75446228e-04 -1.48245010e-06 -1.48195802e-04]]\n",
      "linear.bias:\n",
      " [0.0002204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427065e-03 -9.6259857e-05  3.6377984e-05  9.3410265e-05\n",
      "   1.7894799e-04 -4.8991893e-05 -1.4683396e-04]]\n",
      "linear.bias:\n",
      " [0.00022018]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444599e-03 -9.8631041e-05  3.6481812e-05  8.8886634e-05\n",
      "   1.8159959e-04 -5.0284252e-05 -1.4581604e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04573788e-03 -9.93382564e-05  3.65143605e-05  1.09430825e-04\n",
      "   1.82893957e-04  1.90195351e-06 -1.45336511e-04]]\n",
      "linear.bias:\n",
      " [0.00022022]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471314e-03 -1.0014825e-04  3.6464240e-05  1.0825966e-04\n",
      "   1.8422246e-04  5.0864346e-06 -1.4456706e-04]]\n",
      "linear.bias:\n",
      " [0.00022025]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04834524e-03 -1.00327685e-04  3.63216532e-05  8.49765711e-05\n",
      "   1.84881108e-04 -5.85517701e-05 -1.43817277e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491309e-03 -9.8961485e-05  3.6164140e-05  1.0067274e-04\n",
      "   1.8316094e-04 -3.5886173e-05 -1.4380967e-04]]\n",
      "linear.bias:\n",
      " [0.00021999]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498170e-03 -9.7751239e-05  3.5820151e-05  1.2920382e-04\n",
      "   1.8121956e-04  2.2943841e-05 -1.4399011e-04]]\n",
      "linear.bias:\n",
      " [0.00021993]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494862e-03 -9.6320233e-05  3.5282130e-05  9.9448211e-05\n",
      "   1.7915374e-04 -4.8352176e-05 -1.4499528e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488974e-03 -9.5072937e-05  3.4627050e-05  9.0759313e-05\n",
      "   1.7678904e-04 -7.1234623e-05 -1.4610999e-04]]\n",
      "linear.bias:\n",
      " [0.0002204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480603e-03 -9.2892958e-05  3.3967768e-05  1.1743932e-04\n",
      "   1.7369064e-04 -7.4731361e-06 -1.4740560e-04]]\n",
      "linear.bias:\n",
      " [0.00022059]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474868e-03 -9.1986847e-05  3.3358443e-05  1.1890971e-04\n",
      "   1.7169512e-04  1.1048678e-05 -1.4813920e-04]]\n",
      "linear.bias:\n",
      " [0.00022077]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468814e-03 -9.2221482e-05  3.2957236e-05  9.2822469e-05\n",
      "   1.7088845e-04 -4.0583465e-05 -1.4834151e-04]]\n",
      "linear.bias:\n",
      " [0.00022081]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461435e-03 -9.3080307e-05  3.2651646e-05  8.9152549e-05\n",
      "   1.7023356e-04 -4.7385900e-05 -1.4849324e-04]]\n",
      "linear.bias:\n",
      " [0.00022084]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452861e-03 -9.4501687e-05  3.2432203e-05  1.0567985e-04\n",
      "   1.6971539e-04 -1.3822595e-05 -1.4859941e-04]]\n",
      "linear.bias:\n",
      " [0.00022088]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04514102e-03 -9.68206659e-05  3.24460452e-05  1.11556394e-04\n",
      "   1.70379935e-04 -1.63886270e-05 -1.47920320e-04]]\n",
      "linear.bias:\n",
      " [0.00022079]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455567e-03 -9.9901416e-05  3.2577489e-05  1.0307312e-04\n",
      "   1.7197418e-04 -4.5511348e-05 -1.4670771e-04]]\n",
      "linear.bias:\n",
      " [0.00022071]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04593940e-03 -1.02851904e-04  3.25929504e-05  1.10640569e-04\n",
      "   1.73377630e-04 -3.27188354e-05 -1.45652535e-04]]\n",
      "linear.bias:\n",
      " [0.00022064]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04664941e-03 -1.06394400e-04  3.23620989e-05  1.12769536e-04\n",
      "   1.74866931e-04 -1.87820115e-06 -1.44623278e-04]]\n",
      "linear.bias:\n",
      " [0.00022081]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04763161e-03 -1.10269124e-04  3.22381238e-05  9.58621094e-05\n",
      "   1.76919377e-04 -1.53434084e-05 -1.43201920e-04]]\n",
      "linear.bias:\n",
      " [0.00022085]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480997e-03 -1.1324788e-04  3.1937936e-05  8.8750356e-05\n",
      "   1.7874566e-04 -2.3019915e-05 -1.4184674e-04]]\n",
      "linear.bias:\n",
      " [0.00022112]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482816e-03 -1.1379403e-04  3.1671530e-05  1.0511586e-04\n",
      "   1.7950885e-04  4.9633109e-06 -1.4104829e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475940e-03 -1.1188885e-04  3.1322543e-05  9.7048913e-05\n",
      "   1.7944005e-04 -3.8265171e-05 -1.4051169e-04]]\n",
      "linear.bias:\n",
      " [0.00022175]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04670203e-03 -1.08117769e-04  3.08575291e-05  1.10410896e-04\n",
      "   1.78553484e-04 -2.72795551e-05 -1.40462536e-04]]\n",
      "linear.bias:\n",
      " [0.00022216]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453655e-03 -1.0504863e-04  3.0426252e-05  1.1866793e-04\n",
      "   1.7790093e-04 -4.4875378e-06 -1.4041498e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04412378e-03 -1.02349426e-04  2.99914736e-05  9.50247049e-05\n",
      "   1.77012960e-04 -3.00835418e-05 -1.40438657e-04]]\n",
      "linear.bias:\n",
      " [0.00022349]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429836e-03 -9.9938967e-05  2.9395311e-05  8.8267698e-05\n",
      "   1.7581623e-04 -1.4736845e-05 -1.4064957e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419688e-03 -9.8258701e-05  2.8888340e-05  9.7153439e-05\n",
      "   1.7464583e-04  1.0901171e-05 -1.4085058e-04]]\n",
      "linear.bias:\n",
      " [0.00022479]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418384e-03 -9.7234981e-05  2.8501532e-05  9.4005620e-05\n",
      "   1.7387154e-04 -1.6797898e-05 -1.4061340e-04]]\n",
      "linear.bias:\n",
      " [0.00022513]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420358e-03 -9.7869437e-05  2.8196800e-05  9.9050492e-05\n",
      "   1.7367440e-04 -4.3087985e-05 -1.3996918e-04]]\n",
      "linear.bias:\n",
      " [0.00022533]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422916e-03 -9.9073841e-05  2.7946429e-05  1.1986075e-04\n",
      "   1.7368225e-04 -2.9884348e-05 -1.3933600e-04]]\n",
      "linear.bias:\n",
      " [0.00022544]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04264251e-03 -1.00951926e-04  2.75245966e-05  1.26791565e-04\n",
      "   1.73768087e-04 -2.09598584e-05 -1.38730393e-04]]\n",
      "linear.bias:\n",
      " [0.00022555]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430177e-03 -1.0279056e-04  2.7035589e-05  1.0795331e-04\n",
      "   1.7406269e-04 -4.9669943e-05 -1.3797576e-04]]\n",
      "linear.bias:\n",
      " [0.00022564]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04323833e-03 -1.03153245e-04  2.66296720e-05  1.04110681e-04\n",
      "   1.73547101e-04 -2.93449593e-05 -1.37761337e-04]]\n",
      "linear.bias:\n",
      " [0.00022573]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04313251e-03 -1.04010833e-04  2.63785078e-05  1.07883825e-04\n",
      "   1.73200140e-04  6.72513852e-06 -1.37549257e-04]]\n",
      "linear.bias:\n",
      " [0.00022568]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432588e-03 -1.0492666e-04  2.6207217e-05  8.8891858e-05\n",
      "   1.7321542e-04 -2.2113252e-05 -1.3710838e-04]]\n",
      "linear.bias:\n",
      " [0.00022547]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04346103e-03 -1.06322426e-04  2.61796322e-05  8.90599113e-05\n",
      "   1.73507389e-04 -2.65400231e-05 -1.36598086e-04]]\n",
      "linear.bias:\n",
      " [0.00022509]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04393705e-03 -1.06630614e-04  2.62757767e-05  1.08382388e-04\n",
      "   1.73252760e-04 -1.02936247e-06 -1.36442555e-04]]\n",
      "linear.bias:\n",
      " [0.00022458]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447127e-03 -1.0760095e-04  2.6447311e-05  1.0675650e-04\n",
      "   1.7374335e-04 -1.9510517e-05 -1.3580202e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451666e-03 -1.0823322e-04  2.6690308e-05  9.6750504e-05\n",
      "   1.7436570e-04 -4.6069217e-05 -1.3503042e-04]]\n",
      "linear.bias:\n",
      " [0.00022371]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456054e-03 -1.0756820e-04  2.6875097e-05  1.1074171e-04\n",
      "   1.7372944e-04 -1.6101298e-05 -1.3506223e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04573066e-03 -1.06829117e-04  2.71534409e-05  1.10698624e-04\n",
      "   1.73467182e-04 -4.79593109e-06 -1.34825124e-04]]\n",
      "linear.bias:\n",
      " [0.00022335]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462172e-03 -1.0689150e-04  2.7505555e-05  8.9603156e-05\n",
      "   1.7397253e-04 -3.8127313e-05 -1.3419589e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04670832e-03 -1.05690706e-04  2.78422176e-05  9.48854795e-05\n",
      "   1.73077293e-04 -1.39044023e-05 -1.34405855e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469427e-03 -1.0515681e-04  2.8382798e-05  1.0961836e-04\n",
      "   1.7218661e-04  8.0824193e-06 -1.3450089e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04702765e-03 -1.04618164e-04  2.90322096e-05  9.14519405e-05\n",
      "   1.71040519e-04 -5.58112224e-05 -1.34952861e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471623e-03 -1.0306988e-04  2.9665001e-05  9.9149809e-05\n",
      "   1.6921092e-04 -5.7417299e-05 -1.3595357e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472902e-03 -1.0046699e-04  3.0249508e-05  1.2631217e-04\n",
      "   1.6700318e-04 -4.7370704e-06 -1.3742510e-04]]\n",
      "linear.bias:\n",
      " [0.00022206]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474718e-03 -9.9346551e-05  3.0695795e-05  1.1808402e-04\n",
      "   1.6523857e-04 -7.5633161e-06 -1.3885771e-04]]\n",
      "linear.bias:\n",
      " [0.00022197]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478462e-03 -9.9454170e-05  3.1098090e-05  8.5654145e-05\n",
      "   1.6448363e-04 -5.1290226e-05 -1.3979043e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482214e-03 -9.8857672e-05  3.1593965e-05  7.9567995e-05\n",
      "   1.6347936e-04 -4.0677216e-05 -1.4088389e-04]]\n",
      "linear.bias:\n",
      " [0.0002218]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480206e-03 -9.8928700e-05  3.2010226e-05  1.0072251e-04\n",
      "   1.6252774e-04  1.3258134e-05 -1.4175265e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04834500e-03 -1.00620484e-04  3.25985638e-05  1.03370345e-04\n",
      "   1.63477409e-04  8.00125781e-06 -1.41657059e-04]]\n",
      "linear.bias:\n",
      " [0.00022138]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495755e-03 -1.0332648e-04  3.3218996e-05  9.0450230e-05\n",
      "   1.6593155e-04 -4.0004226e-05 -1.4063423e-04]]\n",
      "linear.bias:\n",
      " [0.00022094]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05041498e-03 -1.05965555e-04  3.37051424e-05  9.81249541e-05\n",
      "   1.67993829e-04 -4.09234235e-05 -1.39773416e-04]]\n",
      "linear.bias:\n",
      " [0.0002206]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05096202e-03 -1.07760352e-04  3.39621656e-05  1.20315126e-04\n",
      "   1.69929437e-04 -2.52795871e-06 -1.38996504e-04]]\n",
      "linear.bias:\n",
      " [0.00022035]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05086225e-03 -1.08831264e-04  3.38387617e-05  1.05716608e-04\n",
      "   1.71591062e-04 -1.58361945e-05 -1.38563220e-04]]\n",
      "linear.bias:\n",
      " [0.00022043]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502324e-03 -1.0885810e-04  3.3761127e-05  8.1475351e-05\n",
      "   1.7349528e-04 -3.8889222e-05 -1.3791682e-04]]\n",
      "linear.bias:\n",
      " [0.00022086]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04928459e-03 -1.07468506e-04  3.35789737e-05  8.85779737e-05\n",
      "   1.73981476e-04 -4.64051118e-06 -1.37782001e-04]]\n",
      "linear.bias:\n",
      " [0.00022137]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04837201e-03 -1.06885600e-04  3.34889955e-05  1.03330494e-04\n",
      "   1.74503773e-04  1.68068273e-05 -1.37454743e-04]]\n",
      "linear.bias:\n",
      " [0.00022177]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477643e-03 -1.0594128e-04  3.3353081e-05  8.8253961e-05\n",
      "   1.7446424e-04 -4.8333000e-05 -1.3749120e-04]]\n",
      "linear.bias:\n",
      " [0.00022212]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04724476e-03 -1.03811144e-04  3.31852534e-05  9.70764668e-05\n",
      "   1.73242923e-04 -5.44630711e-05 -1.38118528e-04]]\n",
      "linear.bias:\n",
      " [0.00022245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04671554e-03 -1.00551486e-04  3.29552822e-05  1.26322950e-04\n",
      "   1.71185777e-04 -9.72480120e-06 -1.39168129e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462347e-03 -9.8386088e-05  3.2536762e-05  1.1876156e-04\n",
      "   1.6933637e-04 -1.7447190e-05 -1.4031389e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460342e-03 -9.7176977e-05  3.2151016e-05  9.0552523e-05\n",
      "   1.6825135e-04 -6.0348135e-05 -1.4093012e-04]]\n",
      "linear.bias:\n",
      " [0.00022391]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459439e-03 -9.4849049e-05  3.1791365e-05  8.8187211e-05\n",
      "   1.6688526e-04 -4.3455282e-05 -1.4183186e-04]]\n",
      "linear.bias:\n",
      " [0.00022436]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456634e-03 -9.3422328e-05  3.1525116e-05  1.0644640e-04\n",
      "   1.6572904e-04  1.1780805e-05 -1.4261242e-04]]\n",
      "linear.bias:\n",
      " [0.00022476]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456162e-03 -9.3618590e-05  3.1465486e-05  1.0420823e-04\n",
      "   1.6637755e-04  7.8227858e-06 -1.4236420e-04]]\n",
      "linear.bias:\n",
      " [0.00022482]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465210e-03 -9.4989045e-05  3.1503241e-05  8.6772357e-05\n",
      "   1.6857570e-04 -3.9048620e-05 -1.4119498e-04]]\n",
      "linear.bias:\n",
      " [0.00022469]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471361e-03 -9.6894240e-05  3.1594991e-05  9.1494418e-05\n",
      "   1.7062946e-04 -4.1201838e-05 -1.4011044e-04]]\n",
      "linear.bias:\n",
      " [0.00022458]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474903e-03 -9.9281438e-05  3.1735406e-05  1.1617986e-04\n",
      "   1.7255322e-04 -3.0904921e-06 -1.3910215e-04]]\n",
      "linear.bias:\n",
      " [0.00022447]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481899e-03 -1.0217275e-04  3.1965188e-05  1.1704303e-04\n",
      "   1.7504099e-04 -1.2332841e-05 -1.3777069e-04]]\n",
      "linear.bias:\n",
      " [0.00022432]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489818e-03 -1.0505348e-04  3.2031949e-05  9.5360505e-05\n",
      "   1.7764099e-04 -5.4350967e-05 -1.3624654e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497231e-03 -1.0640482e-04  3.2036685e-05  9.9454104e-05\n",
      "   1.7879567e-04 -3.6873709e-05 -1.3563500e-04]]\n",
      "linear.bias:\n",
      " [0.00022393]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05060951e-03 -1.06248081e-04  3.19283317e-05  1.20739904e-04\n",
      "   1.78987204e-04  2.61644454e-05 -1.35549737e-04]]\n",
      "linear.bias:\n",
      " [0.00022371]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05021300e-03 -1.05378356e-04  3.16443002e-05  9.06847417e-05\n",
      "   1.78701303e-04 -3.82078651e-05 -1.36457631e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499075e-03 -1.0328259e-04  3.1397456e-05  8.7440225e-05\n",
      "   1.7709234e-04 -4.3424243e-05 -1.3792500e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496840e-03 -1.0008186e-04  3.1184103e-05  1.0834866e-04\n",
      "   1.7429101e-04  4.5922679e-06 -1.3989664e-04]]\n",
      "linear.bias:\n",
      " [0.00022335]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04983849e-03 -9.79099568e-05  3.10790929e-05  1.07769054e-04\n",
      "   1.72506596e-04  6.39463451e-06 -1.41158918e-04]]\n",
      "linear.bias:\n",
      " [0.00022318]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502965e-03 -9.6751210e-05  3.1072010e-05  9.0610600e-05\n",
      "   1.7162734e-04 -3.3888678e-05 -1.4169485e-04]]\n",
      "linear.bias:\n",
      " [0.00022285]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501300e-03 -9.6516284e-05  3.1272641e-05  9.4263582e-05\n",
      "   1.7094614e-04 -3.1629195e-05 -1.4207046e-04]]\n",
      "linear.bias:\n",
      " [0.00022249]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496827e-03 -9.7091550e-05  3.1627125e-05  1.1282241e-04\n",
      "   1.7056009e-04  5.9307531e-06 -1.4227867e-04]]\n",
      "linear.bias:\n",
      " [0.00022205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04950473e-03 -9.88756365e-05  3.21311854e-05  1.03941755e-04\n",
      "   1.71117965e-04 -1.05106865e-05 -1.42084216e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499679e-03 -1.0140463e-04  3.2701100e-05  8.5840249e-05\n",
      "   1.7242350e-04 -5.9041151e-05 -1.4125832e-04]]\n",
      "linear.bias:\n",
      " [0.00022134]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500937e-03 -1.0250759e-04  3.3163131e-05  9.9702549e-05\n",
      "   1.7268681e-04 -4.3850800e-05 -1.4089211e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501841e-03 -1.0352203e-04  3.3366810e-05  1.2716897e-04\n",
      "   1.7251175e-04  8.3834238e-06 -1.4075912e-04]]\n",
      "linear.bias:\n",
      " [0.00022055]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04932359e-03 -1.04478931e-04  3.34788310e-05  1.07956905e-04\n",
      "   1.72119107e-04 -2.99505300e-05 -1.41153869e-04]]\n",
      "linear.bias:\n",
      " [0.00022017]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481054e-03 -1.0571038e-04  3.3557415e-05  8.7931068e-05\n",
      "   1.7197574e-04 -4.1660162e-05 -1.4147340e-04]]\n",
      "linear.bias:\n",
      " [0.00022014]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469774e-03 -1.0561885e-04  3.3653207e-05  9.2243921e-05\n",
      "   1.7125270e-04 -1.3012286e-06 -1.4209519e-04]]\n",
      "linear.bias:\n",
      " [0.00022012]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04652019e-03 -1.06433465e-04  3.38134996e-05  9.18418737e-05\n",
      "   1.71018677e-04  5.11306280e-06 -1.42056539e-04]]\n",
      "linear.bias:\n",
      " [0.00022003]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468111e-03 -1.0802201e-04  3.4054527e-05  8.3607374e-05\n",
      "   1.7149861e-04 -2.1770104e-05 -1.4138820e-04]]\n",
      "linear.bias:\n",
      " [0.00021983]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465548e-03 -1.0864978e-04  3.4120996e-05  9.5812473e-05\n",
      "   1.7160902e-04 -1.9874042e-05 -1.4090446e-04]]\n",
      "linear.bias:\n",
      " [0.00021971]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457656e-03 -1.0871787e-04  3.3886619e-05  1.1307153e-04\n",
      "   1.7153124e-04 -8.1325152e-06 -1.4048505e-04]]\n",
      "linear.bias:\n",
      " [0.00021991]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449962e-03 -1.0827905e-04  3.3456334e-05  1.0566784e-04\n",
      "   1.7193976e-04 -3.1308253e-05 -1.3973752e-04]]\n",
      "linear.bias:\n",
      " [0.00022015]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04424020e-03 -1.07007756e-04  3.28233509e-05  1.01905251e-04\n",
      "   1.72362808e-04 -2.22144627e-05 -1.39216281e-04]]\n",
      "linear.bias:\n",
      " [0.00022068]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434220e-03 -1.0608612e-04  3.2070395e-05  1.0111488e-04\n",
      "   1.7273253e-04  1.0068779e-06 -1.3875148e-04]]\n",
      "linear.bias:\n",
      " [0.00022134]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433751e-03 -1.0609443e-04  3.1488256e-05  8.6363732e-05\n",
      "   1.7383040e-04 -1.8073759e-05 -1.3767232e-04]]\n",
      "linear.bias:\n",
      " [0.00022181]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433933e-03 -1.0653148e-04  3.0989908e-05  9.0121750e-05\n",
      "   1.7472693e-04 -1.4329663e-05 -1.3674230e-04]]\n",
      "linear.bias:\n",
      " [0.00022211]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434056e-03 -1.0743220e-04  3.0589599e-05  1.0666594e-04\n",
      "   1.7549546e-04 -3.5209960e-06 -1.3587032e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440727e-03 -1.0852013e-04  3.0191382e-05  1.0370615e-04\n",
      "   1.7673749e-04 -3.1056588e-05 -1.3460575e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04494358e-03 -1.07969994e-04  2.97065126e-05  1.14774004e-04\n",
      "   1.77015580e-04 -8.46922558e-06 -1.34063172e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457583e-03 -1.0747195e-04  2.8999037e-05  9.2029106e-05\n",
      "   1.7685798e-04 -3.2425225e-05 -1.3381250e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04645558e-03 -1.05656436e-04  2.83479876e-05  9.54334901e-05\n",
      "   1.75549518e-04 -1.81657379e-06 -1.34279820e-04]]\n",
      "linear.bias:\n",
      " [0.00022396]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469510e-03 -1.0425654e-04  2.8077546e-05  9.4578798e-05\n",
      "   1.7504026e-04 -2.2883744e-06 -1.3415689e-04]]\n",
      "linear.bias:\n",
      " [0.00022429]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471097e-03 -1.0332048e-04  2.8138766e-05  9.4792587e-05\n",
      "   1.7496476e-04 -2.7499382e-05 -1.3350208e-04]]\n",
      "linear.bias:\n",
      " [0.00022447]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473627e-03 -1.0104707e-04  2.8088463e-05  1.1168327e-04\n",
      "   1.7397266e-04 -1.2640472e-05 -1.3341995e-04]]\n",
      "linear.bias:\n",
      " [0.00022456]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478290e-03 -9.9760531e-05  2.8034088e-05  1.0501846e-04\n",
      "   1.7367526e-04 -3.5384124e-05 -1.3291925e-04]]\n",
      "linear.bias:\n",
      " [0.00022459]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478897e-03 -9.8624434e-05  2.7909333e-05  1.0861332e-04\n",
      "   1.7304803e-04 -1.8560389e-05 -1.3271498e-04]]\n",
      "linear.bias:\n",
      " [0.00022473]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04757911e-03 -9.84328726e-05  2.79703854e-05  1.05890445e-04\n",
      "   1.72775850e-04 -7.55471137e-06 -1.32415633e-04]]\n",
      "linear.bias:\n",
      " [0.00022505]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476004e-03 -9.9077188e-05  2.8135357e-05  8.7593224e-05\n",
      "   1.7332878e-04 -3.3206121e-05 -1.3162715e-04]]\n",
      "linear.bias:\n",
      " [0.00022528]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477485e-03 -9.8825374e-05  2.8438786e-05  9.7236196e-05\n",
      "   1.7264737e-04 -4.0376253e-06 -1.3163238e-04]]\n",
      "linear.bias:\n",
      " [0.00022542]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04764255e-03 -9.93689900e-05  2.89559739e-05  1.06181986e-04\n",
      "   1.72463580e-04  3.34198239e-06 -1.31294059e-04]]\n",
      "linear.bias:\n",
      " [0.00022536]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478174e-03 -1.0066122e-04  2.9643075e-05  8.9718407e-05\n",
      "   1.7272007e-04 -5.1855961e-05 -1.3095996e-04]]\n",
      "linear.bias:\n",
      " [0.00022536]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480038e-03 -1.0055041e-04  3.0205058e-05  9.9013021e-05\n",
      "   1.7173408e-04 -4.5959783e-05 -1.3143949e-04]]\n",
      "linear.bias:\n",
      " [0.00022525]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484883e-03 -9.9152523e-05  3.0620289e-05  1.2759953e-04\n",
      "   1.6974758e-04  1.1878241e-05 -1.3262880e-04]]\n",
      "linear.bias:\n",
      " [0.00022495]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04778516e-03 -9.76512747e-05  3.08426752e-05  1.06695865e-04\n",
      "   1.67524529e-04 -4.47026323e-05 -1.34578411e-04]]\n",
      "linear.bias:\n",
      " [0.00022463]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469684e-03 -9.6444390e-05  3.1096719e-05  9.4660514e-05\n",
      "   1.6582481e-04 -6.0412844e-05 -1.3638566e-04]]\n",
      "linear.bias:\n",
      " [0.00022433]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462014e-03 -9.4182797e-05  3.1341100e-05  1.0762837e-04\n",
      "   1.6369743e-04 -2.0640629e-05 -1.3851990e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458434e-03 -9.3791081e-05  3.1557633e-05  1.1341788e-04\n",
      "   1.6257414e-04  1.4168309e-05 -1.4010334e-04]]\n",
      "linear.bias:\n",
      " [0.00022372]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454088e-03 -9.4508614e-05  3.2014250e-05  8.9076435e-05\n",
      "   1.6296863e-04 -3.9357332e-05 -1.4120489e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448112e-03 -9.5847623e-05  3.2485088e-05  8.8124354e-05\n",
      "   1.6340047e-04 -4.7375797e-05 -1.4216431e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440667e-03 -9.7746743e-05  3.2968775e-05  1.0824430e-04\n",
      "   1.6386600e-04 -1.4419864e-05 -1.4299570e-04]]\n",
      "linear.bias:\n",
      " [0.00022249]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04439969e-03 -1.00330857e-04  3.35275436e-05  1.13431845e-04\n",
      "   1.65761361e-04 -1.82947842e-05 -1.42893972e-04]]\n",
      "linear.bias:\n",
      " [0.00022203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455786e-03 -1.0357045e-04  3.4055211e-05  1.0297470e-04\n",
      "   1.6878822e-04 -4.9763505e-05 -1.4204807e-04]]\n",
      "linear.bias:\n",
      " [0.00022156]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466874e-03 -1.0658759e-04  3.4419991e-05  1.0679298e-04\n",
      "   1.7149094e-04 -3.8126276e-05 -1.4141542e-04]]\n",
      "linear.bias:\n",
      " [0.0002212]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478578e-03 -1.0914712e-04  3.4541841e-05  1.1772626e-04\n",
      "   1.7380387e-04  8.3565574e-06 -1.4113722e-04]]\n",
      "linear.bias:\n",
      " [0.00022099]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483455e-03 -1.0940451e-04  3.4256653e-05  8.8128945e-05\n",
      "   1.7473822e-04 -3.2852779e-05 -1.4167455e-04]]\n",
      "linear.bias:\n",
      " [0.000221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04849343e-03 -1.07441665e-04  3.38388782e-05  8.32499718e-05\n",
      "   1.74699147e-04 -1.95399316e-05 -1.42621997e-04]]\n",
      "linear.bias:\n",
      " [0.00022113]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483980e-03 -1.0613492e-04  3.3523393e-05  1.0011445e-04\n",
      "   1.7444977e-04  1.6443932e-05 -1.4354150e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486569e-03 -1.0517871e-04  3.3272940e-05  1.0022949e-04\n",
      "   1.7444519e-04 -1.5243078e-05 -1.4393487e-04]]\n",
      "linear.bias:\n",
      " [0.00022111]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485436e-03 -1.0418912e-04  3.3193130e-05  9.7931203e-05\n",
      "   1.7486513e-04 -5.3980199e-05 -1.4388225e-04]]\n",
      "linear.bias:\n",
      " [0.00022123]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04837760e-03 -1.01897313e-04  3.30389412e-05  1.17935764e-04\n",
      "   1.74243687e-04 -3.83406150e-05 -1.44340942e-04]]\n",
      "linear.bias:\n",
      " [0.0002214]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04777224e-03 -1.00213634e-04  3.28771494e-05  1.33160473e-04\n",
      "   1.73900291e-04 -1.29803811e-06 -1.44717022e-04]]\n",
      "linear.bias:\n",
      " [0.00022187]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468684e-03 -9.9424607e-05  3.2553045e-05  1.0050408e-04\n",
      "   1.7345019e-04 -2.7275109e-05 -1.4533795e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454719e-03 -9.9825404e-05  3.2460917e-05  7.9053636e-05\n",
      "   1.7340161e-04 -3.5355599e-05 -1.4556450e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439925e-03 -1.0070943e-04  3.2436747e-05  9.2264476e-05\n",
      "   1.7351548e-04 -4.2048814e-06 -1.4547036e-04]]\n",
      "linear.bias:\n",
      " [0.00022353]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432499e-03 -1.0257716e-04  3.2593558e-05  1.0376626e-04\n",
      "   1.7442562e-04 -3.6884676e-06 -1.4461907e-04]]\n",
      "linear.bias:\n",
      " [0.00022372]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04328885e-03 -1.05119194e-04  3.28332098e-05  9.97847455e-05\n",
      "   1.76029978e-04 -4.33890891e-05 -1.43174751e-04]]\n",
      "linear.bias:\n",
      " [0.00022377]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04355172e-03 -1.05978615e-04  3.29318100e-05  1.14387294e-04\n",
      "   1.76591813e-04 -3.15626930e-05 -1.42358564e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04406744e-03 -1.07677726e-04  3.27660309e-05  1.21338402e-04\n",
      "   1.77280672e-04 -1.12635553e-05 -1.41571916e-04]]\n",
      "linear.bias:\n",
      " [0.00022405]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447229e-03 -1.0889896e-04  3.2406908e-05  9.7554221e-05\n",
      "   1.7782964e-04 -3.4323348e-05 -1.4078851e-04]]\n",
      "linear.bias:\n",
      " [0.00022425]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04554126e-03 -1.08566266e-04  3.19660576e-05  9.43529158e-05\n",
      "   1.77439390e-04 -7.47874037e-06 -1.40568416e-04]]\n",
      "linear.bias:\n",
      " [0.00022444]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459839e-03 -1.0859906e-04  3.1881118e-05  9.2472779e-05\n",
      "   1.7748025e-04 -8.1788667e-06 -1.3981307e-04]]\n",
      "linear.bias:\n",
      " [0.00022448]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04632042e-03 -1.09333225e-04  3.18826933e-05  9.95049340e-05\n",
      "   1.77606053e-04 -1.82739859e-05 -1.38915872e-04]]\n",
      "linear.bias:\n",
      " [0.00022445]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462106e-03 -1.1007902e-04  3.1887663e-05  1.1179639e-04\n",
      "   1.7724704e-04 -1.9801346e-05 -1.3823831e-04]]\n",
      "linear.bias:\n",
      " [0.00022449]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04544475e-03 -1.10567446e-04  3.20038598e-05  1.06707193e-04\n",
      "   1.77225171e-04 -3.90972054e-05 -1.37399344e-04]]\n",
      "linear.bias:\n",
      " [0.00022472]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04503310e-03 -1.09432949e-04  3.19785795e-05  1.16189614e-04\n",
      "   1.76340589e-04 -8.79790605e-06 -1.37257390e-04]]\n",
      "linear.bias:\n",
      " [0.00022505]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448542e-03 -1.0810101e-04  3.1745072e-05  9.4567389e-05\n",
      "   1.7547229e-04 -2.2960125e-05 -1.3705424e-04]]\n",
      "linear.bias:\n",
      " [0.00022534]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448061e-03 -1.0543231e-04  3.1426491e-05  9.2169576e-05\n",
      "   1.7374115e-04  2.0498283e-06 -1.3739264e-04]]\n",
      "linear.bias:\n",
      " [0.00022555]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455423e-03 -1.0363135e-04  3.1212872e-05  8.5412044e-05\n",
      "   1.7267928e-04 -1.5098965e-05 -1.3715660e-04]]\n",
      "linear.bias:\n",
      " [0.00022541]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04626769e-03 -1.02453465e-04  3.10472751e-05  9.68470849e-05\n",
      "   1.71627733e-04 -9.43918712e-06 -1.36987263e-04]]\n",
      "linear.bias:\n",
      " [0.00022517]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475239e-03 -1.0280808e-04  3.0917123e-05  1.0653356e-04\n",
      "   1.7113674e-04 -2.6221074e-05 -1.3639881e-04]]\n",
      "linear.bias:\n",
      " [0.00022462]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481490e-03 -1.0333957e-04  3.0747855e-05  1.1546892e-04\n",
      "   1.7073029e-04 -2.5737852e-05 -1.3593561e-04]]\n",
      "linear.bias:\n",
      " [0.00022426]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477527e-03 -1.0413909e-04  3.0574069e-05  1.1664177e-04\n",
      "   1.7049203e-04 -1.4262191e-05 -1.3557011e-04]]\n",
      "linear.bias:\n",
      " [0.00022413]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04759377e-03 -1.05186424e-04  3.02874905e-05  9.21483006e-05\n",
      "   1.70677202e-04 -4.00544959e-05 -1.34991074e-04]]\n",
      "linear.bias:\n",
      " [0.00022407]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473884e-03 -1.0473846e-04  2.9957446e-05  9.3341638e-05\n",
      "   1.6980064e-04 -1.0935275e-05 -1.3513383e-04]]\n",
      "linear.bias:\n",
      " [0.00022402]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04674476e-03 -1.05184736e-04  2.98950090e-05  1.01720783e-04\n",
      "   1.69138642e-04  4.31528497e-06 -1.34964765e-04]]\n",
      "linear.bias:\n",
      " [0.00022385]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04695070e-03 -1.06191714e-04  2.99173844e-05  9.50636313e-05\n",
      "   1.69129271e-04 -3.09781244e-05 -1.34229893e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473668e-03 -1.0565091e-04  2.9818853e-05  1.0745979e-04\n",
      "   1.6822683e-04 -1.4857038e-05 -1.3405863e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04744360e-03 -1.05498504e-04  2.99945295e-05  1.05183353e-04\n",
      "   1.68080878e-04 -2.50115118e-05 -1.33461304e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04707736e-03 -1.05377643e-04  3.01463060e-05  1.03252096e-04\n",
      "   1.67983817e-04 -1.49022480e-05 -1.33107460e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04636222e-03 -1.06059815e-04  3.04441764e-05  9.73003916e-05\n",
      "   1.68197061e-04 -8.59196734e-06 -1.32719229e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455276e-03 -1.0688302e-04  3.1035688e-05  8.9896181e-05\n",
      "   1.6906427e-04 -2.6504313e-05 -1.3186080e-04]]\n",
      "linear.bias:\n",
      " [0.00022318]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448929e-03 -1.0617208e-04  3.1470714e-05  1.0134336e-04\n",
      "   1.6885833e-04 -3.2289827e-06 -1.3176521e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04501634e-03 -1.06411004e-04  3.19841420e-05  9.81902922e-05\n",
      "   1.69529274e-04 -1.60864474e-05 -1.31086621e-04]]\n",
      "linear.bias:\n",
      " [0.00022301]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450799e-03 -1.0660530e-04  3.2268261e-05  1.0066237e-04\n",
      "   1.6999200e-04 -1.5451704e-05 -1.3063701e-04]]\n",
      "linear.bias:\n",
      " [0.00022307]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453071e-03 -1.0659009e-04  3.2394051e-05  1.0376674e-04\n",
      "   1.7019029e-04 -8.0741383e-06 -1.3049954e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465308e-03 -1.0682047e-04  3.2332766e-05  9.3551069e-05\n",
      "   1.7095143e-04 -3.1501273e-05 -1.2995985e-04]]\n",
      "linear.bias:\n",
      " [0.00022354]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478676e-03 -1.0560208e-04  3.2169839e-05  1.0374762e-04\n",
      "   1.7070839e-04 -3.0640349e-06 -1.3011917e-04]]\n",
      "linear.bias:\n",
      " [0.00022373]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493719e-03 -1.0475986e-04  3.1975851e-05  9.1530957e-05\n",
      "   1.7103316e-04 -1.7378939e-05 -1.2981778e-04]]\n",
      "linear.bias:\n",
      " [0.00022384]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507164e-03 -1.0398437e-04  3.1700394e-05  9.8127734e-05\n",
      "   1.7096224e-04 -5.2459018e-06 -1.2984054e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516788e-03 -1.0408560e-04  3.1705509e-05  1.0433869e-04\n",
      "   1.7134454e-04 -1.3438126e-05 -1.2950502e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05169590e-03 -1.04441126e-04  3.17247759e-05  1.01806218e-04\n",
      "   1.71722495e-04 -2.33959581e-05 -1.29287248e-04]]\n",
      "linear.bias:\n",
      " [0.00022353]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05120172e-03 -1.04747545e-04  3.16909864e-05  1.05764950e-04\n",
      "   1.71687600e-04 -9.12729774e-06 -1.29334236e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04994851e-03 -1.04927174e-04  3.16404985e-05  8.90745432e-05\n",
      "   1.71857304e-04 -2.22170966e-05 -1.29341759e-04]]\n",
      "linear.bias:\n",
      " [0.00022385]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486388e-03 -1.0364951e-04  3.1531988e-05  9.6328149e-05\n",
      "   1.7089213e-04  8.6676882e-06 -1.3005537e-04]]\n",
      "linear.bias:\n",
      " [0.00022402]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479565e-03 -1.0264171e-04  3.1481293e-05  8.9226349e-05\n",
      "   1.7025827e-04 -3.1878964e-05 -1.3059845e-04]]\n",
      "linear.bias:\n",
      " [0.00022385]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472790e-03 -1.0032399e-04  3.1362692e-05  1.0637185e-04\n",
      "   1.6862986e-04 -1.5657492e-05 -1.3176080e-04]]\n",
      "linear.bias:\n",
      " [0.00022369]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471604e-03 -9.9692777e-05  3.1189960e-05  1.1338495e-04\n",
      "   1.6749577e-04 -8.7155104e-06 -1.3263778e-04]]\n",
      "linear.bias:\n",
      " [0.00022368]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473314e-03 -9.9956786e-05  3.1042648e-05  9.4815026e-05\n",
      "   1.6711967e-04 -4.1216583e-05 -1.3307479e-04]]\n",
      "linear.bias:\n",
      " [0.00022366]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474973e-03 -1.0042047e-04  3.0807758e-05  9.5576339e-05\n",
      "   1.6671601e-04 -2.8910799e-05 -1.3366205e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04773242e-03 -1.01533806e-04  3.06226757e-05  1.13878457e-04\n",
      "   1.66556245e-04  1.99671304e-05 -1.34132628e-04]]\n",
      "linear.bias:\n",
      " [0.00022346]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464126e-03 -1.0293581e-04  3.0483545e-05  8.6972825e-05\n",
      "   1.6635480e-04 -4.4393269e-05 -1.3528232e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452708e-03 -1.0345718e-04  3.0537260e-05  8.8191875e-05\n",
      "   1.6575398e-04 -5.1269406e-05 -1.3672592e-04]]\n",
      "linear.bias:\n",
      " [0.0002231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04420981e-03 -1.02702259e-04  3.06018919e-05  1.13962255e-04\n",
      "   1.64590980e-04 -2.74159538e-06 -1.38554125e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04395289e-03 -1.03216393e-04  3.07679948e-05  1.12799324e-04\n",
      "   1.65282196e-04 -6.85202758e-06 -1.39426891e-04]]\n",
      "linear.bias:\n",
      " [0.00022232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441637e-03 -1.0464906e-04  3.1140327e-05  8.9868860e-05\n",
      "   1.6711894e-04 -5.4174627e-05 -1.3958945e-04]]\n",
      "linear.bias:\n",
      " [0.00022179]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444513e-03 -1.0460243e-04  3.1462401e-05  9.3783565e-05\n",
      "   1.6835338e-04 -4.0205610e-05 -1.4010999e-04]]\n",
      "linear.bias:\n",
      " [0.00022132]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04471925e-03 -1.04756386e-04  3.16378937e-05  1.13949005e-04\n",
      "   1.69429099e-04  1.24190447e-05 -1.40619784e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449711e-03 -1.0524415e-04  3.1923217e-05  9.8095079e-05\n",
      "   1.7033779e-04 -2.5334823e-05 -1.4129373e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448914e-03 -1.0589600e-04  3.1943757e-05  9.2274822e-05\n",
      "   1.7085150e-04 -3.9874587e-05 -1.4199286e-04]]\n",
      "linear.bias:\n",
      " [0.00022048]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04478665e-03 -1.05203253e-04  3.19889259e-05  1.10638626e-04\n",
      "   1.70680985e-04 -1.04381616e-06 -1.42978533e-04]]\n",
      "linear.bias:\n",
      " [0.0002204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454644e-03 -1.0537665e-04  3.2131116e-05  1.0945306e-04\n",
      "   1.7135116e-04 -6.2584122e-06 -1.4325866e-04]]\n",
      "linear.bias:\n",
      " [0.00022026]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468474e-03 -1.0633054e-04  3.2360742e-05  9.0654125e-05\n",
      "   1.7277891e-04 -5.1131181e-05 -1.4290302e-04]]\n",
      "linear.bias:\n",
      " [0.00022007]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480597e-03 -1.0590744e-04  3.2594253e-05  9.7368131e-05\n",
      "   1.7343037e-04 -3.9578736e-05 -1.4293949e-04]]\n",
      "linear.bias:\n",
      " [0.0002199]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04912708e-03 -1.05549065e-04  3.25771252e-05  1.19295168e-04\n",
      "   1.73575754e-04  1.01477126e-05 -1.43183061e-04]]\n",
      "linear.bias:\n",
      " [0.00021981]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04959495e-03 -1.05225488e-04  3.27023008e-05  1.01520025e-04\n",
      "   1.73315377e-04 -2.98242667e-05 -1.43668367e-04]]\n",
      "linear.bias:\n",
      " [0.00021973]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494300e-03 -1.0539189e-04  3.2746153e-05  9.1776405e-05\n",
      "   1.7287803e-04 -3.9171238e-05 -1.4403145e-04]]\n",
      "linear.bias:\n",
      " [0.00021992]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04898750e-03 -1.05762840e-04  3.27062335e-05  1.03814324e-04\n",
      "   1.72322470e-04 -4.49067375e-06 -1.44424397e-04]]\n",
      "linear.bias:\n",
      " [0.00022015]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492590e-03 -1.0708802e-04  3.2794913e-05  1.0391371e-04\n",
      "   1.7268522e-04 -7.6600281e-06 -1.4407893e-04]]\n",
      "linear.bias:\n",
      " [0.0002203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490512e-03 -1.0784334e-04  3.3167391e-05  9.5255302e-05\n",
      "   1.7397040e-04 -4.1532789e-05 -1.4307482e-04]]\n",
      "linear.bias:\n",
      " [0.0002205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485591e-03 -1.0622642e-04  3.3334363e-05  1.1010139e-04\n",
      "   1.7420613e-04 -2.0852420e-05 -1.4265576e-04]]\n",
      "linear.bias:\n",
      " [0.00022081]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04758109e-03 -1.04659506e-04  3.35542718e-05  1.13318150e-04\n",
      "   1.74833098e-04 -7.52622054e-06 -1.42027129e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468758e-03 -1.0354878e-04  3.3600256e-05  9.2160422e-05\n",
      "   1.7578781e-04 -2.9864430e-05 -1.4110839e-04]]\n",
      "linear.bias:\n",
      " [0.00022209]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04621623e-03 -1.02571285e-04  3.34129945e-05  8.90630690e-05\n",
      "   1.76203830e-04 -1.05962681e-05 -1.40492906e-04]]\n",
      "linear.bias:\n",
      " [0.0002227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456430e-03 -1.0243165e-04  3.3320041e-05  9.6330405e-05\n",
      "   1.7657239e-04  3.6663268e-06 -1.3977406e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459529e-03 -1.0295071e-04  3.3318502e-05  9.4807132e-05\n",
      "   1.7743235e-04 -2.5514266e-05 -1.3855264e-04]]\n",
      "linear.bias:\n",
      " [0.00022355]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460870e-03 -1.0340932e-04  3.3098037e-05  1.0816510e-04\n",
      "   1.7769930e-04 -2.2447715e-05 -1.3770004e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04652985e-03 -1.04799845e-04  3.26183072e-05  1.14567687e-04\n",
      "   1.78000759e-04 -1.79993513e-05 -1.36867602e-04]]\n",
      "linear.bias:\n",
      " [0.00022426]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04719028e-03 -1.06362175e-04  3.20282415e-05  9.72379930e-05\n",
      "   1.78564951e-04 -4.19095595e-05 -1.35825016e-04]]\n",
      "linear.bias:\n",
      " [0.00022472]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04781543e-03 -1.06365311e-04  3.14470199e-05  1.05849576e-04\n",
      "   1.77772337e-04 -9.73644273e-06 -1.35538285e-04]]\n",
      "linear.bias:\n",
      " [0.00022514]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04857131e-03 -1.06691274e-04  3.07719747e-05  9.59681929e-05\n",
      "   1.77373659e-04 -7.80533264e-06 -1.34952163e-04]]\n",
      "linear.bias:\n",
      " [0.00022551]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487536e-03 -1.0739007e-04  3.0268409e-05  9.1496360e-05\n",
      "   1.7692185e-04 -1.9608549e-05 -1.3416032e-04]]\n",
      "linear.bias:\n",
      " [0.00022572]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491676e-03 -1.0645006e-04  2.9806642e-05  1.0744269e-04\n",
      "   1.7569313e-04  2.3563025e-06 -1.3388759e-04]]\n",
      "linear.bias:\n",
      " [0.00022577]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496124e-03 -1.0539388e-04  2.9422790e-05  9.5066993e-05\n",
      "   1.7423024e-04 -4.8035894e-05 -1.3357084e-04]]\n",
      "linear.bias:\n",
      " [0.00022562]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05004373e-03 -1.03085426e-04  2.90166263e-05  1.09367298e-04\n",
      "   1.71616819e-04 -3.68710971e-05 -1.34116694e-04]]\n",
      "linear.bias:\n",
      " [0.00022535]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502030e-03 -1.0098447e-04  2.8594224e-05  1.2857659e-04\n",
      "   1.6917437e-04  8.3690393e-06 -1.3483474e-04]]\n",
      "linear.bias:\n",
      " [0.00022518]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489173e-03 -9.9358134e-05  2.8250755e-05  9.7883560e-05\n",
      "   1.6673583e-04 -5.7682097e-05 -1.3621119e-04]]\n",
      "linear.bias:\n",
      " [0.00022489]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477260e-03 -9.6643365e-05  2.7958044e-05  9.5344491e-05\n",
      "   1.6390481e-04 -6.2285551e-05 -1.3799002e-04]]\n",
      "linear.bias:\n",
      " [0.00022449]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467769e-03 -9.3599199e-05  2.7807102e-05  1.1935840e-04\n",
      "   1.6143393e-04 -7.9219863e-06 -1.3992043e-04]]\n",
      "linear.bias:\n",
      " [0.00022407]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04632322e-03 -9.22360559e-05  2.78905718e-05  1.16771436e-04\n",
      "   1.60714713e-04 -6.02015552e-06 -1.40986565e-04]]\n",
      "linear.bias:\n",
      " [0.00022362]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466288e-03 -9.2229035e-05  2.8076041e-05  8.9633402e-05\n",
      "   1.6184428e-04 -5.2193140e-05 -1.4115582e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466243e-03 -9.3199800e-05  2.8254179e-05  8.6930857e-05\n",
      "   1.6327343e-04 -4.8793256e-05 -1.4118601e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464005e-03 -9.4812218e-05  2.8478134e-05  1.0662015e-04\n",
      "   1.6464206e-04 -4.8559523e-06 -1.4117848e-04]]\n",
      "linear.bias:\n",
      " [0.00022217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468629e-03 -9.7837074e-05  2.8912697e-05  1.1234854e-04\n",
      "   1.6743012e-04 -2.3938046e-06 -1.4025319e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476817e-03 -1.0194357e-04  2.9524110e-05  9.3236755e-05\n",
      "   1.7145142e-04 -4.7240046e-05 -1.3874558e-04]]\n",
      "linear.bias:\n",
      " [0.00022123]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483852e-03 -1.0433426e-04  3.0101966e-05  1.0005029e-04\n",
      "   1.7442599e-04 -3.5520738e-05 -1.3775169e-04]]\n",
      "linear.bias:\n",
      " [0.0002208]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490047e-03 -1.0646030e-04  3.0378042e-05  1.2094315e-04\n",
      "   1.7666622e-04  1.3934550e-05 -1.3710908e-04]]\n",
      "linear.bias:\n",
      " [0.00022055]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491498e-03 -1.0735595e-04  3.0315039e-05  9.1192080e-05\n",
      "   1.7769277e-04 -3.9787454e-05 -1.3761535e-04]]\n",
      "linear.bias:\n",
      " [0.00022045]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492383e-03 -1.0665227e-04  3.0231122e-05  8.8983754e-05\n",
      "   1.7738569e-04 -3.6534711e-05 -1.3866328e-04]]\n",
      "linear.bias:\n",
      " [0.0002205]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492756e-03 -1.0450740e-04  3.0128354e-05  1.1158667e-04\n",
      "   1.7587689e-04  1.7991224e-05 -1.4019936e-04]]\n",
      "linear.bias:\n",
      " [0.00022068]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483065e-03 -1.0291672e-04  3.0305157e-05  9.2079375e-05\n",
      "   1.7414366e-04 -3.6946229e-05 -1.4196163e-04]]\n",
      "linear.bias:\n",
      " [0.00022077]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470994e-03 -1.0153185e-04  3.0268364e-05  9.4835530e-05\n",
      "   1.7200327e-04 -4.4039502e-05 -1.4378937e-04]]\n",
      "linear.bias:\n",
      " [0.00022099]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457120e-03 -1.0051058e-04  3.0154108e-05  1.1848159e-04\n",
      "   1.6991056e-04 -7.3393603e-06 -1.4550272e-04]]\n",
      "linear.bias:\n",
      " [0.00022125]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04486721e-03 -1.00980942e-04  3.02724911e-05  1.15413895e-04\n",
      "   1.69544786e-04 -2.12163286e-05 -1.46367631e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448196e-03 -1.0255067e-04  3.0509957e-05  9.8275457e-05\n",
      "   1.7025635e-04 -5.4758228e-05 -1.4651957e-04]]\n",
      "linear.bias:\n",
      " [0.00022164]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04474265e-03 -1.02648904e-04  3.07512200e-05  1.06967622e-04\n",
      "   1.70246392e-04 -3.30086259e-05 -1.47022380e-04]]\n",
      "linear.bias:\n",
      " [0.00022183]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442599e-03 -1.0393468e-04  3.1205040e-05  1.1675837e-04\n",
      "   1.7111941e-04  7.7611621e-06 -1.4706308e-04]]\n",
      "linear.bias:\n",
      " [0.00022215]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04414544e-03 -1.05946245e-04  3.16767109e-05  9.53674826e-05\n",
      "   1.72928587e-04 -1.73165008e-05 -1.46637001e-04]]\n",
      "linear.bias:\n",
      " [0.00022236]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04360958e-03 -1.08343396e-04  3.24871253e-05  8.27058393e-05\n",
      "   1.75362511e-04 -4.71621679e-05 -1.45593571e-04]]\n",
      "linear.bias:\n",
      " [0.00022255]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427092e-03 -1.0912151e-04  3.3146149e-05  1.0252732e-04\n",
      "   1.7676652e-04 -1.7577599e-05 -1.4492549e-04]]\n",
      "linear.bias:\n",
      " [0.00022273]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04290457e-03 -1.10107416e-04  3.34191755e-05  1.13170187e-04\n",
      "   1.78211354e-04 -3.53162886e-06 -1.44038611e-04]]\n",
      "linear.bias:\n",
      " [0.00022308]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04338047e-03 -1.10748835e-04  3.35725817e-05  9.87060557e-05\n",
      "   1.79950381e-04 -3.20497020e-05 -1.42788689e-04]]\n",
      "linear.bias:\n",
      " [0.00022321]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04405195e-03 -1.09801564e-04  3.35857112e-05  1.04874045e-04\n",
      "   1.80574731e-04 -9.50330104e-06 -1.42179808e-04]]\n",
      "linear.bias:\n",
      " [0.00022331]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04534940e-03 -1.09368295e-04  3.35578261e-05  1.00846257e-04\n",
      "   1.81647556e-04 -2.02270912e-05 -1.41037846e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04649703e-03 -1.08920976e-04  3.33716671e-05  1.05045357e-04\n",
      "   1.82071439e-04 -2.07554585e-05 -1.40231510e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469792e-03 -1.0887080e-04  3.3199900e-05  1.0771322e-04\n",
      "   1.8209394e-04 -1.9223015e-05 -1.3954306e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04687794e-03 -1.08953296e-04  3.30789771e-05  1.03883962e-04\n",
      "   1.81881012e-04 -1.98256967e-05 -1.38948119e-04]]\n",
      "linear.bias:\n",
      " [0.00022443]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04634673e-03 -1.09117784e-04  3.29738650e-05  1.06720807e-04\n",
      "   1.81185911e-04 -1.26987416e-05 -1.38551346e-04]]\n",
      "linear.bias:\n",
      " [0.00022496]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463276e-03 -1.0945399e-04  3.2745309e-05  9.3058647e-05\n",
      "   1.8073963e-04 -3.2424254e-05 -1.3782534e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462415e-03 -1.0825011e-04  3.2450935e-05  1.0422294e-04\n",
      "   1.7926247e-04  1.2743112e-06 -1.3771594e-04]]\n",
      "linear.bias:\n",
      " [0.00022593]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462084e-03 -1.0660783e-04  3.2074913e-05  9.4677482e-05\n",
      "   1.7771877e-04 -2.7473656e-05 -1.3728789e-04]]\n",
      "linear.bias:\n",
      " [0.00022597]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04629924e-03 -1.03563143e-04  3.16208752e-05  1.04090344e-04\n",
      "   1.75317051e-04 -1.50896703e-05 -1.37458002e-04]]\n",
      "linear.bias:\n",
      " [0.00022594]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04691437e-03 -1.01876234e-04  3.09792558e-05  1.06174673e-04\n",
      "   1.73131222e-04 -1.34806196e-05 -1.37403753e-04]]\n",
      "linear.bias:\n",
      " [0.00022591]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480672e-03 -1.0132715e-04  3.0422927e-05  9.1623202e-05\n",
      "   1.7189735e-04 -4.0435531e-05 -1.3683373e-04]]\n",
      "linear.bias:\n",
      " [0.00022595]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490740e-03 -9.9534467e-05  2.9961977e-05  1.0382744e-04\n",
      "   1.7009737e-04 -1.1030263e-05 -1.3685065e-04]]\n",
      "linear.bias:\n",
      " [0.00022592]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05067424e-03 -9.89461405e-05  2.96758990e-05  1.03766775e-04\n",
      "   1.69369901e-04 -1.91490071e-05 -1.36141884e-04]]\n",
      "linear.bias:\n",
      " [0.00022582]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05147681e-03 -9.94340589e-05  2.95381487e-05  1.03933824e-04\n",
      "   1.69114792e-04 -2.38246830e-05 -1.35317954e-04]]\n",
      "linear.bias:\n",
      " [0.00022587]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516982e-03 -1.0072073e-04  2.9506149e-05  1.0842765e-04\n",
      "   1.6916182e-04 -1.5060014e-05 -1.3444589e-04]]\n",
      "linear.bias:\n",
      " [0.00022592]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0511747e-03 -1.0219914e-04  2.9750074e-05  9.5339652e-05\n",
      "   1.6988044e-04 -3.4265733e-05 -1.3324844e-04]]\n",
      "linear.bias:\n",
      " [0.00022603]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502586e-03 -1.0373508e-04  2.9911827e-05  9.9336496e-05\n",
      "   1.7007801e-04 -1.1973107e-05 -1.3246575e-04]]\n",
      "linear.bias:\n",
      " [0.00022606]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04911509e-03 -1.05925785e-04  3.03202742e-05  1.05323197e-04\n",
      "   1.70707150e-04 -6.35434344e-06 -1.31443536e-04]]\n",
      "linear.bias:\n",
      " [0.00022595]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475649e-03 -1.0807606e-04  3.1045682e-05  9.1692556e-05\n",
      "   1.7207264e-04 -4.0452800e-05 -1.2999987e-04]]\n",
      "linear.bias:\n",
      " [0.00022578]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04620343e-03 -1.08595334e-04  3.16598525e-05  1.05220985e-04\n",
      "   1.71928419e-04 -1.57529867e-05 -1.29534092e-04]]\n",
      "linear.bias:\n",
      " [0.00022556]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04473450e-03 -1.09009939e-04  3.22415799e-05  1.16758005e-04\n",
      "   1.71606924e-04  1.18849330e-05 -1.29314270e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04304426e-03 -1.07724496e-04  3.23831300e-05  8.26344476e-05\n",
      "   1.70161991e-04 -5.60940607e-05 -1.30255445e-04]]\n",
      "linear.bias:\n",
      " [0.00022539]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416480e-03 -1.0513326e-04  3.2410087e-05  8.7681743e-05\n",
      "   1.6689654e-04 -5.3272630e-05 -1.3216070e-04]]\n",
      "linear.bias:\n",
      " [0.00022521]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04045728e-03 -1.01580867e-04  3.24893372e-05  1.19166434e-04\n",
      "   1.63041637e-04  6.64726031e-06 -1.34557107e-04]]\n",
      "linear.bias:\n",
      " [0.00022484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03971269e-03 -9.96284216e-05  3.24278262e-05  1.13476526e-04\n",
      "   1.60980635e-04 -2.12863961e-06 -1.36684175e-04]]\n",
      "linear.bias:\n",
      " [0.00022451]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397773e-03 -9.9126730e-05  3.2485990e-05  8.2954561e-05\n",
      "   1.6095431e-04 -5.8121994e-05 -1.3778549e-04]]\n",
      "linear.bias:\n",
      " [0.00022408]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399434e-03 -9.7904776e-05  3.2629239e-05  8.7089211e-05\n",
      "   1.6060188e-04 -5.1014511e-05 -1.3922135e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400043e-03 -9.7500990e-05  3.2781725e-05  1.1450306e-04\n",
      "   1.6059153e-04  1.0628428e-06 -1.4049857e-04]]\n",
      "linear.bias:\n",
      " [0.00022294]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407957e-03 -9.8396202e-05  3.3032808e-05  1.1375536e-04\n",
      "   1.6241522e-04 -1.5772605e-07 -1.4083310e-04]]\n",
      "linear.bias:\n",
      " [0.00022232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422453e-03 -1.0046198e-04  3.3372744e-05  8.7639579e-05\n",
      "   1.6589164e-04 -4.9350754e-05 -1.4031821e-04]]\n",
      "linear.bias:\n",
      " [0.00022162]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435971e-03 -1.0150616e-04  3.3855613e-05  8.9784902e-05\n",
      "   1.6860993e-04 -4.3695887e-05 -1.4012412e-04]]\n",
      "linear.bias:\n",
      " [0.00022093]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445064e-03 -1.0267816e-04  3.4207245e-05  1.1332860e-04\n",
      "   1.7088841e-04  4.7900066e-06 -1.4001846e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457052e-03 -1.0497649e-04  3.4632838e-05  1.0880305e-04\n",
      "   1.7407253e-04  4.5806064e-07 -1.3940588e-04]]\n",
      "linear.bias:\n",
      " [0.00021987]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471054e-03 -1.0731858e-04  3.4965626e-05  8.2162056e-05\n",
      "   1.7752056e-04 -4.3669832e-05 -1.3837914e-04]]\n",
      "linear.bias:\n",
      " [0.00021934]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04801264e-03 -1.07840846e-04  3.51773269e-05  9.47549634e-05\n",
      "   1.78653194e-04 -2.19930607e-05 -1.38169024e-04]]\n",
      "linear.bias:\n",
      " [0.00021888]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04867097e-03 -1.08243737e-04  3.51455201e-05  1.17324205e-04\n",
      "   1.79219758e-04  2.18872283e-05 -1.38225529e-04]]\n",
      "linear.bias:\n",
      " [0.00021859]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04822696e-03 -1.06961495e-04  3.48213398e-05  8.48054624e-05\n",
      "   1.78790840e-04 -5.38933236e-05 -1.39370677e-04]]\n",
      "linear.bias:\n",
      " [0.00021861]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474551e-03 -1.0409065e-04  3.4477944e-05  9.3346200e-05\n",
      "   1.7620526e-04 -6.0096190e-05 -1.4118382e-04]]\n",
      "linear.bias:\n",
      " [0.0002187]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463756e-03 -9.9830511e-05  3.4034008e-05  1.2800044e-04\n",
      "   1.7275180e-04 -1.1252414e-05 -1.4328021e-04]]\n",
      "linear.bias:\n",
      " [0.00021891]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04539213e-03 -9.69729299e-05  3.32560885e-05  1.17763724e-04\n",
      "   1.69727267e-04 -1.56113765e-05 -1.45356898e-04]]\n",
      "linear.bias:\n",
      " [0.00021952]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451851e-03 -9.5284551e-05  3.2553864e-05  8.7658373e-05\n",
      "   1.6770123e-04 -5.4204909e-05 -1.4669134e-04]]\n",
      "linear.bias:\n",
      " [0.00022007]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445375e-03 -9.4536197e-05  3.1893233e-05  8.6632004e-05\n",
      "   1.6642046e-04 -3.8946524e-05 -1.4765130e-04]]\n",
      "linear.bias:\n",
      " [0.00022077]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04372611e-03 -9.46291329e-05  3.13643104e-05  1.08485314e-04\n",
      "   1.65351827e-04  1.57527975e-05 -1.48479710e-04]]\n",
      "linear.bias:\n",
      " [0.0002214]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436741e-03 -9.6484131e-05  3.1121665e-05  1.0807277e-04\n",
      "   1.6638027e-04  1.0114996e-05 -1.4817680e-04]]\n",
      "linear.bias:\n",
      " [0.00022176]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442763e-03 -9.9888093e-05  3.1118012e-05  8.9850473e-05\n",
      "   1.6927537e-04 -4.7757854e-05 -1.4675433e-04]]\n",
      "linear.bias:\n",
      " [0.00022181]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445899e-03 -1.0372174e-04  3.1180844e-05  9.6254364e-05\n",
      "   1.7196745e-04 -5.8889411e-05 -1.4543720e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448372e-03 -1.0581514e-04  3.1265750e-05  1.2676473e-04\n",
      "   1.7371945e-04 -1.6734943e-05 -1.4462919e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452751e-03 -1.0805611e-04  3.1200820e-05  1.2691203e-04\n",
      "   1.7573172e-04 -1.5301728e-05 -1.4362992e-04]]\n",
      "linear.bias:\n",
      " [0.00022199]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458705e-03 -1.0990140e-04  3.0956504e-05  9.7797129e-05\n",
      "   1.7784408e-04 -5.1697956e-05 -1.4247259e-04]]\n",
      "linear.bias:\n",
      " [0.00022202]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463358e-03 -1.1001697e-04  3.0645613e-05  9.5501215e-05\n",
      "   1.7864283e-04 -3.2978329e-05 -1.4198905e-04]]\n",
      "linear.bias:\n",
      " [0.00022211]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04700529e-03 -1.08548535e-04  3.02367225e-05  1.13085385e-04\n",
      "   1.78391027e-04  3.22610940e-05 -1.42086457e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467768e-03 -1.0660778e-04  3.0015090e-05  7.8833356e-05\n",
      "   1.7790488e-04 -3.9043196e-05 -1.4278776e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462133e-03 -1.0325594e-04  2.9726554e-05  8.4824147e-05\n",
      "   1.7547319e-04 -4.2141826e-05 -1.4414158e-04]]\n",
      "linear.bias:\n",
      " [0.00022273]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04575302e-03 -9.94099755e-05  2.96459184e-05  1.16108386e-04\n",
      "   1.72865257e-04  4.74049739e-06 -1.45634098e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04559527e-03 -9.73919450e-05  2.97843198e-05  1.15773124e-04\n",
      "   1.71550564e-04 -4.38507686e-06 -1.46542065e-04]]\n",
      "linear.bias:\n",
      " [0.0002231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458436e-03 -9.6981086e-05  3.0120005e-05  9.2635571e-05\n",
      "   1.7192296e-04 -5.7544446e-05 -1.4655375e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458371e-03 -9.7384414e-05  3.0488862e-05  9.4712064e-05\n",
      "   1.7234380e-04 -6.4554777e-05 -1.4652789e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457957e-03 -9.6654243e-05  3.0802246e-05  1.2423063e-04\n",
      "   1.7222000e-04  8.6353975e-07 -1.4677225e-04]]\n",
      "linear.bias:\n",
      " [0.00022332]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464732e-03 -9.7153934e-05  3.1196716e-05  1.1796136e-04\n",
      "   1.7333975e-04  5.0488693e-06 -1.4642665e-04]]\n",
      "linear.bias:\n",
      " [0.00022335]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473407e-03 -9.9053665e-05  3.1763604e-05  8.3754116e-05\n",
      "   1.7538510e-04 -4.2478703e-05 -1.4567802e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04781101e-03 -1.01615784e-04  3.22837004e-05  7.99688642e-05\n",
      "   1.77201029e-04 -4.29608954e-05 -1.44960955e-04]]\n",
      "linear.bias:\n",
      " [0.00022347]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478072e-03 -1.0242582e-04  3.2744003e-05  1.1313280e-04\n",
      "   1.7753085e-04  1.6066344e-05 -1.4473221e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04722753e-03 -1.03716186e-04  3.34199503e-05  1.05193241e-04\n",
      "   1.77704438e-04 -2.56038365e-05 -1.44715494e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461148e-03 -1.0528514e-04  3.3991499e-05  9.9332203e-05\n",
      "   1.7788925e-04 -4.9309463e-05 -1.4461920e-04]]\n",
      "linear.bias:\n",
      " [0.00022352]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04536547e-03 -1.05112296e-04  3.43761894e-05  1.13810303e-04\n",
      "   1.77076377e-04 -2.25091644e-05 -1.45069833e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04531751e-03 -1.05427425e-04  3.45871995e-05  1.10031106e-04\n",
      "   1.76739792e-04 -1.78167775e-05 -1.45108846e-04]]\n",
      "linear.bias:\n",
      " [0.00022388]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459016e-03 -1.0618227e-04  3.4641722e-05  8.9802692e-05\n",
      "   1.7683234e-04 -3.3041488e-05 -1.4477698e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460769e-03 -1.0691198e-04  3.4485252e-05  9.2654678e-05\n",
      "   1.7630791e-04 -4.3163709e-06 -1.4473058e-04]]\n",
      "linear.bias:\n",
      " [0.00022491]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468552e-03 -1.0857501e-04  3.4422515e-05  9.3929018e-05\n",
      "   1.7629967e-04 -7.0917981e-06 -1.4401753e-04]]\n",
      "linear.bias:\n",
      " [0.00022521]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481770e-03 -1.1107913e-04  3.4444231e-05  9.3781855e-05\n",
      "   1.7675656e-04 -3.8240611e-05 -1.4270372e-04]]\n",
      "linear.bias:\n",
      " [0.00022526]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04904093e-03 -1.10874724e-04  3.42834137e-05  1.17507443e-04\n",
      "   1.76181231e-04 -1.50368196e-05 -1.42040080e-04]]\n",
      "linear.bias:\n",
      " [0.00022545]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04973698e-03 -1.09581670e-04  3.38425089e-05  1.11329915e-04\n",
      "   1.76074871e-04 -2.97358056e-05 -1.41033350e-04]]\n",
      "linear.bias:\n",
      " [0.00022555]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04955793e-03 -1.07831926e-04  3.33192838e-05  1.03654573e-04\n",
      "   1.76151400e-04 -2.86958602e-05 -1.40099597e-04]]\n",
      "linear.bias:\n",
      " [0.00022592]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04878598e-03 -1.06393680e-04  3.28057431e-05  1.07987355e-04\n",
      "   1.75785884e-04 -4.43845965e-06 -1.39383454e-04]]\n",
      "linear.bias:\n",
      " [0.00022625]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482715e-03 -1.0519168e-04  3.2305103e-05  8.7657856e-05\n",
      "   1.7586933e-04 -2.3888559e-05 -1.3827812e-04]]\n",
      "linear.bias:\n",
      " [0.00022642]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474679e-03 -1.0408269e-04  3.1769741e-05  9.1598638e-05\n",
      "   1.7544342e-04 -1.4631311e-05 -1.3746496e-04]]\n",
      "linear.bias:\n",
      " [0.00022656]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04649772e-03 -1.03732775e-04  3.15689431e-05  1.06586333e-04\n",
      "   1.74959801e-04 -6.11855739e-06 -1.36621209e-04]]\n",
      "linear.bias:\n",
      " [0.00022655]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04603695e-03 -1.04242215e-04  3.14892277e-05  9.81823323e-05\n",
      "   1.75381123e-04 -4.09265303e-05 -1.35265698e-04]]\n",
      "linear.bias:\n",
      " [0.0002264]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458798e-03 -1.0313566e-04  3.1299161e-05  1.1147938e-04\n",
      "   1.7474123e-04 -2.2453878e-05 -1.3475347e-04]]\n",
      "linear.bias:\n",
      " [0.00022619]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457690e-03 -1.0314576e-04  3.0894262e-05  1.1025921e-04\n",
      "   1.7423306e-04 -1.3283077e-05 -1.3427608e-04]]\n",
      "linear.bias:\n",
      " [0.00022615]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458580e-03 -1.0347796e-04  3.0366056e-05  8.3713443e-05\n",
      "   1.7419508e-04 -3.9502385e-05 -1.3346682e-04]]\n",
      "linear.bias:\n",
      " [0.0002261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458998e-03 -1.0232119e-04  2.9858307e-05  9.4889176e-05\n",
      "   1.7212980e-04 -3.3725119e-06 -1.3373366e-04]]\n",
      "linear.bias:\n",
      " [0.00022593]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466081e-03 -1.0285342e-04  2.9422166e-05  1.0428791e-04\n",
      "   1.7077703e-04  6.9950784e-06 -1.3348916e-04]]\n",
      "linear.bias:\n",
      " [0.00022541]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473846e-03 -1.0349696e-04  2.9101693e-05  8.8749977e-05\n",
      "   1.6981897e-04 -5.6641482e-05 -1.3310819e-04]]\n",
      "linear.bias:\n",
      " [0.00022466]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481530e-03 -1.0281225e-04  2.8870116e-05  1.0242309e-04\n",
      "   1.6800794e-04 -5.6642893e-05 -1.3347110e-04]]\n",
      "linear.bias:\n",
      " [0.00022378]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491807e-03 -1.0073269e-04  2.8640174e-05  1.3365054e-04\n",
      "   1.6584694e-04 -4.2718675e-06 -1.3444936e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491386e-03 -9.9715930e-05  2.8156732e-05  1.0870924e-04\n",
      "   1.6403856e-04 -2.1176991e-05 -1.3581107e-04]]\n",
      "linear.bias:\n",
      " [0.00022221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486428e-03 -9.9417775e-05  2.8072385e-05  7.7445540e-05\n",
      "   1.6356043e-04 -4.3337754e-05 -1.3647320e-04]]\n",
      "linear.bias:\n",
      " [0.00022192]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478420e-03 -9.8272649e-05  2.8088456e-05  8.3925355e-05\n",
      "   1.6252769e-04 -7.5085482e-06 -1.3741547e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464493e-03 -9.8463250e-05  2.8432672e-05  1.0022867e-04\n",
      "   1.6227785e-04  2.0330761e-05 -1.3773321e-04]]\n",
      "linear.bias:\n",
      " [0.00022102]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450827e-03 -1.0018826e-04  2.9192846e-05  8.9179754e-05\n",
      "   1.6330868e-04 -4.6773846e-05 -1.3774104e-04]]\n",
      "linear.bias:\n",
      " [0.00022049]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04361703e-03 -1.02531340e-04  2.99453750e-05  1.02511985e-04\n",
      "   1.64324258e-04 -6.62369130e-05 -1.37710929e-04]]\n",
      "linear.bias:\n",
      " [0.00022002]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424396e-03 -1.0308134e-04  3.0624466e-05  1.3316257e-04\n",
      "   1.6527601e-04 -1.8165927e-05 -1.3810536e-04]]\n",
      "linear.bias:\n",
      " [0.00021988]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418256e-03 -1.0446043e-04  3.0789677e-05  1.1716591e-04\n",
      "   1.6680920e-04 -2.2269604e-05 -1.3834437e-04]]\n",
      "linear.bias:\n",
      " [0.00021997]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419106e-03 -1.0618134e-04  3.0800671e-05  8.5716703e-05\n",
      "   1.6859223e-04 -4.5480840e-05 -1.3818643e-04]]\n",
      "linear.bias:\n",
      " [0.00022027]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04195089e-03 -1.06331776e-04  3.08397393e-05  8.26825853e-05\n",
      "   1.69505627e-04 -1.42175923e-05 -1.38433548e-04]]\n",
      "linear.bias:\n",
      " [0.00022053]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04195753e-03 -1.07187734e-04  3.10629366e-05  1.05453422e-04\n",
      "   1.70576983e-04  2.92309232e-05 -1.38422518e-04]]\n",
      "linear.bias:\n",
      " [0.00022077]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414578e-03 -1.0822605e-04  3.1429725e-05  8.8816247e-05\n",
      "   1.7166474e-04 -5.1151856e-05 -1.3874279e-04]]\n",
      "linear.bias:\n",
      " [0.00022127]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409715e-03 -1.0775929e-04  3.1789248e-05  9.9147939e-05\n",
      "   1.7195079e-04 -7.1461080e-05 -1.3942124e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410403e-03 -1.0568711e-04  3.2156273e-05  1.3548561e-04\n",
      "   1.7149991e-04  2.5096233e-07 -1.4079665e-04]]\n",
      "linear.bias:\n",
      " [0.00022241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04124937e-03 -1.02094775e-04  3.17641206e-05  1.06969252e-04\n",
      "   1.70630767e-04 -1.32660525e-05 -1.42600577e-04]]\n",
      "linear.bias:\n",
      " [0.00022332]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421693e-03 -9.9941994e-05  3.1547072e-05  6.9810936e-05\n",
      "   1.7079050e-04 -5.9825819e-05 -1.4346142e-04]]\n",
      "linear.bias:\n",
      " [0.00022407]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04365405e-03 -9.76458978e-05  3.11225776e-05  1.08512744e-04\n",
      "   1.69181876e-04  3.31430783e-06 -1.44922233e-04]]\n",
      "linear.bias:\n",
      " [0.00022424]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461146e-03 -9.6993877e-05  3.0848776e-05  1.2571589e-04\n",
      "   1.6964761e-04  1.6118269e-05 -1.4511615e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473585e-03 -9.5936957e-05  3.0715528e-05  9.1516486e-05\n",
      "   1.7052298e-04 -7.4884541e-05 -1.4534881e-04]]\n",
      "linear.bias:\n",
      " [0.00022377]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482463e-03 -9.3358853e-05  3.0594347e-05  9.5694530e-05\n",
      "   1.7078992e-04 -5.5023273e-05 -1.4599379e-04]]\n",
      "linear.bias:\n",
      " [0.00022354]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04836316e-03 -9.19906233e-05  3.07293267e-05  1.21210505e-04\n",
      "   1.71160747e-04  1.94901440e-06 -1.46448408e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487702e-03 -9.2441580e-05  3.1192121e-05  1.1593763e-04\n",
      "   1.7300686e-04  2.9680014e-06 -1.4622147e-04]]\n",
      "linear.bias:\n",
      " [0.00022301]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494017e-03 -9.4340365e-05  3.1826807e-05  8.2055878e-05\n",
      "   1.7573703e-04 -4.7085501e-05 -1.4556674e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493224e-03 -9.6782009e-05  3.2361895e-05  8.2356768e-05\n",
      "   1.7813884e-04 -4.7133894e-05 -1.4483758e-04]]\n",
      "linear.bias:\n",
      " [0.00022272]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489176e-03 -9.7511882e-05  3.2875352e-05  1.2120200e-04\n",
      "   1.7868364e-04  1.4168167e-05 -1.4474209e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475722e-03 -9.8421013e-05  3.3454246e-05  1.0728179e-04\n",
      "   1.7861370e-04 -3.2798656e-05 -1.4528401e-04]]\n",
      "linear.bias:\n",
      " [0.0002222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04668748e-03 -1.00397665e-04  3.36247322e-05  9.90419503e-05\n",
      "   1.78357222e-04 -5.20499198e-05 -1.45635800e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04581728e-03 -1.00571408e-04  3.36838530e-05  1.16153366e-04\n",
      "   1.76979840e-04 -1.85227909e-05 -1.46533013e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04575092e-03 -1.01105186e-04  3.35730620e-05  1.10039473e-04\n",
      "   1.76094036e-04 -1.38698924e-05 -1.46958104e-04]]\n",
      "linear.bias:\n",
      " [0.00022228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462847e-03 -1.0272103e-04  3.3496515e-05  9.0560221e-05\n",
      "   1.7606537e-04 -3.8233196e-05 -1.4668249e-04]]\n",
      "linear.bias:\n",
      " [0.00022242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464414e-03 -1.0441989e-04  3.3340038e-05  9.5378819e-05\n",
      "   1.7586129e-04 -1.7318880e-05 -1.4650701e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459564e-03 -1.0700909e-04  3.3404260e-05  1.1051865e-04\n",
      "   1.7581307e-04  2.8654158e-06 -1.4606342e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459428e-03 -1.1018563e-04  3.3565699e-05  1.0191616e-04\n",
      "   1.7664761e-04 -2.1021926e-05 -1.4505358e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449553e-03 -1.1207255e-04  3.3647000e-05  9.2838200e-05\n",
      "   1.7751764e-04 -4.4502151e-05 -1.4378062e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04372983e-03 -1.11238136e-04  3.35343975e-05  1.08999688e-04\n",
      "   1.77284572e-04 -1.47312458e-05 -1.43169440e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04305486e-03 -1.09681641e-04  3.31476112e-05  1.04269806e-04\n",
      "   1.77773807e-04 -1.37508905e-05 -1.42112898e-04]]\n",
      "linear.bias:\n",
      " [0.00022443]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04319234e-03 -1.08731554e-04  3.27565758e-05  8.99124934e-05\n",
      "   1.78763614e-04 -4.37129274e-05 -1.40522840e-04]]\n",
      "linear.bias:\n",
      " [0.00022493]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433497e-03 -1.0633337e-04  3.2349672e-05  1.0292327e-04\n",
      "   1.7822566e-04 -1.7398488e-05 -1.3980761e-04]]\n",
      "linear.bias:\n",
      " [0.00022539]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04399398e-03 -1.05186649e-04  3.17085214e-05  1.12237074e-04\n",
      "   1.77693117e-04  2.98926352e-06 -1.39060227e-04]]\n",
      "linear.bias:\n",
      " [0.00022579]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04467082e-03 -1.03923674e-04  3.11461408e-05  9.21010142e-05\n",
      "   1.77007169e-04 -4.44767211e-05 -1.38186180e-04]]\n",
      "linear.bias:\n",
      " [0.00022587]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04531390e-03 -1.01240985e-04  3.05848371e-05  9.99455733e-05\n",
      "   1.74957604e-04 -3.39105645e-05 -1.38117030e-04]]\n",
      "linear.bias:\n",
      " [0.00022594]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04586594e-03 -9.88503089e-05  2.98265513e-05  1.24188926e-04\n",
      "   1.72621352e-04  1.47711435e-05 -1.38289004e-04]]\n",
      "linear.bias:\n",
      " [0.00022607]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453045e-03 -9.7108728e-05  2.9295066e-05  9.6087926e-05\n",
      "   1.7007813e-04 -4.5989465e-05 -1.3921921e-04]]\n",
      "linear.bias:\n",
      " [0.00022612]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448952e-03 -9.6321397e-05  2.8846136e-05  8.9976114e-05\n",
      "   1.6801659e-04 -6.3188629e-05 -1.3999146e-04]]\n",
      "linear.bias:\n",
      " [0.00022609]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448989e-03 -9.4811650e-05  2.8646462e-05  1.1785096e-04\n",
      "   1.6546932e-04 -5.5478631e-06 -1.4127733e-04]]\n",
      "linear.bias:\n",
      " [0.00022591]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456854e-03 -9.4790645e-05  2.8587618e-05  1.1642384e-04\n",
      "   1.6512454e-04 -1.1594161e-06 -1.4156794e-04]]\n",
      "linear.bias:\n",
      " [0.00022561]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471772e-03 -9.6111093e-05  2.8655668e-05  8.8602494e-05\n",
      "   1.6676434e-04 -4.4703571e-05 -1.4096180e-04]]\n",
      "linear.bias:\n",
      " [0.0002252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482798e-03 -9.8109740e-05  2.8786628e-05  8.7202789e-05\n",
      "   1.6833050e-04 -4.3362717e-05 -1.4037786e-04]]\n",
      "linear.bias:\n",
      " [0.00022482]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04903162e-03 -1.00719604e-04  2.89742802e-05  1.09604320e-04\n",
      "   1.69830426e-04 -1.60897252e-06 -1.39813885e-04]]\n",
      "linear.bias:\n",
      " [0.00022448]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501361e-03 -1.0392328e-04  2.9247920e-05  1.0737163e-04\n",
      "   1.7206799e-04 -6.0752736e-06 -1.3868947e-04]]\n",
      "linear.bias:\n",
      " [0.00022403]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505724e-03 -1.0699869e-04  2.9878018e-05  8.5397100e-05\n",
      "   1.7494017e-04 -4.8721609e-05 -1.3711562e-04]]\n",
      "linear.bias:\n",
      " [0.00022355]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05092570e-03 -1.08263106e-04  3.04122768e-05  1.01459758e-04\n",
      "   1.75427020e-04 -2.80010227e-05 -1.36727569e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506212e-03 -1.0948978e-04  3.0835752e-05  1.2599057e-04\n",
      "   1.7542652e-04  1.3264047e-05 -1.3654897e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493137e-03 -1.0791061e-04  3.0731455e-05  9.0124930e-05\n",
      "   1.7478452e-04 -5.4426477e-05 -1.3752545e-04]]\n",
      "linear.bias:\n",
      " [0.00022242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482016e-03 -1.0494047e-04  3.0661620e-05  8.6387219e-05\n",
      "   1.7254331e-04 -6.0482889e-05 -1.3936136e-04]]\n",
      "linear.bias:\n",
      " [0.00022232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04692706e-03 -1.00850666e-04  3.06273214e-05  1.26651983e-04\n",
      "   1.68705170e-04  1.35363007e-05 -1.41759811e-04]]\n",
      "linear.bias:\n",
      " [0.00022208]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446474e-03 -9.6957730e-05  3.0608560e-05  1.0864607e-04\n",
      "   1.6542642e-04 -2.9152965e-05 -1.4453835e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431772e-03 -9.5323965e-05  3.0569936e-05  8.8852139e-05\n",
      "   1.6348220e-04 -4.9561488e-05 -1.4663905e-04]]\n",
      "linear.bias:\n",
      " [0.00022154]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415473e-03 -9.4910603e-05  3.0572406e-05  9.4092095e-05\n",
      "   1.6214367e-04 -2.4831854e-05 -1.4837280e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411810e-03 -9.6187498e-05  3.0517724e-05  1.0650334e-04\n",
      "   1.6226417e-04  1.1534601e-05 -1.4922234e-04]]\n",
      "linear.bias:\n",
      " [0.00022109]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415408e-03 -9.9179204e-05  3.0696781e-05  9.9076591e-05\n",
      "   1.6446474e-04 -7.8284720e-06 -1.4876579e-04]]\n",
      "linear.bias:\n",
      " [0.00022046]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430004e-03 -1.0300573e-04  3.1003339e-05  8.0965168e-05\n",
      "   1.6816995e-04 -5.9482143e-05 -1.4724847e-04]]\n",
      "linear.bias:\n",
      " [0.00021967]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04441901e-03 -1.05350511e-04  3.13391829e-05  1.06063926e-04\n",
      "   1.70987987e-04 -3.43026841e-05 -1.45951271e-04]]\n",
      "linear.bias:\n",
      " [0.00021911]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04520051e-03 -1.08103312e-04  3.17413178e-05  1.26411163e-04\n",
      "   1.74235189e-04  1.21481935e-05 -1.44548889e-04]]\n",
      "linear.bias:\n",
      " [0.0002189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458835e-03 -1.0823654e-04  3.1731364e-05  8.9127607e-05\n",
      "   1.7677793e-04 -5.0044757e-05 -1.4401815e-04]]\n",
      "linear.bias:\n",
      " [0.00021886]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461158e-03 -1.0654028e-04  3.1644879e-05  8.5240899e-05\n",
      "   1.7767695e-04 -5.2081432e-05 -1.4409621e-04]]\n",
      "linear.bias:\n",
      " [0.00021904]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04594196e-03 -1.03195453e-04  3.14894241e-05  1.11434136e-04\n",
      "   1.77094931e-04  1.21399353e-08 -1.44722842e-04]]\n",
      "linear.bias:\n",
      " [0.00021943]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462174e-03 -1.0104584e-04  3.1455202e-05  1.1247757e-04\n",
      "   1.7746710e-04  5.0820631e-06 -1.4466402e-04]]\n",
      "linear.bias:\n",
      " [0.00021963]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468080e-03 -9.9911820e-05  3.1628646e-05  8.1232822e-05\n",
      "   1.7807470e-04 -4.3791977e-05 -1.4443969e-04]]\n",
      "linear.bias:\n",
      " [0.00021996]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469090e-03 -9.7347453e-05  3.1773689e-05  8.7948145e-05\n",
      "   1.7756756e-04 -3.1672418e-05 -1.4459663e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467179e-03 -9.5661839e-05  3.1847860e-05  1.1694646e-04\n",
      "   1.7674340e-04  1.8858093e-05 -1.4489105e-04]]\n",
      "linear.bias:\n",
      " [0.00022073]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459188e-03 -9.4836141e-05  3.2226584e-05  1.0382659e-04\n",
      "   1.7570559e-04 -3.4328201e-05 -1.4542144e-04]]\n",
      "linear.bias:\n",
      " [0.0002211]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456106e-03 -9.5909571e-05  3.2381384e-05  9.9004472e-05\n",
      "   1.7483297e-04 -6.1078048e-05 -1.4560419e-04]]\n",
      "linear.bias:\n",
      " [0.00022151]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04529550e-03 -9.54229909e-05  3.25510737e-05  1.20548175e-04\n",
      "   1.73328197e-04 -3.38458158e-05 -1.46173130e-04]]\n",
      "linear.bias:\n",
      " [0.00022187]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454745e-03 -9.6105825e-05  3.2393924e-05  1.3431790e-04\n",
      "   1.7225850e-04  1.0264317e-05 -1.4658544e-04]]\n",
      "linear.bias:\n",
      " [0.00022249]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445868e-03 -9.6572498e-05  3.2055756e-05  8.6426357e-05\n",
      "   1.7185105e-04 -4.6678153e-05 -1.4717692e-04]]\n",
      "linear.bias:\n",
      " [0.00022298]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435422e-03 -9.7816228e-05  3.1822103e-05  6.7197412e-05\n",
      "   1.7157514e-04 -5.7691177e-05 -1.4767083e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431674e-03 -9.8599565e-05  3.1367239e-05  1.2143354e-04\n",
      "   1.6980790e-04  3.2557138e-05 -1.4859342e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419952e-03 -9.8595869e-05  3.1157833e-05  1.1424563e-04\n",
      "   1.6906224e-04 -2.5801677e-05 -1.4948440e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418745e-03 -9.9777280e-05  3.0935964e-05  9.3387731e-05\n",
      "   1.6995061e-04 -9.4049348e-05 -1.4944308e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419956e-03 -9.8810720e-05  3.0751271e-05  1.1961374e-04\n",
      "   1.6963409e-04 -3.7768204e-05 -1.5014531e-04]]\n",
      "linear.bias:\n",
      " [0.00022337]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431730e-03 -9.9020930e-05  3.0528689e-05  1.3417978e-04\n",
      "   1.7096553e-04  2.0773605e-05 -1.4999422e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430382e-03 -9.8541968e-05  3.0219653e-05  8.2097642e-05\n",
      "   1.7327517e-04 -4.5005912e-05 -1.4975180e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425057e-03 -9.8774450e-05  2.9893188e-05  6.9516740e-05\n",
      "   1.7535430e-04 -6.0643237e-05 -1.4929613e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427018e-03 -9.8755605e-05  2.9467843e-05  1.3477357e-04\n",
      "   1.7504195e-04  3.2146054e-05 -1.4951090e-04]]\n",
      "linear.bias:\n",
      " [0.00022294]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04187650e-03 -9.81782941e-05  2.90629087e-05  1.20877114e-04\n",
      "   1.75420835e-04 -3.66715176e-05 -1.50201144e-04]]\n",
      "linear.bias:\n",
      " [0.00022272]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417651e-03 -9.8343931e-05  2.8602781e-05  9.8825185e-05\n",
      "   1.7680365e-04 -8.7761509e-05 -1.5028381e-04]]\n",
      "linear.bias:\n",
      " [0.00022281]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04191678e-03 -9.64946375e-05  2.82009441e-05  1.20826335e-04\n",
      "   1.77257316e-04 -1.99593051e-05 -1.51017943e-04]]\n",
      "linear.bias:\n",
      " [0.0002229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04282645e-03 -9.59864992e-05  2.79656888e-05  1.19598684e-04\n",
      "   1.78884307e-04  8.33389822e-06 -1.50905282e-04]]\n",
      "linear.bias:\n",
      " [0.0002229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436408e-03 -9.6147647e-05  2.7930040e-05  7.8264944e-05\n",
      "   1.8048738e-04 -3.2989126e-05 -1.5063360e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441397e-03 -9.6888391e-05  2.8035267e-05  7.9334292e-05\n",
      "   1.8192777e-04 -3.2165346e-05 -1.5009602e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446957e-03 -9.8302175e-05  2.8315677e-05  1.1526416e-04\n",
      "   1.8325294e-04  3.7134268e-06 -1.4941812e-04]]\n",
      "linear.bias:\n",
      " [0.00022285]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453489e-03 -1.0027362e-04  2.8750323e-05  1.1768305e-04\n",
      "   1.8463087e-04 -1.3803128e-05 -1.4848764e-04]]\n",
      "linear.bias:\n",
      " [0.00022278]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459798e-03 -1.0219370e-04  2.8982724e-05  9.2265866e-05\n",
      "   1.8612255e-04 -6.3978012e-05 -1.4727570e-04]]\n",
      "linear.bias:\n",
      " [0.00022264]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462560e-03 -1.0200620e-04  2.9175822e-05  1.0826337e-04\n",
      "   1.8484215e-04 -3.2065054e-05 -1.4698123e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04583288e-03 -1.02362006e-04  2.92707700e-05  1.29540189e-04\n",
      "   1.83456621e-04  2.24989562e-05 -1.46631282e-04]]\n",
      "linear.bias:\n",
      " [0.00022271]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04480633e-03 -1.01962694e-04  2.93506328e-05  9.25792701e-05\n",
      "   1.81412761e-04 -4.64513651e-05 -1.47173472e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438053e-03 -9.9929224e-05  2.9324168e-05  8.4378989e-05\n",
      "   1.7837757e-04 -5.9010996e-05 -1.4826657e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426235e-03 -9.6589072e-05  2.9341580e-05  1.1981880e-04\n",
      "   1.7376807e-04  4.3725340e-06 -1.4981424e-04]]\n",
      "linear.bias:\n",
      " [0.00022352]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422294e-03 -9.5163887e-05  2.9590881e-05  1.2213561e-04\n",
      "   1.7150649e-04  1.1795701e-05 -1.5040796e-04]]\n",
      "linear.bias:\n",
      " [0.00022369]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419372e-03 -9.5301839e-05  3.0151799e-05  8.8088709e-05\n",
      "   1.7111842e-04 -5.1036041e-05 -1.5015116e-04]]\n",
      "linear.bias:\n",
      " [0.00022354]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414253e-03 -9.6261698e-05  3.0728846e-05  8.1422098e-05\n",
      "   1.7086131e-04 -6.8230627e-05 -1.4988059e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411204e-03 -9.7028555e-05  3.1248885e-05  1.2347184e-04\n",
      "   1.6973006e-04  3.1740710e-06 -1.5004883e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416566e-03 -9.9170335e-05  3.1968051e-05  1.2784920e-04\n",
      "   1.7050889e-04  1.5446712e-05 -1.4939366e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04223506e-03 -1.00858604e-04  3.28311507e-05  8.34876118e-05\n",
      "   1.71615044e-04 -7.02279722e-05 -1.48709500e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04274740e-03 -1.00851525e-04  3.34175529e-05  9.04321714e-05\n",
      "   1.71454696e-04 -5.62602181e-05 -1.48669948e-04]]\n",
      "linear.bias:\n",
      " [0.0002215]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428262e-03 -9.9211480e-05  3.3927841e-05  1.2605329e-04\n",
      "   1.7054575e-04  9.1117145e-06 -1.4894643e-04]]\n",
      "linear.bias:\n",
      " [0.00022111]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435120e-03 -9.8020188e-05  3.4391356e-05  1.1121032e-04\n",
      "   1.7047906e-04 -1.8420460e-06 -1.4882210e-04]]\n",
      "linear.bias:\n",
      " [0.00022091]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453149e-03 -9.8440993e-05  3.4923207e-05  7.9695732e-05\n",
      "   1.7243871e-04 -5.4093856e-05 -1.4752679e-04]]\n",
      "linear.bias:\n",
      " [0.00022051]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467327e-03 -9.7170174e-05  3.5311918e-05  8.7841610e-05\n",
      "   1.7337556e-04 -4.7552559e-05 -1.4657184e-04]]\n",
      "linear.bias:\n",
      " [0.00022022]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473246e-03 -9.6128810e-05  3.5521422e-05  1.2141821e-04\n",
      "   1.7400077e-04  2.6349189e-06 -1.4568771e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481465e-03 -9.6582524e-05  3.5891266e-05  1.1838473e-04\n",
      "   1.7527545e-04 -5.5929695e-06 -1.4460826e-04]]\n",
      "linear.bias:\n",
      " [0.00022017]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491543e-03 -9.8408505e-05  3.6224807e-05  8.5878128e-05\n",
      "   1.7748224e-04 -5.3357573e-05 -1.4318245e-04]]\n",
      "linear.bias:\n",
      " [0.00022029]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495810e-03 -9.8267490e-05  3.6383415e-05  9.0892885e-05\n",
      "   1.7791784e-04 -4.2515934e-05 -1.4246338e-04]]\n",
      "linear.bias:\n",
      " [0.00022055]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495859e-03 -9.8194527e-05  3.6303878e-05  1.1744166e-04\n",
      "   1.7765268e-04  7.9867095e-06 -1.4208895e-04]]\n",
      "linear.bias:\n",
      " [0.00022094]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494603e-03 -9.8567027e-05  3.6245921e-05  1.0045043e-04\n",
      "   1.7684375e-04 -2.5275567e-05 -1.4220535e-04]]\n",
      "linear.bias:\n",
      " [0.00022145]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500151e-03 -9.9839883e-05  3.5628269e-05  9.2020447e-05\n",
      "   1.7579169e-04 -3.9844290e-05 -1.4235979e-04]]\n",
      "linear.bias:\n",
      " [0.00022205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501348e-03 -1.0104024e-04  3.4849301e-05  1.0649051e-04\n",
      "   1.7418571e-04 -1.2221084e-05 -1.4277243e-04]]\n",
      "linear.bias:\n",
      " [0.00022275]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508680e-03 -1.0331728e-04  3.4172292e-05  1.0515374e-04\n",
      "   1.7354978e-04 -1.4975116e-05 -1.4245026e-04]]\n",
      "linear.bias:\n",
      " [0.00022338]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05206389e-03 -1.05976964e-04  3.34221841e-05  8.84322799e-05\n",
      "   1.73506720e-04 -4.28494241e-05 -1.41582292e-04]]\n",
      "linear.bias:\n",
      " [0.00022402]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05310220e-03 -1.06878324e-04  3.27778289e-05  9.95518203e-05\n",
      "   1.72728935e-04 -1.79804119e-05 -1.41216326e-04]]\n",
      "linear.bias:\n",
      " [0.0002246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0533131e-03 -1.0821177e-04  3.2156488e-05  1.1281601e-04\n",
      "   1.7203846e-04  1.0738599e-05 -1.4077703e-04]]\n",
      "linear.bias:\n",
      " [0.00022519]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0521184e-03 -1.0788160e-04  3.1503161e-05  8.3828250e-05\n",
      "   1.7137171e-04 -4.3267784e-05 -1.4064189e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505683e-03 -1.0601748e-04  3.0834486e-05  9.1577560e-05\n",
      "   1.6987718e-04 -3.7635469e-05 -1.4082840e-04]]\n",
      "linear.bias:\n",
      " [0.00022563]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04913372e-03 -1.02841565e-04  3.02635362e-05  1.24769722e-04\n",
      "   1.67790582e-04  1.73679437e-05 -1.41412966e-04]]\n",
      "linear.bias:\n",
      " [0.00022582]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04658387e-03 -9.95091177e-05  2.98160703e-05  1.01419515e-04\n",
      "   1.66582438e-04 -4.27586274e-05 -1.42209770e-04]]\n",
      "linear.bias:\n",
      " [0.00022561]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440936e-03 -9.7441705e-05  2.9659292e-05  9.4173178e-05\n",
      "   1.6612056e-04 -6.4781336e-05 -1.4272112e-04]]\n",
      "linear.bias:\n",
      " [0.00022519]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420594e-03 -9.4878676e-05  2.9642413e-05  1.1883221e-04\n",
      "   1.6564041e-04 -1.4968216e-05 -1.4335646e-04]]\n",
      "linear.bias:\n",
      " [0.00022488]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408636e-03 -9.3979412e-05  2.9612431e-05  1.1372477e-04\n",
      "   1.6703673e-04 -8.5711526e-06 -1.4302555e-04]]\n",
      "linear.bias:\n",
      " [0.00022446]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410335e-03 -9.4573188e-05  2.9700908e-05  8.7545573e-05\n",
      "   1.7035271e-04 -4.4674853e-05 -1.4163932e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409337e-03 -9.5957781e-05  2.9853738e-05  8.8204157e-05\n",
      "   1.7343277e-04 -3.8040504e-05 -1.4035101e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405906e-03 -9.8055018e-05  3.0064559e-05  1.1303830e-04\n",
      "   1.7630043e-04  7.0755923e-06 -1.3915084e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04042352e-03 -1.00023084e-04  3.04279747e-05  1.00849036e-04\n",
      "   1.78438713e-04 -2.53253638e-05 -1.38234449e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411313e-03 -1.0241677e-04  3.0214351e-05  9.9349738e-05\n",
      "   1.7989044e-04 -3.4597175e-05 -1.3762480e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04204565e-03 -1.02833874e-04  2.98794403e-05  1.18863980e-04\n",
      "   1.80124131e-04  3.27162707e-06 -1.37664916e-04]]\n",
      "linear.bias:\n",
      " [0.00022229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429549e-03 -1.0200358e-04  2.9204637e-05  9.4862611e-05\n",
      "   1.7890731e-04 -3.9400533e-05 -1.3855730e-04]]\n",
      "linear.bias:\n",
      " [0.00022236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436953e-03 -9.9543497e-05  2.8496315e-05  9.8676202e-05\n",
      "   1.7658941e-04 -2.8682833e-05 -1.3997967e-04]]\n",
      "linear.bias:\n",
      " [0.00022249]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04394718e-03 -9.81164631e-05  2.79456945e-05  1.19263765e-04\n",
      "   1.74312663e-04  1.50425840e-05 -1.41295750e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436104e-03 -9.7476448e-05  2.7790147e-05  9.3219249e-05\n",
      "   1.7216257e-04 -4.1079984e-05 -1.4283349e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430529e-03 -9.7754441e-05  2.7723610e-05  9.4083574e-05\n",
      "   1.7032081e-04 -5.2530428e-05 -1.4417808e-04]]\n",
      "linear.bias:\n",
      " [0.00022246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422963e-03 -9.8859622e-05  2.7737271e-05  1.1918740e-04\n",
      "   1.6875674e-04 -2.3758008e-05 -1.4534868e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424354e-03 -1.0117324e-04  2.7900101e-05  1.2606007e-04\n",
      "   1.6854568e-04 -1.8029932e-05 -1.4568162e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432941e-03 -1.0426944e-04  2.8062281e-05  1.0452783e-04\n",
      "   1.6991582e-04 -5.0090606e-05 -1.4522423e-04]]\n",
      "linear.bias:\n",
      " [0.00022237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435993e-03 -1.0745832e-04  2.8261235e-05  1.0209311e-04\n",
      "   1.7115258e-04 -4.1951796e-05 -1.4476560e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04340585e-03 -1.10730878e-04  2.84933340e-05  1.16863695e-04\n",
      "   1.72269269e-04  2.38578286e-06 -1.44305828e-04]]\n",
      "linear.bias:\n",
      " [0.00022196]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432749e-03 -1.1343761e-04  2.8751943e-05  1.0304657e-04\n",
      "   1.7418226e-04 -1.4705392e-06 -1.4332963e-04]]\n",
      "linear.bias:\n",
      " [0.00022167]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04270084e-03 -1.15243754e-04  2.93033263e-05  7.62938726e-05\n",
      "   1.76978239e-04 -4.07308798e-05 -1.41628174e-04]]\n",
      "linear.bias:\n",
      " [0.00022141]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417561e-03 -1.1386209e-04  2.9634055e-05  9.5416588e-05\n",
      "   1.7723111e-04 -1.7518438e-05 -1.4082657e-04]]\n",
      "linear.bias:\n",
      " [0.0002214]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410635e-03 -1.0974151e-04  2.9897396e-05  1.2664766e-04\n",
      "   1.7661451e-04  1.5106869e-05 -1.4053355e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403891e-03 -1.0375129e-04  2.9735909e-05  9.6795433e-05\n",
      "   1.7496338e-04 -5.3142139e-05 -1.4133309e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397027e-03 -9.6630625e-05  2.9489020e-05  9.5476906e-05\n",
      "   1.7224440e-04 -6.5461973e-05 -1.4267692e-04]]\n",
      "linear.bias:\n",
      " [0.00022198]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0393859e-03 -8.8730143e-05  2.9302410e-05  1.2663180e-04\n",
      "   1.6880894e-04 -5.1938841e-06 -1.4445125e-04]]\n",
      "linear.bias:\n",
      " [0.00022223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03963667e-03 -8.32950682e-05  2.92527839e-05  1.21969555e-04\n",
      "   1.67469028e-04  5.23549170e-06 -1.45343933e-04]]\n",
      "linear.bias:\n",
      " [0.00022245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400651e-03 -8.0445359e-05  2.9572755e-05  8.6927976e-05\n",
      "   1.6834770e-04 -4.2712880e-05 -1.4524718e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415082e-03 -8.0262733e-05  2.9614372e-05  7.8791396e-05\n",
      "   1.6919248e-04 -4.9572933e-05 -1.4509608e-04]]\n",
      "linear.bias:\n",
      " [0.00022239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427278e-03 -8.1862454e-05  2.9638259e-05  1.0175753e-04\n",
      "   1.6985048e-04 -1.4705824e-05 -1.4494805e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445659e-03 -8.6325184e-05  2.9780491e-05  1.2100186e-04\n",
      "   1.7166449e-04  5.7593752e-08 -1.4401384e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465081e-03 -9.1959504e-05  3.0144445e-05  1.0783531e-04\n",
      "   1.7445363e-04 -3.5811587e-05 -1.4268511e-04]]\n",
      "linear.bias:\n",
      " [0.00022118]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486529e-03 -9.8865952e-05  3.0286657e-05  9.5619384e-05\n",
      "   1.7720541e-04 -4.8662936e-05 -1.4130835e-04]]\n",
      "linear.bias:\n",
      " [0.00022112]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505050e-03 -1.0334999e-04  3.0312724e-05  1.1027764e-04\n",
      "   1.7844490e-04 -1.1081589e-05 -1.4069563e-04]]\n",
      "linear.bias:\n",
      " [0.00022115]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05125189e-03 -1.07152606e-04  3.04799378e-05  1.03663115e-04\n",
      "   1.80048301e-04 -8.28084922e-07 -1.39790616e-04]]\n",
      "linear.bias:\n",
      " [0.00022132]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510248e-03 -1.1008256e-04  3.0886298e-05  7.7841141e-05\n",
      "   1.8190253e-04 -2.8266502e-05 -1.3841354e-04]]\n",
      "linear.bias:\n",
      " [0.00022133]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05029286e-03 -1.10571294e-04  3.11042531e-05  9.79424367e-05\n",
      "   1.80787261e-04  5.77780520e-06 -1.38176751e-04]]\n",
      "linear.bias:\n",
      " [0.00022149]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04889669e-03 -1.09754590e-04  3.14729259e-05  1.04569976e-04\n",
      "   1.78994829e-04 -1.56698643e-05 -1.37751282e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04731717e-03 -1.08701046e-04  3.19214814e-05  1.00106743e-04\n",
      "   1.77618422e-04 -4.46945414e-05 -1.37111696e-04]]\n",
      "linear.bias:\n",
      " [0.00022178]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04623742e-03 -1.05813044e-04  3.21653642e-05  1.12352034e-04\n",
      "   1.75313544e-04 -2.46068957e-05 -1.37291587e-04]]\n",
      "linear.bias:\n",
      " [0.00022221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04449445e-03 -1.03753206e-04  3.23751738e-05  1.16923322e-04\n",
      "   1.73426160e-04 -2.63225593e-06 -1.37410752e-04]]\n",
      "linear.bias:\n",
      " [0.00022299]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431228e-03 -1.0223207e-04  3.2185777e-05  8.5009626e-05\n",
      "   1.7154457e-04 -2.3214770e-05 -1.3772157e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416023e-03 -1.0143738e-04  3.2091026e-05  8.1124825e-05\n",
      "   1.6958288e-04 -1.8336035e-05 -1.3808419e-04]]\n",
      "linear.bias:\n",
      " [0.00022469]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03998766e-03 -1.01505793e-04  3.22161759e-05  1.03410224e-04\n",
      "   1.68034312e-04  1.01713013e-05 -1.38290416e-04]]\n",
      "linear.bias:\n",
      " [0.00022522]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "Epoch [2000/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0398666e-03 -1.0212275e-04  3.2296452e-05  1.0646179e-04\n",
      "   1.6767882e-04 -1.2420038e-05 -1.3762181e-04]]\n",
      "linear.bias:\n",
      " [0.00022538]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406072e-03 -1.0375301e-04  3.2517477e-05  9.3758092e-05\n",
      "   1.6840559e-04 -6.5396918e-05 -1.3629539e-04]]\n",
      "linear.bias:\n",
      " [0.00022553]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04158255e-03 -1.03752216e-04  3.27669222e-05  1.15991228e-04\n",
      "   1.68025683e-04 -4.00353965e-05 -1.35857190e-04]]\n",
      "linear.bias:\n",
      " [0.00022559]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437749e-03 -1.0404324e-04  3.2436757e-05  1.3380210e-04\n",
      "   1.6784010e-04  7.8825469e-06 -1.3560971e-04]]\n",
      "linear.bias:\n",
      " [0.00022587]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04546698e-03 -1.02381055e-04  3.14020654e-05  8.52487574e-05\n",
      "   1.67968537e-04 -4.97784276e-05 -1.36203656e-04]]\n",
      "linear.bias:\n",
      " [0.00022605]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470676e-03 -9.9481746e-05  3.0533563e-05  7.0927483e-05\n",
      "   1.6703222e-04 -4.6921181e-05 -1.3752174e-04]]\n",
      "linear.bias:\n",
      " [0.00022597]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482363e-03 -9.5618620e-05  2.9799461e-05  1.1025730e-04\n",
      "   1.6503216e-04  1.5571793e-05 -1.3920380e-04]]\n",
      "linear.bias:\n",
      " [0.00022559]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487287e-03 -9.3789087e-05  2.9598203e-05  1.1486829e-04\n",
      "   1.6467003e-04 -1.0520935e-05 -1.4033641e-04]]\n",
      "linear.bias:\n",
      " [0.00022493]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496136e-03 -9.3731818e-05  2.9655614e-05  9.4402276e-05\n",
      "   1.6610368e-04 -7.7074190e-05 -1.4044500e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05019775e-03 -9.16599165e-05  2.97623465e-05  1.13277594e-04\n",
      "   1.67207472e-04 -3.45061817e-05 -1.41130411e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0513498e-03 -9.1805225e-05  2.9835115e-05  1.2654782e-04\n",
      "   1.6928483e-04  2.1272735e-05 -1.4131631e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507428e-03 -9.1938542e-05  3.0043653e-05  8.2171871e-05\n",
      "   1.7110337e-04 -3.7463509e-05 -1.4222112e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498448e-03 -9.3020521e-05  3.0242285e-05  7.1311624e-05\n",
      "   1.7271163e-04 -4.9922310e-05 -1.4298747e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493089e-03 -9.4203868e-05  3.0576150e-05  1.1257437e-04\n",
      "   1.7228311e-04 -1.3671015e-06 -1.4444924e-04]]\n",
      "linear.bias:\n",
      " [0.00022105]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492288e-03 -9.6654847e-05  3.0980482e-05  1.2414658e-04\n",
      "   1.7317345e-04 -1.2693519e-06 -1.4505592e-04]]\n",
      "linear.bias:\n",
      " [0.00022021]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493003e-03 -1.0036260e-04  3.1408832e-05  9.7781798e-05\n",
      "   1.7451955e-04 -4.8907979e-05 -1.4542881e-04]]\n",
      "linear.bias:\n",
      " [0.00021969]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04900962e-03 -1.03968494e-04  3.16986698e-05  9.76106894e-05\n",
      "   1.75536465e-04 -5.05576863e-05 -1.45844271e-04]]\n",
      "linear.bias:\n",
      " [0.0002193]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487078e-03 -1.0566278e-04  3.1992044e-05  1.2429137e-04\n",
      "   1.7568393e-04 -2.3648536e-06 -1.4665052e-04]]\n",
      "linear.bias:\n",
      " [0.00021895]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480373e-03 -1.0673162e-04  3.2084594e-05  1.0727100e-04\n",
      "   1.7587701e-04 -7.4169748e-06 -1.4737131e-04]]\n",
      "linear.bias:\n",
      " [0.00021903]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479563e-03 -1.0788441e-04  3.2218974e-05  7.9475562e-05\n",
      "   1.7724164e-04 -4.4939698e-05 -1.4712273e-04]]\n",
      "linear.bias:\n",
      " [0.0002191]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476982e-03 -1.0716649e-04  3.2316970e-05  9.3623516e-05\n",
      "   1.7740110e-04 -2.5062716e-05 -1.4718530e-04]]\n",
      "linear.bias:\n",
      " [0.00021933]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470799e-03 -1.0683817e-04  3.2132251e-05  1.1753966e-04\n",
      "   1.7716031e-04  1.1972006e-05 -1.4730918e-04]]\n",
      "linear.bias:\n",
      " [0.00021969]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461550e-03 -1.0586982e-04  3.2051477e-05  9.9895449e-05\n",
      "   1.7674392e-04 -3.1875312e-05 -1.4752573e-04]]\n",
      "linear.bias:\n",
      " [0.00022017]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452810e-03 -1.0510246e-04  3.1747008e-05  9.7005475e-05\n",
      "   1.7591004e-04 -3.9411618e-05 -1.4785575e-04]]\n",
      "linear.bias:\n",
      " [0.00022085]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445049e-03 -1.0465059e-04  3.1332991e-05  1.1339944e-04\n",
      "   1.7511523e-04 -7.8783523e-06 -1.4820303e-04]]\n",
      "linear.bias:\n",
      " [0.00022145]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04474684e-03 -1.05214953e-04  3.10838477e-05  1.07959626e-04\n",
      "   1.75403053e-04 -1.79514864e-05 -1.47775572e-04]]\n",
      "linear.bias:\n",
      " [0.00022192]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457222e-03 -1.0698495e-04  3.0878535e-05  8.9438945e-05\n",
      "   1.7639081e-04 -4.8332833e-05 -1.4673834e-04]]\n",
      "linear.bias:\n",
      " [0.00022242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04656012e-03 -1.07017004e-04  3.07262017e-05  9.97106035e-05\n",
      "   1.76507572e-04 -2.59359240e-05 -1.46238905e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04643300e-03 -1.07539236e-04  3.05097310e-05  1.18445649e-04\n",
      "   1.76273796e-04  1.19792912e-05 -1.45758502e-04]]\n",
      "linear.bias:\n",
      " [0.00022336]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457905e-03 -1.0774399e-04  3.0488653e-05  8.7297667e-05\n",
      "   1.7555358e-04 -4.2967557e-05 -1.4577973e-04]]\n",
      "linear.bias:\n",
      " [0.00022364]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04517152e-03 -1.06363805e-04  3.05022841e-05  8.62273082e-05\n",
      "   1.74130953e-04 -4.27166633e-05 -1.46234219e-04]]\n",
      "linear.bias:\n",
      " [0.00022389]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445736e-03 -1.0355546e-04  3.0547191e-05  1.1224888e-04\n",
      "   1.7207535e-04  7.2128678e-06 -1.4707910e-04]]\n",
      "linear.bias:\n",
      " [0.00022411]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448294e-03 -1.0188198e-04  3.0571151e-05  1.1482707e-04\n",
      "   1.7150413e-04  1.0404149e-05 -1.4690950e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455273e-03 -1.0105865e-04  3.0641353e-05  8.3711449e-05\n",
      "   1.7194739e-04 -5.4051943e-05 -1.4633550e-04]]\n",
      "linear.bias:\n",
      " [0.00022373]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457503e-03 -9.9315672e-05  3.0766434e-05  9.2053415e-05\n",
      "   1.7175135e-04 -5.9040176e-05 -1.4604443e-04]]\n",
      "linear.bias:\n",
      " [0.00022333]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459074e-03 -9.6200172e-05  3.0884570e-05  1.2686923e-04\n",
      "   1.7084500e-04 -1.2559693e-05 -1.4624400e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463725e-03 -9.5104406e-05  3.1128995e-05  1.2828816e-04\n",
      "   1.7164287e-04 -1.0209007e-05 -1.4573711e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469191e-03 -9.5941694e-05  3.1307478e-05  9.1997637e-05\n",
      "   1.7344461e-04 -5.0977862e-05 -1.4485531e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471469e-03 -9.7584772e-05  3.1544736e-05  8.4273932e-05\n",
      "   1.7516541e-04 -4.8646143e-05 -1.4401940e-04]]\n",
      "linear.bias:\n",
      " [0.00022228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469485e-03 -9.8036748e-05  3.1847703e-05  1.1345684e-04\n",
      "   1.7607149e-04  5.2124233e-06 -1.4346800e-04]]\n",
      "linear.bias:\n",
      " [0.0002221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470657e-03 -1.0010945e-04  3.2363729e-05  1.0863920e-04\n",
      "   1.7807890e-04  4.6285445e-06 -1.4246885e-04]]\n",
      "linear.bias:\n",
      " [0.00022203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475919e-03 -1.0302741e-04  3.2943819e-05  8.4047584e-05\n",
      "   1.8084650e-04 -3.6843096e-05 -1.4077655e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480415e-03 -1.0400723e-04  3.3412347e-05  9.5389849e-05\n",
      "   1.8142337e-04 -2.1227348e-05 -1.4010443e-04]]\n",
      "linear.bias:\n",
      " [0.00022144]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04824803e-03 -1.04871069e-04  3.35894510e-05  1.19511984e-04\n",
      "   1.81399548e-04  1.65072743e-05 -1.39740863e-04]]\n",
      "linear.bias:\n",
      " [0.00022127]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479927e-03 -1.0435524e-04  3.3374599e-05  8.7188819e-05\n",
      "   1.7986460e-04 -4.5978810e-05 -1.4063556e-04]]\n",
      "linear.bias:\n",
      " [0.00022127]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04783115e-03 -1.02152335e-04  3.31929696e-05  8.71626326e-05\n",
      "   1.76692236e-04 -5.07536861e-05 -1.42301928e-04]]\n",
      "linear.bias:\n",
      " [0.00022136]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472366e-03 -9.8213161e-05  3.2872133e-05  1.1680205e-04\n",
      "   1.7252192e-04 -3.2205171e-06 -1.4434381e-04]]\n",
      "linear.bias:\n",
      " [0.0002216]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471465e-03 -9.6123069e-05  3.2710945e-05  1.1512293e-04\n",
      "   1.7009400e-04 -6.0030052e-06 -1.4557585e-04]]\n",
      "linear.bias:\n",
      " [0.00022182]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475171e-03 -9.5868207e-05  3.2810000e-05  8.8642977e-05\n",
      "   1.6970839e-04 -5.1432617e-05 -1.4575274e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475845e-03 -9.6533418e-05  3.2976215e-05  8.9849200e-05\n",
      "   1.6946005e-04 -5.3320800e-05 -1.4586994e-04]]\n",
      "linear.bias:\n",
      " [0.00022188]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473786e-03 -9.8027689e-05  3.3202956e-05  1.1599448e-04\n",
      "   1.6933537e-04 -1.6004131e-05 -1.4593336e-04]]\n",
      "linear.bias:\n",
      " [0.0002219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475458e-03 -1.0058052e-04  3.3534023e-05  1.1413449e-04\n",
      "   1.7050067e-04 -1.6772570e-05 -1.4522459e-04]]\n",
      "linear.bias:\n",
      " [0.00022177]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484100e-03 -1.0403520e-04  3.3857745e-05  9.4118703e-05\n",
      "   1.7242531e-04 -4.4510034e-05 -1.4396528e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488256e-03 -1.0741893e-04  3.4051300e-05  1.0000104e-04\n",
      "   1.7395901e-04 -2.8194478e-05 -1.4291264e-04]]\n",
      "linear.bias:\n",
      " [0.00022177]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491612e-03 -1.1042562e-04  3.3951896e-05  1.1913579e-04\n",
      "   1.7488458e-04  1.9303749e-05 -1.4221043e-04]]\n",
      "linear.bias:\n",
      " [0.00022205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04798342e-03 -1.11046385e-04  3.35923396e-05  7.61742704e-05\n",
      "   1.75308232e-04 -4.70122759e-05 -1.42476085e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465371e-03 -1.0882114e-04  3.3191023e-05  8.1557191e-05\n",
      "   1.7408318e-04 -4.8418326e-05 -1.4319245e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04473124e-03 -1.05153485e-04  3.27443122e-05  1.21569756e-04\n",
      "   1.72030530e-04  4.22188168e-06 -1.44164849e-04]]\n",
      "linear.bias:\n",
      " [0.00022311]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04348129e-03 -1.02327904e-04  3.23997701e-05  1.14647388e-04\n",
      "   1.70661413e-04 -1.50938849e-05 -1.44711885e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04353472e-03 -1.00629644e-04  3.19542050e-05  8.46837866e-05\n",
      "   1.70578249e-04 -6.62794555e-05 -1.44430873e-04]]\n",
      "linear.bias:\n",
      " [0.0002233]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434118e-03 -9.7424112e-05  3.1474581e-05  1.0223320e-04\n",
      "   1.6894886e-04 -3.4384466e-05 -1.4474322e-04]]\n",
      "linear.bias:\n",
      " [0.00022327]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439958e-03 -9.6610725e-05  3.0962372e-05  1.2710661e-04\n",
      "   1.6833587e-04  1.8478622e-05 -1.4456850e-04]]\n",
      "linear.bias:\n",
      " [0.00022299]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439415e-03 -9.5490228e-05  3.0778421e-05  9.3852308e-05\n",
      "   1.6810441e-04 -4.3697732e-05 -1.4470382e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440001e-03 -9.5353411e-05  3.0645930e-05  8.4351748e-05\n",
      "   1.6815141e-04 -6.3725260e-05 -1.4475262e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438104e-03 -9.4409173e-05  3.0539930e-05  1.1617237e-04\n",
      "   1.6796144e-04 -8.3224040e-06 -1.4486723e-04]]\n",
      "linear.bias:\n",
      " [0.00022181]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440956e-03 -9.5202100e-05  3.0691077e-05  1.1972613e-04\n",
      "   1.6960877e-04 -1.2175451e-06 -1.4402872e-04]]\n",
      "linear.bias:\n",
      " [0.00022135]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446528e-03 -9.7606855e-05  3.1074043e-05  9.1574802e-05\n",
      "   1.7230159e-04 -4.3659089e-05 -1.4276346e-04]]\n",
      "linear.bias:\n",
      " [0.00022102]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448855e-03 -1.0067636e-04  3.1496722e-05  9.1414302e-05\n",
      "   1.7482643e-04 -4.3001437e-05 -1.4158153e-04]]\n",
      "linear.bias:\n",
      " [0.00022073]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04501192e-03 -1.01624406e-04  3.17706035e-05  1.17644704e-04\n",
      "   1.75803914e-04  6.40528015e-06 -1.41173470e-04]]\n",
      "linear.bias:\n",
      " [0.00022054]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448979e-03 -1.0328803e-04  3.2058808e-05  9.8115255e-05\n",
      "   1.7633686e-04 -1.8976656e-05 -1.4116112e-04]]\n",
      "linear.bias:\n",
      " [0.00022062]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443483e-03 -1.0516254e-04  3.2029515e-05  8.8482739e-05\n",
      "   1.7642930e-04 -3.2025979e-05 -1.4122529e-04]]\n",
      "linear.bias:\n",
      " [0.00022102]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04377023e-03 -1.05031337e-04  3.18962047e-05  1.06214284e-04\n",
      "   1.75214125e-04  5.04572745e-06 -1.41940473e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441660e-03 -1.0602672e-04  3.1903626e-05  1.0506917e-04\n",
      "   1.7513594e-04 -3.4917321e-07 -1.4170696e-04]]\n",
      "linear.bias:\n",
      " [0.00022169]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454395e-03 -1.0803724e-04  3.2037853e-05  8.6917840e-05\n",
      "   1.7608222e-04 -4.3981596e-05 -1.4061863e-04]]\n",
      "linear.bias:\n",
      " [0.00022174]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465345e-03 -1.0799763e-04  3.2125427e-05  9.8569770e-05\n",
      "   1.7542562e-04 -3.4104552e-05 -1.4036389e-04]]\n",
      "linear.bias:\n",
      " [0.00022194]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478158e-03 -1.0610865e-04  3.2052325e-05  1.3078384e-04\n",
      "   1.7368978e-04  2.0701558e-05 -1.4076255e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475761e-03 -1.0351432e-04  3.1668733e-05  9.2239279e-05\n",
      "   1.7194875e-04 -4.7976868e-05 -1.4228164e-04]]\n",
      "linear.bias:\n",
      " [0.00022237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473187e-03 -9.9570789e-05  3.1356809e-05  8.4934094e-05\n",
      "   1.6958572e-04 -6.0386388e-05 -1.4409686e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468160e-03 -9.4287512e-05  3.0948366e-05  1.1844124e-04\n",
      "   1.6656095e-04  1.3179379e-06 -1.4606171e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04724499e-03 -9.10366653e-05  3.07167393e-05  1.20226134e-04\n",
      "   1.66031256e-04  1.14309760e-05 -1.46854654e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478456e-03 -9.0271264e-05  3.0893763e-05  8.9915935e-05\n",
      "   1.6775928e-04 -3.6344903e-05 -1.4661635e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476055e-03 -9.0672533e-05  3.1332402e-05  8.6172680e-05\n",
      "   1.6946459e-04 -4.1981875e-05 -1.4625740e-04]]\n",
      "linear.bias:\n",
      " [0.00022273]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471180e-03 -9.1945658e-05  3.1805888e-05  1.0811831e-04\n",
      "   1.7110104e-04 -8.2783263e-06 -1.4589126e-04]]\n",
      "linear.bias:\n",
      " [0.00022259]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475614e-03 -9.4553980e-05  3.2529872e-05  1.1638302e-04\n",
      "   1.7416649e-04 -9.9671761e-06 -1.4447131e-04]]\n",
      "linear.bias:\n",
      " [0.0002223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482778e-03 -9.7913995e-05  3.3169767e-05  9.7200231e-05\n",
      "   1.7771921e-04 -4.6337474e-05 -1.4262539e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04851148e-03 -1.00998339e-04  3.35047807e-05  1.03128266e-04\n",
      "   1.80205330e-04 -3.87334621e-05 -1.41259356e-04]]\n",
      "linear.bias:\n",
      " [0.00022181]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487047e-03 -1.0374262e-04  3.3504712e-05  1.2535088e-04\n",
      "   1.8190255e-04  5.0403250e-06 -1.4034101e-04]]\n",
      "linear.bias:\n",
      " [0.00022184]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04842032e-03 -1.04471794e-04  3.29769864e-05  9.13740951e-05\n",
      "   1.81455238e-04 -3.26769587e-05 -1.40726523e-04]]\n",
      "linear.bias:\n",
      " [0.00022204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481121e-03 -1.0326347e-04  3.2468197e-05  8.8900873e-05\n",
      "   1.7953159e-04 -1.7595012e-05 -1.4180481e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04746968e-03 -1.02892824e-04  3.20970939e-05  1.10446665e-04\n",
      "   1.77511451e-04  1.04211613e-05 -1.42822406e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468650e-03 -1.0256446e-04  3.1944794e-05  9.3694631e-05\n",
      "   1.7514061e-04 -3.6187699e-05 -1.4387410e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04594999e-03 -1.02547478e-04  3.17075283e-05  1.02808706e-04\n",
      "   1.72801781e-04 -3.71310161e-05 -1.44904348e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446247e-03 -1.0296124e-04  3.1550528e-05  1.2870260e-04\n",
      "   1.7069878e-04 -1.2769888e-06 -1.4578205e-04]]\n",
      "linear.bias:\n",
      " [0.00022329]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441148e-03 -1.0428895e-04  3.1505198e-05  1.1069680e-04\n",
      "   1.6959870e-04 -2.6246480e-05 -1.4614200e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443026e-03 -1.0684346e-04  3.1550444e-05  8.4078361e-05\n",
      "   1.6998916e-04 -4.9858587e-05 -1.4578637e-04]]\n",
      "linear.bias:\n",
      " [0.00022355]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439571e-03 -1.0744350e-04  3.1503994e-05  9.5741663e-05\n",
      "   1.6937044e-04 -1.7411709e-05 -1.4580062e-04]]\n",
      "linear.bias:\n",
      " [0.00022374]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04330620e-03 -1.08648244e-04  3.19682877e-05  1.09364133e-04\n",
      "   1.70174986e-04  2.24944051e-06 -1.44953214e-04]]\n",
      "linear.bias:\n",
      " [0.00022383]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440397e-03 -1.1066490e-04  3.2379430e-05  1.0368638e-04\n",
      "   1.7226748e-04 -1.9601672e-05 -1.4315260e-04]]\n",
      "linear.bias:\n",
      " [0.00022366]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440069e-03 -1.1120619e-04  3.2769552e-05  9.0901129e-05\n",
      "   1.7454322e-04 -4.9444599e-05 -1.4108546e-04]]\n",
      "linear.bias:\n",
      " [0.00022384]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04389270e-03 -1.09845096e-04  3.30122093e-05  1.06072417e-04\n",
      "   1.75273221e-04 -2.74843787e-05 -1.39891970e-04]]\n",
      "linear.bias:\n",
      " [0.00022409]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438438e-03 -1.0836266e-04  3.2992557e-05  1.2444878e-04\n",
      "   1.7576906e-04  1.3174193e-05 -1.3918584e-04]]\n",
      "linear.bias:\n",
      " [0.00022447]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436273e-03 -1.0495513e-04  3.2443233e-05  8.2629434e-05\n",
      "   1.7487750e-04 -4.4327040e-05 -1.3975693e-04]]\n",
      "linear.bias:\n",
      " [0.0002249]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04339758e-03 -1.00425554e-04  3.19786850e-05  8.29616256e-05\n",
      "   1.72414657e-04 -3.91183166e-05 -1.41157725e-04]]\n",
      "linear.bias:\n",
      " [0.00022496]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04315148e-03 -9.54480929e-05  3.17065860e-05  1.16655865e-04\n",
      "   1.69564068e-04  1.42104400e-05 -1.42738325e-04]]\n",
      "linear.bias:\n",
      " [0.00022484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04281539e-03 -9.19920058e-05  3.16289406e-05  1.10733796e-04\n",
      "   1.68211496e-04 -1.82833428e-05 -1.43783298e-04]]\n",
      "linear.bias:\n",
      " [0.00022441]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432909e-03 -9.0292786e-05  3.1728468e-05  8.7686924e-05\n",
      "   1.6841151e-04 -7.3735355e-05 -1.4386834e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438837e-03 -8.8799970e-05  3.1827854e-05  1.1616348e-04\n",
      "   1.6801413e-04 -3.3351731e-05 -1.4459399e-04]]\n",
      "linear.bias:\n",
      " [0.00022349]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450793e-03 -8.9581714e-05  3.1892672e-05  1.3795255e-04\n",
      "   1.6880158e-04  2.0326333e-05 -1.4479144e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449089e-03 -9.0303387e-05  3.1795167e-05  8.3108927e-05\n",
      "   1.6986665e-04 -5.1596173e-05 -1.4571309e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442859e-03 -9.2703725e-05  3.1610612e-05  6.9193906e-05\n",
      "   1.7072905e-04 -7.1616239e-05 -1.4644566e-04]]\n",
      "linear.bias:\n",
      " [0.00022266]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444032e-03 -9.5163457e-05  3.1233678e-05  1.4160319e-04\n",
      "   1.6940561e-04  2.5734305e-05 -1.4794480e-04]]\n",
      "linear.bias:\n",
      " [0.00022177]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429196e-03 -9.7001772e-05  3.0679075e-05  1.2974876e-04\n",
      "   1.6917445e-04 -2.0377513e-05 -1.4998099e-04]]\n",
      "linear.bias:\n",
      " [0.00022122]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423071e-03 -1.0036090e-04  3.0021549e-05  8.3799823e-05\n",
      "   1.7109132e-04 -1.0087440e-04 -1.5089937e-04]]\n",
      "linear.bias:\n",
      " [0.00022072]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418931e-03 -1.0127057e-04  2.9331457e-05  1.0296685e-04\n",
      "   1.7131525e-04 -5.1417472e-05 -1.5233738e-04]]\n",
      "linear.bias:\n",
      " [0.00021994]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410498e-03 -1.0353673e-04  2.8934835e-05  1.3618164e-04\n",
      "   1.7219887e-04  2.8456878e-05 -1.5325240e-04]]\n",
      "linear.bias:\n",
      " [0.00021924]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0395062e-03 -1.0521821e-04  2.8751729e-05  9.4539530e-05\n",
      "   1.7369993e-04 -3.8364797e-05 -1.5406607e-04]]\n",
      "linear.bias:\n",
      " [0.00021877]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03822700e-03 -1.07631386e-04  2.86210161e-05  7.77712266e-05\n",
      "   1.75314912e-04 -6.31782241e-05 -1.54723486e-04]]\n",
      "linear.bias:\n",
      " [0.00021827]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374265e-03 -1.0731815e-04  2.8476059e-05  1.1783305e-04\n",
      "   1.7573180e-04 -7.4332856e-06 -1.5532038e-04]]\n",
      "linear.bias:\n",
      " [0.00021799]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03813561e-03 -1.08083594e-04  2.84821981e-05  1.33428330e-04\n",
      "   1.78026603e-04  4.98880308e-06 -1.54710666e-04]]\n",
      "linear.bias:\n",
      " [0.00021748]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03908428e-03 -1.07588225e-04  2.83663467e-05  9.34622003e-05\n",
      "   1.80852934e-04 -5.58528482e-05 -1.53755085e-04]]\n",
      "linear.bias:\n",
      " [0.00021727]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0395456e-03 -1.0529741e-04  2.8318027e-05  9.0260743e-05\n",
      "   1.8233446e-04 -5.8885478e-05 -1.5331013e-04]]\n",
      "linear.bias:\n",
      " [0.00021725]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396439e-03 -1.0141706e-04  2.8339764e-05  1.2372050e-04\n",
      "   1.8239648e-04  4.7168687e-06 -1.5329970e-04]]\n",
      "linear.bias:\n",
      " [0.00021749]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04015647e-03 -9.85771403e-05  2.87217263e-05  1.09404195e-04\n",
      "   1.82938922e-04  1.98834618e-06 -1.53009139e-04]]\n",
      "linear.bias:\n",
      " [0.00021787]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415616e-03 -9.7166121e-05  2.9196917e-05  7.9197416e-05\n",
      "   1.8447345e-04 -3.8519407e-05 -1.5184405e-04]]\n",
      "linear.bias:\n",
      " [0.00021805]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423951e-03 -9.6616597e-05  2.9646375e-05  9.0242036e-05\n",
      "   1.8564035e-04 -3.2951662e-05 -1.5059553e-04]]\n",
      "linear.bias:\n",
      " [0.00021837]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428571e-03 -9.6803313e-05  3.0062831e-05  1.2635533e-04\n",
      "   1.8605849e-04  9.8612909e-06 -1.4971429e-04]]\n",
      "linear.bias:\n",
      " [0.00021884]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432844e-03 -9.7306634e-05  3.0471670e-05  1.1135685e-04\n",
      "   1.8569478e-04 -3.0635714e-05 -1.4941875e-04]]\n",
      "linear.bias:\n",
      " [0.00021934]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439982e-03 -9.9093530e-05  3.0456191e-05  9.6264135e-05\n",
      "   1.8531580e-04 -4.5954130e-05 -1.4908635e-04]]\n",
      "linear.bias:\n",
      " [0.00022021]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04458758e-03 -9.87947569e-05  3.04079113e-05  1.11025394e-04\n",
      "   1.83418684e-04 -1.15102193e-05 -1.49535001e-04]]\n",
      "linear.bias:\n",
      " [0.00022116]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04589644e-03 -9.97273019e-05  3.03628021e-05  1.04294988e-04\n",
      "   1.82547999e-04 -1.32691075e-05 -1.49162996e-04]]\n",
      "linear.bias:\n",
      " [0.00022194]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04804349e-03 -1.01745245e-04  3.04554287e-05  8.84648180e-05\n",
      "   1.82715841e-04 -4.60357769e-05 -1.47954808e-04]]\n",
      "linear.bias:\n",
      " [0.00022247]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495383e-03 -1.0148116e-04  3.0449995e-05  1.0616089e-04\n",
      "   1.8127319e-04 -2.4462608e-05 -1.4750402e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499071e-03 -1.0190807e-04  3.0376385e-05  1.2610988e-04\n",
      "   1.7962496e-04  1.9212530e-06 -1.4700602e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496868e-03 -1.0249121e-04  3.0515044e-05  9.5617390e-05\n",
      "   1.7801714e-04 -4.4472377e-05 -1.4661574e-04]]\n",
      "linear.bias:\n",
      " [0.00022501]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489203e-03 -1.0154080e-04  3.0881460e-05  9.4183823e-05\n",
      "   1.7579782e-04 -3.8967322e-05 -1.4662171e-04]]\n",
      "linear.bias:\n",
      " [0.00022566]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474249e-03 -1.0180949e-04  3.1499367e-05  1.1676489e-04\n",
      "   1.7395314e-04  2.8091563e-06 -1.4647821e-04]]\n",
      "linear.bias:\n",
      " [0.00022615]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463960e-03 -1.0281783e-04  3.2193519e-05  1.1139794e-04\n",
      "   1.7310136e-04 -3.2465641e-07 -1.4566556e-04]]\n",
      "linear.bias:\n",
      " [0.00022635]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04631274e-03 -1.04634186e-04  3.28011120e-05  8.50641954e-05\n",
      "   1.73693305e-04 -4.40223484e-05 -1.43945814e-04]]\n",
      "linear.bias:\n",
      " [0.00022618]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460973e-03 -1.0469824e-04  3.3313569e-05  9.3756607e-05\n",
      "   1.7326744e-04 -3.3293702e-05 -1.4285246e-04]]\n",
      "linear.bias:\n",
      " [0.00022595]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459151e-03 -1.0501132e-04  3.3625707e-05  1.2125183e-04\n",
      "   1.7283708e-04  1.3892681e-05 -1.4192137e-04]]\n",
      "linear.bias:\n",
      " [0.00022574]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445309e-03 -1.0449909e-04  3.3764303e-05  9.2084956e-05\n",
      "   1.7285264e-04 -4.1453863e-05 -1.4134579e-04]]\n",
      "linear.bias:\n",
      " [0.00022495]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04324135e-03 -1.02370934e-04  3.39238577e-05  9.36935758e-05\n",
      "   1.72041953e-04 -4.26628576e-05 -1.41291341e-04]]\n",
      "linear.bias:\n",
      " [0.00022425]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424304e-03 -9.8755569e-05  3.4055782e-05  1.1820920e-04\n",
      "   1.7064966e-04  1.9843246e-06 -1.4167439e-04]]\n",
      "linear.bias:\n",
      " [0.00022353]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04257092e-03 -9.68360619e-05  3.41696250e-05  1.10440626e-04\n",
      "   1.71144318e-04 -3.22909500e-06 -1.41227210e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437043e-03 -9.6147072e-05  3.4404526e-05  8.2506507e-05\n",
      "   1.7266389e-04 -4.5538258e-05 -1.4003225e-04]]\n",
      "linear.bias:\n",
      " [0.00022204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446847e-03 -9.4606432e-05  3.4765817e-05  9.1055146e-05\n",
      "   1.7338424e-04 -3.5786521e-05 -1.3928305e-04]]\n",
      "linear.bias:\n",
      " [0.0002212]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452424e-03 -9.3937735e-05  3.5026118e-05  1.2354308e-04\n",
      "   1.7360944e-04  1.0506854e-05 -1.3878479e-04]]\n",
      "linear.bias:\n",
      " [0.00022053]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450406e-03 -9.3365728e-05  3.5302230e-05  9.9011551e-05\n",
      "   1.7314832e-04 -3.8270897e-05 -1.3932746e-04]]\n",
      "linear.bias:\n",
      " [0.00021992]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459779e-03 -9.3654686e-05  3.4928504e-05  9.3012473e-05\n",
      "   1.7219259e-04 -4.8629143e-05 -1.4002612e-04]]\n",
      "linear.bias:\n",
      " [0.00021937]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04643905e-03 -9.42029510e-05  3.44884866e-05  1.12167516e-04\n",
      "   1.71121268e-04 -1.76126268e-05 -1.40741235e-04]]\n",
      "linear.bias:\n",
      " [0.00021897]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474827e-03 -9.6034128e-05  3.4047647e-05  1.1360399e-04\n",
      "   1.7107182e-04 -4.5287888e-06 -1.4078914e-04]]\n",
      "linear.bias:\n",
      " [0.00021886]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487243e-03 -9.9281235e-05  3.3651217e-05  8.2965606e-05\n",
      "   1.7222128e-04 -3.2075630e-05 -1.4032064e-04]]\n",
      "linear.bias:\n",
      " [0.00021884]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495492e-03 -1.0289737e-04  3.3306122e-05  8.1809725e-05\n",
      "   1.7261395e-04 -1.9049879e-05 -1.4014558e-04]]\n",
      "linear.bias:\n",
      " [0.000219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500134e-03 -1.0675309e-04  3.3155404e-05  1.0842852e-04\n",
      "   1.7245785e-04  1.5790629e-05 -1.4014817e-04]]\n",
      "linear.bias:\n",
      " [0.00021915]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504132e-03 -1.0891886e-04  3.2823136e-05  9.0271991e-05\n",
      "   1.7210924e-04 -3.6140063e-05 -1.4064224e-04]]\n",
      "linear.bias:\n",
      " [0.00021953]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05037540e-03 -1.07871740e-04  3.23040731e-05  1.00656034e-04\n",
      "   1.70592655e-04 -3.49939291e-05 -1.41720346e-04]]\n",
      "linear.bias:\n",
      " [0.00022005]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500128e-03 -1.0580443e-04  3.1414900e-05  1.2690159e-04\n",
      "   1.6882278e-04  2.2990826e-06 -1.4295921e-04]]\n",
      "linear.bias:\n",
      " [0.00022078]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04874012e-03 -1.02323516e-04  3.05498543e-05  9.69007815e-05\n",
      "   1.67988794e-04 -3.91668873e-05 -1.43886617e-04]]\n",
      "linear.bias:\n",
      " [0.00022134]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04717526e-03 -1.00296835e-04  3.00156444e-05  8.91087402e-05\n",
      "   1.67558028e-04 -4.25755607e-05 -1.44538615e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04548258e-03 -9.94243383e-05  2.96165781e-05  1.07961954e-04\n",
      "   1.67275415e-04 -7.46342630e-06 -1.45080921e-04]]\n",
      "linear.bias:\n",
      " [0.00022199]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04488013e-03 -1.00165846e-04  2.95681330e-05  1.13190821e-04\n",
      "   1.68683895e-04 -7.39071538e-06 -1.44430276e-04]]\n",
      "linear.bias:\n",
      " [0.00022209]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04539830e-03 -1.02112004e-04  2.98058621e-05  9.78017270e-05\n",
      "   1.71569234e-04 -4.42921992e-05 -1.42821664e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04587700e-03 -1.04123275e-04  2.98686464e-05  1.03774662e-04\n",
      "   1.74120025e-04 -3.99913843e-05 -1.41427285e-04]]\n",
      "linear.bias:\n",
      " [0.00022194]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458088e-03 -1.0596571e-04  2.9819883e-05  1.2109461e-04\n",
      "   1.7591774e-04 -6.7971268e-07 -1.4051434e-04]]\n",
      "linear.bias:\n",
      " [0.00022205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458636e-03 -1.0766733e-04  2.9844039e-05  9.9011224e-05\n",
      "   1.7731314e-04 -1.4885274e-05 -1.3965649e-04]]\n",
      "linear.bias:\n",
      " [0.00022232]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453177e-03 -1.0962755e-04  2.9972767e-05  8.6375621e-05\n",
      "   1.7830914e-04 -3.0255971e-05 -1.3874231e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04477163e-03 -1.09443376e-04  3.00536012e-05  1.03759805e-04\n",
      "   1.77616370e-04  4.25105827e-06 -1.38683332e-04]]\n",
      "linear.bias:\n",
      " [0.00022312]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448257e-03 -1.0937855e-04  3.0234243e-05  9.8461867e-05\n",
      "   1.7702411e-04 -2.4629344e-05 -1.3812138e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450188e-03 -1.0725192e-04  3.0257848e-05  1.0994476e-04\n",
      "   1.7529783e-04 -1.9657189e-05 -1.3830756e-04]]\n",
      "linear.bias:\n",
      " [0.00022335]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448004e-03 -1.0513316e-04  3.0441784e-05  1.0396811e-04\n",
      "   1.7419489e-04 -3.0178377e-05 -1.3808896e-04]]\n",
      "linear.bias:\n",
      " [0.00022383]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04428164e-03 -1.03188082e-04  3.05576796e-05  1.03071354e-04\n",
      "   1.73167136e-04 -1.10260007e-05 -1.38122938e-04]]\n",
      "linear.bias:\n",
      " [0.00022444]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448056e-03 -1.0264235e-04  3.0798423e-05  9.2337425e-05\n",
      "   1.7321589e-04 -2.5058147e-05 -1.3725985e-04]]\n",
      "linear.bias:\n",
      " [0.00022482]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451896e-03 -1.0280706e-04  3.0915024e-05  1.0136892e-04\n",
      "   1.7291310e-04 -1.2389329e-05 -1.3667511e-04]]\n",
      "linear.bias:\n",
      " [0.00022507]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04636932e-03 -1.04814528e-04  3.10297255e-05  1.07133375e-04\n",
      "   1.73275228e-04 -2.21990376e-05 -1.35604598e-04]]\n",
      "linear.bias:\n",
      " [0.00022495]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04675395e-03 -1.07003056e-04  3.10866053e-05  1.10253437e-04\n",
      "   1.73652355e-04 -1.75747318e-05 -1.34664166e-04]]\n",
      "linear.bias:\n",
      " [0.00022511]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04618887e-03 -1.08723594e-04  3.12904558e-05  9.32317635e-05\n",
      "   1.74403729e-04 -3.04300193e-05 -1.33504771e-04]]\n",
      "linear.bias:\n",
      " [0.00022551]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04599644e-03 -1.08351676e-04  3.13288292e-05  1.01412981e-04\n",
      "   1.73829176e-04  4.65694757e-06 -1.33330381e-04]]\n",
      "linear.bias:\n",
      " [0.00022578]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461441e-03 -1.0820024e-04  3.1416501e-05  8.8557026e-05\n",
      "   1.7336261e-04 -2.3724169e-05 -1.3273259e-04]]\n",
      "linear.bias:\n",
      " [0.00022559]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464352e-03 -1.0609877e-04  3.1363277e-05  9.9020479e-05\n",
      "   1.7160698e-04 -1.2080551e-05 -1.3311110e-04]]\n",
      "linear.bias:\n",
      " [0.00022524]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04640354e-03 -1.05247571e-04  3.16433689e-05  1.12444766e-04\n",
      "   1.70471438e-04 -8.99440056e-06 -1.33127454e-04]]\n",
      "linear.bias:\n",
      " [0.00022485]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466449e-03 -1.0492691e-04  3.1718377e-05  9.3257215e-05\n",
      "   1.6999344e-04 -4.0445000e-05 -1.3280175e-04]]\n",
      "linear.bias:\n",
      " [0.00022457]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04677735e-03 -1.02743244e-04  3.16878795e-05  1.04435494e-04\n",
      "   1.68141763e-04 -1.91609743e-05 -1.33413312e-04]]\n",
      "linear.bias:\n",
      " [0.00022433]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461321e-03 -1.0195693e-04  3.1813521e-05  1.1121324e-04\n",
      "   1.6700244e-04  2.9321782e-06 -1.3385087e-04]]\n",
      "linear.bias:\n",
      " [0.00022437]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460169e-03 -1.0250212e-04  3.2115488e-05  8.9257504e-05\n",
      "   1.6721370e-04 -2.1115387e-05 -1.3380509e-04]]\n",
      "linear.bias:\n",
      " [0.00022441]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460432e-03 -1.0383255e-04  3.2573684e-05  9.2002425e-05\n",
      "   1.6781299e-04 -2.2032269e-05 -1.3359735e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461526e-03 -1.0563861e-04  3.3022967e-05  1.1601684e-04\n",
      "   1.6822219e-04 -2.7912065e-06 -1.3346948e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466347e-03 -1.0779251e-04  3.3199562e-05  1.0560871e-04\n",
      "   1.6908260e-04 -2.6356958e-05 -1.3322607e-04]]\n",
      "linear.bias:\n",
      " [0.00022355]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471256e-03 -1.0946240e-04  3.3108387e-05  1.0108167e-04\n",
      "   1.6968772e-04 -2.6901367e-05 -1.3339415e-04]]\n",
      "linear.bias:\n",
      " [0.00022349]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04762416e-03 -1.10696281e-04  3.27759408e-05  1.01853264e-04\n",
      "   1.70062835e-04 -6.70722875e-06 -1.33932976e-04]]\n",
      "linear.bias:\n",
      " [0.00022362]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04751927e-03 -1.10231529e-04  3.26236222e-05  9.24804845e-05\n",
      "   1.71202017e-04 -1.28105075e-05 -1.33850728e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475580e-03 -1.0975133e-04  3.2432003e-05  9.7605560e-05\n",
      "   1.7172957e-04 -1.4547465e-05 -1.3388014e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04794523e-03 -1.09130786e-04  3.22209380e-05  1.09595174e-04\n",
      "   1.72111017e-04 -1.54774334e-05 -1.34010115e-04]]\n",
      "linear.bias:\n",
      " [0.00022416]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04737375e-03 -1.08319320e-04  3.21849730e-05  1.00399746e-04\n",
      "   1.72870248e-04 -3.34320357e-05 -1.33811613e-04]]\n",
      "linear.bias:\n",
      " [0.00022457]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472427e-03 -1.0541752e-04  3.1973392e-05  1.0952087e-04\n",
      "   1.7236118e-04 -4.0609975e-06 -1.3447911e-04]]\n",
      "linear.bias:\n",
      " [0.00022512]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476371e-03 -1.0382741e-04  3.1908319e-05  9.2836322e-05\n",
      "   1.7296584e-04 -1.7650793e-05 -1.3434108e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480783e-03 -1.0300695e-04  3.1886604e-05  9.9462253e-05\n",
      "   1.7337914e-04 -9.7414786e-06 -1.3427634e-04]]\n",
      "linear.bias:\n",
      " [0.00022554]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481378e-03 -1.0335572e-04  3.2211479e-05  1.0575902e-04\n",
      "   1.7435821e-04 -2.0734777e-05 -1.3373372e-04]]\n",
      "linear.bias:\n",
      " [0.00022537]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04787911e-03 -1.03601611e-04  3.25408691e-05  1.10675894e-04\n",
      "   1.74993460e-04 -2.55643190e-05 -1.33501817e-04]]\n",
      "linear.bias:\n",
      " [0.00022531]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465353e-03 -1.0389277e-04  3.2842629e-05  1.0939143e-04\n",
      "   1.7557325e-04 -1.4888837e-05 -1.3355336e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04543613e-03 -1.05453764e-04  3.28299102e-05  9.07495269e-05\n",
      "   1.76205882e-04 -1.68602419e-05 -1.33503985e-04]]\n",
      "linear.bias:\n",
      " [0.00022563]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444284e-03 -1.0679425e-04  3.2665033e-05  9.4419811e-05\n",
      "   1.7631940e-04  3.7755017e-06 -1.3365356e-04]]\n",
      "linear.bias:\n",
      " [0.00022571]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451374e-03 -1.0857675e-04  3.2410979e-05  9.2120114e-05\n",
      "   1.7684865e-04 -1.8330999e-05 -1.3334742e-04]]\n",
      "linear.bias:\n",
      " [0.00022562]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04610797e-03 -1.08094566e-04  3.21711850e-05  1.14001959e-04\n",
      "   1.76232061e-04 -7.42342218e-06 -1.33657537e-04]]\n",
      "linear.bias:\n",
      " [0.00022535]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470197e-03 -1.0780347e-04  3.1546697e-05  9.3550669e-05\n",
      "   1.7524428e-04 -3.8640930e-05 -1.3419875e-04]]\n",
      "linear.bias:\n",
      " [0.00022529]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478853e-03 -1.0571064e-04  3.0933836e-05  1.0534370e-04\n",
      "   1.7257984e-04 -1.4542331e-05 -1.3576401e-04]]\n",
      "linear.bias:\n",
      " [0.00022515]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482600e-03 -1.0350390e-04  3.0526735e-05  1.0101460e-04\n",
      "   1.7060655e-04 -1.3157159e-05 -1.3672681e-04]]\n",
      "linear.bias:\n",
      " [0.0002252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482578e-03 -1.0261046e-04  3.0506513e-05  9.7447846e-05\n",
      "   1.6943991e-04 -3.0091851e-05 -1.3710676e-04]]\n",
      "linear.bias:\n",
      " [0.00022498]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478253e-03 -1.0294484e-04  3.0739931e-05  1.1391361e-04\n",
      "   1.6871856e-04 -1.0861830e-05 -1.3726063e-04]]\n",
      "linear.bias:\n",
      " [0.0002246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477760e-03 -1.0433068e-04  3.0937186e-05  1.0091518e-04\n",
      "   1.6891885e-04 -2.8402776e-05 -1.3679070e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04718679e-03 -1.05623345e-04  3.10778232e-05  9.58598976e-05\n",
      "   1.68963408e-04 -2.52080827e-05 -1.36523930e-04]]\n",
      "linear.bias:\n",
      " [0.00022379]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465665e-03 -1.0745774e-04  3.1102110e-05  1.1034767e-04\n",
      "   1.6864936e-04  3.3189754e-06 -1.3648035e-04]]\n",
      "linear.bias:\n",
      " [0.00022335]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465638e-03 -1.1019212e-04  3.1274863e-05  9.5677482e-05\n",
      "   1.6946929e-04 -1.3236026e-05 -1.3582283e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463855e-03 -1.1171440e-04  3.1245439e-05  8.6797329e-05\n",
      "   1.7044690e-04 -3.2077143e-05 -1.3508648e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04581378e-03 -1.09988250e-04  3.09917850e-05  1.06267544e-04\n",
      "   1.70084633e-04 -2.79629603e-07 -1.35077615e-04]]\n",
      "linear.bias:\n",
      " [0.00022257]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454961e-03 -1.0834238e-04  3.0778916e-05  9.8346587e-05\n",
      "   1.7099817e-04 -1.2035012e-05 -1.3426387e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04535499e-03 -1.07045256e-04  3.05133217e-05  9.58702149e-05\n",
      "   1.71895736e-04 -2.64911141e-05 -1.33444904e-04]]\n",
      "linear.bias:\n",
      " [0.0002224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454002e-03 -1.0376086e-04  3.0106530e-05  1.1331745e-04\n",
      "   1.7139484e-04 -3.6645852e-06 -1.3348483e-04]]\n",
      "linear.bias:\n",
      " [0.00022237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459364e-03 -1.0202491e-04  2.9700450e-05  9.7777345e-05\n",
      "   1.7177206e-04 -2.6693773e-05 -1.3325465e-04]]\n",
      "linear.bias:\n",
      " [0.00022234]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462386e-03 -1.0038328e-04  2.9023096e-05  9.9976540e-05\n",
      "   1.7144337e-04 -1.9997125e-05 -1.3343059e-04]]\n",
      "linear.bias:\n",
      " [0.0002224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459990e-03 -9.9755584e-05  2.8576133e-05  1.0795080e-04\n",
      "   1.7133217e-04 -5.9056056e-06 -1.3356688e-04]]\n",
      "linear.bias:\n",
      " [0.00022246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463418e-03 -1.0027832e-04  2.8325285e-05  8.7300017e-05\n",
      "   1.7234033e-04 -3.5575042e-05 -1.3306823e-04]]\n",
      "linear.bias:\n",
      " [0.00022242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467035e-03 -9.9467259e-05  2.8272014e-05  1.0060265e-04\n",
      "   1.7189691e-04 -1.3895769e-05 -1.3348128e-04]]\n",
      "linear.bias:\n",
      " [0.00022239]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04672811e-03 -9.98035612e-05  2.85600927e-05  1.16664894e-04\n",
      "   1.71953943e-04 -1.88532522e-06 -1.33520793e-04]]\n",
      "linear.bias:\n",
      " [0.00022227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470174e-03 -1.0140030e-04  2.8915054e-05  9.0922171e-05\n",
      "   1.7220968e-04 -4.6169713e-05 -1.3387790e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04732299e-03 -1.00986814e-04  2.91836222e-05  9.82238562e-05\n",
      "   1.70644998e-04 -3.35242948e-05 -1.35289549e-04]]\n",
      "linear.bias:\n",
      " [0.00022266]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475650e-03 -1.0064532e-04  2.9115607e-05  1.2422084e-04\n",
      "   1.6863478e-04  1.5447513e-05 -1.3684786e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459875e-03 -1.0029536e-04  2.9215671e-05  8.7300592e-05\n",
      "   1.6667765e-04 -4.4982167e-05 -1.3916162e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446273e-03 -9.8919285e-05  2.9535569e-05  8.4256375e-05\n",
      "   1.6437913e-04 -5.2036052e-05 -1.4159568e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04364194e-03 -9.65360668e-05  2.99989188e-05  1.12954076e-04\n",
      "   1.62063545e-04 -6.65002517e-06 -1.44164223e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04420923e-03 -9.60272373e-05  3.05508838e-05  1.14998526e-04\n",
      "   1.62379729e-04 -7.43352894e-06 -1.45207698e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461754e-03 -9.7207216e-05  3.1182724e-05  9.3034330e-05\n",
      "   1.6506719e-04 -4.9783899e-05 -1.4487712e-04]]\n",
      "linear.bias:\n",
      " [0.00022221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475735e-03 -9.9557634e-05  3.1797055e-05  9.9228309e-05\n",
      "   1.6798922e-04 -4.6360656e-05 -1.4438707e-04]]\n",
      "linear.bias:\n",
      " [0.00022193]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489509e-03 -1.0263397e-04  3.2386750e-05  1.2653890e-04\n",
      "   1.7090159e-04 -7.2702642e-06 -1.4386539e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05034269e-03 -1.07316926e-04  3.30477487e-05  1.15028568e-04\n",
      "   1.74628731e-04 -1.56294154e-05 -1.42973207e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0515103e-03 -1.1080449e-04  3.3323187e-05  7.4963311e-05\n",
      "   1.7868307e-04 -5.5983794e-05 -1.4163033e-04]]\n",
      "linear.bias:\n",
      " [0.00022143]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0520678e-03 -1.1026361e-04  3.3246146e-05  9.3632756e-05\n",
      "   1.7866449e-04 -1.2999000e-05 -1.4186680e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0513620e-03 -1.0925836e-04  3.3124248e-05  1.2116451e-04\n",
      "   1.7865140e-04  2.9166265e-05 -1.4180355e-04]]\n",
      "linear.bias:\n",
      " [0.00022208]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04868214e-03 -1.05811036e-04  3.27467496e-05  7.88531979e-05\n",
      "   1.78522503e-04 -6.17741607e-05 -1.43003796e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460733e-03 -1.0032091e-04  3.2199780e-05  9.5991862e-05\n",
      "   1.7508560e-04 -5.4077645e-05 -1.4547638e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436784e-03 -9.3615607e-05  3.1743948e-05  1.4043866e-04\n",
      "   1.7111919e-04  2.2379099e-06 -1.4819312e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416760e-03 -8.7769986e-05  3.1004565e-05  1.1605854e-04\n",
      "   1.6787311e-04 -1.0821433e-05 -1.5084502e-04]]\n",
      "linear.bias:\n",
      " [0.00022357]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413373e-03 -8.4154279e-05  3.0474373e-05  7.0259484e-05\n",
      "   1.6736756e-04 -6.4057567e-05 -1.5195500e-04]]\n",
      "linear.bias:\n",
      " [0.00022387]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408340e-03 -8.3097417e-05  2.9443323e-05  1.0213643e-04\n",
      "   1.6719487e-04 -2.8722970e-05 -1.5226171e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415136e-03 -8.5527703e-05  2.8619455e-05  1.3652057e-04\n",
      "   1.6838456e-04  1.5589227e-05 -1.5176811e-04]]\n",
      "linear.bias:\n",
      " [0.00022318]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422717e-03 -8.8661480e-05  2.8051394e-05  1.0472145e-04\n",
      "   1.7128780e-04 -3.9860519e-05 -1.5071224e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436241e-03 -9.3985349e-05  2.7505230e-05  8.0408819e-05\n",
      "   1.7502334e-04 -6.8150679e-05 -1.4915595e-04]]\n",
      "linear.bias:\n",
      " [0.00022237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449341e-03 -9.8262120e-05  2.7155724e-05  1.1453901e-04\n",
      "   1.7651767e-04 -8.2644365e-06 -1.4843821e-04]]\n",
      "linear.bias:\n",
      " [0.00022162]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471807e-03 -1.0321492e-04  2.6981279e-05  1.2348547e-04\n",
      "   1.7900154e-04  7.5351272e-06 -1.4695233e-04]]\n",
      "linear.bias:\n",
      " [0.00022085]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04918168e-03 -1.08271335e-04  2.70846685e-05  8.48762138e-05\n",
      "   1.81021838e-04 -4.88855949e-05 -1.45641083e-04]]\n",
      "linear.bias:\n",
      " [0.00022025]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505191e-03 -1.1074129e-04  2.7062233e-05  9.3249968e-05\n",
      "   1.8025139e-04 -4.1858082e-05 -1.4539849e-04]]\n",
      "linear.bias:\n",
      " [0.00021971]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516662e-03 -1.1092197e-04  2.7005246e-05  1.3048061e-04\n",
      "   1.7789111e-04  1.3319779e-05 -1.4598120e-04]]\n",
      "linear.bias:\n",
      " [0.0002194]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512777e-03 -1.0891829e-04  2.6864573e-05  1.0157087e-04\n",
      "   1.7505820e-04 -3.7978447e-05 -1.4733503e-04]]\n",
      "linear.bias:\n",
      " [0.00021931]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500624e-03 -1.0652994e-04  2.6711639e-05  9.1469956e-05\n",
      "   1.7268138e-04 -4.9039434e-05 -1.4836967e-04]]\n",
      "linear.bias:\n",
      " [0.00021932]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04794779e-03 -1.02619284e-04  2.67738942e-05  1.13303322e-04\n",
      "   1.69678329e-04 -8.39604036e-06 -1.49563522e-04]]\n",
      "linear.bias:\n",
      " [0.00021932]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471612e-03 -1.0044470e-04  2.7126405e-05  1.1214843e-04\n",
      "   1.6867780e-04 -9.1637985e-06 -1.4956100e-04]]\n",
      "linear.bias:\n",
      " [0.00021915]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475711e-03 -9.9834200e-05  2.7740460e-05  9.0284928e-05\n",
      "   1.6948149e-04 -4.7220030e-05 -1.4848057e-04]]\n",
      "linear.bias:\n",
      " [0.00021881]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04764081e-03 -1.00290315e-04  2.83800073e-05  9.74415161e-05\n",
      "   1.70316387e-04 -4.28547355e-05 -1.47460305e-04]]\n",
      "linear.bias:\n",
      " [0.0002185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04684115e-03 -1.01905476e-04  2.92643344e-05  1.28873333e-04\n",
      "   1.71233012e-04 -1.68384940e-06 -1.46382095e-04]]\n",
      "linear.bias:\n",
      " [0.00021813]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465798e-03 -1.0448859e-04  3.0112111e-05  1.0488792e-04\n",
      "   1.7269848e-04 -1.8108753e-05 -1.4516008e-04]]\n",
      "linear.bias:\n",
      " [0.00021826]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456567e-03 -1.0749125e-04  3.1168951e-05  7.5747244e-05\n",
      "   1.7491038e-04 -4.0586841e-05 -1.4344329e-04]]\n",
      "linear.bias:\n",
      " [0.00021873]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446134e-03 -1.0818329e-04  3.2094264e-05  9.2000722e-05\n",
      "   1.7567695e-04 -7.6740325e-06 -1.4222549e-04]]\n",
      "linear.bias:\n",
      " [0.00021934]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04375486e-03 -1.08967644e-04  3.31303345e-05  1.10610505e-04\n",
      "   1.76865869e-04  3.54099302e-06 -1.40570599e-04]]\n",
      "linear.bias:\n",
      " [0.00021998]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435057e-03 -1.0810415e-04  3.3668373e-05  8.9305453e-05\n",
      "   1.7691551e-04 -5.6378925e-05 -1.3958162e-04]]\n",
      "linear.bias:\n",
      " [0.00022074]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04335858e-03 -1.05360050e-04  3.41662817e-05  1.01400845e-04\n",
      "   1.74935121e-04 -5.93008735e-05 -1.39664742e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04318897e-03 -1.00731384e-04  3.44949513e-05  1.36813120e-04\n",
      "   1.71720472e-04 -1.29289147e-05 -1.40603210e-04]]\n",
      "linear.bias:\n",
      " [0.0002224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04360527e-03 -9.66285879e-05  3.41265259e-05  1.10868525e-04\n",
      "   1.68861545e-04 -2.27954624e-05 -1.41628916e-04]]\n",
      "linear.bias:\n",
      " [0.00022346]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445418e-03 -9.5388408e-05  3.3795845e-05  7.7425517e-05\n",
      "   1.6747259e-04 -3.7181195e-05 -1.4197888e-04]]\n",
      "linear.bias:\n",
      " [0.00022451]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457925e-03 -9.6171345e-05  3.3613473e-05  8.6679116e-05\n",
      "   1.6640138e-04 -1.5517349e-05 -1.4202535e-04]]\n",
      "linear.bias:\n",
      " [0.00022528]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479968e-03 -9.9095138e-05  3.3268159e-05  1.1058047e-04\n",
      "   1.6607117e-04  8.3897357e-06 -1.4158149e-04]]\n",
      "linear.bias:\n",
      " [0.00022578]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507730e-03 -1.0327295e-04  3.2951786e-05  1.0748687e-04\n",
      "   1.6837379e-04 -1.4745830e-05 -1.3982857e-04]]\n",
      "linear.bias:\n",
      " [0.00022578]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0535340e-03 -1.0829407e-04  3.2684660e-05  8.1403887e-05\n",
      "   1.7139374e-04 -6.4394277e-05 -1.3762669e-04]]\n",
      "linear.bias:\n",
      " [0.00022578]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0556610e-03 -1.1069859e-04  3.2352942e-05  1.1089784e-04\n",
      "   1.7215790e-04 -2.0965887e-05 -1.3657603e-04]]\n",
      "linear.bias:\n",
      " [0.00022541]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0562068e-03 -1.1138657e-04  3.2094096e-05  1.1913023e-04\n",
      "   1.7342392e-04  5.4469037e-06 -1.3531861e-04]]\n",
      "linear.bias:\n",
      " [0.00022554]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0552228e-03 -1.0805904e-04  3.0918520e-05  7.1525836e-05\n",
      "   1.7345283e-04 -5.8087193e-05 -1.3550535e-04]]\n",
      "linear.bias:\n",
      " [0.00022556]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0539095e-03 -1.0281665e-04  2.9597930e-05  1.0494920e-04\n",
      "   1.6949783e-04 -1.6054091e-05 -1.3730029e-04]]\n",
      "linear.bias:\n",
      " [0.00022512]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0515403e-03 -9.9444514e-05  2.8668230e-05  1.2361714e-04\n",
      "   1.6647286e-04  4.7060694e-06 -1.3853029e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472423e-03 -9.7333490e-05  2.8041046e-05  9.0833710e-05\n",
      "   1.6450981e-04 -6.0217535e-05 -1.3990265e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435430e-03 -9.4604155e-05  2.7631995e-05  9.3449082e-05\n",
      "   1.6285070e-04 -6.3426793e-05 -1.4159252e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400136e-03 -9.3383584e-05  2.7254018e-05  1.2327069e-04\n",
      "   1.6217082e-04 -2.0799653e-05 -1.4294346e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03763887e-03 -9.40269456e-05  2.69210577e-05  1.17001844e-04\n",
      "   1.63784120e-04 -2.22733597e-05 -1.43208934e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0369108e-03 -9.5958349e-05  2.6649592e-05  9.3180803e-05\n",
      "   1.6703799e-04 -4.4323224e-05 -1.4242498e-04]]\n",
      "linear.bias:\n",
      " [0.00022147]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363769e-03 -9.8683944e-05  2.6442638e-05  9.3693256e-05\n",
      "   1.7025697e-04 -2.8479491e-05 -1.4163640e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03620160e-03 -1.02069338e-04  2.64390837e-05  1.18944066e-04\n",
      "   1.73675668e-04  1.61322932e-05 -1.40701392e-04]]\n",
      "linear.bias:\n",
      " [0.00022018]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0362734e-03 -1.0523175e-04  2.6793938e-05  9.1995636e-05\n",
      "   1.7689259e-04 -3.1685158e-05 -1.4026211e-04]]\n",
      "linear.bias:\n",
      " [0.00021972]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0367059e-03 -1.0596321e-04  2.7025606e-05  9.2638380e-05\n",
      "   1.7826745e-04 -2.8876490e-05 -1.4064838e-04]]\n",
      "linear.bias:\n",
      " [0.00021941]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03746331e-03 -1.04504419e-04  2.71462977e-05  1.18134005e-04\n",
      "   1.77982700e-04  1.95037828e-05 -1.41778481e-04]]\n",
      "linear.bias:\n",
      " [0.00021921]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03808416e-03 -1.02511985e-04  2.74635950e-05  8.58156782e-05\n",
      "   1.77095106e-04 -4.29340398e-05 -1.43368321e-04]]\n",
      "linear.bias:\n",
      " [0.00021923]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386321e-03 -9.8877266e-05  2.7870276e-05  8.7721462e-05\n",
      "   1.7516606e-04 -4.9786420e-05 -1.4537876e-04]]\n",
      "linear.bias:\n",
      " [0.00021933]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392237e-03 -9.4475203e-05  2.8557530e-05  1.2173205e-04\n",
      "   1.7263951e-04 -8.8097258e-06 -1.4762716e-04]]\n",
      "linear.bias:\n",
      " [0.00021942]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0401298e-03 -9.2483686e-05  2.9335677e-05  1.1985352e-04\n",
      "   1.7222653e-04 -1.0902263e-05 -1.4885966e-04]]\n",
      "linear.bias:\n",
      " [0.0002195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418313e-03 -9.2660892e-05  3.0181760e-05  9.1921596e-05\n",
      "   1.7373118e-04 -4.7851638e-05 -1.4896315e-04]]\n",
      "linear.bias:\n",
      " [0.00021958]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430582e-03 -9.3846138e-05  3.1031952e-05  9.3871568e-05\n",
      "   1.7519950e-04 -4.2581814e-05 -1.4900809e-04]]\n",
      "linear.bias:\n",
      " [0.00021965]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438575e-03 -9.5939693e-05  3.1885898e-05  1.2273647e-04\n",
      "   1.7663516e-04  7.0258466e-07 -1.4900026e-04]]\n",
      "linear.bias:\n",
      " [0.00021971]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04493031e-03 -9.95248338e-05  3.28762471e-05  1.11216366e-04\n",
      "   1.78797418e-04 -1.28588499e-05 -1.48647145e-04]]\n",
      "linear.bias:\n",
      " [0.00021995]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04671437e-03 -1.04078164e-04  3.37973979e-05  8.10062047e-05\n",
      "   1.81747877e-04 -5.17748231e-05 -1.47617189e-04]]\n",
      "linear.bias:\n",
      " [0.00022025]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478443e-03 -1.0604101e-04  3.4508354e-05  9.7504220e-05\n",
      "   1.8174779e-04 -2.9152225e-05 -1.4765227e-04]]\n",
      "linear.bias:\n",
      " [0.00022053]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488273e-03 -1.0784064e-04  3.4826175e-05  1.3211908e-04\n",
      "   1.8112220e-04  2.8389835e-05 -1.4798257e-04]]\n",
      "linear.bias:\n",
      " [0.00022088]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04814349e-03 -1.05577696e-04  3.41035557e-05  8.25660245e-05\n",
      "   1.80552306e-04 -4.96322536e-05 -1.49353247e-04]]\n",
      "linear.bias:\n",
      " [0.00022137]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469129e-03 -1.0130522e-04  3.3282649e-05  8.0163867e-05\n",
      "   1.7773097e-04 -6.4527383e-05 -1.5138176e-04]]\n",
      "linear.bias:\n",
      " [0.00022191]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454314e-03 -9.5434494e-05  3.2558248e-05  1.2772557e-04\n",
      "   1.7300215e-04  1.4046673e-06 -1.5390074e-04]]\n",
      "linear.bias:\n",
      " [0.0002223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450877e-03 -9.2066512e-05  3.2031840e-05  1.2843897e-04\n",
      "   1.7106895e-04  1.0709252e-05 -1.5512003e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449793e-03 -9.0502806e-05  3.1906438e-05  8.1613536e-05\n",
      "   1.7165633e-04 -5.0789156e-05 -1.5511125e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445850e-03 -9.1070040e-05  3.1460466e-05  8.3484338e-05\n",
      "   1.7286971e-04 -5.9102069e-05 -1.5435267e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437139e-03 -9.3845338e-05  3.0951160e-05  1.2555420e-04\n",
      "   1.7397857e-04 -6.1942810e-06 -1.5335188e-04]]\n",
      "linear.bias:\n",
      " [0.00022278]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439302e-03 -9.8054734e-05  3.0647116e-05  1.3295503e-04\n",
      "   1.7746758e-04 -3.5373694e-06 -1.5134233e-04]]\n",
      "linear.bias:\n",
      " [0.00022272]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447061e-03 -1.0295343e-04  3.0174195e-05  8.6886903e-05\n",
      "   1.8122194e-04 -5.3365613e-05 -1.4921870e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04497303e-03 -1.05462364e-04  2.97892493e-05  9.01586463e-05\n",
      "   1.82507007e-04 -4.01590769e-05 -1.48033185e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451544e-03 -1.0561226e-04  2.9404635e-05  1.2320394e-04\n",
      "   1.8194396e-04  2.0216532e-05 -1.4779267e-04]]\n",
      "linear.bias:\n",
      " [0.00022307]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04464649e-03 -1.04662926e-04  2.92520872e-05  9.33617630e-05\n",
      "   1.80648087e-04 -3.47625974e-05 -1.48349762e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437224e-03 -1.0387452e-04  2.8841079e-05  9.1352624e-05\n",
      "   1.7867223e-04 -4.4449236e-05 -1.4918749e-04]]\n",
      "linear.bias:\n",
      " [0.00022378]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428429e-03 -1.0133209e-04  2.8509168e-05  1.1900744e-04\n",
      "   1.7598632e-04 -4.3952714e-06 -1.5045181e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04259793e-03 -1.00134675e-04  2.83442223e-05  1.18178701e-04\n",
      "   1.74702538e-04 -8.05393211e-06 -1.50801279e-04]]\n",
      "linear.bias:\n",
      " [0.00022434]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04341272e-03 -1.00174904e-04  2.83366517e-05  9.19892773e-05\n",
      "   1.75642068e-04 -5.11938997e-05 -1.49917745e-04]]\n",
      "linear.bias:\n",
      " [0.00022412]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442098e-03 -9.9098121e-05  2.8570916e-05  9.9197758e-05\n",
      "   1.7592568e-04 -4.3417367e-05 -1.4948985e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444705e-03 -9.9337463e-05  2.9048993e-05  1.2592180e-04\n",
      "   1.7653056e-04 -2.3603898e-06 -1.4890466e-04]]\n",
      "linear.bias:\n",
      " [0.00022337]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04502693e-03 -1.01082886e-04  2.98022969e-05  1.10204994e-04\n",
      "   1.78104470e-04 -1.70847998e-05 -1.47819970e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462988e-03 -1.0412856e-04  3.0510808e-05  7.9827987e-05\n",
      "   1.8052035e-04 -5.7354686e-05 -1.4598816e-04]]\n",
      "linear.bias:\n",
      " [0.00022241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04723498e-03 -1.04901264e-04  3.11921140e-05  1.02576552e-04\n",
      "   1.80021161e-04 -1.89490311e-05 -1.45114303e-04]]\n",
      "linear.bias:\n",
      " [0.00022191]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04699330e-03 -1.06334846e-04  3.17293561e-05  1.27329215e-04\n",
      "   1.79184150e-04  2.26148150e-05 -1.44225211e-04]]\n",
      "linear.bias:\n",
      " [0.00022184]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460346e-03 -1.0667828e-04  3.2205779e-05  8.6282271e-05\n",
      "   1.7734228e-04 -5.0406921e-05 -1.4457795e-04]]\n",
      "linear.bias:\n",
      " [0.00022196]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446836e-03 -1.0467374e-04  3.2536016e-05  8.3317740e-05\n",
      "   1.7391177e-04 -6.4978427e-05 -1.4560402e-04]]\n",
      "linear.bias:\n",
      " [0.00022235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432689e-03 -1.0092712e-04  3.2742595e-05  1.2893346e-04\n",
      "   1.6902197e-04 -1.5842816e-06 -1.4718295e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429495e-03 -9.9245059e-05  3.2894466e-05  1.2667495e-04\n",
      "   1.6638970e-04  4.9921819e-06 -1.4778662e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437988e-03 -9.9251673e-05  3.3276610e-05  7.9995792e-05\n",
      "   1.6655850e-04 -4.1705869e-05 -1.4719262e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04404415e-03 -1.00096244e-04  3.35598634e-05  7.71125051e-05\n",
      "   1.66709535e-04 -4.19477146e-05 -1.46357823e-04]]\n",
      "linear.bias:\n",
      " [0.00022333]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04393356e-03 -1.01638580e-04  3.39028302e-05  1.16504634e-04\n",
      "   1.67081133e-04 -5.66739618e-06 -1.45160375e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04480598e-03 -1.04705694e-04  3.43423380e-05  1.24040234e-04\n",
      "   1.69905426e-04 -1.58965413e-05 -1.42823701e-04]]\n",
      "linear.bias:\n",
      " [0.00022353]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465068e-03 -1.0725655e-04  3.4312183e-05  9.6654905e-05\n",
      "   1.7348492e-04 -5.9949427e-05 -1.4016629e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479384e-03 -1.0747883e-04  3.4129356e-05  1.0088094e-04\n",
      "   1.7526273e-04 -5.0295264e-05 -1.3856254e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495681e-03 -1.0554124e-04  3.3789420e-05  1.2816067e-04\n",
      "   1.7554335e-04  3.5610319e-06 -1.3784289e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495866e-03 -1.0244512e-04  3.2736305e-05  8.8792985e-05\n",
      "   1.7452850e-04 -2.5627158e-05 -1.3857392e-04]]\n",
      "linear.bias:\n",
      " [0.00022322]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489579e-03 -9.9678960e-05  3.1525346e-05  7.6783253e-05\n",
      "   1.7270548e-04 -2.1588745e-05 -1.3962272e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480235e-03 -9.8205375e-05  3.0696956e-05  1.0110518e-04\n",
      "   1.7093522e-04  7.2477160e-06 -1.4049046e-04]]\n",
      "linear.bias:\n",
      " [0.00022336]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482434e-03 -9.8167904e-05  3.0098621e-05  1.0447279e-04\n",
      "   1.7051781e-04 -4.9488526e-06 -1.4025556e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494090e-03 -9.9565288e-05  2.9739827e-05  9.4067364e-05\n",
      "   1.7138827e-04 -4.8210237e-05 -1.3903403e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504107e-03 -9.8965596e-05  2.9455470e-05  1.1436084e-04\n",
      "   1.7125282e-04 -3.8396800e-05 -1.3845113e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506257e-03 -9.8998411e-05  2.9164843e-05  1.2901511e-04\n",
      "   1.7145665e-04 -7.7057375e-06 -1.3787046e-04]]\n",
      "linear.bias:\n",
      " [0.00022281]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502879e-03 -9.9990233e-05  2.8821340e-05  8.6365850e-05\n",
      "   1.7131557e-04 -3.7278478e-05 -1.3782897e-04]]\n",
      "linear.bias:\n",
      " [0.00022322]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496703e-03 -1.0193612e-04  2.8602644e-05  7.5346143e-05\n",
      "   1.7130490e-04 -2.5605725e-05 -1.3774208e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04891777e-03 -1.04755258e-04  2.86543782e-05  1.02207356e-04\n",
      "   1.71256877e-04  1.95855682e-05 -1.37536306e-04]]\n",
      "linear.bias:\n",
      " [0.00022381]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475646e-03 -1.0847625e-04  2.9130493e-05  9.3494935e-05\n",
      "   1.7173930e-04 -2.1374279e-05 -1.3734809e-04]]\n",
      "linear.bias:\n",
      " [0.00022373]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458495e-03 -1.1269772e-04  2.9831624e-05  1.0629071e-04\n",
      "   1.7208749e-04 -3.9663479e-05 -1.3712574e-04]]\n",
      "linear.bias:\n",
      " [0.00022338]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445998e-03 -1.1286462e-04  3.0183775e-05  1.3086561e-04\n",
      "   1.7170592e-04 -1.3623745e-05 -1.3772892e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427358e-03 -1.1100544e-04  3.0025298e-05  9.7046155e-05\n",
      "   1.7054251e-04 -4.2104904e-05 -1.3887310e-04]]\n",
      "linear.bias:\n",
      " [0.00022332]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414494e-03 -1.0742916e-04  2.9869423e-05  9.1200425e-05\n",
      "   1.6875337e-04 -2.1847281e-05 -1.4038723e-04]]\n",
      "linear.bias:\n",
      " [0.00022329]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04043330e-03 -1.05127066e-04  2.99328494e-05  1.09536675e-04\n",
      "   1.67589737e-04  1.70543790e-05 -1.41568526e-04]]\n",
      "linear.bias:\n",
      " [0.00022298]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03936391e-03 -1.04229584e-04  3.02080898e-05  8.69565411e-05\n",
      "   1.67690334e-04 -3.08935923e-05 -1.42360252e-04]]\n",
      "linear.bias:\n",
      " [0.00022242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03871769e-03 -1.04386556e-04  3.06454676e-05  9.18077349e-05\n",
      "   1.68320024e-04 -4.39694122e-05 -1.42840057e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03820034e-03 -1.03393126e-04  3.12851262e-05  1.27257983e-04\n",
      "   1.68313622e-04 -9.15553028e-06 -1.43647048e-04]]\n",
      "linear.bias:\n",
      " [0.00022099]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386884e-03 -1.0401877e-04  3.1537649e-05  1.1571713e-04\n",
      "   1.7002138e-04 -1.9704537e-05 -1.4356988e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04043190e-03 -1.04995954e-04  3.14233730e-05  8.44961905e-05\n",
      "   1.72486936e-04 -4.82653777e-05 -1.42830511e-04]]\n",
      "linear.bias:\n",
      " [0.00021993]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419905e-03 -1.0396892e-04  3.1445794e-05  8.7887187e-05\n",
      "   1.7353659e-04 -2.4863508e-05 -1.4276442e-04]]\n",
      "linear.bias:\n",
      " [0.00021967]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04322017e-03 -1.03792285e-04  3.15440338e-05  1.20281242e-04\n",
      "   1.74246772e-04  2.85385177e-05 -1.42755001e-04]]\n",
      "linear.bias:\n",
      " [0.00021943]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438469e-03 -1.0272820e-04  3.1520813e-05  8.3897568e-05\n",
      "   1.7456604e-04 -4.4923458e-05 -1.4386537e-04]]\n",
      "linear.bias:\n",
      " [0.00021941]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439635e-03 -9.9667122e-05  3.1563752e-05  8.6471351e-05\n",
      "   1.7364105e-04 -5.9245598e-05 -1.4533900e-04]]\n",
      "linear.bias:\n",
      " [0.00021958]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438659e-03 -9.4755138e-05  3.1564312e-05  1.2722352e-04\n",
      "   1.7185784e-04 -2.9561306e-06 -1.4703056e-04]]\n",
      "linear.bias:\n",
      " [0.00022003]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441081e-03 -9.2342729e-05  3.1536212e-05  1.1804850e-04\n",
      "   1.7142606e-04  3.3451706e-06 -1.4803867e-04]]\n",
      "linear.bias:\n",
      " [0.00022062]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447289e-03 -9.2416485e-05  3.1966400e-05  7.6553159e-05\n",
      "   1.7305541e-04 -3.8336701e-05 -1.4809713e-04]]\n",
      "linear.bias:\n",
      " [0.00022115]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453160e-03 -9.4255229e-05  3.2499927e-05  8.4944644e-05\n",
      "   1.7442736e-04 -3.8547947e-05 -1.4781828e-04]]\n",
      "linear.bias:\n",
      " [0.00022163]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455276e-03 -9.6976051e-05  3.3072058e-05  1.2003004e-04\n",
      "   1.7578053e-04 -5.0800372e-07 -1.4751707e-04]]\n",
      "linear.bias:\n",
      " [0.00022206]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460725e-03 -1.0142028e-04  3.3878456e-05  1.1732342e-04\n",
      "   1.7842553e-04 -1.4323437e-05 -1.4664404e-04]]\n",
      "linear.bias:\n",
      " [0.00022254]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468197e-03 -1.0586144e-04  3.4382243e-05  8.4637635e-05\n",
      "   1.8137773e-04 -5.8923324e-05 -1.4534220e-04]]\n",
      "linear.bias:\n",
      " [0.00022298]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470041e-03 -1.0753651e-04  3.4703808e-05  1.0515387e-04\n",
      "   1.8057486e-04 -2.1849828e-05 -1.4521292e-04]]\n",
      "linear.bias:\n",
      " [0.00022318]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04735605e-03 -1.10674555e-04  3.45479384e-05  1.25092949e-04\n",
      "   1.79494338e-04  1.52589600e-05 -1.44918537e-04]]\n",
      "linear.bias:\n",
      " [0.00022365]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04703952e-03 -1.09055225e-04  3.34860633e-05  7.49023311e-05\n",
      "   1.77964292e-04 -4.87800025e-05 -1.45774626e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466448e-03 -1.0550975e-04  3.2558699e-05  7.8409452e-05\n",
      "   1.7449626e-04 -4.9272683e-05 -1.4717656e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459996e-03 -1.0016406e-04  3.1612093e-05  1.2705690e-04\n",
      "   1.6989387e-04  4.9755472e-06 -1.4881522e-04]]\n",
      "linear.bias:\n",
      " [0.00022506]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459035e-03 -9.6405485e-05  3.1055733e-05  1.2856182e-04\n",
      "   1.6744316e-04 -6.8143863e-06 -1.4940641e-04]]\n",
      "linear.bias:\n",
      " [0.00022505]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470230e-03 -9.4755327e-05  3.0545994e-05  9.0228408e-05\n",
      "   1.6780780e-04 -6.3782478e-05 -1.4872719e-04]]\n",
      "linear.bias:\n",
      " [0.00022485]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474699e-03 -9.4408759e-05  3.0025240e-05  9.1451016e-05\n",
      "   1.6871328e-04 -5.2590207e-05 -1.4777861e-04]]\n",
      "linear.bias:\n",
      " [0.00022496]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469502e-03 -9.5406933e-05  2.9851828e-05  1.1852842e-04\n",
      "   1.6976021e-04 -4.4760855e-06 -1.4678491e-04]]\n",
      "linear.bias:\n",
      " [0.00022487]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470238e-03 -9.8256816e-05  2.9988511e-05  1.1539154e-04\n",
      "   1.7286211e-04 -3.1708137e-06 -1.4477182e-04]]\n",
      "linear.bias:\n",
      " [0.00022459]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04765594e-03 -1.01952624e-04  3.02501321e-05  8.64437316e-05\n",
      "   1.76829184e-04 -4.15756731e-05 -1.42142904e-04]]\n",
      "linear.bias:\n",
      " [0.00022414]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04817608e-03 -1.03383274e-04  3.05252797e-05  9.03206237e-05\n",
      "   1.79462717e-04 -2.75229977e-05 -1.40303615e-04]]\n",
      "linear.bias:\n",
      " [0.00022374]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04816060e-03 -1.04740466e-04  3.04893874e-05  1.19091994e-04\n",
      "   1.80995674e-04  2.48150500e-05 -1.38995718e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471541e-03 -1.0562841e-04  3.0373034e-05  8.2420636e-05\n",
      "   1.8123306e-04 -3.7422167e-05 -1.3927270e-04]]\n",
      "linear.bias:\n",
      " [0.00022362]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461910e-03 -1.0438770e-04  3.0206716e-05  9.0050562e-05\n",
      "   1.7870851e-04 -3.9257040e-05 -1.4065734e-04]]\n",
      "linear.bias:\n",
      " [0.00022356]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452248e-03 -1.0111072e-04  2.9929985e-05  1.2584327e-04\n",
      "   1.7489365e-04  6.9431153e-06 -1.4268473e-04]]\n",
      "linear.bias:\n",
      " [0.00022361]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436535e-03 -9.8535857e-05  2.9706753e-05  1.0223924e-04\n",
      "   1.7101251e-04 -2.2668313e-05 -1.4496448e-04]]\n",
      "linear.bias:\n",
      " [0.00022365]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430713e-03 -9.8683988e-05  2.9632203e-05  8.6623964e-05\n",
      "   1.6878398e-04 -4.5945737e-05 -1.4622610e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04222633e-03 -9.98948162e-05  2.96578273e-05  1.00218174e-04\n",
      "   1.66896309e-04 -2.87942385e-05 -1.47311483e-04]]\n",
      "linear.bias:\n",
      " [0.00022317]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424769e-03 -1.0350132e-04  2.9792744e-05  1.1968388e-04\n",
      "   1.6655713e-04 -5.5650708e-07 -1.4744500e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04374730e-03 -1.08534550e-04  3.00756401e-05  1.06140425e-04\n",
      "   1.68851955e-04 -1.98208490e-05 -1.46408012e-04]]\n",
      "linear.bias:\n",
      " [0.00022221]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441266e-03 -1.1280774e-04  3.0849893e-05  8.7178756e-05\n",
      "   1.7293065e-04 -5.3911150e-05 -1.4426344e-04]]\n",
      "linear.bias:\n",
      " [0.0002219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04362215e-03 -1.13313334e-04  3.14018216e-05  1.03657592e-04\n",
      "   1.75799345e-04 -3.32713971e-05 -1.42670382e-04]]\n",
      "linear.bias:\n",
      " [0.00022182]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04321551e-03 -1.10105335e-04  3.16041696e-05  1.33327543e-04\n",
      "   1.77328213e-04  2.60046691e-05 -1.42040677e-04]]\n",
      "linear.bias:\n",
      " [0.00022214]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411750e-03 -1.0331129e-04  3.1070373e-05  7.7520075e-05\n",
      "   1.7852140e-04 -5.0554769e-05 -1.4293962e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0393726e-03 -9.4989562e-05  3.0610408e-05  7.7653487e-05\n",
      "   1.7713290e-04 -6.0569815e-05 -1.4446363e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0387674e-03 -8.7752822e-05  3.0331092e-05  1.4693392e-04\n",
      "   1.7253436e-04  1.5568949e-05 -1.4715416e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374519e-03 -8.1797261e-05  3.0048346e-05  1.2892245e-04\n",
      "   1.6888593e-04 -2.4335131e-05 -1.5019356e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0370701e-03 -7.8369427e-05  2.9582288e-05  7.7172517e-05\n",
      "   1.6805030e-04 -9.6797317e-05 -1.5172004e-04]]\n",
      "linear.bias:\n",
      " [0.00022273]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0382195e-03 -7.7093522e-05  2.9222072e-05  1.1805368e-04\n",
      "   1.6550288e-04 -3.3264012e-05 -1.5378909e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407480e-03 -8.0180638e-05  2.8628636e-05  1.4584212e-04\n",
      "   1.6570659e-04  3.5590245e-05 -1.5469223e-04]]\n",
      "linear.bias:\n",
      " [0.00022065]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397889e-03 -8.4049672e-05  2.8430319e-05  7.3822899e-05\n",
      "   1.6830595e-04 -6.0151513e-05 -1.5562655e-04]]\n",
      "linear.bias:\n",
      " [0.00021991]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0388742e-03 -8.9576955e-05  2.7915608e-05  6.1186453e-05\n",
      "   1.7189067e-04 -8.2638915e-05 -1.5524017e-04]]\n",
      "linear.bias:\n",
      " [0.00021935]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0394212e-03 -9.5658637e-05  2.7847635e-05  1.5601484e-04\n",
      "   1.7256571e-04  2.2791493e-05 -1.5529990e-04]]\n",
      "linear.bias:\n",
      " [0.00021766]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0388531e-03 -1.0035966e-04  2.7787934e-05  1.5423502e-04\n",
      "   1.7463873e-04 -6.0348229e-06 -1.5602342e-04]]\n",
      "linear.bias:\n",
      " [0.00021633]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386199e-03 -1.0513965e-04  2.7381615e-05  7.5743206e-05\n",
      "   1.7684123e-04 -1.0214465e-04 -1.5699069e-04]]\n",
      "linear.bias:\n",
      " [0.00021563]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0395424e-03 -1.0554587e-04  2.7646189e-05  9.4971489e-05\n",
      "   1.7622476e-04 -4.9995204e-05 -1.5874012e-04]]\n",
      "linear.bias:\n",
      " [0.00021441]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03984028e-03 -1.06025866e-04  2.77161798e-05  1.43083700e-04\n",
      "   1.75465728e-04  3.71878232e-05 -1.60085823e-04]]\n",
      "linear.bias:\n",
      " [0.0002137]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386597e-03 -1.0247121e-04  2.7493790e-05  9.9010955e-05\n",
      "   1.7622861e-04 -4.2238313e-05 -1.6172184e-04]]\n",
      "linear.bias:\n",
      " [0.00021395]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03712594e-03 -1.01251535e-04  2.75325165e-05  7.37308874e-05\n",
      "   1.78073547e-04 -8.86018679e-05 -1.62341443e-04]]\n",
      "linear.bias:\n",
      " [0.00021447]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363546e-03 -9.7307951e-05  2.7880398e-05  1.2730573e-04\n",
      "   1.7760094e-04 -1.5745667e-05 -1.6315711e-04]]\n",
      "linear.bias:\n",
      " [0.00021484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0370562e-03 -9.5757794e-05  2.7992735e-05  1.4392726e-04\n",
      "   1.7968965e-04  1.6089489e-05 -1.6258724e-04]]\n",
      "linear.bias:\n",
      " [0.00021517]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0375322e-03 -9.4705705e-05  2.8285682e-05  8.8063665e-05\n",
      "   1.8300299e-04 -4.5650926e-05 -1.6155718e-04]]\n",
      "linear.bias:\n",
      " [0.00021587]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0375927e-03 -9.4507021e-05  2.8650042e-05  7.5889831e-05\n",
      "   1.8570632e-04 -6.3605832e-05 -1.6018070e-04]]\n",
      "linear.bias:\n",
      " [0.00021689]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0388520e-03 -9.3762086e-05  2.9132454e-05  1.4083710e-04\n",
      "   1.8479969e-04  7.9180245e-06 -1.5943607e-04]]\n",
      "linear.bias:\n",
      " [0.00021771]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407070e-03 -9.3318180e-05  2.9584566e-05  1.3183456e-04\n",
      "   1.8467644e-04 -6.1010187e-06 -1.5850703e-04]]\n",
      "linear.bias:\n",
      " [0.00021884]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425284e-03 -9.4326686e-05  2.9943049e-05  7.1246555e-05\n",
      "   1.8481247e-04 -6.8170601e-05 -1.5751336e-04]]\n",
      "linear.bias:\n",
      " [0.00022015]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451919e-03 -9.5123643e-05  3.0322135e-05  1.0143473e-04\n",
      "   1.8108739e-04 -2.2382737e-05 -1.5760225e-04]]\n",
      "linear.bias:\n",
      " [0.00022075]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482981e-03 -9.7703451e-05  3.0881274e-05  1.3144927e-04\n",
      "   1.7895910e-04  7.9058082e-06 -1.5656090e-04]]\n",
      "linear.bias:\n",
      " [0.00022128]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510694e-03 -1.0066267e-04  3.1566262e-05  1.0271634e-04\n",
      "   1.7794197e-04 -3.9157472e-05 -1.5507678e-04]]\n",
      "linear.bias:\n",
      " [0.00022176]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0527408e-03 -1.0436505e-04  3.2239761e-05  9.0571259e-05\n",
      "   1.7722201e-04 -5.2209594e-05 -1.5339066e-04]]\n",
      "linear.bias:\n",
      " [0.00022229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0537450e-03 -1.0556034e-04  3.2822958e-05  1.1315665e-04\n",
      "   1.7557274e-04 -1.4321529e-05 -1.5228098e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0546114e-03 -1.0673478e-04  3.3209697e-05  1.0807427e-04\n",
      "   1.7520631e-04 -1.3819426e-05 -1.5039252e-04]]\n",
      "linear.bias:\n",
      " [0.00022329]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0547088e-03 -1.0713135e-04  3.3999619e-05  9.2527524e-05\n",
      "   1.7632278e-04 -4.1406711e-05 -1.4764602e-04]]\n",
      "linear.bias:\n",
      " [0.00022377]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05377252e-03 -1.04502426e-04  3.48690919e-05  1.06044507e-04\n",
      "   1.76609552e-04 -2.06599489e-05 -1.45525890e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05201581e-03 -1.02845195e-04  3.56080491e-05  1.17747477e-04\n",
      "   1.76900619e-04  2.22805829e-06 -1.43452940e-04]]\n",
      "linear.bias:\n",
      " [0.00022488]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503847e-03 -1.0074086e-04  3.6138892e-05  9.0671732e-05\n",
      "   1.7686997e-04 -2.8892468e-05 -1.4144623e-04]]\n",
      "linear.bias:\n",
      " [0.0002254]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484199e-03 -9.8916535e-05  3.6326139e-05  9.1434740e-05\n",
      "   1.7598284e-04 -1.8545121e-05 -1.3999631e-04]]\n",
      "linear.bias:\n",
      " [0.00022607]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480873e-03 -9.8867611e-05  3.6157599e-05  1.1188529e-04\n",
      "   1.7507630e-04  6.9042271e-06 -1.3868256e-04]]\n",
      "linear.bias:\n",
      " [0.00022637]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478938e-03 -9.8716133e-05  3.5839490e-05  9.0752015e-05\n",
      "   1.7369927e-04 -3.3057426e-05 -1.3776499e-04]]\n",
      "linear.bias:\n",
      " [0.00022644]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472228e-03 -9.8650467e-05  3.5261783e-05  9.6892589e-05\n",
      "   1.7159831e-04 -3.0653588e-05 -1.3729642e-04]]\n",
      "linear.bias:\n",
      " [0.0002267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466992e-03 -9.9393437e-05  3.4611247e-05  1.2375382e-04\n",
      "   1.6940282e-04  5.0076560e-06 -1.3704285e-04]]\n",
      "linear.bias:\n",
      " [0.00022694]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450775e-03 -9.9832170e-05  3.3548600e-05  8.9428941e-05\n",
      "   1.6809309e-04 -3.8208502e-05 -1.3721563e-04]]\n",
      "linear.bias:\n",
      " [0.00022665]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432843e-03 -1.0136045e-04  3.2652912e-05  8.6353175e-05\n",
      "   1.6709359e-04 -3.8983180e-05 -1.3735042e-04]]\n",
      "linear.bias:\n",
      " [0.0002263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417373e-03 -1.0162852e-04  3.2087148e-05  1.1619092e-04\n",
      "   1.6560797e-04  7.7396835e-06 -1.3812940e-04]]\n",
      "linear.bias:\n",
      " [0.00022568]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409848e-03 -1.0331965e-04  3.1552576e-05  1.0594437e-04\n",
      "   1.6646484e-04 -3.3234846e-06 -1.3819442e-04]]\n",
      "linear.bias:\n",
      " [0.00022492]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420069e-03 -1.0608760e-04  3.1233678e-05  7.4606316e-05\n",
      "   1.6951803e-04 -4.9780487e-05 -1.3688918e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04281411e-03 -1.06494655e-04  3.09605784e-05  9.65320069e-05\n",
      "   1.70115352e-04 -3.38174978e-05 -1.36634117e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04390108e-03 -1.04601204e-04  3.05293106e-05  1.39961019e-04\n",
      "   1.69257415e-04  2.41427733e-05 -1.37170427e-04]]\n",
      "linear.bias:\n",
      " [0.00022188]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430638e-03 -1.0015996e-04  2.9433177e-05  8.8519679e-05\n",
      "   1.6977631e-04 -6.0605420e-05 -1.3890138e-04]]\n",
      "linear.bias:\n",
      " [0.0002211]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427026e-03 -9.4290663e-05  2.8510301e-05  7.9810125e-05\n",
      "   1.6892664e-04 -6.8405039e-05 -1.4142304e-04]]\n",
      "linear.bias:\n",
      " [0.0002203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428273e-03 -8.8891909e-05  2.7716906e-05  1.3194441e-04\n",
      "   1.6670952e-04  1.5285557e-05 -1.4477552e-04]]\n",
      "linear.bias:\n",
      " [0.00021948]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423313e-03 -8.4972788e-05  2.7035059e-05  1.0627292e-04\n",
      "   1.6609480e-04 -6.2322306e-06 -1.4817319e-04]]\n",
      "linear.bias:\n",
      " [0.00021904]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428830e-03 -8.3808132e-05  2.6771273e-05  6.8234811e-05\n",
      "   1.6788008e-04 -5.8879108e-05 -1.4985158e-04]]\n",
      "linear.bias:\n",
      " [0.00021854]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429856e-03 -8.4488456e-05  2.6113636e-05  9.8204167e-05\n",
      "   1.7038178e-04 -4.0679442e-05 -1.5015900e-04]]\n",
      "linear.bias:\n",
      " [0.0002181]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422746e-03 -8.7258260e-05  2.5751191e-05  1.3950709e-04\n",
      "   1.7364309e-04  5.2582072e-06 -1.4976482e-04]]\n",
      "linear.bias:\n",
      " [0.00021779]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04135717e-03 -9.15355413e-05  2.54378938e-05  1.04811275e-04\n",
      "   1.76855276e-04 -2.55090963e-05 -1.49668238e-04]]\n",
      "linear.bias:\n",
      " [0.00021823]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410047e-03 -9.8174882e-05  2.5150557e-05  6.9561764e-05\n",
      "   1.8100433e-04 -5.4572618e-05 -1.4889282e-04]]\n",
      "linear.bias:\n",
      " [0.00021871]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417027e-03 -1.0439843e-04  2.5262314e-05  1.1097036e-04\n",
      "   1.8042664e-04  4.8118964e-06 -1.4949655e-04]]\n",
      "linear.bias:\n",
      " [0.00021885]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433408e-03 -1.1132967e-04  2.5689706e-05  1.2124688e-04\n",
      "   1.8083936e-04  1.7324028e-05 -1.4932120e-04]]\n",
      "linear.bias:\n",
      " [0.00021908]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434254e-03 -1.1578591e-04  2.6409565e-05  7.1271512e-05\n",
      "   1.8111103e-04 -6.7987552e-05 -1.4952989e-04]]\n",
      "linear.bias:\n",
      " [0.00021928]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04388327e-03 -1.15555464e-04  2.74008999e-05  9.88793472e-05\n",
      "   1.77676775e-04 -4.70333980e-05 -1.50781285e-04]]\n",
      "linear.bias:\n",
      " [0.00021936]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04387978e-03 -1.12096226e-04  2.82082528e-05  1.53224843e-04\n",
      "   1.73795182e-04  1.83000811e-05 -1.52390989e-04]]\n",
      "linear.bias:\n",
      " [0.00021954]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419687e-03 -1.0312790e-04  2.7751074e-05  1.0825193e-04\n",
      "   1.7165532e-04 -4.7387708e-05 -1.5463388e-04]]\n",
      "linear.bias:\n",
      " [0.00021969]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0395508e-03 -9.7267046e-05  2.7639986e-05  7.4256823e-05\n",
      "   1.7138160e-04 -8.0624020e-05 -1.5588943e-04]]\n",
      "linear.bias:\n",
      " [0.00021994]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03833328e-03 -9.12181276e-05  2.79685319e-05  1.20472105e-04\n",
      "   1.69968247e-04 -8.60141881e-07 -1.57033079e-04]]\n",
      "linear.bias:\n",
      " [0.00021975]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0388790e-03 -8.7619184e-05  2.8416471e-05  1.3760464e-04\n",
      "   1.7140622e-04  3.2020282e-05 -1.5662977e-04]]\n",
      "linear.bias:\n",
      " [0.00021938]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383832e-03 -8.4431733e-05  2.9249555e-05  7.6270779e-05\n",
      "   1.7435141e-04 -7.1236114e-05 -1.5618835e-04]]\n",
      "linear.bias:\n",
      " [0.00021925]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0385432e-03 -8.3763050e-05  2.9862160e-05  9.4915296e-05\n",
      "   1.7621851e-04 -7.6365985e-05 -1.5547304e-04]]\n",
      "linear.bias:\n",
      " [0.00021883]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0382347e-03 -8.5124288e-05  3.0458168e-05  1.4617696e-04\n",
      "   1.7849119e-04 -9.5488867e-06 -1.5454677e-04]]\n",
      "linear.bias:\n",
      " [0.00021886]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386306e-03 -8.7679022e-05  3.0530427e-05  1.3449279e-04\n",
      "   1.8088121e-04  3.2486878e-07 -1.5371203e-04]]\n",
      "linear.bias:\n",
      " [0.00021908]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391419e-03 -9.1422917e-05  3.0545641e-05  7.1419941e-05\n",
      "   1.8328660e-04 -3.9294093e-05 -1.5279934e-04]]\n",
      "linear.bias:\n",
      " [0.00021959]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397773e-03 -9.6722863e-05  3.0767758e-05  6.7270565e-05\n",
      "   1.8432977e-04 -3.6924168e-05 -1.5169455e-04]]\n",
      "linear.bias:\n",
      " [0.00021995]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04075775e-03 -1.01213045e-04  3.12400807e-05  1.28088461e-04\n",
      "   1.82263248e-04  1.28728243e-05 -1.51312051e-04]]\n",
      "linear.bias:\n",
      " [0.00022016]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419996e-03 -1.0479343e-04  3.2007087e-05  1.3041032e-04\n",
      "   1.8001194e-04 -2.1468306e-05 -1.5111925e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04335300e-03 -1.08173794e-04  3.23054810e-05  9.21713654e-05\n",
      "   1.78314353e-04 -8.54397222e-05 -1.50373700e-04]]\n",
      "linear.bias:\n",
      " [0.00022082]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447181e-03 -1.0891203e-04  3.2457807e-05  1.1503462e-04\n",
      "   1.7456127e-04 -3.8136419e-05 -1.5079907e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450698e-03 -1.0829796e-04  3.2724878e-05  1.2717210e-04\n",
      "   1.7274334e-04  1.7388600e-05 -1.5046036e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04457140e-03 -1.04960265e-04  3.28771057e-05  7.69362232e-05\n",
      "   1.71969630e-04 -2.60469496e-05 -1.50152569e-04]]\n",
      "linear.bias:\n",
      " [0.00022193]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437653e-03 -1.0279719e-04  3.3108918e-05  7.3956508e-05\n",
      "   1.7152679e-04 -3.0686861e-05 -1.4939505e-04]]\n",
      "linear.bias:\n",
      " [0.00022215]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04268198e-03 -1.01692305e-04  3.34124452e-05  1.13520597e-04\n",
      "   1.71382038e-04 -3.90780770e-07 -1.48232299e-04]]\n",
      "linear.bias:\n",
      " [0.00022236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427797e-03 -1.0164217e-04  3.3664295e-05  1.2243462e-04\n",
      "   1.7289919e-04 -1.1325817e-05 -1.4614657e-04]]\n",
      "linear.bias:\n",
      " [0.00022223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437825e-03 -1.0266134e-04  3.3736826e-05  9.8170225e-05\n",
      "   1.7569229e-04 -5.6189714e-05 -1.4353356e-04]]\n",
      "linear.bias:\n",
      " [0.00022202]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04458176e-03 -1.01312646e-04  3.36688900e-05  1.05076440e-04\n",
      "   1.76589718e-04 -5.11873077e-05 -1.41999713e-04]]\n",
      "linear.bias:\n",
      " [0.00022193]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457478e-03 -9.7572825e-05  3.3399239e-05  1.2947986e-04\n",
      "   1.7601038e-04 -4.0516970e-06 -1.4160298e-04]]\n",
      "linear.bias:\n",
      " [0.00022205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467618e-03 -9.5028838e-05  3.2665888e-05  9.3928524e-05\n",
      "   1.7504810e-04 -9.1689326e-06 -1.4164601e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483174e-03 -9.5019110e-05  3.1991298e-05  6.8466274e-05\n",
      "   1.7442700e-04 -2.6622231e-05 -1.4113208e-04]]\n",
      "linear.bias:\n",
      " [0.00022292]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497128e-03 -9.7410470e-05  3.1504671e-05  9.8931676e-05\n",
      "   1.7287279e-04 -3.0360115e-06 -1.4062665e-04]]\n",
      "linear.bias:\n",
      " [0.00022295]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05201208e-03 -1.01105987e-04  3.12604534e-05  1.12850415e-04\n",
      "   1.72816275e-04 -1.23150194e-05 -1.39083088e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0544760e-03 -1.0568832e-04  3.1025567e-05  9.6474942e-05\n",
      "   1.7374837e-04 -5.3172516e-05 -1.3698923e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0565907e-03 -1.0753955e-04  3.0680298e-05  1.1054118e-04\n",
      "   1.7296379e-04 -4.4487882e-05 -1.3592602e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05781073e-03 -1.05714396e-04  3.03145389e-05  1.36159972e-04\n",
      "   1.71308231e-04  3.69985355e-06 -1.35729773e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05651119e-03 -1.01209764e-04  2.91344222e-05  8.22946895e-05\n",
      "   1.69930543e-04 -3.16353617e-05 -1.36802992e-04]]\n",
      "linear.bias:\n",
      " [0.00022353]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0543682e-03 -9.8511642e-05  2.8419598e-05  5.9412319e-05\n",
      "   1.6887579e-04 -2.8568238e-05 -1.3758958e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0521468e-03 -9.4664079e-05  2.7878934e-05  1.0654614e-04\n",
      "   1.6578657e-04  2.4467254e-05 -1.3910377e-04]]\n",
      "linear.bias:\n",
      " [0.00022402]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492761e-03 -9.3570430e-05  2.8077186e-05  1.1442174e-04\n",
      "   1.6463677e-04 -1.9411118e-05 -1.4015650e-04]]\n",
      "linear.bias:\n",
      " [0.00022383]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470365e-03 -9.4270268e-05  2.8451739e-05  9.8753968e-05\n",
      "   1.6529762e-04 -8.5185806e-05 -1.4013970e-04]]\n",
      "linear.bias:\n",
      " [0.00022356]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449917e-03 -9.2200047e-05  2.8791064e-05  1.2785815e-04\n",
      "   1.6558392e-04 -4.7244605e-05 -1.4100224e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433138e-03 -9.3123708e-05  2.8893861e-05  1.3829271e-04\n",
      "   1.6800246e-04  9.6929034e-06 -1.4105861e-04]]\n",
      "linear.bias:\n",
      " [0.0002237]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402545e-03 -9.4351599e-05  2.8799641e-05  6.7642664e-05\n",
      "   1.7111191e-04 -3.6282756e-05 -1.4177362e-04]]\n",
      "linear.bias:\n",
      " [0.00022416]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0376507e-03 -9.8027216e-05  2.8912076e-05  6.0160641e-05\n",
      "   1.7247282e-04 -3.5201880e-05 -1.4280493e-04]]\n",
      "linear.bias:\n",
      " [0.00022416]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0355051e-03 -1.0126565e-04  2.9202802e-05  1.1999256e-04\n",
      "   1.7184070e-04  1.6852846e-05 -1.4443466e-04]]\n",
      "linear.bias:\n",
      " [0.00022355]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03354594e-03 -1.04115570e-04  2.98313989e-05  1.21030316e-04\n",
      "   1.71578460e-04 -2.57214379e-05 -1.45909071e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0335360e-03 -1.0673558e-04  3.0085565e-05  9.6208481e-05\n",
      "   1.7297055e-04 -8.6845714e-05 -1.4622380e-04]]\n",
      "linear.bias:\n",
      " [0.000222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0338745e-03 -1.0634170e-04  3.0331692e-05  1.2209498e-04\n",
      "   1.7313346e-04 -3.8250419e-05 -1.4741624e-04]]\n",
      "linear.bias:\n",
      " [0.00022129]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03567750e-03 -1.05899460e-04  2.99896292e-05  1.31848719e-04\n",
      "   1.74564906e-04  1.40506745e-05 -1.47812971e-04]]\n",
      "linear.bias:\n",
      " [0.00022096]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0379032e-03 -1.0300596e-04  2.9223962e-05  7.5102478e-05\n",
      "   1.7564118e-04 -2.9576611e-05 -1.4877190e-04]]\n",
      "linear.bias:\n",
      " [0.00022066]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03958452e-03 -1.01220845e-04  2.87237108e-05  6.81040547e-05\n",
      "   1.76605929e-04 -3.42472777e-05 -1.49231826e-04]]\n",
      "linear.bias:\n",
      " [0.0002205]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411565e-03 -9.8007600e-05  2.8633438e-05  1.1312392e-04\n",
      "   1.7626886e-04  6.3109255e-06 -1.4981572e-04]]\n",
      "linear.bias:\n",
      " [0.00022025]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435245e-03 -9.7253214e-05  2.8849407e-05  1.2573788e-04\n",
      "   1.7751293e-04  1.2838241e-06 -1.4945610e-04]]\n",
      "linear.bias:\n",
      " [0.00022013]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460309e-03 -9.7840479e-05  2.9359704e-05  9.1517773e-05\n",
      "   1.7902872e-04 -5.7105019e-05 -1.4886929e-04]]\n",
      "linear.bias:\n",
      " [0.00022012]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477646e-03 -9.6135060e-05  2.9794895e-05  9.4409173e-05\n",
      "   1.7934796e-04 -6.1218605e-05 -1.4876781e-04]]\n",
      "linear.bias:\n",
      " [0.00022022]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488955e-03 -9.2398746e-05  3.0173778e-05  1.3455517e-04\n",
      "   1.7833337e-04 -2.7126916e-06 -1.4907219e-04]]\n",
      "linear.bias:\n",
      " [0.00022051]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499998e-03 -9.0669055e-05  3.0241039e-05  1.1431638e-04\n",
      "   1.7735448e-04  5.9760328e-07 -1.4959458e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512675e-03 -9.1348200e-05  3.0587518e-05  6.8227906e-05\n",
      "   1.7795654e-04 -4.0235311e-05 -1.4911850e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0521929e-03 -9.4218361e-05  3.0903797e-05  8.8650282e-05\n",
      "   1.7742271e-04 -3.5099369e-05 -1.4869098e-04]]\n",
      "linear.bias:\n",
      " [0.00022174]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0520412e-03 -9.8178301e-05  3.1540858e-05  1.3268960e-04\n",
      "   1.7713020e-04  4.1983076e-06 -1.4812389e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05021195e-03 -1.02184014e-04  3.16161386e-05  1.07803295e-04\n",
      "   1.76505288e-04 -2.31552694e-05 -1.48233827e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "Epoch [2500/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476565e-03 -1.0576306e-04  3.1794261e-05  7.6347766e-05\n",
      "   1.7657838e-04 -5.2885836e-05 -1.4778745e-04]]\n",
      "linear.bias:\n",
      " [0.00022228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452373e-03 -1.0673731e-04  3.1985743e-05  9.6753050e-05\n",
      "   1.7439228e-04 -2.5794085e-05 -1.4806537e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420858e-03 -1.0933535e-04  3.2458272e-05  1.2798989e-04\n",
      "   1.7300881e-04  1.3527431e-05 -1.4784781e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0390676e-03 -1.0827358e-04  3.2628031e-05  9.5365293e-05\n",
      "   1.7246538e-04 -3.6656817e-05 -1.4774952e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363644e-03 -1.0763014e-04  3.2598029e-05  8.7107983e-05\n",
      "   1.7191865e-04 -4.6521749e-05 -1.4772652e-04]]\n",
      "linear.bias:\n",
      " [0.00022315]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03387737e-03 -1.05011190e-04  3.26135378e-05  1.09598506e-04\n",
      "   1.70417174e-04 -9.58927558e-06 -1.48273466e-04]]\n",
      "linear.bias:\n",
      " [0.00022315]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0335449e-03 -1.0358086e-04  3.2710985e-05  1.1063258e-04\n",
      "   1.7149458e-04 -1.2294986e-05 -1.4717606e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0350202e-03 -1.0359280e-04  3.2968386e-05  8.9388734e-05\n",
      "   1.7484694e-04 -5.0305014e-05 -1.4476391e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03629590e-03 -1.01560676e-04  3.32427662e-05  1.00224752e-04\n",
      "   1.76854897e-04 -3.86769570e-05 -1.43160374e-04]]\n",
      "linear.bias:\n",
      " [0.00022115]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03881198e-03 -1.00712816e-04  3.27295311e-05  1.27247054e-04\n",
      "   1.78002854e-04  3.45661101e-06 -1.41972923e-04]]\n",
      "linear.bias:\n",
      " [0.00022052]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409866e-03 -9.9232166e-05  3.1640840e-05  9.4085146e-05\n",
      "   1.7746130e-04 -2.1803065e-05 -1.4199546e-04]]\n",
      "linear.bias:\n",
      " [0.00022047]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442184e-03 -9.9627272e-05  3.0170460e-05  7.8059653e-05\n",
      "   1.7669681e-04 -2.7827975e-05 -1.4209062e-04]]\n",
      "linear.bias:\n",
      " [0.00022032]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472775e-03 -1.0102400e-04  2.9105275e-05  1.0408158e-04\n",
      "   1.7604750e-04 -1.2234086e-06 -1.4190607e-04]]\n",
      "linear.bias:\n",
      " [0.00022019]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05120370e-03 -1.03704951e-04  2.83090467e-05  1.08748194e-04\n",
      "   1.76761605e-04 -1.32019959e-05 -1.40618067e-04]]\n",
      "linear.bias:\n",
      " [0.00021986]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541290e-03 -1.0585890e-04  2.7797591e-05  9.4256713e-05\n",
      "   1.7810776e-04 -4.3842523e-05 -1.3889404e-04]]\n",
      "linear.bias:\n",
      " [0.00021988]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0566970e-03 -1.0543399e-04  2.7294460e-05  1.1190523e-04\n",
      "   1.7739157e-04 -2.5858693e-05 -1.3826875e-04]]\n",
      "linear.bias:\n",
      " [0.0002201]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05735334e-03 -1.05719373e-04  2.68154672e-05  1.16842486e-04\n",
      "   1.76948437e-04 -7.95145934e-06 -1.37739014e-04]]\n",
      "linear.bias:\n",
      " [0.00022073]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0564645e-03 -1.0514156e-04  2.6701142e-05  8.0988393e-05\n",
      "   1.7597170e-04 -3.0569223e-05 -1.3746004e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0549516e-03 -1.0340412e-04  2.6952966e-05  8.3739680e-05\n",
      "   1.7344193e-04 -7.3769770e-06 -1.3783835e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0521011e-03 -1.0336425e-04  2.7637750e-05  1.0455935e-04\n",
      "   1.7105009e-04  1.1975775e-05 -1.3779306e-04]]\n",
      "linear.bias:\n",
      " [0.00022329]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488866e-03 -1.0440714e-04  2.8679935e-05  9.0740519e-05\n",
      "   1.6929363e-04 -4.5517885e-05 -1.3754571e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459387e-03 -1.0328888e-04  2.9661309e-05  1.0839316e-04\n",
      "   1.6669398e-04 -5.1313466e-05 -1.3789559e-04]]\n",
      "linear.bias:\n",
      " [0.00022387]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433923e-03 -1.0011376e-04  3.0805812e-05  1.3695419e-04\n",
      "   1.6410285e-04 -1.7080125e-05 -1.3876471e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420805e-03 -9.8844343e-05  3.1318683e-05  1.1121910e-04\n",
      "   1.6322221e-04 -3.0061154e-05 -1.3919771e-04]]\n",
      "linear.bias:\n",
      " [0.00022424]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04173331e-03 -1.00380814e-04  3.17494014e-05  8.38534106e-05\n",
      "   1.63872843e-04 -2.56259664e-05 -1.39012802e-04]]\n",
      "linear.bias:\n",
      " [0.00022466]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417700e-03 -1.0282832e-04  3.2346208e-05  8.4705236e-05\n",
      "   1.6505303e-04  6.7561232e-06 -1.3858925e-04]]\n",
      "linear.bias:\n",
      " [0.00022483]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446620e-03 -1.0569520e-04  3.2740863e-05  8.5012311e-05\n",
      "   1.6803783e-04  1.0633821e-06 -1.3685229e-04]]\n",
      "linear.bias:\n",
      " [0.00022446]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04884966e-03 -1.09554945e-04  3.29561299e-05  8.56578263e-05\n",
      "   1.71359192e-04 -2.81117136e-05 -1.34411690e-04]]\n",
      "linear.bias:\n",
      " [0.00022391]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05251337e-03 -1.10685076e-04  3.30120747e-05  1.15376191e-04\n",
      "   1.72675820e-04 -8.96584061e-06 -1.33061723e-04]]\n",
      "linear.bias:\n",
      " [0.00022352]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05405413e-03 -1.09578192e-04  3.28430287e-05  1.02365666e-04\n",
      "   1.73496068e-04 -2.70244745e-05 -1.32170549e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0546463e-03 -1.0479564e-04  3.2645588e-05  1.0203292e-04\n",
      "   1.7305485e-04 -1.4924472e-05 -1.3216518e-04]]\n",
      "linear.bias:\n",
      " [0.00022387]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0539211e-03 -1.0079838e-04  3.2457669e-05  9.4296120e-05\n",
      "   1.7251301e-04 -5.3474623e-06 -1.3233299e-04]]\n",
      "linear.bias:\n",
      " [0.00022422]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525269e-03 -9.8523909e-05  3.2656939e-05  9.5123905e-05\n",
      "   1.7225381e-04 -6.9903299e-06 -1.3205159e-04]]\n",
      "linear.bias:\n",
      " [0.00022443]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505299e-03 -9.7801509e-05  3.3205069e-05  1.0366804e-04\n",
      "   1.7224927e-04 -1.8741690e-05 -1.3136542e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478096e-03 -9.7645534e-05  3.3621505e-05  1.0959661e-04\n",
      "   1.7229642e-04 -2.3518856e-05 -1.3080629e-04]]\n",
      "linear.bias:\n",
      " [0.00022492]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451209e-03 -9.9158089e-05  3.3329765e-05  9.9417128e-05\n",
      "   1.7226292e-04 -2.2192384e-05 -1.3073011e-04]]\n",
      "linear.bias:\n",
      " [0.00022559]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04391121e-03 -1.01386664e-04  3.22918895e-05  1.04366256e-04\n",
      "   1.71479987e-04  1.49662264e-06 -1.31037697e-04]]\n",
      "linear.bias:\n",
      " [0.00022619]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435554e-03 -1.0418962e-04  3.1474039e-05  8.2754676e-05\n",
      "   1.7171558e-04 -2.2485106e-05 -1.3059289e-04]]\n",
      "linear.bias:\n",
      " [0.00022642]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432751e-03 -1.0510806e-04  3.1030952e-05  9.6378411e-05\n",
      "   1.7075255e-04 -1.3272032e-05 -1.3102533e-04]]\n",
      "linear.bias:\n",
      " [0.00022631]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435578e-03 -1.0660433e-04  3.0834599e-05  1.1956650e-04\n",
      "   1.7014501e-04 -5.9845847e-06 -1.3131851e-04]]\n",
      "linear.bias:\n",
      " [0.000226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440582e-03 -1.0759583e-04  3.0077501e-05  9.7113589e-05\n",
      "   1.6914590e-04 -3.7858186e-05 -1.3188005e-04]]\n",
      "linear.bias:\n",
      " [0.00022582]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04489608e-03 -1.06138395e-04  2.92180885e-05  1.02124388e-04\n",
      "   1.66715559e-04 -2.23709976e-05 -1.33449765e-04]]\n",
      "linear.bias:\n",
      " [0.00022556]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451865e-03 -1.0554861e-04  2.8629196e-05  1.1119566e-04\n",
      "   1.6477522e-04  7.7094955e-06 -1.3504105e-04]]\n",
      "linear.bias:\n",
      " [0.00022532]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04556722e-03 -1.05962514e-04  2.82136753e-05  8.34515231e-05\n",
      "   1.64317942e-04 -3.11197255e-05 -1.36354050e-04]]\n",
      "linear.bias:\n",
      " [0.00022489]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461940e-03 -1.0500745e-04  2.8280945e-05  9.3107679e-05\n",
      "   1.6353451e-04 -2.6904416e-05 -1.3778958e-04]]\n",
      "linear.bias:\n",
      " [0.00022429]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04645197e-03 -1.05454914e-04  2.88126121e-05  1.25564926e-04\n",
      "   1.63492557e-04  4.15535214e-06 -1.38691074e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04581157e-03 -1.05305066e-04  2.91997185e-05  9.56149524e-05\n",
      "   1.64989775e-04 -4.60739975e-05 -1.39681972e-04]]\n",
      "linear.bias:\n",
      " [0.00022245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456732e-03 -1.0304462e-04  2.9533589e-05  9.3800838e-05\n",
      "   1.6550938e-04 -4.7743724e-05 -1.4111496e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451970e-03 -1.0219006e-04  2.9935914e-05  1.2021752e-04\n",
      "   1.6610783e-04 -1.2902943e-05 -1.4234976e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451989e-03 -1.0369544e-04  3.0481926e-05  1.1032392e-04\n",
      "   1.6879449e-04 -1.8332637e-05 -1.4254793e-04]]\n",
      "linear.bias:\n",
      " [0.00021975]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463347e-03 -1.0687324e-04  3.1181728e-05  8.3269682e-05\n",
      "   1.7286904e-04 -4.1992731e-05 -1.4172928e-04]]\n",
      "linear.bias:\n",
      " [0.00021914]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468587e-03 -1.0739284e-04  3.1883010e-05  9.4986368e-05\n",
      "   1.7518768e-04 -1.4008379e-05 -1.4151978e-04]]\n",
      "linear.bias:\n",
      " [0.00021879]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469594e-03 -1.0828779e-04  3.2305434e-05  1.1732854e-04\n",
      "   1.7703699e-04  1.5323069e-05 -1.4126461e-04]]\n",
      "linear.bias:\n",
      " [0.0002188]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459051e-03 -1.0606826e-04  3.1979995e-05  8.0851532e-05\n",
      "   1.7726595e-04 -4.1475869e-05 -1.4250002e-04]]\n",
      "linear.bias:\n",
      " [0.00021913]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442784e-03 -1.0155595e-04  3.1487296e-05  8.8035369e-05\n",
      "   1.7528716e-04 -4.2658517e-05 -1.4440808e-04]]\n",
      "linear.bias:\n",
      " [0.00021965]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427594e-03 -9.5396994e-05  3.1087322e-05  1.2497403e-04\n",
      "   1.7246835e-04  2.5852387e-06 -1.4670956e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04250677e-03 -9.11893585e-05  3.08577874e-05  1.12510905e-04\n",
      "   1.71051492e-04 -1.08462391e-05 -1.48279403e-04]]\n",
      "linear.bias:\n",
      " [0.00022063]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435183e-03 -8.9616631e-05  3.0988373e-05  7.6983466e-05\n",
      "   1.7221677e-04 -6.1083265e-05 -1.4836242e-04]]\n",
      "linear.bias:\n",
      " [0.00022099]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445939e-03 -9.0584064e-05  3.1061354e-05  9.8451252e-05\n",
      "   1.7256488e-04 -4.0835337e-05 -1.4837172e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462281e-03 -9.4263763e-05  3.0981646e-05  1.3281507e-04\n",
      "   1.7352743e-04  2.4147557e-06 -1.4783903e-04]]\n",
      "linear.bias:\n",
      " [0.0002216]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478637e-03 -9.9107165e-05  3.0857023e-05  1.0985631e-04\n",
      "   1.7466258e-04 -7.3891224e-06 -1.4718871e-04]]\n",
      "linear.bias:\n",
      " [0.00022208]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505391e-03 -1.0492935e-04  3.0912066e-05  7.0104317e-05\n",
      "   1.7701786e-04 -5.2487863e-05 -1.4545163e-04]]\n",
      "linear.bias:\n",
      " [0.0002223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05254608e-03 -1.07590866e-04  3.08233830e-05  9.49890018e-05\n",
      "   1.76885747e-04 -2.38831508e-05 -1.44407270e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0534225e-03 -1.1019702e-04  3.0678944e-05  1.3110117e-04\n",
      "   1.7610460e-04  2.2610950e-05 -1.4365700e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0518368e-03 -1.0892906e-04  2.9886420e-05  8.4560299e-05\n",
      "   1.7549899e-04 -5.8931539e-05 -1.4450637e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497570e-03 -1.0557694e-04  2.9219142e-05  9.3246534e-05\n",
      "   1.7213456e-04 -6.0287570e-05 -1.4607466e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473396e-03 -1.0023384e-04  2.8592955e-05  1.3547705e-04\n",
      "   1.6801691e-04 -1.2676763e-05 -1.4793110e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460946e-03 -9.7708580e-05  2.8004964e-05  1.2689499e-04\n",
      "   1.6673045e-04 -1.2035711e-05 -1.4855464e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459151e-03 -9.7476302e-05  2.7484170e-05  8.4643958e-05\n",
      "   1.6817989e-04 -4.8922258e-05 -1.4800156e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449069e-03 -9.8244840e-05  2.7048663e-05  7.8668796e-05\n",
      "   1.6957217e-04 -4.3193453e-05 -1.4730451e-04]]\n",
      "linear.bias:\n",
      " [0.00022281]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436199e-03 -9.9830810e-05  2.6757016e-05  1.1663971e-04\n",
      "   1.7109531e-04 -3.3981414e-06 -1.4616712e-04]]\n",
      "linear.bias:\n",
      " [0.00022285]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430652e-03 -1.0343497e-04  2.6821048e-05  1.2273915e-04\n",
      "   1.7487514e-04 -7.5198504e-06 -1.4389554e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426032e-03 -1.0806992e-04  2.7069129e-05  9.1149079e-05\n",
      "   1.7889819e-04 -4.9929724e-05 -1.4143970e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422787e-03 -1.0991253e-04  2.7308413e-05  9.5474206e-05\n",
      "   1.8012014e-04 -4.0190393e-05 -1.4038268e-04]]\n",
      "linear.bias:\n",
      " [0.00022246]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04191829e-03 -1.09130415e-04  2.74799313e-05  1.30609435e-04\n",
      "   1.79229392e-04  1.44606674e-05 -1.40388176e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04152306e-03 -1.05247294e-04  2.70783021e-05  9.53110502e-05\n",
      "   1.76898888e-04 -2.68991353e-05 -1.41876502e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04105740e-03 -1.02570455e-04  2.65914205e-05  8.37759289e-05\n",
      "   1.74367087e-04 -4.01828838e-05 -1.43457277e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04075298e-03 -9.88373358e-05  2.65291783e-05  1.07035376e-04\n",
      "   1.71162290e-04 -7.72051135e-06 -1.45393977e-04]]\n",
      "linear.bias:\n",
      " [0.00022347]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416402e-03 -9.7398995e-05  2.6864787e-05  1.1517347e-04\n",
      "   1.7037091e-04 -8.4618014e-06 -1.4570322e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437750e-03 -9.7713732e-05  2.7521410e-05  1.0059470e-04\n",
      "   1.7169482e-04 -4.4254852e-05 -1.4469348e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04516873e-03 -9.93954891e-05  2.84217112e-05  1.08458975e-04\n",
      "   1.73291221e-04 -4.42092132e-05 -1.43553014e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461175e-03 -1.0127796e-04  2.9356499e-05  1.2218207e-04\n",
      "   1.7525774e-04 -1.3564426e-05 -1.4253161e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04730867e-03 -1.03529499e-04  2.99770545e-05  1.00714526e-04\n",
      "   1.77708192e-04 -1.83586199e-05 -1.41186931e-04]]\n",
      "linear.bias:\n",
      " [0.00022234]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471272e-03 -1.0640978e-04  3.0447671e-05  8.5811320e-05\n",
      "   1.7946685e-04 -1.6055485e-05 -1.3985793e-04]]\n",
      "linear.bias:\n",
      " [0.00022264]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465257e-03 -1.0991036e-04  3.1083986e-05  1.0062548e-04\n",
      "   1.8039568e-04 -1.6544982e-07 -1.3881113e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456329e-03 -1.1185358e-04  3.1955598e-05  9.8309312e-05\n",
      "   1.8129671e-04 -2.4770512e-05 -1.3720315e-04]]\n",
      "linear.bias:\n",
      " [0.00022304]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04504009e-03 -1.11009744e-04  3.25349938e-05  1.17182150e-04\n",
      "   1.80503470e-04 -1.34001557e-05 -1.36708171e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445599e-03 -1.1024528e-04  3.2579428e-05  8.9555702e-05\n",
      "   1.7907024e-04 -4.3304273e-05 -1.3668180e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442245e-03 -1.0725876e-04  3.2655214e-05  9.8797500e-05\n",
      "   1.7531036e-04 -2.0898813e-05 -1.3807857e-04]]\n",
      "linear.bias:\n",
      " [0.0002237]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04367163e-03 -1.04462815e-04  3.23715831e-05  1.21121258e-04\n",
      "   1.71207590e-04  2.08783422e-05 -1.39725016e-04]]\n",
      "linear.bias:\n",
      " [0.00022419]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426377e-03 -1.0042509e-04  3.1769017e-05  7.3093921e-05\n",
      "   1.6737096e-04 -4.5485762e-05 -1.4246340e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417214e-03 -9.5161507e-05  3.1471518e-05  8.1250029e-05\n",
      "   1.6298283e-04 -5.9050879e-05 -1.4505374e-04]]\n",
      "linear.bias:\n",
      " [0.00022471]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404120e-03 -9.2936549e-05  3.0998741e-05  1.2811436e-04\n",
      "   1.5967507e-04 -2.3869110e-05 -1.4707897e-04]]\n",
      "linear.bias:\n",
      " [0.00022478]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400354e-03 -9.3455368e-05  3.0287962e-05  1.3309059e-04\n",
      "   1.5991145e-04 -2.4796607e-05 -1.4737272e-04]]\n",
      "linear.bias:\n",
      " [0.00022484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405467e-03 -9.6507625e-05  2.9392606e-05  9.7553871e-05\n",
      "   1.6337735e-04 -6.0069848e-05 -1.4626441e-04]]\n",
      "linear.bias:\n",
      " [0.000225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413307e-03 -1.0031104e-04  2.8573389e-05  8.8326968e-05\n",
      "   1.6825915e-04 -4.8726808e-05 -1.4491605e-04]]\n",
      "linear.bias:\n",
      " [0.00022504]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421107e-03 -1.0243672e-04  2.8117172e-05  1.1211748e-04\n",
      "   1.7199856e-04  5.7466095e-06 -1.4413119e-04]]\n",
      "linear.bias:\n",
      " [0.00022496]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434528e-03 -1.0562774e-04  2.7862996e-05  1.0668334e-04\n",
      "   1.7669291e-04  1.7045899e-05 -1.4250167e-04]]\n",
      "linear.bias:\n",
      " [0.00022468]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437286e-03 -1.0883214e-04  2.8026778e-05  6.4224063e-05\n",
      "   1.8023243e-04 -5.2968939e-05 -1.4107421e-04]]\n",
      "linear.bias:\n",
      " [0.00022398]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04409375e-03 -1.09246124e-04  2.79984979e-05  1.14118207e-04\n",
      "   1.78373783e-04 -2.00840768e-05 -1.41760800e-04]]\n",
      "linear.bias:\n",
      " [0.00022291]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04392506e-03 -1.09360604e-04  2.81793582e-05  1.41237775e-04\n",
      "   1.77272756e-04 -4.71049316e-06 -1.41889192e-04]]\n",
      "linear.bias:\n",
      " [0.00022239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04312622e-03 -1.07947904e-04  2.77434701e-05  9.36318684e-05\n",
      "   1.75495457e-04 -5.62945061e-05 -1.42725141e-04]]\n",
      "linear.bias:\n",
      " [0.00022236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04251364e-03 -1.04636856e-04  2.74565482e-05  8.30604040e-05\n",
      "   1.72414206e-04 -5.44370196e-05 -1.44276943e-04]]\n",
      "linear.bias:\n",
      " [0.00022223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414852e-03 -9.9476827e-05  2.7242435e-05  1.1654851e-04\n",
      "   1.6765793e-04 -2.1446613e-07 -1.4640784e-04]]\n",
      "linear.bias:\n",
      " [0.0002221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417385e-03 -9.6845368e-05  2.7231808e-05  1.1485317e-04\n",
      "   1.6630959e-04  6.0333159e-06 -1.4702056e-04]]\n",
      "linear.bias:\n",
      " [0.00022177]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429445e-03 -9.6785203e-05  2.7563261e-05  7.8298624e-05\n",
      "   1.6785272e-04 -3.4114080e-05 -1.4640462e-04]]\n",
      "linear.bias:\n",
      " [0.00022136]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441446e-03 -9.7863602e-05  2.8035010e-05  8.5148356e-05\n",
      "   1.6956283e-04 -3.8236718e-05 -1.4547593e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448623e-03 -1.0005390e-04  2.8564795e-05  1.1970796e-04\n",
      "   1.7123755e-04 -5.6044410e-06 -1.4458229e-04]]\n",
      "linear.bias:\n",
      " [0.00022046]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459143e-03 -1.0430901e-04  2.9375266e-05  1.1545380e-04\n",
      "   1.7437869e-04 -2.1916519e-05 -1.4308856e-04]]\n",
      "linear.bias:\n",
      " [0.00022018]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04784593e-03 -1.08879714e-04  2.98924115e-05  9.08459187e-05\n",
      "   1.77828071e-04 -5.39355096e-05 -1.41167489e-04]]\n",
      "linear.bias:\n",
      " [0.00022026]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04917691e-03 -1.10395820e-04  3.03033685e-05  1.05685394e-04\n",
      "   1.78439033e-04 -3.20923209e-05 -1.40469347e-04]]\n",
      "linear.bias:\n",
      " [0.00022055]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497592e-03 -1.0797611e-04  3.0640440e-05  1.2974764e-04\n",
      "   1.7786484e-04  2.3813391e-05 -1.4052946e-04]]\n",
      "linear.bias:\n",
      " [0.00022126]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04769913e-03 -1.01983875e-04  3.02764329e-05  7.22793338e-05\n",
      "   1.76613888e-04 -4.26421720e-05 -1.42435165e-04]]\n",
      "linear.bias:\n",
      " [0.00022234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458491e-03 -9.5049872e-05  3.0220664e-05  7.2104573e-05\n",
      "   1.7350195e-04 -5.0214829e-05 -1.4470507e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445615e-03 -8.8458648e-05  3.0370633e-05  1.2553908e-04\n",
      "   1.6867240e-04 -3.1088312e-06 -1.4738852e-04]]\n",
      "linear.bias:\n",
      " [0.00022364]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443853e-03 -8.4845247e-05  3.0848547e-05  1.3856635e-04\n",
      "   1.6709567e-04 -6.4314154e-06 -1.4863092e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451834e-03 -8.3938867e-05  3.1254138e-05  1.0322973e-04\n",
      "   1.6816221e-04 -5.1674841e-05 -1.4867338e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471365e-03 -8.7079432e-05  3.1428819e-05  9.0531925e-05\n",
      "   1.6996049e-04 -6.0287523e-05 -1.4826235e-04]]\n",
      "linear.bias:\n",
      " [0.00022409]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04880880e-03 -9.26940265e-05  3.15700818e-05  1.08788015e-04\n",
      "   1.72159693e-04 -2.76016217e-05 -1.47739789e-04]]\n",
      "linear.bias:\n",
      " [0.00022389]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509230e-03 -1.0067422e-04  3.1681884e-05  1.2316799e-04\n",
      "   1.7553396e-04  8.6590371e-06 -1.4656443e-04]]\n",
      "linear.bias:\n",
      " [0.00022371]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0514073e-03 -1.0870668e-04  3.2226941e-05  8.1547056e-05\n",
      "   1.7860410e-04 -3.2923876e-05 -1.4547509e-04]]\n",
      "linear.bias:\n",
      " [0.00022332]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0511412e-03 -1.1333352e-04  3.2510743e-05  8.4619329e-05\n",
      "   1.7910321e-04 -2.0483320e-05 -1.4531908e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05040567e-03 -1.13502960e-04  3.26737463e-05  1.18185315e-04\n",
      "   1.78169474e-04  2.22706767e-05 -1.45885366e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04800297e-03 -1.10075394e-04  3.25971851e-05  8.30378049e-05\n",
      "   1.77186841e-04 -3.94486015e-05 -1.47164217e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04514998e-03 -1.04711355e-04  3.24114080e-05  9.12595206e-05\n",
      "   1.75002089e-04 -4.48420324e-05 -1.48763997e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425246e-03 -9.7704753e-05  3.2289503e-05  1.2953172e-04\n",
      "   1.7195786e-04 -3.5145713e-06 -1.5081036e-04]]\n",
      "linear.bias:\n",
      " [0.00022251]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411225e-03 -9.3755501e-05  3.2154832e-05  1.1682392e-04\n",
      "   1.7171637e-04 -8.5377887e-06 -1.5157096e-04]]\n",
      "linear.bias:\n",
      " [0.00022236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416695e-03 -9.2235750e-05  3.2201177e-05  8.0001140e-05\n",
      "   1.7448618e-04 -5.1868235e-05 -1.5067639e-04]]\n",
      "linear.bias:\n",
      " [0.000222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419296e-03 -9.3025628e-05  3.2136340e-05  8.9485635e-05\n",
      "   1.7687361e-04 -5.0708997e-05 -1.4956789e-04]]\n",
      "linear.bias:\n",
      " [0.00022167]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417965e-03 -9.4970630e-05  3.2184191e-05  1.2652462e-04\n",
      "   1.7915985e-04 -1.3376961e-05 -1.4851164e-04]]\n",
      "linear.bias:\n",
      " [0.00022138]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421437e-03 -9.8308352e-05  3.2021984e-05  1.2263657e-04\n",
      "   1.8245900e-04 -1.3499275e-05 -1.4688840e-04]]\n",
      "linear.bias:\n",
      " [0.00022123]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425196e-03 -1.0152885e-04  3.1639702e-05  8.6257438e-05\n",
      "   1.8580230e-04 -4.5214671e-05 -1.4487110e-04]]\n",
      "linear.bias:\n",
      " [0.00022098]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427928e-03 -1.0208364e-04  3.1224710e-05  9.5473501e-05\n",
      "   1.8566509e-04 -2.2124748e-05 -1.4435964e-04]]\n",
      "linear.bias:\n",
      " [0.00022064]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428068e-03 -1.0251973e-04  3.0612009e-05  1.2140022e-04\n",
      "   1.8450458e-04  2.0972717e-05 -1.4432533e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419391e-03 -1.0178726e-04  3.0051535e-05  7.8438577e-05\n",
      "   1.8216728e-04 -4.4920038e-05 -1.4566432e-04]]\n",
      "linear.bias:\n",
      " [0.00022072]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409737e-03 -9.8412973e-05  2.9388511e-05  8.9099973e-05\n",
      "   1.7695004e-04 -5.0591385e-05 -1.4789036e-04]]\n",
      "linear.bias:\n",
      " [0.00022097]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0401799e-03 -9.4046954e-05  2.9079087e-05  1.3098418e-04\n",
      "   1.7158111e-04 -1.1585333e-05 -1.5033355e-04]]\n",
      "linear.bias:\n",
      " [0.00022108]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404327e-03 -9.2489528e-05  2.8775408e-05  1.2142972e-04\n",
      "   1.6926111e-04 -1.8699962e-05 -1.5144506e-04]]\n",
      "linear.bias:\n",
      " [0.00022118]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422575e-03 -9.3203620e-05  2.8494031e-05  8.4417901e-05\n",
      "   1.6989639e-04 -5.8883525e-05 -1.5102989e-04]]\n",
      "linear.bias:\n",
      " [0.00022116]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431267e-03 -9.5255855e-05  2.8115721e-05  9.2840077e-05\n",
      "   1.7089328e-04 -3.5546753e-05 -1.5022040e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433632e-03 -9.8548160e-05  2.8094255e-05  1.2165378e-04\n",
      "   1.7220851e-04  1.7703944e-05 -1.4925264e-04]]\n",
      "linear.bias:\n",
      " [0.00022154]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436042e-03 -1.0173866e-04  2.8666680e-05  9.3837058e-05\n",
      "   1.7442051e-04 -2.3701894e-05 -1.4809848e-04]]\n",
      "linear.bias:\n",
      " [0.00022126]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429953e-03 -1.0639964e-04  2.9682795e-05  8.5092572e-05\n",
      "   1.7732472e-04 -5.0982475e-05 -1.4638135e-04]]\n",
      "linear.bias:\n",
      " [0.00022078]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419226e-03 -1.0813563e-04  3.0672534e-05  1.1393484e-04\n",
      "   1.7852073e-04 -2.6411031e-05 -1.4538967e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04155601e-03 -1.10527384e-04  3.12545053e-05  1.23689286e-04\n",
      "   1.80351781e-04 -1.20656032e-05 -1.43982412e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04157196e-03 -1.11946014e-04  3.14345016e-05  9.03094187e-05\n",
      "   1.81683499e-04 -3.79404191e-05 -1.42680903e-04]]\n",
      "linear.bias:\n",
      " [0.0002214]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415154e-03 -1.1068550e-04  3.1550888e-05  9.1960370e-05\n",
      "   1.8081276e-04 -1.5366450e-05 -1.4250418e-04]]\n",
      "linear.bias:\n",
      " [0.00022203]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416358e-03 -1.0947115e-04  3.1585685e-05  1.0823309e-04\n",
      "   1.7938823e-04  8.5011470e-06 -1.4247808e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04223925e-03 -1.06946674e-04  3.13635064e-05  8.49759235e-05\n",
      "   1.76931135e-04 -3.70869457e-05 -1.42781559e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04271155e-03 -1.02131366e-04  3.11176664e-05  9.57732846e-05\n",
      "   1.72645276e-04 -3.22476953e-05 -1.44051723e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432858e-03 -9.9001882e-05  3.0942178e-05  1.2877994e-04\n",
      "   1.6913934e-04  5.6795652e-06 -1.4509438e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443326e-03 -9.6658528e-05  3.0892752e-05  1.0790324e-04\n",
      "   1.6645668e-04 -2.3903636e-05 -1.4567604e-04]]\n",
      "linear.bias:\n",
      " [0.00022426]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460925e-03 -9.6770316e-05  3.0983512e-05  7.6492295e-05\n",
      "   1.6592453e-04 -6.4452892e-05 -1.4496072e-04]]\n",
      "linear.bias:\n",
      " [0.00022461]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04750297e-03 -9.54265051e-05  3.08764829e-05  1.09488945e-04\n",
      "   1.64599449e-04 -1.81314099e-05 -1.44727848e-04]]\n",
      "linear.bias:\n",
      " [0.00022447]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496702e-03 -9.6357478e-05  3.1102867e-05  1.2821835e-04\n",
      "   1.6574364e-04 -1.1329957e-06 -1.4299921e-04]]\n",
      "linear.bias:\n",
      " [0.00022423]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0520443e-03 -9.9180405e-05  3.1510124e-05  1.0336056e-04\n",
      "   1.6973708e-04 -3.5010227e-05 -1.4027553e-04]]\n",
      "linear.bias:\n",
      " [0.00022368]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0536313e-03 -1.0317918e-04  3.2198812e-05  1.0230283e-04\n",
      "   1.7375426e-04 -3.3248089e-05 -1.3758201e-04]]\n",
      "linear.bias:\n",
      " [0.00022295]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0543362e-03 -1.0698089e-04  3.2681328e-05  1.1846290e-04\n",
      "   1.7669596e-04  1.5737241e-06 -1.3544444e-04]]\n",
      "linear.bias:\n",
      " [0.00022241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0532202e-03 -1.0850306e-04  3.2232489e-05  7.4433614e-05\n",
      "   1.7742335e-04 -3.0492854e-05 -1.3504566e-04]]\n",
      "linear.bias:\n",
      " [0.00022227]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0514563e-03 -1.0681461e-04  3.1634459e-05  8.6687018e-05\n",
      "   1.7399377e-04 -3.6192851e-06 -1.3640664e-04]]\n",
      "linear.bias:\n",
      " [0.00022225]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04905525e-03 -1.06798703e-04  3.15118778e-05  1.07532345e-04\n",
      "   1.71131120e-04  1.07539718e-05 -1.37104988e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469898e-03 -1.0691785e-04  3.1607655e-05  8.5536522e-05\n",
      "   1.6818776e-04 -4.7554793e-05 -1.3806832e-04]]\n",
      "linear.bias:\n",
      " [0.00022167]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04507257e-03 -1.04805025e-04  3.17401973e-05  9.68756358e-05\n",
      "   1.64438767e-04 -5.38043751e-05 -1.39553769e-04]]\n",
      "linear.bias:\n",
      " [0.00022138]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04352063e-03 -1.00543664e-04  3.18750499e-05  1.39239390e-04\n",
      "   1.60266747e-04 -1.02870326e-05 -1.41507160e-04]]\n",
      "linear.bias:\n",
      " [0.00022122]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424894e-03 -9.7768010e-05  3.1437310e-05  1.2031777e-04\n",
      "   1.5953109e-04 -1.9129187e-05 -1.4254051e-04]]\n",
      "linear.bias:\n",
      " [0.00022097]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432308e-03 -9.7479795e-05  3.1066160e-05  7.1844755e-05\n",
      "   1.6167063e-04 -6.2723760e-05 -1.4219836e-04]]\n",
      "linear.bias:\n",
      " [0.00022074]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04382751e-03 -9.51178008e-05  3.01934979e-05  1.00352394e-04\n",
      "   1.63553312e-04 -1.84760465e-05 -1.41921439e-04]]\n",
      "linear.bias:\n",
      " [0.0002203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451276e-03 -9.6076015e-05  2.9581088e-05  1.2483739e-04\n",
      "   1.6695542e-04  1.4987079e-05 -1.4071750e-04]]\n",
      "linear.bias:\n",
      " [0.00021991]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450456e-03 -9.7371390e-05  2.9386403e-05  8.5211876e-05\n",
      "   1.6984946e-04 -4.9950180e-05 -1.4071072e-04]]\n",
      "linear.bias:\n",
      " [0.00021968]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450486e-03 -9.7186581e-05  2.9503863e-05  8.2055711e-05\n",
      "   1.7177260e-04 -6.4305052e-05 -1.4115116e-04]]\n",
      "linear.bias:\n",
      " [0.00021935]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451362e-03 -9.4607851e-05  2.9545901e-05  1.3476252e-04\n",
      "   1.7091387e-04 -6.9294038e-07 -1.4282651e-04]]\n",
      "linear.bias:\n",
      " [0.00021905]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454425e-03 -9.4629126e-05  2.9313265e-05  1.2421972e-04\n",
      "   1.7056173e-04  5.8791206e-06 -1.4478611e-04]]\n",
      "linear.bias:\n",
      " [0.00021947]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461597e-03 -9.6548618e-05  2.9404813e-05  7.3382384e-05\n",
      "   1.7112056e-04 -3.9146245e-05 -1.4622527e-04]]\n",
      "linear.bias:\n",
      " [0.00022019]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464487e-03 -9.9183337e-05  2.9696290e-05  7.3633222e-05\n",
      "   1.7161889e-04 -4.4806962e-05 -1.4707538e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04657782e-03 -9.99130207e-05  3.01726468e-05  1.20655066e-04\n",
      "   1.70952175e-04 -2.15396358e-06 -1.48078208e-04]]\n",
      "linear.bias:\n",
      " [0.00022175]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479194e-03 -1.0266359e-04  3.0790881e-05  1.3072096e-04\n",
      "   1.7340071e-04 -6.2242398e-06 -1.4762422e-04]]\n",
      "linear.bias:\n",
      " [0.00022224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04929483e-03 -1.06959225e-04  3.12625089e-05  8.63240639e-05\n",
      "   1.76084941e-04 -5.68665091e-05 -1.46933307e-04]]\n",
      "linear.bias:\n",
      " [0.00022291]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498241e-03 -1.0848399e-04  3.1566989e-05  8.6620385e-05\n",
      "   1.7716456e-04 -5.2313109e-05 -1.4677231e-04]]\n",
      "linear.bias:\n",
      " [0.00022352]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495909e-03 -1.0751237e-04  3.1720891e-05  1.2715580e-04\n",
      "   1.7679854e-04  1.9161089e-06 -1.4708872e-04]]\n",
      "linear.bias:\n",
      " [0.00022406]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04830158e-03 -1.04002109e-04  3.16499354e-05  1.06754684e-04\n",
      "   1.76166708e-04 -1.37747556e-05 -1.47532352e-04]]\n",
      "linear.bias:\n",
      " [0.00022455]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483089e-03 -1.0256873e-04  3.1803393e-05  7.4251038e-05\n",
      "   1.7710238e-04 -5.8465914e-05 -1.4671234e-04]]\n",
      "linear.bias:\n",
      " [0.00022488]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482421e-03 -9.8424105e-05  3.1915173e-05  1.0598068e-04\n",
      "   1.7463547e-04 -1.8815368e-05 -1.4691267e-04]]\n",
      "linear.bias:\n",
      " [0.00022483]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493111e-03 -9.6896227e-05  3.2261178e-05  1.2164524e-04\n",
      "   1.7415079e-04 -1.7730599e-06 -1.4579394e-04]]\n",
      "linear.bias:\n",
      " [0.00022467]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504555e-03 -9.7594988e-05  3.2941927e-05  9.8329052e-05\n",
      "   1.7511816e-04 -3.3035016e-05 -1.4411219e-04]]\n",
      "linear.bias:\n",
      " [0.00022453]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509267e-03 -9.9703044e-05  3.3881770e-05  9.8736265e-05\n",
      "   1.7641678e-04 -2.8974624e-05 -1.4235327e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503876e-03 -1.0183608e-04  3.4627112e-05  1.1642598e-04\n",
      "   1.7677102e-04 -6.0991806e-07 -1.4105812e-04]]\n",
      "linear.bias:\n",
      " [0.00022373]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500317e-03 -1.0376812e-04  3.5013014e-05  9.2317692e-05\n",
      "   1.7688604e-04 -1.2297671e-05 -1.3977525e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492933e-03 -1.0605312e-04  3.5156998e-05  8.4501873e-05\n",
      "   1.7671322e-04 -1.8232491e-05 -1.3848388e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480740e-03 -1.0806752e-04  3.5148983e-05  1.0521397e-04\n",
      "   1.7574170e-04  1.6541344e-07 -1.3761786e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475122e-03 -1.1033641e-04  3.5057401e-05  9.5197145e-05\n",
      "   1.7583695e-04 -1.8843857e-05 -1.3604404e-04]]\n",
      "linear.bias:\n",
      " [0.00022328]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04674138e-03 -1.12266942e-04  3.46033812e-05  1.00436220e-04\n",
      "   1.75165624e-04 -1.44113255e-05 -1.35037233e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04586419e-03 -1.12366062e-04  3.38176687e-05  1.09899745e-04\n",
      "   1.74363086e-04 -4.84026077e-06 -1.34368849e-04]]\n",
      "linear.bias:\n",
      " [0.00022372]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455588e-03 -1.0938732e-04  3.2389489e-05  8.1379680e-05\n",
      "   1.7358754e-04 -4.0093197e-05 -1.3356761e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452215e-03 -1.0433667e-04  3.1051230e-05  9.9411045e-05\n",
      "   1.6958469e-04 -1.8859802e-05 -1.3446632e-04]]\n",
      "linear.bias:\n",
      " [0.00022405]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449687e-03 -1.0064025e-04  2.9775962e-05  1.2416171e-04\n",
      "   1.6615185e-04  9.0960348e-06 -1.3538921e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430100e-03 -9.7162454e-05  2.8476414e-05  8.4484884e-05\n",
      "   1.6273709e-04 -4.9688369e-05 -1.3740553e-04]]\n",
      "linear.bias:\n",
      " [0.0002241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413247e-03 -9.2748196e-05  2.7584952e-05  8.2997365e-05\n",
      "   1.5898437e-04 -5.5928751e-05 -1.3998241e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399581e-03 -9.1595648e-05  2.6755037e-05  1.1404905e-04\n",
      "   1.5646681e-04 -1.6889240e-05 -1.4241341e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404926e-03 -9.2845199e-05  2.6221223e-05  1.2163610e-04\n",
      "   1.5738723e-04 -1.5039308e-05 -1.4296993e-04]]\n",
      "linear.bias:\n",
      " [0.00022259]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422150e-03 -9.6090997e-05  2.5932268e-05  9.5991541e-05\n",
      "   1.6130444e-04 -5.5969736e-05 -1.4209645e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435213e-03 -1.0053757e-04  2.5699257e-05  1.0203494e-04\n",
      "   1.6578958e-04 -5.1101517e-05 -1.4105870e-04]]\n",
      "linear.bias:\n",
      " [0.00022141]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441332e-03 -1.0603399e-04  2.5819267e-05  1.2899893e-04\n",
      "   1.7025979e-04 -1.4400022e-05 -1.3987743e-04]]\n",
      "linear.bias:\n",
      " [0.00022078]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04483799e-03 -1.11692927e-04  2.58878317e-05  1.13754555e-04\n",
      "   1.74625238e-04 -1.85821282e-05 -1.38608870e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449468e-03 -1.1651569e-04  2.6167660e-05  8.1839164e-05\n",
      "   1.7916151e-04 -3.6610913e-05 -1.3694877e-04]]\n",
      "linear.bias:\n",
      " [0.00022083]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445033e-03 -1.1630421e-04  2.6223744e-05  9.4782576e-05\n",
      "   1.7956279e-04 -2.2897329e-06 -1.3703077e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431685e-03 -1.1374755e-04  2.6525673e-05  1.0636502e-04\n",
      "   1.7948348e-04 -3.0751848e-06 -1.3672939e-04]]\n",
      "linear.bias:\n",
      " [0.00022218]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413865e-03 -1.1013740e-04  2.7178650e-05  8.7507869e-05\n",
      "   1.7897418e-04 -4.4380762e-05 -1.3627927e-04]]\n",
      "linear.bias:\n",
      " [0.00022321]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03985239e-03 -1.04373961e-04  2.78088955e-05  1.09281624e-04\n",
      "   1.75371577e-04 -2.98207924e-05 -1.37516996e-04]]\n",
      "linear.bias:\n",
      " [0.00022403]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03940582e-03 -1.00255544e-04  2.79169144e-05  1.26639759e-04\n",
      "   1.72021406e-04 -2.78945117e-06 -1.38825082e-04]]\n",
      "linear.bias:\n",
      " [0.00022488]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391109e-03 -9.8218821e-05  2.7935668e-05  8.7437089e-05\n",
      "   1.6879376e-04 -2.9161314e-05 -1.4035044e-04]]\n",
      "linear.bias:\n",
      " [0.000226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392312e-03 -9.7560252e-05  2.8183442e-05  7.8766818e-05\n",
      "   1.6654396e-04 -2.4264822e-05 -1.4143999e-04]]\n",
      "linear.bias:\n",
      " [0.00022677]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03946030e-03 -9.81654957e-05  2.85899059e-05  1.11636546e-04\n",
      "   1.64857222e-04  1.22691908e-05 -1.42025339e-04]]\n",
      "linear.bias:\n",
      " [0.00022734]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04013050e-03 -1.00966063e-04  2.92743898e-05  1.10690824e-04\n",
      "   1.66352314e-04 -1.83896609e-05 -1.41274344e-04]]\n",
      "linear.bias:\n",
      " [0.00022717]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04260165e-03 -1.05113715e-04  3.01200580e-05  9.19353333e-05\n",
      "   1.70445506e-04 -7.64197030e-05 -1.39015086e-04]]\n",
      "linear.bias:\n",
      " [0.00022677]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452921e-03 -1.0534243e-04  3.0978485e-05  1.3182477e-04\n",
      "   1.7182114e-04 -2.2608161e-05 -1.3860234e-04]]\n",
      "linear.bias:\n",
      " [0.00022607]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481747e-03 -1.0539099e-04  3.0984367e-05  1.1751759e-04\n",
      "   1.7318816e-04 -1.0382136e-05 -1.3818705e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508874e-03 -1.0572519e-04  3.0774336e-05  6.8257854e-05\n",
      "   1.7484780e-04 -3.2891836e-05 -1.3740023e-04]]\n",
      "linear.bias:\n",
      " [0.00022486]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05299789e-03 -1.04411185e-04  3.07025693e-05  9.54409916e-05\n",
      "   1.73905413e-04 -2.56539170e-06 -1.37609677e-04]]\n",
      "linear.bias:\n",
      " [0.00022388]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0546290e-03 -1.0375915e-04  3.1256273e-05  1.1624564e-04\n",
      "   1.7430006e-04 -1.9917547e-07 -1.3670555e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0547554e-03 -1.0232138e-04  3.1337018e-05  7.9089528e-05\n",
      "   1.7307592e-04 -5.3768617e-05 -1.3686711e-04]]\n",
      "linear.bias:\n",
      " [0.00022177]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0543286e-03 -9.8733457e-05  3.1442476e-05  9.5070071e-05\n",
      "   1.6936356e-04 -4.4408498e-05 -1.3823537e-04]]\n",
      "linear.bias:\n",
      " [0.00022063]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0534200e-03 -9.5896787e-05  3.1395786e-05  1.3715134e-04\n",
      "   1.6573229e-04  2.5151421e-06 -1.3958513e-04]]\n",
      "linear.bias:\n",
      " [0.00021972]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507914e-03 -9.3091396e-05  3.0919287e-05  9.9421217e-05\n",
      "   1.6256885e-04 -3.1307689e-05 -1.4187615e-04]]\n",
      "linear.bias:\n",
      " [0.00021925]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477033e-03 -9.2651906e-05  3.0902695e-05  6.8008863e-05\n",
      "   1.6125766e-04 -4.2856460e-05 -1.4322062e-04]]\n",
      "linear.bias:\n",
      " [0.00021906]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447575e-03 -9.3781164e-05  3.0580959e-05  1.0079935e-04\n",
      "   1.6110498e-04 -1.2096509e-05 -1.4342535e-04]]\n",
      "linear.bias:\n",
      " [0.00021878]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429480e-03 -9.7706543e-05  3.0612380e-05  1.1662027e-04\n",
      "   1.6386485e-04 -1.2167984e-05 -1.4196866e-04]]\n",
      "linear.bias:\n",
      " [0.00021852]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424926e-03 -1.0380541e-04  3.0857118e-05  9.9820856e-05\n",
      "   1.6876843e-04 -4.7229725e-05 -1.3955029e-04]]\n",
      "linear.bias:\n",
      " [0.0002184]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426564e-03 -1.0670191e-04  3.1038897e-05  1.0503820e-04\n",
      "   1.7231265e-04 -3.5156027e-05 -1.3820235e-04]]\n",
      "linear.bias:\n",
      " [0.00021842]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04283402e-03 -1.09210720e-04  3.08379931e-05  1.19231605e-04\n",
      "   1.74868270e-04  5.51957419e-06 -1.37422059e-04]]\n",
      "linear.bias:\n",
      " [0.00021902]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04312506e-03 -1.09628214e-04  3.00868614e-05  8.21643989e-05\n",
      "   1.74989516e-04 -2.93696976e-05 -1.38027608e-04]]\n",
      "linear.bias:\n",
      " [0.00021991]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435474e-03 -1.0727794e-04  2.9548148e-05  8.4101972e-05\n",
      "   1.7322821e-04 -1.9775904e-05 -1.3943252e-04]]\n",
      "linear.bias:\n",
      " [0.00022083]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04354497e-03 -1.05984283e-04  2.92828154e-05  1.17049174e-04\n",
      "   1.70942440e-04  1.09111716e-05 -1.40917648e-04]]\n",
      "linear.bias:\n",
      " [0.00022166]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433145e-03 -1.0513882e-04  2.9296158e-05  9.9549143e-05\n",
      "   1.6847151e-04 -3.8619735e-05 -1.4268677e-04]]\n",
      "linear.bias:\n",
      " [0.00022241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04326254e-03 -1.05638996e-04  2.93561498e-05  1.07478736e-04\n",
      "   1.66615981e-04 -4.95150052e-05 -1.44174119e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04286894e-03 -1.06363404e-04  2.95117807e-05  1.24079859e-04\n",
      "   1.65516059e-04 -2.73669539e-05 -1.45610771e-04]]\n",
      "linear.bias:\n",
      " [0.00022346]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439580e-03 -1.0792362e-04  2.9535726e-05  1.0923928e-04\n",
      "   1.6676764e-04 -3.4458128e-05 -1.4566707e-04]]\n",
      "linear.bias:\n",
      " [0.00022356]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04428479e-03 -1.11263056e-04  2.99720741e-05  9.44925559e-05\n",
      "   1.69464300e-04 -2.14632419e-05 -1.45163023e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435648e-03 -1.1415375e-04  3.0790048e-05  1.0060021e-04\n",
      "   1.7284592e-04  4.4786648e-06 -1.4417245e-04]]\n",
      "linear.bias:\n",
      " [0.00022416]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448641e-03 -1.1536783e-04  3.1193304e-05  8.7939065e-05\n",
      "   1.7752637e-04 -1.6098120e-05 -1.4193641e-04]]\n",
      "linear.bias:\n",
      " [0.00022372]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460520e-03 -1.1216219e-04  3.1393301e-05  1.0268359e-04\n",
      "   1.8049424e-04 -5.6444887e-06 -1.4063103e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464949e-03 -1.0862799e-04  3.1977161e-05  1.0483944e-04\n",
      "   1.8370671e-04 -2.1957581e-05 -1.3854972e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04694406e-03 -1.05304316e-04  3.22534033e-05  1.10440364e-04\n",
      "   1.85674653e-04 -2.92977093e-05 -1.37142211e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468998e-03 -9.9696466e-05  3.2633303e-05  1.2517885e-04\n",
      "   1.8590791e-04 -8.4305448e-06 -1.3675448e-04]]\n",
      "linear.bias:\n",
      " [0.00022274]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461471e-03 -9.4242467e-05  3.2631440e-05  7.9943435e-05\n",
      "   1.8480273e-04 -3.9201455e-05 -1.3725006e-04]]\n",
      "linear.bias:\n",
      " [0.00022315]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457895e-03 -8.8163804e-05  3.2411648e-05  9.5709795e-05\n",
      "   1.7853359e-04 -9.4336046e-06 -1.4002791e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04632613e-03 -8.55297840e-05  3.22386732e-05  1.11533926e-04\n",
      "   1.73211622e-04 -1.16029696e-06 -1.41693497e-04]]\n",
      "linear.bias:\n",
      " [0.00022281]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474125e-03 -8.5233180e-05  3.2238295e-05  9.5482916e-05\n",
      "   1.7033142e-04 -3.4622612e-05 -1.4212984e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495331e-03 -8.9318622e-05  3.2040050e-05  9.8472257e-05\n",
      "   1.6834339e-04 -3.9071609e-05 -1.4197858e-04]]\n",
      "linear.bias:\n",
      " [0.00022164]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508640e-03 -9.4527823e-05  3.2199772e-05  1.2294998e-04\n",
      "   1.6699563e-04 -1.0545549e-05 -1.4158932e-04]]\n",
      "linear.bias:\n",
      " [0.00022073]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0522630e-03 -1.0175278e-04  3.2515869e-05  1.0542303e-04\n",
      "   1.6724558e-04 -2.5804613e-05 -1.4067898e-04]]\n",
      "linear.bias:\n",
      " [0.00022015]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0526469e-03 -1.1015076e-04  3.3236447e-05  8.6576358e-05\n",
      "   1.6893871e-04 -2.9119861e-05 -1.3936350e-04]]\n",
      "linear.bias:\n",
      " [0.00021987]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0519685e-03 -1.1628803e-04  3.3388009e-05  9.6105454e-05\n",
      "   1.6965557e-04  5.9215909e-06 -1.3852814e-04]]\n",
      "linear.bias:\n",
      " [0.00021997]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506742e-03 -1.1947213e-04  3.3719443e-05  9.5186129e-05\n",
      "   1.7098679e-04  4.9244363e-06 -1.3693386e-04]]\n",
      "linear.bias:\n",
      " [0.00022006]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04948971e-03 -1.18124866e-04  3.35461045e-05  8.26969335e-05\n",
      "   1.71660897e-04 -4.26121696e-05 -1.35509748e-04]]\n",
      "linear.bias:\n",
      " [0.00022038]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04737969e-03 -1.12528192e-04  3.31370138e-05  1.08963555e-04\n",
      "   1.70192623e-04 -3.51535818e-05 -1.35326554e-04]]\n",
      "linear.bias:\n",
      " [0.00022103]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456680e-03 -1.0306901e-04  3.2490931e-05  1.4001154e-04\n",
      "   1.6833810e-04  7.1876748e-06 -1.3603896e-04]]\n",
      "linear.bias:\n",
      " [0.00022208]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429381e-03 -9.1356778e-05  3.0460964e-05  7.2544120e-05\n",
      "   1.6672013e-04 -4.7117745e-05 -1.3853819e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404197e-03 -8.3229803e-05  2.8677690e-05  6.4555425e-05\n",
      "   1.6388259e-04 -4.8213878e-05 -1.4122992e-04]]\n",
      "linear.bias:\n",
      " [0.00022444]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381475e-03 -7.8457764e-05  2.7025479e-05  1.2583613e-04\n",
      "   1.6042343e-04 -1.1129086e-06 -1.4397102e-04]]\n",
      "linear.bias:\n",
      " [0.00022468]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363014e-03 -7.7557757e-05  2.6153210e-05  1.4317714e-04\n",
      "   1.6071940e-04 -1.4504068e-05 -1.4528695e-04]]\n",
      "linear.bias:\n",
      " [0.00022478]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0357045e-03 -7.9646044e-05  2.5251224e-05  1.0834000e-04\n",
      "   1.6419076e-04 -6.6557150e-05 -1.4503968e-04]]\n",
      "linear.bias:\n",
      " [0.00022487]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371632e-03 -8.5138345e-05  2.4306408e-05  8.5944041e-05\n",
      "   1.6943048e-04 -7.3443261e-05 -1.4444682e-04]]\n",
      "linear.bias:\n",
      " [0.00022471]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0394849e-03 -9.0432775e-05  2.3600549e-05  1.2722274e-04\n",
      "   1.7230968e-04  1.1580953e-05 -1.4535589e-04]]\n",
      "linear.bias:\n",
      " [0.00022396]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409430e-03 -9.6222808e-05  2.3799477e-05  1.0961469e-04\n",
      "   1.7620559e-04  9.8656010e-06 -1.4568922e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426627e-03 -1.0422024e-04  2.4474553e-05  6.7579873e-05\n",
      "   1.8130490e-04 -4.9632730e-05 -1.4487030e-04]]\n",
      "linear.bias:\n",
      " [0.000222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444559e-03 -1.1024086e-04  2.5513673e-05  1.0440692e-04\n",
      "   1.8073595e-04 -3.4086646e-05 -1.4599711e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457617e-03 -1.1324060e-04  2.6564616e-05  1.5294563e-04\n",
      "   1.7875747e-04  1.5942249e-05 -1.4766757e-04]]\n",
      "linear.bias:\n",
      " [0.00021952]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442942e-03 -1.0977084e-04  2.6183679e-05  9.6013791e-05\n",
      "   1.7737484e-04 -5.3700591e-05 -1.5083126e-04]]\n",
      "linear.bias:\n",
      " [0.00021905]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429120e-03 -1.0429682e-04  2.5889653e-05  7.6542157e-05\n",
      "   1.7496716e-04 -6.9946422e-05 -1.5433416e-04]]\n",
      "linear.bias:\n",
      " [0.00021863]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420204e-03 -9.5973795e-05  2.5573168e-05  1.2759546e-04\n",
      "   1.7117191e-04  3.1225209e-06 -1.5762380e-04]]\n",
      "linear.bias:\n",
      " [0.00021826]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426781e-03 -9.0249254e-05  2.5837571e-05  1.3014681e-04\n",
      "   1.7084838e-04  1.8045102e-05 -1.5920692e-04]]\n",
      "linear.bias:\n",
      " [0.0002178]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433104e-03 -8.5766449e-05  2.6448888e-05  6.9386217e-05\n",
      "   1.7349581e-04 -5.1004790e-05 -1.5935430e-04]]\n",
      "linear.bias:\n",
      " [0.0002175]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438864e-03 -8.4283485e-05  2.6911343e-05  7.5966876e-05\n",
      "   1.7685367e-04 -6.0994909e-05 -1.5762156e-04]]\n",
      "linear.bias:\n",
      " [0.00021736]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443886e-03 -8.5287960e-05  2.6990712e-05  1.4013823e-04\n",
      "   1.7995003e-04 -5.8607584e-06 -1.5528369e-04]]\n",
      "linear.bias:\n",
      " [0.00021747]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450250e-03 -8.7908542e-05  2.7002892e-05  1.4179727e-04\n",
      "   1.8303930e-04 -4.9781488e-06 -1.5298704e-04]]\n",
      "linear.bias:\n",
      " [0.00021793]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456978e-03 -9.2168993e-05  2.6695319e-05  8.3409745e-05\n",
      "   1.8574524e-04 -5.4108910e-05 -1.5120769e-04]]\n",
      "linear.bias:\n",
      " [0.00021883]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464097e-03 -9.5784642e-05  2.6707632e-05  8.6338718e-05\n",
      "   1.8550939e-04 -3.0943451e-05 -1.5037846e-04]]\n",
      "linear.bias:\n",
      " [0.00021939]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458909e-03 -1.0027729e-04  2.7029864e-05  1.1692379e-04\n",
      "   1.8446366e-04  2.4612094e-05 -1.4983052e-04]]\n",
      "linear.bias:\n",
      " [0.00022002]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439254e-03 -1.0424199e-04  2.7983422e-05  8.4112296e-05\n",
      "   1.8304821e-04 -2.6900980e-05 -1.4981191e-04]]\n",
      "linear.bias:\n",
      " [0.00022035]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424043e-03 -1.0856160e-04  2.9032435e-05  9.1097740e-05\n",
      "   1.8126480e-04 -4.2944623e-05 -1.4980664e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04095833e-03 -1.09724795e-04  2.99279509e-05  1.29843713e-04\n",
      "   1.77435053e-04 -1.14786817e-05 -1.50871230e-04]]\n",
      "linear.bias:\n",
      " [0.00022161]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04037044e-03 -1.08113294e-04  2.98029190e-05  1.11111876e-04\n",
      "   1.74349683e-04 -2.43718168e-05 -1.51419910e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416942e-03 -1.0843808e-04  2.9727602e-05  7.4527445e-05\n",
      "   1.7393744e-04 -5.5497359e-05 -1.5056980e-04]]\n",
      "linear.bias:\n",
      " [0.00022308]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04324275e-03 -1.06166684e-04  2.99642725e-05  1.04638682e-04\n",
      "   1.72594649e-04 -1.37944044e-05 -1.49493426e-04]]\n",
      "linear.bias:\n",
      " [0.00022371]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04593427e-03 -1.06269210e-04  3.06148613e-05  1.18451506e-04\n",
      "   1.73724708e-04 -6.25504208e-06 -1.46921666e-04]]\n",
      "linear.bias:\n",
      " [0.00022403]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04906550e-03 -1.07773689e-04  3.13739729e-05  1.03145285e-04\n",
      "   1.76210058e-04 -3.71558381e-05 -1.43585174e-04]]\n",
      "linear.bias:\n",
      " [0.00022408]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510894e-03 -1.0943428e-04  3.1932577e-05  1.0867552e-04\n",
      "   1.7770327e-04 -3.1229145e-05 -1.4082107e-04]]\n",
      "linear.bias:\n",
      " [0.00022412]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0522540e-03 -1.1094872e-04  3.2418346e-05  1.1441809e-04\n",
      "   1.7888729e-04 -8.9121622e-06 -1.3862604e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05131383e-03 -1.09617766e-04  3.28313799e-05  8.43823800e-05\n",
      "   1.79872965e-04 -2.13195417e-05 -1.36363495e-04]]\n",
      "linear.bias:\n",
      " [0.0002249]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05024630e-03 -1.05227526e-04  3.32244781e-05  9.42836050e-05\n",
      "   1.78257440e-04 -1.00355828e-06 -1.35460723e-04]]\n",
      "linear.bias:\n",
      " [0.00022546]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04864512e-03 -1.02449194e-04  3.39927356e-05  1.10904512e-04\n",
      "   1.76686211e-04 -4.53018947e-06 -1.34174421e-04]]\n",
      "linear.bias:\n",
      " [0.00022549]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04720239e-03 -1.00076366e-04  3.40881270e-05  8.41220681e-05\n",
      "   1.74634915e-04 -4.44463076e-05 -1.33201640e-04]]\n",
      "linear.bias:\n",
      " [0.00022563]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04583253e-03 -9.54779825e-05  3.40776896e-05  1.04799474e-04\n",
      "   1.69374383e-04 -2.61014520e-05 -1.34071946e-04]]\n",
      "linear.bias:\n",
      " [0.0002254]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454155e-03 -9.3780727e-05  3.3768654e-05  1.2206265e-04\n",
      "   1.6520412e-04 -7.1995964e-07 -1.3470478e-04]]\n",
      "linear.bias:\n",
      " [0.00022519]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444381e-03 -9.5021722e-05  3.3467990e-05  9.4608644e-05\n",
      "   1.6337962e-04 -2.8092811e-05 -1.3527698e-04]]\n",
      "linear.bias:\n",
      " [0.00022524]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453589e-03 -9.8546210e-05  3.2782787e-05  9.0753092e-05\n",
      "   1.6216876e-04 -2.2119604e-05 -1.3559044e-04]]\n",
      "linear.bias:\n",
      " [0.00022505]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04636978e-03 -1.02892169e-04  3.24260036e-05  1.12587964e-04\n",
      "   1.61649688e-04  2.92318873e-06 -1.35640090e-04]]\n",
      "linear.bias:\n",
      " [0.0002245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474954e-03 -1.0882196e-04  3.2001135e-05  9.5909476e-05\n",
      "   1.6521740e-04 -2.1243672e-05 -1.3451085e-04]]\n",
      "linear.bias:\n",
      " [0.00022365]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04875676e-03 -1.13883565e-04  3.14621575e-05  9.33979172e-05\n",
      "   1.68476661e-04 -2.89086347e-05 -1.33671885e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498903e-03 -1.1413552e-04  3.0597443e-05  1.1610321e-04\n",
      "   1.6993481e-04  7.2147595e-06 -1.3377107e-04]]\n",
      "linear.bias:\n",
      " [0.00022231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489587e-03 -1.0965106e-04  2.8796780e-05  7.6395634e-05\n",
      "   1.6970786e-04 -4.3931486e-05 -1.3585779e-04]]\n",
      "linear.bias:\n",
      " [0.00022192]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475602e-03 -1.0318326e-04  2.7251002e-05  9.0416957e-05\n",
      "   1.6670738e-04 -3.3526761e-05 -1.3897543e-04]]\n",
      "linear.bias:\n",
      " [0.00022133]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458980e-03 -9.8712444e-05  2.5975611e-05  1.3250345e-04\n",
      "   1.6415514e-04  1.2298766e-05 -1.4171911e-04]]\n",
      "linear.bias:\n",
      " [0.00022079]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426230e-03 -9.5030795e-05  2.4769768e-05  9.6339543e-05\n",
      "   1.6374061e-04 -3.5307487e-05 -1.4447249e-04]]\n",
      "linear.bias:\n",
      " [0.00022018]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0387853e-03 -9.3809882e-05  2.3984339e-05  8.2567974e-05\n",
      "   1.6405719e-04 -5.0017767e-05 -1.4642769e-04]]\n",
      "linear.bias:\n",
      " [0.00021951]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0354976e-03 -9.4167473e-05  2.3288794e-05  1.0334137e-04\n",
      "   1.6545043e-04 -2.2046517e-05 -1.4777042e-04]]\n",
      "linear.bias:\n",
      " [0.00021928]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0335676e-03 -9.6760858e-05  2.2994091e-05  1.1489998e-04\n",
      "   1.6902105e-04 -1.1614084e-05 -1.4755048e-04]]\n",
      "linear.bias:\n",
      " [0.00021919]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0332466e-03 -1.0163019e-04  2.3114459e-05  9.9812009e-05\n",
      "   1.7502780e-04 -4.0473107e-05 -1.4583069e-04]]\n",
      "linear.bias:\n",
      " [0.00021899]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03313464e-03 -1.07458451e-04  2.33072315e-05  1.07571075e-04\n",
      "   1.80824805e-04 -3.39744620e-05 -1.44077087e-04]]\n",
      "linear.bias:\n",
      " [0.00021881]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0335526e-03 -1.0978837e-04  2.3298669e-05  1.2807192e-04\n",
      "   1.8449484e-04  9.6025324e-06 -1.4349585e-04]]\n",
      "linear.bias:\n",
      " [0.00021913]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0338241e-03 -1.0836233e-04  2.2800099e-05  8.1401537e-05\n",
      "   1.8538987e-04 -3.4113255e-05 -1.4453453e-04]]\n",
      "linear.bias:\n",
      " [0.0002198]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0347797e-03 -1.0390958e-04  2.2615413e-05  8.5751839e-05\n",
      "   1.8293377e-04 -2.7934342e-05 -1.4669281e-04]]\n",
      "linear.bias:\n",
      " [0.00022052]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363815e-03 -9.7843760e-05  2.2841701e-05  1.3037391e-04\n",
      "   1.7931673e-04  1.5973414e-05 -1.4919405e-04]]\n",
      "linear.bias:\n",
      " [0.00022129]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0373718e-03 -9.2283721e-05  2.3631865e-05  1.1181284e-04\n",
      "   1.7590653e-04 -3.6871417e-05 -1.5171920e-04]]\n",
      "linear.bias:\n",
      " [0.00022198]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391633e-03 -9.0581678e-05  2.4307630e-05  9.4647388e-05\n",
      "   1.7450022e-04 -6.8622248e-05 -1.5314529e-04]]\n",
      "linear.bias:\n",
      " [0.00022273]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407608e-03 -9.1939743e-05  2.4905796e-05  1.1516711e-04\n",
      "   1.7367378e-04 -3.7684433e-05 -1.5417962e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431752e-03 -9.6296790e-05  2.5408028e-05  1.2918659e-04\n",
      "   1.7461828e-04  6.4441629e-06 -1.5443852e-04]]\n",
      "linear.bias:\n",
      " [0.00022425]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458141e-03 -1.0236235e-04  2.6643091e-05  9.5599527e-05\n",
      "   1.7853748e-04 -1.3329702e-05 -1.5318482e-04]]\n",
      "linear.bias:\n",
      " [0.00022465]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04769610e-03 -1.08929045e-04  2.86081831e-05  6.52176459e-05\n",
      "   1.83594922e-04 -5.42116832e-05 -1.50558233e-04]]\n",
      "linear.bias:\n",
      " [0.00022476]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491171e-03 -1.1129232e-04  3.0405397e-05  1.3277930e-04\n",
      "   1.8303817e-04  4.7847425e-06 -1.4923676e-04]]\n",
      "linear.bias:\n",
      " [0.00022412]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493023e-03 -1.0905815e-04  3.1466287e-05  1.2872842e-04\n",
      "   1.8086245e-04 -1.0441541e-05 -1.4906803e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04963011e-03 -1.04451174e-04  3.19158717e-05  7.64668002e-05\n",
      "   1.78626753e-04 -6.53660318e-05 -1.48789419e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499383e-03 -9.7355376e-05  3.2327232e-05  9.4635892e-05\n",
      "   1.7272761e-04 -2.4830242e-05 -1.4993019e-04]]\n",
      "linear.bias:\n",
      " [0.00022264]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493059e-03 -9.2935203e-05  3.3249216e-05  1.2783970e-04\n",
      "   1.6842056e-04  2.1703065e-05 -1.5021069e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466787e-03 -8.8486115e-05  3.4179717e-05  7.7920267e-05\n",
      "   1.6754064e-04 -4.9494094e-05 -1.5022056e-04]]\n",
      "linear.bias:\n",
      " [0.00022076]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439190e-03 -8.7102104e-05  3.4575292e-05  8.0843318e-05\n",
      "   1.6765705e-04 -6.9106303e-05 -1.4923254e-04]]\n",
      "linear.bias:\n",
      " [0.00021991]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417525e-03 -8.8050263e-05  3.4289082e-05  1.4296488e-04\n",
      "   1.6869961e-04 -1.5164322e-05 -1.4762810e-04]]\n",
      "linear.bias:\n",
      " [0.00021926]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407228e-03 -9.1391463e-05  3.3524637e-05  1.4509502e-04\n",
      "   1.7126821e-04 -1.0660864e-05 -1.4579263e-04]]\n",
      "linear.bias:\n",
      " [0.00021892]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407406e-03 -9.6386386e-05  3.2281383e-05  8.7535846e-05\n",
      "   1.7432678e-04 -5.6080618e-05 -1.4417034e-04]]\n",
      "linear.bias:\n",
      " [0.00021911]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0401297e-03 -9.8208104e-05  3.1132713e-05  7.1790397e-05\n",
      "   1.7582829e-04 -4.8104645e-05 -1.4322100e-04]]\n",
      "linear.bias:\n",
      " [0.00021941]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04030967e-03 -9.93358044e-05  3.02811877e-05  1.14636074e-04\n",
      "   1.74754168e-04  1.42400240e-05 -1.43181722e-04]]\n",
      "linear.bias:\n",
      " [0.00021955]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406069e-03 -1.0120375e-04  2.9779931e-05  1.0858557e-04\n",
      "   1.7356602e-04 -2.5005556e-07 -1.4334521e-04]]\n",
      "linear.bias:\n",
      " [0.00021993]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423410e-03 -1.0439920e-04  2.9521390e-05  7.9137237e-05\n",
      "   1.7406017e-04 -4.9016358e-05 -1.4233851e-04]]\n",
      "linear.bias:\n",
      " [0.00022014]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04376127e-03 -1.04589300e-04  2.93257417e-05  1.04756706e-04\n",
      "   1.71813605e-04 -3.86409301e-05 -1.42244724e-04]]\n",
      "linear.bias:\n",
      " [0.00022034]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451691e-03 -1.0499754e-04  2.8942413e-05  1.4193817e-04\n",
      "   1.6976964e-04  5.0271810e-06 -1.4239000e-04]]\n",
      "linear.bias:\n",
      " [0.00022088]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450991e-03 -1.0425837e-04  2.7873277e-05  8.3442290e-05\n",
      "   1.6889785e-04 -4.1759231e-05 -1.4367710e-04]]\n",
      "linear.bias:\n",
      " [0.00022163]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451202e-03 -1.0211562e-04  2.7230637e-05  6.4145228e-05\n",
      "   1.6736626e-04 -3.9800063e-05 -1.4532432e-04]]\n",
      "linear.bias:\n",
      " [0.00022217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449506e-03 -9.7241464e-05  2.6970774e-05  1.1550568e-04\n",
      "   1.6566848e-04  1.0474068e-05 -1.4616179e-04]]\n",
      "linear.bias:\n",
      " [0.00022216]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451225e-03 -9.6127034e-05  2.7321134e-05  1.2454488e-04\n",
      "   1.6748006e-04  2.5575482e-06 -1.4547280e-04]]\n",
      "linear.bias:\n",
      " [0.0002219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463857e-03 -9.7740602e-05  2.8023169e-05  9.6285708e-05\n",
      "   1.7223624e-04 -5.0222254e-05 -1.4352886e-04]]\n",
      "linear.bias:\n",
      " [0.00022155]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04711205e-03 -1.00574456e-04  2.87742641e-05  1.00338773e-04\n",
      "   1.76671747e-04 -6.14966775e-05 -1.41713375e-04]]\n",
      "linear.bias:\n",
      " [0.00022123]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478236e-03 -1.0047799e-04  2.9356532e-05  1.3647717e-04\n",
      "   1.7821146e-04 -2.4098958e-05 -1.4130960e-04]]\n",
      "linear.bias:\n",
      " [0.00022094]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04867644e-03 -1.00686644e-04  2.92853947e-05  1.11253466e-04\n",
      "   1.78372837e-04 -2.94065758e-05 -1.41618235e-04]]\n",
      "linear.bias:\n",
      " [0.0002213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483126e-03 -1.0156809e-04  2.9194813e-05  8.2952509e-05\n",
      "   1.7882761e-04 -2.2431625e-05 -1.4188918e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475785e-03 -1.0323549e-04  2.9346658e-05  8.9100315e-05\n",
      "   1.7849401e-04  5.7928264e-06 -1.4236683e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464718e-03 -1.0487335e-04  3.0057836e-05  9.6442651e-05\n",
      "   1.7856136e-04  1.1462676e-06 -1.4190034e-04]]\n",
      "linear.bias:\n",
      " [0.00022317]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469075e-03 -1.0808998e-04  3.0895335e-05  9.1778762e-05\n",
      "   1.8002954e-04 -3.2686501e-05 -1.4018879e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04717247e-03 -1.08203618e-04  3.14858189e-05  1.18526106e-04\n",
      "   1.79365015e-04 -1.75319801e-05 -1.39653668e-04]]\n",
      "linear.bias:\n",
      " [0.00022333]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04764418e-03 -1.08563625e-04  3.17419508e-05  1.09907836e-04\n",
      "   1.78997623e-04 -2.97321239e-05 -1.38663483e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473891e-03 -1.0890755e-04  3.1954769e-05  1.0291637e-04\n",
      "   1.7850082e-04 -2.3751752e-05 -1.3807570e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04609423e-03 -1.09367764e-04  3.20477920e-05  1.09191926e-04\n",
      "   1.77302834e-04  1.89209095e-06 -1.37838710e-04]]\n",
      "linear.bias:\n",
      " [0.00022427]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449468e-03 -1.0841859e-04  3.1885982e-05  7.7618970e-05\n",
      "   1.7540564e-04 -3.1850515e-05 -1.3747011e-04]]\n",
      "linear.bias:\n",
      " [0.0002243]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440960e-03 -1.0491011e-04  3.1881373e-05  9.7093151e-05\n",
      "   1.7041517e-04 -1.4292464e-05 -1.3870808e-04]]\n",
      "linear.bias:\n",
      " [0.00022396]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453542e-03 -1.0421158e-04  3.1589108e-05  1.2000381e-04\n",
      "   1.6652053e-04 -6.7898327e-06 -1.3934317e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475205e-03 -1.0562799e-04  3.1120486e-05  1.0316220e-04\n",
      "   1.6527588e-04 -3.8260427e-05 -1.3894108e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491012e-03 -1.0719564e-04  3.0806874e-05  9.7617616e-05\n",
      "   1.6476402e-04 -3.4687419e-05 -1.3868279e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505422e-03 -1.0898492e-04  3.0303539e-05  1.1532882e-04\n",
      "   1.6423377e-04  4.2709617e-06 -1.3852934e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0511985e-03 -1.1106449e-04  2.9700102e-05  9.5514712e-05\n",
      "   1.6636585e-04 -4.4609505e-06 -1.3740628e-04]]\n",
      "linear.bias:\n",
      " [0.00022164]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510639e-03 -1.1181746e-04  2.9641509e-05  7.1715411e-05\n",
      "   1.6988051e-04 -3.7796024e-05 -1.3520569e-04]]\n",
      "linear.bias:\n",
      " [0.00022118]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502428e-03 -1.0769651e-04  2.9475465e-05  1.0815123e-04\n",
      "   1.7081367e-04 -1.9643907e-05 -1.3402720e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484785e-03 -1.0377353e-04  2.9459203e-05  1.2719109e-04\n",
      "   1.7244824e-04 -8.0280115e-06 -1.3248462e-04]]\n",
      "linear.bias:\n",
      " [0.00022139]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04578061e-03 -1.00307676e-04  2.91087417e-05  8.89302173e-05\n",
      "   1.72899890e-04 -4.67329264e-05 -1.32247267e-04]]\n",
      "linear.bias:\n",
      " [0.00022234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434636e-03 -9.4526207e-05  2.8834587e-05  9.0253248e-05\n",
      "   1.7044767e-04 -3.2190546e-05 -1.3367842e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409664e-03 -9.0778121e-05  2.8730992e-05  1.2239031e-04\n",
      "   1.6833731e-04  1.8631803e-05 -1.3519872e-04]]\n",
      "linear.bias:\n",
      " [0.00022384]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371474e-03 -8.8448374e-05  2.8875900e-05  9.0116053e-05\n",
      "   1.6600202e-04 -2.8434384e-05 -1.3786447e-04]]\n",
      "linear.bias:\n",
      " [0.00022442]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0362618e-03 -9.0097885e-05  2.8736118e-05  8.7043169e-05\n",
      "   1.6454446e-04 -4.4776367e-05 -1.3991841e-04]]\n",
      "linear.bias:\n",
      " [0.00022444]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03717763e-03 -9.54919815e-05  2.81665689e-05  1.13069465e-04\n",
      "   1.63392237e-04 -2.44484363e-05 -1.41703553e-04]]\n",
      "linear.bias:\n",
      " [0.00022408]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03959080e-03 -1.02360988e-04  2.75971306e-05  1.18596654e-04\n",
      "   1.65004021e-04 -2.04333610e-05 -1.41877637e-04]]\n",
      "linear.bias:\n",
      " [0.00022388]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04366569e-03 -1.10200664e-04  2.70906858e-05  9.65920553e-05\n",
      "   1.69029227e-04 -4.77970607e-05 -1.40501317e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04785583e-03 -1.14734896e-04  2.66171573e-05  1.03474165e-04\n",
      "   1.71669279e-04 -2.87330950e-05 -1.39904500e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05097075e-03 -1.14187926e-04  2.61831610e-05  1.16666903e-04\n",
      "   1.73195091e-04  1.45417325e-05 -1.40252319e-04]]\n",
      "linear.bias:\n",
      " [0.00022259]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0519576e-03 -1.1102886e-04  2.6284646e-05  6.9962480e-05\n",
      "   1.7395680e-04 -3.7005579e-05 -1.4104767e-04]]\n",
      "linear.bias:\n",
      " [0.00022203]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0529005e-03 -1.0577422e-04  2.6810334e-05  8.9681562e-05\n",
      "   1.7179258e-04 -3.5829267e-05 -1.4251684e-04]]\n",
      "linear.bias:\n",
      " [0.00022153]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525448e-03 -1.0272421e-04  2.7714546e-05  1.3513881e-04\n",
      "   1.7007386e-04  3.5947596e-07 -1.4361707e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05033477e-03 -9.99473123e-05  2.80779823e-05  1.03815706e-04\n",
      "   1.68332233e-04 -3.32976379e-05 -1.45265658e-04]]\n",
      "linear.bias:\n",
      " [0.00022068]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475629e-03 -9.9709076e-05  2.8852515e-05  7.8234887e-05\n",
      "   1.6843084e-04 -4.4677290e-05 -1.4597105e-04]]\n",
      "linear.bias:\n",
      " [0.00022069]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443669e-03 -1.0062445e-04  2.9467919e-05  9.7945274e-05\n",
      "   1.6851834e-04 -1.5063459e-05 -1.4620200e-04]]\n",
      "linear.bias:\n",
      " [0.00022083]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04253809e-03 -1.03902334e-04  3.03900724e-05  1.10326466e-04\n",
      "   1.70980202e-04 -2.68572239e-06 -1.44854508e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423941e-03 -1.0840474e-04  3.1418047e-05  9.7228338e-05\n",
      "   1.7479972e-04 -2.7485305e-05 -1.4245870e-04]]\n",
      "linear.bias:\n",
      " [0.00022094]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04218302e-03 -1.12490794e-04  3.19371065e-05  1.03723345e-04\n",
      "   1.77501381e-04 -1.86910838e-05 -1.40615943e-04]]\n",
      "linear.bias:\n",
      " [0.00022118]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417965e-03 -1.1375870e-04  3.2123418e-05  9.8617107e-05\n",
      "   1.8048244e-04 -1.8570245e-05 -1.3861254e-04]]\n",
      "linear.bias:\n",
      " [0.00022216]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04145415e-03 -1.10251407e-04  3.20334839e-05  1.08035565e-04\n",
      "   1.81459691e-04 -2.45720184e-06 -1.37710289e-04]]\n",
      "linear.bias:\n",
      " [0.0002233]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429601e-03 -1.0534111e-04  3.1353484e-05  8.7104418e-05\n",
      "   1.8136782e-04 -3.6881313e-05 -1.3692037e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443935e-03 -9.8160468e-05  3.0787567e-05  1.0814855e-04\n",
      "   1.7783242e-04 -1.5963491e-05 -1.3801359e-04]]\n",
      "linear.bias:\n",
      " [0.00022488]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467578e-03 -9.4629693e-05  3.0156898e-05  1.1267611e-04\n",
      "   1.7534080e-04 -8.2688421e-06 -1.3855370e-04]]\n",
      "linear.bias:\n",
      " [0.00022562]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493783e-03 -9.3016875e-05  2.9570296e-05  8.5353102e-05\n",
      "   1.7432480e-04 -3.4173743e-05 -1.3816083e-04]]\n",
      "linear.bias:\n",
      " [0.00022616]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0517591e-03 -9.4381227e-05  2.9147273e-05  9.3716670e-05\n",
      "   1.7338773e-04 -1.9145144e-05 -1.3810013e-04]]\n",
      "linear.bias:\n",
      " [0.00022639]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0529960e-03 -9.7659453e-05  2.9301335e-05  1.2173680e-04\n",
      "   1.7346334e-04  8.5553656e-06 -1.3736830e-04]]\n",
      "linear.bias:\n",
      " [0.00022621]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05135597e-03 -1.01123056e-04  2.95112222e-05  8.19218039e-05\n",
      "   1.73071050e-04 -6.18938793e-05 -1.38115618e-04]]\n",
      "linear.bias:\n",
      " [0.0002258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491647e-03 -1.0139587e-04  2.9722863e-05  1.0560773e-04\n",
      "   1.6931865e-04 -4.4768465e-05 -1.4019867e-04]]\n",
      "linear.bias:\n",
      " [0.00022491]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464942e-03 -1.0212399e-04  3.0000476e-05  1.4369302e-04\n",
      "   1.6596787e-04  5.6168028e-06 -1.4218020e-04]]\n",
      "linear.bias:\n",
      " [0.00022411]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417259e-03 -1.0184513e-04  2.9371633e-05  8.6826156e-05\n",
      "   1.6457727e-04 -4.1484447e-05 -1.4489205e-04]]\n",
      "linear.bias:\n",
      " [0.00022327]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03700929e-03 -1.03013444e-04  2.89276286e-05  6.55053882e-05\n",
      "   1.63482007e-04 -4.74141707e-05 -1.47267187e-04]]\n",
      "linear.bias:\n",
      " [0.00022251]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03279366e-03 -1.00943143e-04  2.88609226e-05  1.19809454e-04\n",
      "   1.63169592e-04 -8.98646249e-07 -1.48206615e-04]]\n",
      "linear.bias:\n",
      " [0.00022131]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0313226e-03 -1.0092468e-04  2.9189732e-05  1.3656888e-04\n",
      "   1.6662620e-04 -2.5762088e-06 -1.4731429e-04]]\n",
      "linear.bias:\n",
      " [0.00022023]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0317224e-03 -1.0157285e-04  2.9405643e-05  9.0099784e-05\n",
      "   1.7202030e-04 -5.7378205e-05 -1.4562269e-04]]\n",
      "linear.bias:\n",
      " [0.00021964]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0322800e-03 -9.9486213e-05  2.9617620e-05  8.1692662e-05\n",
      "   1.7597624e-04 -5.7323272e-05 -1.4479666e-04]]\n",
      "linear.bias:\n",
      " [0.00021924]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0333260e-03 -9.4624542e-05  2.9739027e-05  1.3383609e-04\n",
      "   1.7669830e-04  1.6657341e-05 -1.4499329e-04]]\n",
      "linear.bias:\n",
      " [0.00021927]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0333383e-03 -9.0420101e-05  2.9803627e-05  9.6081814e-05\n",
      "   1.7745723e-04 -2.4774206e-05 -1.4638147e-04]]\n",
      "linear.bias:\n",
      " [0.00021967]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0349260e-03 -8.9846631e-05  2.9445251e-05  7.4022544e-05\n",
      "   1.7896800e-04 -4.1024457e-05 -1.4694559e-04]]\n",
      "linear.bias:\n",
      " [0.00022017]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0365471e-03 -9.1763934e-05  2.9394158e-05  1.0932075e-04\n",
      "   1.7914480e-04 -1.5683681e-05 -1.4738737e-04]]\n",
      "linear.bias:\n",
      " [0.00022036]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03923108e-03 -9.55284559e-05  2.93789308e-05  1.24732629e-04\n",
      "   1.80481089e-04 -1.27406765e-05 -1.46731050e-04]]\n",
      "linear.bias:\n",
      " [0.00022066]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04196311e-03 -1.00914935e-04  2.95676491e-05  1.00939731e-04\n",
      "   1.82756296e-04 -4.78546499e-05 -1.45602156e-04]]\n",
      "linear.bias:\n",
      " [0.00022106]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04488758e-03 -1.02851729e-04  2.94985402e-05  1.05197476e-04\n",
      "   1.83005264e-04 -3.64458028e-05 -1.45573504e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04671065e-03 -1.04962324e-04  2.93155426e-05  1.24180922e-04\n",
      "   1.82462391e-04  5.93275035e-06 -1.45776226e-04]]\n",
      "linear.bias:\n",
      " [0.000222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04756386e-03 -1.04882616e-04  2.91924825e-05  8.63067107e-05\n",
      "   1.80046351e-04 -2.88649899e-05 -1.46740902e-04]]\n",
      "linear.bias:\n",
      " [0.00022239]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04814768e-03 -1.05775536e-04  2.93032845e-05  8.59416905e-05\n",
      "   1.77226000e-04 -2.91717733e-05 -1.47782412e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485051e-03 -1.0793189e-04  2.9730070e-05  1.1863673e-04\n",
      "   1.7516837e-04  1.9387444e-06 -1.4845346e-04]]\n",
      "linear.bias:\n",
      " [0.00022318]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04884291e-03 -1.09399894e-04  3.01618893e-05  1.17756630e-04\n",
      "   1.74788031e-04 -8.98951475e-06 -1.47931729e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04901032e-03 -1.09251145e-04  3.03183515e-05  8.52214071e-05\n",
      "   1.75441804e-04 -5.56857703e-05 -1.46532795e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04835792e-03 -1.06464664e-04  3.03231373e-05  9.78492462e-05\n",
      "   1.74516448e-04 -4.72748216e-05 -1.45795188e-04]]\n",
      "linear.bias:\n",
      " [0.00022299]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04770495e-03 -1.01420854e-04  3.03803135e-05  1.41677359e-04\n",
      "   1.72428874e-04  6.73821705e-06 -1.45836661e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449799e-03 -9.6998258e-05  2.9779330e-05  9.5432013e-05\n",
      "   1.7129282e-04 -3.3225169e-05 -1.4652332e-04]]\n",
      "linear.bias:\n",
      " [0.00022294]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418943e-03 -9.4686126e-05  2.9607401e-05  7.6034630e-05\n",
      "   1.7075276e-04 -3.6825804e-05 -1.4686539e-04]]\n",
      "linear.bias:\n",
      " [0.00022272]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391036e-03 -9.5039046e-05  2.9532979e-05  1.0646944e-04\n",
      "   1.7046719e-04 -4.7794711e-06 -1.4662031e-04]]\n",
      "linear.bias:\n",
      " [0.0002224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381101e-03 -9.7466349e-05  2.9890754e-05  1.1469863e-04\n",
      "   1.7262320e-04 -1.1638273e-05 -1.4467232e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03874889e-03 -1.01234284e-04  3.04145342e-05  9.77436503e-05\n",
      "   1.76199843e-04 -5.37383530e-05 -1.41711746e-04]]\n",
      "linear.bias:\n",
      " [0.00022097]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391918e-03 -1.0173939e-04  3.0716335e-05  1.1383637e-04\n",
      "   1.7735893e-04 -4.5830853e-05 -1.4008992e-04]]\n",
      "linear.bias:\n",
      " [0.00022043]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415516e-03 -1.0333499e-04  3.0142995e-05  1.2993724e-04\n",
      "   1.7845472e-04 -1.1374443e-05 -1.3899154e-04]]\n",
      "linear.bias:\n",
      " [0.00022034]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437412e-03 -1.0488031e-04  2.9273217e-05  8.9041008e-05\n",
      "   1.7820593e-04 -2.6080041e-05 -1.3865950e-04]]\n",
      "linear.bias:\n",
      " [0.00022064]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456308e-03 -1.0333535e-04  2.8437114e-05  8.5445805e-05\n",
      "   1.7558670e-04  6.7976180e-06 -1.3951231e-04]]\n",
      "linear.bias:\n",
      " [0.00022117]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468868e-03 -1.0204243e-04  2.8435576e-05  8.5782565e-05\n",
      "   1.7294992e-04  3.0816768e-06 -1.3967296e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474130e-03 -1.0156069e-04  2.9075423e-05  8.7504945e-05\n",
      "   1.7138128e-04 -2.2778755e-05 -1.3867299e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474792e-03 -1.0242823e-04  3.0001156e-05  1.2049194e-04\n",
      "   1.7033063e-04 -2.3615123e-05 -1.3757273e-04]]\n",
      "linear.bias:\n",
      " [0.00022137]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04798225e-03 -1.04087871e-04  3.06028633e-05  1.21279765e-04\n",
      "   1.70100160e-04 -4.55073678e-05 -1.36201677e-04]]\n",
      "linear.bias:\n",
      " [0.00022157]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478031e-03 -1.0581717e-04  3.1148458e-05  1.2118428e-04\n",
      "   1.7009069e-04 -4.0115439e-05 -1.3517134e-04]]\n",
      "linear.bias:\n",
      " [0.00022227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462304e-03 -1.0754041e-04  3.1627580e-05  1.1630094e-04\n",
      "   1.7021812e-04 -1.2035955e-05 -1.3456079e-04]]\n",
      "linear.bias:\n",
      " [0.00022329]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452193e-03 -1.0976096e-04  3.1793024e-05  7.5920354e-05\n",
      "   1.7114992e-04 -1.9359995e-05 -1.3350009e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445368e-03 -1.0937111e-04  3.2146341e-05  8.9002438e-05\n",
      "   1.6961076e-04  5.6327808e-06 -1.3370029e-04]]\n",
      "linear.bias:\n",
      " [0.00022516]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463325e-03 -1.0997130e-04  3.2295851e-05  9.6373456e-05\n",
      "   1.6916811e-04 -6.4555443e-06 -1.3293154e-04]]\n",
      "linear.bias:\n",
      " [0.00022538]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484797e-03 -1.1072350e-04  3.2779000e-05  9.9423065e-05\n",
      "   1.7010639e-04 -4.1570158e-05 -1.3125113e-04]]\n",
      "linear.bias:\n",
      " [0.00022544]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509702e-03 -1.0832127e-04  3.2994540e-05  1.2522463e-04\n",
      "   1.6908966e-04 -2.8210769e-05 -1.3123610e-04]]\n",
      "linear.bias:\n",
      " [0.00022549]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05061720e-03 -1.02810096e-04  3.26697955e-05  1.10549321e-04\n",
      "   1.68651313e-04 -3.51620256e-05 -1.31503926e-04]]\n",
      "linear.bias:\n",
      " [0.00022567]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496485e-03 -9.7943674e-05  3.2344353e-05  9.9221725e-05\n",
      "   1.6845178e-04 -1.4997511e-05 -1.3205167e-04]]\n",
      "linear.bias:\n",
      " [0.00022623]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483334e-03 -9.5130090e-05  3.2545744e-05  9.3640556e-05\n",
      "   1.6894325e-04 -3.9069319e-06 -1.3205581e-04]]\n",
      "linear.bias:\n",
      " [0.0002266]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483895e-03 -9.5506301e-05  3.2766140e-05  8.7749417e-05\n",
      "   1.7032352e-04 -1.3753031e-05 -1.3116271e-04]]\n",
      "linear.bias:\n",
      " [0.00022627]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04847248e-03 -9.69983521e-05  3.30549701e-05  1.06317915e-04\n",
      "   1.71301377e-04 -1.04400851e-05 -1.30692220e-04]]\n",
      "linear.bias:\n",
      " [0.00022572]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486061e-03 -1.0147415e-04  3.2902808e-05  9.9097211e-05\n",
      "   1.7261630e-04 -2.7581838e-05 -1.3032735e-04]]\n",
      "linear.bias:\n",
      " [0.00022522]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484651e-03 -1.0545131e-04  3.2329022e-05  1.1223777e-04\n",
      "   1.7275399e-04 -1.5838516e-05 -1.3087445e-04]]\n",
      "linear.bias:\n",
      " [0.00022477]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486359e-03 -1.1004469e-04  3.1259868e-05  9.4030846e-05\n",
      "   1.7314426e-04 -2.5877222e-05 -1.3131784e-04]]\n",
      "linear.bias:\n",
      " [0.00022476]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04902906e-03 -1.11209498e-04  3.00971478e-05  1.03154256e-04\n",
      "   1.71475855e-04  7.16687282e-07 -1.33104128e-04]]\n",
      "linear.bias:\n",
      " [0.00022449]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480455e-03 -1.1038512e-04  2.9531324e-05  8.5934109e-05\n",
      "   1.7133080e-04 -1.8194994e-05 -1.3383025e-04]]\n",
      "linear.bias:\n",
      " [0.00022412]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04720367e-03 -1.07587824e-04  2.93621069e-05  1.04955121e-04\n",
      "   1.69800958e-04 -5.30363832e-06 -1.35207942e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04609609e-03 -1.05676423e-04  2.99610365e-05  1.06240834e-04\n",
      "   1.70123560e-04 -2.11743300e-05 -1.35334340e-04]]\n",
      "linear.bias:\n",
      " [0.0002231]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438026e-03 -1.0486454e-04  3.0483852e-05  9.9450408e-05\n",
      "   1.7073052e-04 -3.1816220e-05 -1.3537612e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417099e-03 -1.0408042e-04  3.0472340e-05  1.1350085e-04\n",
      "   1.7041182e-04 -6.3679599e-06 -1.3591202e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406536e-03 -1.0498616e-04  3.0686766e-05  9.4483927e-05\n",
      "   1.7176714e-04 -2.3501028e-05 -1.3547354e-04]]\n",
      "linear.bias:\n",
      " [0.00022426]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03956845e-03 -1.06800966e-04  3.07271875e-05  9.91339402e-05\n",
      "   1.72459520e-04 -1.45943513e-05 -1.35371971e-04]]\n",
      "linear.bias:\n",
      " [0.00022443]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04105729e-03 -1.10365152e-04  3.04879777e-05  1.10133726e-04\n",
      "   1.73483160e-04 -1.11978106e-05 -1.35134673e-04]]\n",
      "linear.bias:\n",
      " [0.00022432]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435386e-03 -1.1424685e-04  2.9983481e-05  9.0751142e-05\n",
      "   1.7525058e-04 -3.7248006e-05 -1.3409894e-04]]\n",
      "linear.bias:\n",
      " [0.00022436]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04583963e-03 -1.14999857e-04  2.94534930e-05  1.07985594e-04\n",
      "   1.74182627e-04 -1.10177880e-05 -1.34781803e-04]]\n",
      "linear.bias:\n",
      " [0.00022426]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462540e-03 -1.1274696e-04  2.8898847e-05  9.2068120e-05\n",
      "   1.7428125e-04 -1.5322477e-05 -1.3467937e-04]]\n",
      "linear.bias:\n",
      " [0.0002243]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473543e-03 -1.0758940e-04  2.8531225e-05  9.7423865e-05\n",
      "   1.7266096e-04 -7.6087817e-06 -1.3533171e-04]]\n",
      "linear.bias:\n",
      " [0.00022421]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480615e-03 -1.0344786e-04  2.8876173e-05  9.6514508e-05\n",
      "   1.7263314e-04 -2.6426233e-05 -1.3475552e-04]]\n",
      "linear.bias:\n",
      " [0.00022386]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475868e-03 -9.9989331e-05  2.9070285e-05  1.1397967e-04\n",
      "   1.7166765e-04 -1.8193674e-05 -1.3456983e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477089e-03 -9.8714714e-05  2.9259907e-05  1.0486646e-04\n",
      "   1.7197036e-04 -3.2414227e-05 -1.3362219e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470508e-03 -9.7615048e-05  2.9268618e-05  1.1067830e-04\n",
      "   1.7147489e-04 -1.0944199e-05 -1.3329617e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468945e-03 -9.8523589e-05  2.9338511e-05  8.6606939e-05\n",
      "   1.7244453e-04 -2.0995751e-05 -1.3229059e-04]]\n",
      "linear.bias:\n",
      " [0.00022331]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463276e-03 -1.0033291e-04  2.9673445e-05  9.8821249e-05\n",
      "   1.7246870e-04 -6.3725147e-06 -1.3194600e-04]]\n",
      "linear.bias:\n",
      " [0.00022332]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04709517e-03 -1.04809653e-04  2.99899129e-05  1.07049746e-04\n",
      "   1.73462933e-04 -1.36900835e-05 -1.30802146e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469570e-03 -1.0966861e-04  3.0367755e-05  1.0145597e-04\n",
      "   1.7453374e-04 -2.6314410e-05 -1.2961346e-04]]\n",
      "linear.bias:\n",
      " [0.00022271]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471718e-03 -1.1068881e-04  3.0456329e-05  1.1485642e-04\n",
      "   1.7356245e-04 -3.1208310e-06 -1.2989737e-04]]\n",
      "linear.bias:\n",
      " [0.00022278]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04671880e-03 -1.10343084e-04  2.97596816e-05  6.90796878e-05\n",
      "   1.70595129e-04 -3.69497648e-05 -1.31747540e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461820e-03 -1.0643116e-04  2.9025061e-05  8.8185036e-05\n",
      "   1.6398953e-04 -1.6952834e-05 -1.3493735e-04]]\n",
      "linear.bias:\n",
      " [0.00022415]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04589725e-03 -1.04189756e-04  2.86480135e-05  1.31609064e-04\n",
      "   1.58665789e-04  2.10324997e-05 -1.37555428e-04]]\n",
      "linear.bias:\n",
      " [0.00022434]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429136e-03 -9.9078257e-05  2.8099746e-05  7.9508987e-05\n",
      "   1.5779723e-04 -7.5021242e-05 -1.4064697e-04]]\n",
      "linear.bias:\n",
      " [0.00022411]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405011e-03 -9.2249385e-05  2.7758608e-05  8.7242130e-05\n",
      "   1.5714143e-04 -6.5026928e-05 -1.4439809e-04]]\n",
      "linear.bias:\n",
      " [0.0002239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386836e-03 -8.8879104e-05  2.7481512e-05  1.3046153e-04\n",
      "   1.5798680e-04  5.0610543e-06 -1.4741957e-04]]\n",
      "linear.bias:\n",
      " [0.00022371]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0376935e-03 -8.8990128e-05  2.7853281e-05  1.1781094e-04\n",
      "   1.6280700e-04  7.6638480e-06 -1.4865924e-04]]\n",
      "linear.bias:\n",
      " [0.00022354]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371499e-03 -9.2599403e-05  2.8814356e-05  6.7982146e-05\n",
      "   1.7072744e-04 -4.4085966e-05 -1.4822884e-04]]\n",
      "linear.bias:\n",
      " [0.00022312]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0361612e-03 -9.7676697e-05  2.9371186e-05  9.0072397e-05\n",
      "   1.7808599e-04 -4.9523791e-05 -1.4684582e-04]]\n",
      "linear.bias:\n",
      " [0.00022234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03536120e-03 -1.00662335e-04  3.02163953e-05  1.44427322e-04\n",
      "   1.83910393e-04 -9.56318763e-06 -1.46124818e-04]]\n",
      "linear.bias:\n",
      " [0.00022151]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0342972e-03 -1.0282250e-04  3.0099854e-05  1.2012639e-04\n",
      "   1.8842299e-04 -2.8394708e-05 -1.4622236e-04]]\n",
      "linear.bias:\n",
      " [0.00022116]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03453430e-03 -1.05664665e-04  2.97366969e-05  7.59762479e-05\n",
      "   1.93240092e-04 -6.29304850e-05 -1.45610873e-04]]\n",
      "linear.bias:\n",
      " [0.00022125]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03499007e-03 -1.05070925e-04  2.92675868e-05  1.21704754e-04\n",
      "   1.89837825e-04  2.60411616e-06 -1.47916653e-04]]\n",
      "linear.bias:\n",
      " [0.00022106]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03545538e-03 -1.03050414e-04  2.89133768e-05  1.11514644e-04\n",
      "   1.84989258e-04 -8.39072072e-06 -1.50525870e-04]]\n",
      "linear.bias:\n",
      " [0.00022088]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374570e-03 -1.0286404e-04  2.8802520e-05  7.7579032e-05\n",
      "   1.8231101e-04 -5.4569649e-05 -1.5163013e-04]]\n",
      "linear.bias:\n",
      " [0.0002206]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0394288e-03 -9.9716664e-05  2.8745828e-05  1.0662203e-04\n",
      "   1.7618710e-04 -2.5016770e-05 -1.5356492e-04]]\n",
      "linear.bias:\n",
      " [0.00022034]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420654e-03 -9.9451529e-05  2.8846454e-05  1.2221861e-04\n",
      "   1.7287309e-04 -8.1979069e-06 -1.5394895e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458215e-03 -1.0159758e-04  2.9122848e-05  1.0508158e-04\n",
      "   1.7342747e-04 -3.4362991e-05 -1.5250573e-04]]\n",
      "linear.bias:\n",
      " [0.00022]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04835536e-03 -1.06021624e-04  2.98694758e-05  9.42333136e-05\n",
      "   1.75665496e-04 -3.83118568e-05 -1.50307067e-04]]\n",
      "linear.bias:\n",
      " [0.0002198]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04920287e-03 -1.10750436e-04  3.07071823e-05  1.11385772e-04\n",
      "   1.77428956e-04 -4.23501479e-06 -1.48296531e-04]]\n",
      "linear.bias:\n",
      " [0.00021962]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05010590e-03 -1.13834285e-04  3.11941767e-05  9.61607439e-05\n",
      "   1.80399744e-04 -9.73628994e-06 -1.45470010e-04]]\n",
      "linear.bias:\n",
      " [0.00021946]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04957586e-03 -1.14542425e-04  3.18385573e-05  8.03008006e-05\n",
      "   1.83647891e-04 -3.28030146e-05 -1.41947035e-04]]\n",
      "linear.bias:\n",
      " [0.00021971]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475043e-03 -1.0963739e-04  3.1920532e-05  1.1788224e-04\n",
      "   1.8253978e-04 -3.6209894e-07 -1.4016782e-04]]\n",
      "linear.bias:\n",
      " [0.00022048]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04537525e-03 -1.03751794e-04  3.11731092e-05  9.58754317e-05\n",
      "   1.79144539e-04 -3.05876347e-05 -1.40054195e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434081e-03 -9.8498502e-05  3.0032268e-05  9.8273129e-05\n",
      "   1.7517993e-04 -2.2239332e-05 -1.4038529e-04]]\n",
      "linear.bias:\n",
      " [0.00022321]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04212202e-03 -9.68604145e-05  2.86489703e-05  1.10364854e-04\n",
      "   1.71590116e-04 -3.19702303e-06 -1.40323478e-04]]\n",
      "linear.bias:\n",
      " [0.00022431]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425567e-03 -9.7028736e-05  2.7612767e-05  9.6403761e-05\n",
      "   1.7005604e-04 -2.2417120e-05 -1.3901465e-04]]\n",
      "linear.bias:\n",
      " [0.00022516]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425927e-03 -9.8665558e-05  2.7384624e-05  9.9183097e-05\n",
      "   1.7011441e-04 -2.7769656e-05 -1.3723539e-04]]\n",
      "linear.bias:\n",
      " [0.00022539]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420365e-03 -1.0172041e-04  2.7633951e-05  1.1735615e-04\n",
      "   1.7114216e-04 -1.1388702e-05 -1.3534128e-04]]\n",
      "linear.bias:\n",
      " [0.00022505]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421141e-03 -1.0620364e-04  2.7875631e-05  9.8570243e-05\n",
      "   1.7341076e-04 -3.1684467e-05 -1.3290103e-04]]\n",
      "linear.bias:\n",
      " [0.00022475]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426707e-03 -1.0718714e-04  2.7842714e-05  1.0795015e-04\n",
      "   1.7356730e-04 -6.3202733e-06 -1.3173904e-04]]\n",
      "linear.bias:\n",
      " [0.00022447]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438020e-03 -1.0860730e-04  2.7713921e-05  8.5985288e-05\n",
      "   1.7484816e-04 -1.9701856e-05 -1.2975959e-04]]\n",
      "linear.bias:\n",
      " [0.00022409]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447642e-03 -1.0675049e-04  2.7801369e-05  1.0285351e-04\n",
      "   1.7366036e-04  2.0318384e-06 -1.2935657e-04]]\n",
      "linear.bias:\n",
      " [0.00022362]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465933e-03 -1.0617120e-04  2.8103679e-05  8.6360364e-05\n",
      "   1.7349304e-04 -2.9847610e-05 -1.2849629e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483610e-03 -1.0279416e-04  2.8420369e-05  1.0839569e-04\n",
      "   1.7027394e-04 -8.4426138e-06 -1.2948719e-04]]\n",
      "linear.bias:\n",
      " [0.00022254]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483521e-03 -1.0096311e-04  2.9056439e-05  9.7094118e-05\n",
      "   1.6857700e-04 -1.8701225e-05 -1.3055788e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472472e-03 -1.0070435e-04  2.9827745e-05  9.9142177e-05\n",
      "   1.6672695e-04 -1.7759949e-05 -1.3156456e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04514777e-03 -1.02341743e-04  3.07175796e-05  1.04657396e-04\n",
      "   1.65602192e-04 -1.35425435e-05 -1.32145244e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "Epoch [3000/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447251e-03 -1.0567153e-04  3.1775820e-05  9.0388974e-05\n",
      "   1.6639722e-04 -4.0540115e-05 -1.3141685e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04421214e-03 -1.05716164e-04  3.25758119e-05  1.10945897e-04\n",
      "   1.64897239e-04 -1.70180010e-05 -1.32172208e-04]]\n",
      "linear.bias:\n",
      " [0.00022372]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449638e-03 -1.0666713e-04  3.3033994e-05  1.0700374e-04\n",
      "   1.6431176e-04 -1.3498473e-05 -1.3214232e-04]]\n",
      "linear.bias:\n",
      " [0.00022436]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468396e-03 -1.0946421e-04  3.3489578e-05  8.0994811e-05\n",
      "   1.6525459e-04 -3.6006961e-05 -1.3107197e-04]]\n",
      "linear.bias:\n",
      " [0.00022508]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483043e-03 -1.0957304e-04  3.3822758e-05  9.7961223e-05\n",
      "   1.6458707e-04 -5.1816605e-06 -1.3119976e-04]]\n",
      "linear.bias:\n",
      " [0.00022532]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488391e-03 -1.0846115e-04  3.4646724e-05  1.0707069e-04\n",
      "   1.6570941e-04 -3.3643641e-06 -1.3002950e-04]]\n",
      "linear.bias:\n",
      " [0.00022539]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484281e-03 -1.0581058e-04  3.4750832e-05  7.8708603e-05\n",
      "   1.6880086e-04 -4.1961011e-05 -1.2818645e-04]]\n",
      "linear.bias:\n",
      " [0.00022533]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479789e-03 -1.0066593e-04  3.4736629e-05  1.0004491e-04\n",
      "   1.6776031e-04 -2.1433805e-05 -1.2848356e-04]]\n",
      "linear.bias:\n",
      " [0.00022486]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476685e-03 -9.5677708e-05  3.4358167e-05  1.2622523e-04\n",
      "   1.6649743e-04  1.8278135e-05 -1.2967631e-04]]\n",
      "linear.bias:\n",
      " [0.00022457]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449305e-03 -8.9997251e-05  3.3429205e-05  7.7475052e-05\n",
      "   1.6469361e-04 -4.9611837e-05 -1.3271875e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425274e-03 -8.8214307e-05  3.2622793e-05  7.4967560e-05\n",
      "   1.6238877e-04 -6.7235989e-05 -1.3605090e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0412148e-03 -8.7400113e-05  3.1830768e-05  1.4765272e-04\n",
      "   1.5747870e-04  1.6011516e-05 -1.4093009e-04]]\n",
      "linear.bias:\n",
      " [0.00022166]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0364662e-03 -8.6551845e-05  3.1203646e-05  1.1153903e-04\n",
      "   1.5805692e-04 -2.1973166e-05 -1.4558034e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0336845e-03 -8.9209192e-05  3.0500243e-05  5.6959969e-05\n",
      "   1.6258407e-04 -7.1177317e-05 -1.4792367e-04]]\n",
      "linear.bias:\n",
      " [0.00021954]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03302801e-03 -9.42288680e-05  3.00342708e-05  1.18756594e-04\n",
      "   1.64223573e-04 -6.38821803e-07 -1.50786829e-04]]\n",
      "linear.bias:\n",
      " [0.00021747]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0347209e-03 -1.0132825e-04  2.9858138e-05  1.4406881e-04\n",
      "   1.6941669e-04  2.1583175e-05 -1.5162116e-04]]\n",
      "linear.bias:\n",
      " [0.00021546]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352856e-03 -1.0606908e-04  2.9347348e-05  7.3041723e-05\n",
      "   1.7555903e-04 -8.6120788e-05 -1.5376454e-04]]\n",
      "linear.bias:\n",
      " [0.00021447]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0366755e-03 -1.0635135e-04  2.9234068e-05  9.1679387e-05\n",
      "   1.7749825e-04 -6.8308378e-05 -1.5666297e-04]]\n",
      "linear.bias:\n",
      " [0.00021345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381311e-03 -1.0341865e-04  2.9238667e-05  1.5266024e-04\n",
      "   1.7855124e-04  2.1672349e-05 -1.5948521e-04]]\n",
      "linear.bias:\n",
      " [0.00021348]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03874994e-03 -9.84267972e-05  2.88231695e-05  1.15183284e-04\n",
      "   1.79996860e-04 -2.13753519e-05 -1.62988144e-04]]\n",
      "linear.bias:\n",
      " [0.0002142]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407646e-03 -9.6272190e-05  2.8716455e-05  6.1692233e-05\n",
      "   1.8342484e-04 -7.9000034e-05 -1.6486133e-04]]\n",
      "linear.bias:\n",
      " [0.00021498]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437428e-03 -9.3120216e-05  2.9230008e-05  1.2897140e-04\n",
      "   1.8263036e-04 -1.6492078e-05 -1.6660488e-04]]\n",
      "linear.bias:\n",
      " [0.00021473]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477254e-03 -9.3396382e-05  2.9637780e-05  1.5522884e-04\n",
      "   1.8486050e-04  7.2742205e-06 -1.6660072e-04]]\n",
      "linear.bias:\n",
      " [0.00021463]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499842e-03 -9.3796843e-05  2.9692732e-05  8.7413609e-05\n",
      "   1.8786482e-04 -6.0095670e-05 -1.6683580e-04]]\n",
      "linear.bias:\n",
      " [0.0002151]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500237e-03 -9.4981522e-05  2.9792480e-05  7.3903895e-05\n",
      "   1.8954113e-04 -6.3077176e-05 -1.6613913e-04]]\n",
      "linear.bias:\n",
      " [0.00021607]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497952e-03 -9.3766706e-05  3.0210478e-05  1.3725652e-04\n",
      "   1.8783390e-04  8.6039654e-06 -1.6486943e-04]]\n",
      "linear.bias:\n",
      " [0.00021667]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490837e-03 -9.3535862e-05  3.1005464e-05  1.3019548e-04\n",
      "   1.8696542e-04 -2.2838203e-06 -1.6326254e-04]]\n",
      "linear.bias:\n",
      " [0.00021748]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486534e-03 -9.5289528e-05  3.1653537e-05  6.5576416e-05\n",
      "   1.8652754e-04 -6.0841900e-05 -1.6159669e-04]]\n",
      "linear.bias:\n",
      " [0.00021862]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485282e-03 -9.6990567e-05  3.2307940e-05  1.0658552e-04\n",
      "   1.8136526e-04 -2.6168393e-05 -1.6007719e-04]]\n",
      "linear.bias:\n",
      " [0.00021855]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04895537e-03 -1.01359874e-04  3.30278708e-05  1.40146512e-04\n",
      "   1.78339804e-04 -1.66897735e-06 -1.57313843e-04]]\n",
      "linear.bias:\n",
      " [0.00021877]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04950985e-03 -1.04316736e-04  3.31705378e-05  9.97789757e-05\n",
      "   1.76037400e-04 -3.61343591e-05 -1.54801091e-04]]\n",
      "linear.bias:\n",
      " [0.00021951]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04882393e-03 -1.08411194e-04  3.34164288e-05  7.51754123e-05\n",
      "   1.74366884e-04 -4.22733938e-05 -1.51948305e-04]]\n",
      "linear.bias:\n",
      " [0.00022045]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473527e-03 -1.0709192e-04  3.3124954e-05  1.0538945e-04\n",
      "   1.7180275e-04  4.0236991e-06 -1.4927442e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04779389e-03 -1.06067724e-04  3.29144932e-05  1.11950030e-04\n",
      "   1.72878747e-04  9.24072083e-06 -1.44692662e-04]]\n",
      "linear.bias:\n",
      " [0.00022218]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487078e-03 -1.0547972e-04  3.2852971e-05  8.3939907e-05\n",
      "   1.7461130e-04 -4.1910702e-05 -1.3998442e-04]]\n",
      "linear.bias:\n",
      " [0.00022231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492847e-03 -1.0198097e-04  3.2628504e-05  9.7817385e-05\n",
      "   1.7340628e-04 -4.0647654e-05 -1.3695587e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497528e-03 -9.8878219e-05  3.1946103e-05  1.3245791e-04\n",
      "   1.7138977e-04 -4.4234184e-06 -1.3467370e-04]]\n",
      "linear.bias:\n",
      " [0.00022292]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481265e-03 -9.6683820e-05  3.0493924e-05  9.2734932e-05\n",
      "   1.6933170e-04 -2.6627771e-05 -1.3376604e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465216e-03 -9.5755990e-05  2.9026120e-05  7.8817306e-05\n",
      "   1.6692455e-04 -2.2580934e-05 -1.3325637e-04]]\n",
      "linear.bias:\n",
      " [0.00022446]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446492e-03 -9.6369731e-05  2.8101114e-05  9.9420446e-05\n",
      "   1.6507937e-04  4.7217036e-06 -1.3291134e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444570e-03 -9.9473575e-05  2.7785984e-05  9.7644399e-05\n",
      "   1.6623628e-04 -8.4164576e-06 -1.3102416e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456181e-03 -1.0524134e-04  2.7517739e-05  9.3275492e-05\n",
      "   1.6829331e-04 -4.0415183e-05 -1.2845450e-04]]\n",
      "linear.bias:\n",
      " [0.00022385]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467337e-03 -1.0755685e-04  2.7196733e-05  1.2416005e-04\n",
      "   1.6735442e-04 -2.0128384e-05 -1.2783625e-04]]\n",
      "linear.bias:\n",
      " [0.00022312]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461265e-03 -1.0969517e-04  2.7044276e-05  1.1271858e-04\n",
      "   1.6645246e-04 -2.9877810e-05 -1.2769915e-04]]\n",
      "linear.bias:\n",
      " [0.00022315]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04520505e-03 -1.08618115e-04  2.71568933e-05  1.03871294e-04\n",
      "   1.64715559e-04 -1.47132678e-05 -1.28484258e-04]]\n",
      "linear.bias:\n",
      " [0.00022346]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443866e-03 -1.0749565e-04  2.8045652e-05  9.0171699e-05\n",
      "   1.6442694e-04 -1.2753492e-05 -1.2867044e-04]]\n",
      "linear.bias:\n",
      " [0.00022387]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440318e-03 -1.0752436e-04  2.9085502e-05  9.6320109e-05\n",
      "   1.6382578e-04 -8.2335118e-06 -1.2911776e-04]]\n",
      "linear.bias:\n",
      " [0.00022397]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04416115e-03 -1.07699605e-04  3.03829765e-05  1.01066413e-04\n",
      "   1.64665194e-04 -2.40497120e-05 -1.28589454e-04]]\n",
      "linear.bias:\n",
      " [0.00022405]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04436779e-03 -1.07427935e-04  3.11526419e-05  1.10987123e-04\n",
      "   1.65150792e-04 -1.86674260e-05 -1.28730739e-04]]\n",
      "linear.bias:\n",
      " [0.00022441]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04485173e-03 -1.07967426e-04  3.15503712e-05  9.63638959e-05\n",
      "   1.66265017e-04 -2.88468982e-05 -1.28370535e-04]]\n",
      "linear.bias:\n",
      " [0.00022515]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04556384e-03 -1.05200765e-04  3.16707265e-05  1.07103042e-04\n",
      "   1.65152233e-04 -3.04551213e-06 -1.29594249e-04]]\n",
      "linear.bias:\n",
      " [0.00022567]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469502e-03 -1.0471271e-04  3.2081138e-05  8.3977691e-05\n",
      "   1.6612827e-04 -2.1624412e-05 -1.2999274e-04]]\n",
      "linear.bias:\n",
      " [0.00022615]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476972e-03 -1.0536184e-04  3.2610820e-05  9.5324023e-05\n",
      "   1.6646934e-04 -1.5228403e-05 -1.3082722e-04]]\n",
      "linear.bias:\n",
      " [0.00022629]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486870e-03 -1.0699588e-04  3.3248889e-05  1.1965515e-04\n",
      "   1.6730982e-04 -5.1805209e-06 -1.3142220e-04]]\n",
      "linear.bias:\n",
      " [0.00022629]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478705e-03 -1.0685631e-04  3.2619595e-05  8.6944594e-05\n",
      "   1.6789979e-04 -4.0541596e-05 -1.3268387e-04]]\n",
      "linear.bias:\n",
      " [0.000226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04706490e-03 -1.04103456e-04  3.20878462e-05  9.23075713e-05\n",
      "   1.67096252e-04 -2.32462280e-05 -1.34954011e-04]]\n",
      "linear.bias:\n",
      " [0.00022547]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465479e-03 -1.0296919e-04  3.1907588e-05  1.2347320e-04\n",
      "   1.6702802e-04  1.2077666e-05 -1.3673134e-04]]\n",
      "linear.bias:\n",
      " [0.00022456]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435844e-03 -1.0185272e-04  3.1390959e-05  8.3352352e-05\n",
      "   1.6734400e-04 -5.3135940e-05 -1.3961589e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411363e-03 -9.9276658e-05  3.1111238e-05  8.9998583e-05\n",
      "   1.6695792e-04 -6.0588631e-05 -1.4311967e-04]]\n",
      "linear.bias:\n",
      " [0.00022154]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0390208e-03 -9.4550349e-05  3.0768348e-05  1.2973069e-04\n",
      "   1.6632245e-04 -1.4126999e-05 -1.4685051e-04]]\n",
      "linear.bias:\n",
      " [0.00022019]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383263e-03 -9.3142742e-05  3.0195073e-05  1.2312086e-04\n",
      "   1.6930379e-04 -9.3871076e-06 -1.4867900e-04]]\n",
      "linear.bias:\n",
      " [0.00021897]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397612e-03 -9.4602547e-05  2.9707269e-05  8.3653125e-05\n",
      "   1.7544477e-04 -4.1026011e-05 -1.4875529e-04]]\n",
      "linear.bias:\n",
      " [0.00021787]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411342e-03 -9.7244847e-05  2.9508545e-05  8.4303210e-05\n",
      "   1.8089928e-04 -3.3216711e-05 -1.4869090e-04]]\n",
      "linear.bias:\n",
      " [0.00021717]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04245159e-03 -1.00952653e-04  2.95702539e-05  1.21077406e-04\n",
      "   1.85735596e-04  1.01137994e-05 -1.48499748e-04]]\n",
      "linear.bias:\n",
      " [0.00021681]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04375498e-03 -1.04634557e-04  2.99840885e-05  1.01188045e-04\n",
      "   1.89299215e-04 -2.54880870e-05 -1.48596271e-04]]\n",
      "linear.bias:\n",
      " [0.0002165]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443412e-03 -1.0850888e-04  3.0014251e-05  9.4339790e-05\n",
      "   1.9150080e-04 -4.1038489e-05 -1.4888721e-04]]\n",
      "linear.bias:\n",
      " [0.00021691]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447447e-03 -1.0856969e-04  3.0059009e-05  1.2380214e-04\n",
      "   1.9044249e-04 -8.1047874e-06 -1.5052759e-04]]\n",
      "linear.bias:\n",
      " [0.0002177]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452765e-03 -1.0852745e-04  3.0019655e-05  9.7620592e-05\n",
      "   1.8859397e-04 -2.3141225e-05 -1.5215449e-04]]\n",
      "linear.bias:\n",
      " [0.0002187]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441635e-03 -1.0965031e-04  3.0022939e-05  8.2647544e-05\n",
      "   1.8596854e-04 -2.9247933e-05 -1.5350214e-04]]\n",
      "linear.bias:\n",
      " [0.00022016]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430419e-03 -1.0709305e-04  2.9965589e-05  1.1974128e-04\n",
      "   1.8119301e-04  9.8880319e-06 -1.5537009e-04]]\n",
      "linear.bias:\n",
      " [0.00022176]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04309083e-03 -1.03268612e-04  3.01578057e-05  1.02467806e-04\n",
      "   1.76693342e-04 -2.47905646e-05 -1.56593844e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445818e-03 -1.0218834e-04  3.0680756e-05  8.7001434e-05\n",
      "   1.7502540e-04 -6.1145409e-05 -1.5608819e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450202e-03 -9.9348639e-05  3.1355285e-05  1.2180849e-04\n",
      "   1.7178396e-04 -2.9188323e-05 -1.5589732e-04]]\n",
      "linear.bias:\n",
      " [0.00022383]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471855e-03 -9.9033721e-05  3.1899614e-05  1.3465075e-04\n",
      "   1.7181803e-04 -1.4775766e-05 -1.5412763e-04]]\n",
      "linear.bias:\n",
      " [0.00022436]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504781e-03 -1.0095788e-04  3.2138691e-05  9.6020522e-05\n",
      "   1.7487862e-04 -4.2124870e-05 -1.5094718e-04]]\n",
      "linear.bias:\n",
      " [0.00022441]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0521029e-03 -1.0456082e-04  3.2833224e-05  8.9835441e-05\n",
      "   1.7789053e-04 -3.1417032e-05 -1.4783551e-04]]\n",
      "linear.bias:\n",
      " [0.00022431]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0520583e-03 -1.0858833e-04  3.3632492e-05  1.1141534e-04\n",
      "   1.8033797e-04  1.5654648e-05 -1.4500128e-04]]\n",
      "linear.bias:\n",
      " [0.00022423]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498416e-03 -1.0913447e-04  3.4232849e-05  8.3440376e-05\n",
      "   1.8121563e-04 -2.9905797e-05 -1.4313978e-04]]\n",
      "linear.bias:\n",
      " [0.00022373]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04759401e-03 -1.06589316e-04  3.46005254e-05  9.77837262e-05\n",
      "   1.79177732e-04 -2.32986677e-05 -1.42702294e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452215e-03 -1.0426496e-04  3.4501270e-05  1.2781227e-04\n",
      "   1.7638817e-04  4.8582060e-06 -1.4273313e-04]]\n",
      "linear.bias:\n",
      " [0.00022328]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423410e-03 -9.9895107e-05  3.3379722e-05  8.5469794e-05\n",
      "   1.7196636e-04 -3.4387602e-05 -1.4427172e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392803e-03 -9.7527940e-05  3.2504853e-05  7.8105673e-05\n",
      "   1.6815797e-04 -3.3086817e-05 -1.4558336e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03667122e-03 -9.68542809e-05  3.19402170e-05  1.14564005e-04\n",
      "   1.65141319e-04  3.76752723e-07 -1.46282793e-04]]\n",
      "linear.bias:\n",
      " [0.00022357]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0366272e-03 -9.8841047e-05  3.1645319e-05  1.1996985e-04\n",
      "   1.6622951e-04 -8.7118297e-06 -1.4490052e-04]]\n",
      "linear.bias:\n",
      " [0.00022328]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0389558e-03 -1.0330437e-04  3.1632218e-05  9.4371193e-05\n",
      "   1.7106310e-04 -5.7953577e-05 -1.4184765e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409750e-03 -1.0458707e-04  3.1630159e-05  1.0505597e-04\n",
      "   1.7412344e-04 -5.4376123e-05 -1.3991637e-04]]\n",
      "linear.bias:\n",
      " [0.00022236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434145e-03 -1.0222749e-04  3.1338001e-05  1.3506049e-04\n",
      "   1.7494784e-04 -7.9057718e-06 -1.3954809e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446351e-03 -1.0064582e-04  3.0365438e-05  9.2953262e-05\n",
      "   1.7484916e-04 -1.8048966e-05 -1.4006934e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457251e-03 -1.0038928e-04  2.9601413e-05  7.4594493e-05\n",
      "   1.7467080e-04 -2.0387019e-05 -1.4045938e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466495e-03 -1.0150524e-04  2.9287123e-05  1.0135755e-04\n",
      "   1.7442777e-04  1.0861986e-06 -1.4051866e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490753e-03 -1.0444484e-04  2.9225759e-05  1.0455792e-04\n",
      "   1.7597481e-04 -1.6184469e-05 -1.3904636e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05034374e-03 -1.07936525e-04  2.92149471e-05  1.04729414e-04\n",
      "   1.77219146e-04 -3.28726237e-05 -1.37516210e-04]]\n",
      "linear.bias:\n",
      " [0.00022323]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512269e-03 -1.0786521e-04  2.9261701e-05  1.2315632e-04\n",
      "   1.7648608e-04 -5.8895148e-06 -1.3733773e-04]]\n",
      "linear.bias:\n",
      " [0.00022354]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509015e-03 -1.0756969e-04  2.8858400e-05  8.3026665e-05\n",
      "   1.7442519e-04 -2.9097542e-05 -1.3820252e-04]]\n",
      "linear.bias:\n",
      " [0.00022424]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508028e-03 -1.0399952e-04  2.8662145e-05  8.4312109e-05\n",
      "   1.7030223e-04 -8.6554046e-06 -1.4002339e-04]]\n",
      "linear.bias:\n",
      " [0.00022502]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04936829e-03 -1.03231236e-04  2.91462729e-05  9.93618887e-05\n",
      "   1.67951963e-04  5.78367417e-06 -1.40599368e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497479e-03 -1.0485939e-04  3.0049459e-05  9.3131639e-05\n",
      "   1.6848958e-04 -1.7231185e-05 -1.3921816e-04]]\n",
      "linear.bias:\n",
      " [0.00022538]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489275e-03 -1.0879325e-04  3.1512544e-05  1.0288961e-04\n",
      "   1.7012400e-04 -3.6081183e-05 -1.3704147e-04]]\n",
      "linear.bias:\n",
      " [0.00022519]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04792882e-03 -1.09110006e-04  3.28866772e-05  1.29983629e-04\n",
      "   1.69736362e-04 -1.09739667e-05 -1.36284580e-04]]\n",
      "linear.bias:\n",
      " [0.00022516]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447735e-03 -1.0581948e-04  3.2986020e-05  8.8704721e-05\n",
      "   1.6882493e-04 -4.0205778e-05 -1.3654972e-04]]\n",
      "linear.bias:\n",
      " [0.00022513]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418660e-03 -1.0012538e-04  3.3159802e-05  8.6341672e-05\n",
      "   1.6655466e-04 -1.8365272e-05 -1.3790485e-04]]\n",
      "linear.bias:\n",
      " [0.00022496]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413887e-03 -9.7670840e-05  3.3076558e-05  1.0760609e-04\n",
      "   1.6524024e-04  1.8031742e-05 -1.3874311e-04]]\n",
      "linear.bias:\n",
      " [0.00022424]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405065e-03 -9.7733158e-05  3.3395703e-05  8.6059386e-05\n",
      "   1.6600166e-04 -3.1405551e-05 -1.3916235e-04]]\n",
      "linear.bias:\n",
      " [0.00022316]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0395255e-03 -9.9288249e-05  3.4045632e-05  1.0082208e-04\n",
      "   1.6722165e-04 -4.4233395e-05 -1.3924408e-04]]\n",
      "linear.bias:\n",
      " [0.00022204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04059256e-03 -1.02417056e-04  3.38328064e-05  1.34599599e-04\n",
      "   1.68300263e-04 -2.27692472e-05 -1.39298936e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04298478e-03 -1.05913750e-04  3.24179127e-05  1.09672954e-04\n",
      "   1.70955842e-04 -4.27527339e-05 -1.38909178e-04]]\n",
      "linear.bias:\n",
      " [0.00022]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04537106e-03 -1.09021996e-04  3.07577284e-05  9.20934908e-05\n",
      "   1.73345485e-04 -3.00363827e-05 -1.39066891e-04]]\n",
      "linear.bias:\n",
      " [0.00021977]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04737375e-03 -1.08630011e-04  2.90750759e-05  1.08684224e-04\n",
      "   1.73219290e-04  2.76533210e-05 -1.40362739e-04]]\n",
      "linear.bias:\n",
      " [0.00021971]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465931e-03 -1.0572771e-04  2.7712240e-05  6.3968058e-05\n",
      "   1.7290220e-04 -2.8408511e-05 -1.4278063e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04527106e-03 -1.00110796e-04  2.65774888e-05  9.23450643e-05\n",
      "   1.70853731e-04 -3.27826929e-05 -1.45209473e-04]]\n",
      "linear.bias:\n",
      " [0.00022083]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427159e-03 -9.6957767e-05  2.6043799e-05  1.4670241e-04\n",
      "   1.6926981e-04 -1.2851160e-06 -1.4714424e-04]]\n",
      "linear.bias:\n",
      " [0.00022109]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04066043e-03 -9.49574387e-05  2.50903759e-05  1.10151464e-04\n",
      "   1.68340805e-04 -4.21040313e-05 -1.49439380e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399504e-03 -9.6818978e-05  2.4189292e-05  7.2570299e-05\n",
      "   1.6947795e-04 -6.2443825e-05 -1.5071998e-04]]\n",
      "linear.bias:\n",
      " [0.00022347]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404565e-03 -9.6902470e-05  2.3707917e-05  1.1681509e-04\n",
      "   1.6949803e-04  3.5465200e-07 -1.5145331e-04]]\n",
      "linear.bias:\n",
      " [0.0002239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423954e-03 -9.9537327e-05  2.3473884e-05  1.2498074e-04\n",
      "   1.7331429e-04  1.5683032e-05 -1.5019323e-04]]\n",
      "linear.bias:\n",
      " [0.00022386]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442124e-03 -1.0219973e-04  2.3984136e-05  7.4235177e-05\n",
      "   1.7843765e-04 -5.7541420e-05 -1.4845144e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04643323e-03 -1.02288395e-04  2.54591723e-05  9.74410432e-05\n",
      "   1.79120703e-04 -4.86998615e-05 -1.47595012e-04]]\n",
      "linear.bias:\n",
      " [0.00022225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474660e-03 -9.9858284e-05  2.7198608e-05  1.4970989e-04\n",
      "   1.7842311e-04  4.6486566e-06 -1.4743221e-04]]\n",
      "linear.bias:\n",
      " [0.00022122]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473074e-03 -9.7820339e-05  2.8435332e-05  1.0804176e-04\n",
      "   1.7730090e-04 -2.9406667e-05 -1.4850673e-04]]\n",
      "linear.bias:\n",
      " [0.00022101]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462757e-03 -9.8557095e-05  3.0057552e-05  7.3245545e-05\n",
      "   1.7818550e-04 -4.1033563e-05 -1.4858841e-04]]\n",
      "linear.bias:\n",
      " [0.00022111]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454278e-03 -9.6975207e-05  3.2022261e-05  9.9529090e-05\n",
      "   1.7729567e-04 -5.8570258e-06 -1.4889942e-04]]\n",
      "linear.bias:\n",
      " [0.00022106]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462961e-03 -9.7671764e-05  3.4046123e-05  1.1332726e-04\n",
      "   1.7809629e-04 -3.6615013e-06 -1.4760534e-04]]\n",
      "linear.bias:\n",
      " [0.00022058]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479233e-03 -9.9985533e-05  3.6075555e-05  9.6485936e-05\n",
      "   1.8057032e-04 -3.9722257e-05 -1.4522074e-04]]\n",
      "linear.bias:\n",
      " [0.00021986]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486662e-03 -1.0217183e-04  3.7479407e-05  1.0963168e-04\n",
      "   1.8154649e-04 -3.4043467e-05 -1.4359363e-04]]\n",
      "linear.bias:\n",
      " [0.00021949]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509769e-03 -1.0594258e-04  3.7685069e-05  1.2509804e-04\n",
      "   1.8197839e-04 -6.2831641e-06 -1.4224098e-04]]\n",
      "linear.bias:\n",
      " [0.00021989]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05186435e-03 -1.06121865e-04  3.68024521e-05  8.00493872e-05\n",
      "   1.80724703e-04 -3.21780244e-05 -1.42419784e-04]]\n",
      "linear.bias:\n",
      " [0.00022097]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0515488e-03 -1.0249543e-04  3.5570629e-05  8.6763823e-05\n",
      "   1.7608935e-04 -5.5577875e-06 -1.4387764e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502238e-03 -1.0115595e-04  3.4994104e-05  1.0339105e-04\n",
      "   1.7220422e-04  8.4766170e-06 -1.4451524e-04]]\n",
      "linear.bias:\n",
      " [0.00022336]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499465e-03 -1.0124455e-04  3.4635552e-05  9.3678143e-05\n",
      "   1.6996701e-04 -2.5179532e-05 -1.4389335e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483771e-03 -1.0373996e-04  3.4691304e-05  1.0292998e-04\n",
      "   1.6863267e-04 -3.6153444e-05 -1.4278840e-04]]\n",
      "linear.bias:\n",
      " [0.00022365]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464238e-03 -1.0663859e-04  3.4894481e-05  1.2745212e-04\n",
      "   1.6808341e-04 -1.3772744e-05 -1.4162381e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04538305e-03 -1.06949505e-04  3.37426318e-05  1.04696548e-04\n",
      "   1.69949635e-04 -2.72200814e-05 -1.39537166e-04]]\n",
      "linear.bias:\n",
      " [0.00022306]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04419258e-03 -1.07396016e-04  3.22316446e-05  8.66684422e-05\n",
      "   1.71625870e-04 -2.38382163e-05 -1.37989802e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04259106e-03 -1.08864464e-04  3.10117211e-05  1.01770558e-04\n",
      "   1.72639542e-04  1.17171658e-06 -1.36749921e-04]]\n",
      "linear.bias:\n",
      " [0.00022327]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429606e-03 -1.1199711e-04  3.0093013e-05  9.7730714e-05\n",
      "   1.7508429e-04 -1.2032217e-05 -1.3411992e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04353891e-03 -1.14606424e-04  2.91480119e-05  1.08205917e-04\n",
      "   1.76481582e-04 -2.08081874e-05 -1.32005865e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04451389e-03 -1.11488647e-04  2.80962722e-05  1.19844546e-04\n",
      "   1.76467322e-04 -1.58971543e-05 -1.31147084e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436882e-03 -1.0737325e-04  2.7053833e-05  8.6041968e-05\n",
      "   1.7521404e-04 -4.3140302e-05 -1.3118074e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430330e-03 -1.0051298e-04  2.6168216e-05  9.7134580e-05\n",
      "   1.7013773e-04 -1.5294474e-05 -1.3327460e-04]]\n",
      "linear.bias:\n",
      " [0.00022449]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04227476e-03 -9.55736614e-05  2.60059205e-05  1.17102674e-04\n",
      "   1.66009777e-04  7.42704833e-06 -1.34847578e-04]]\n",
      "linear.bias:\n",
      " [0.00022469]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418580e-03 -9.4243704e-05  2.6341882e-05  9.3917006e-05\n",
      "   1.6483734e-04 -2.5720698e-05 -1.3588002e-04]]\n",
      "linear.bias:\n",
      " [0.000225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411369e-03 -9.4668496e-05  2.7367128e-05  9.2237548e-05\n",
      "   1.6520330e-04 -3.9516832e-05 -1.3626815e-04]]\n",
      "linear.bias:\n",
      " [0.00022456]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406809e-03 -9.6616204e-05  2.8349885e-05  1.1602827e-04\n",
      "   1.6599133e-04 -1.7817205e-05 -1.3648646e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416990e-03 -1.0092904e-04  2.9572117e-05  1.1276911e-04\n",
      "   1.6923589e-04 -2.5051912e-05 -1.3539294e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04343391e-03 -1.08078195e-04  3.04005080e-05  1.02187609e-04\n",
      "   1.73119974e-04 -2.48363976e-05 -1.34065442e-04]]\n",
      "linear.bias:\n",
      " [0.00022365]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450911e-03 -1.1406398e-04  3.0726991e-05  9.8421857e-05\n",
      "   1.7633314e-04 -4.7992125e-06 -1.3351922e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04647363e-03 -1.16703704e-04  3.09104071e-05  8.94594414e-05\n",
      "   1.80455521e-04 -9.16543740e-06 -1.32047848e-04]]\n",
      "linear.bias:\n",
      " [0.00022432]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04785105e-03 -1.13318994e-04  3.10013929e-05  1.06367326e-04\n",
      "   1.81622498e-04 -1.75062542e-06 -1.31791865e-04]]\n",
      "linear.bias:\n",
      " [0.00022497]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476678e-03 -1.0600191e-04  3.0631585e-05  8.1382808e-05\n",
      "   1.7980617e-04 -5.8362861e-05 -1.3295560e-04]]\n",
      "linear.bias:\n",
      " [0.0002257]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474586e-03 -9.6219745e-05  3.0044859e-05  1.3496530e-04\n",
      "   1.7098480e-04 -1.5390313e-05 -1.3697003e-04]]\n",
      "linear.bias:\n",
      " [0.00022577]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464257e-03 -8.9347821e-05  2.9063951e-05  1.1642706e-04\n",
      "   1.6296236e-04 -2.9543968e-05 -1.4111318e-04]]\n",
      "linear.bias:\n",
      " [0.00022613]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465132e-03 -8.6907596e-05  2.8169625e-05  9.0337962e-05\n",
      "   1.5765589e-04 -3.9233968e-05 -1.4399319e-04]]\n",
      "linear.bias:\n",
      " [0.00022645]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465388e-03 -8.8584093e-05  2.7853313e-05  9.4665964e-05\n",
      "   1.5438283e-04 -1.6046495e-05 -1.4592080e-04]]\n",
      "linear.bias:\n",
      " [0.00022615]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480172e-03 -9.4603907e-05  2.7541817e-05  9.4030773e-05\n",
      "   1.5506140e-04 -1.3911502e-05 -1.4585059e-04]]\n",
      "linear.bias:\n",
      " [0.00022529]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491852e-03 -1.0108373e-04  2.7987147e-05  8.8631052e-05\n",
      "   1.5922479e-04 -3.3063461e-05 -1.4368996e-04]]\n",
      "linear.bias:\n",
      " [0.00022408]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491331e-03 -1.0877938e-04  2.9120056e-05  1.1610276e-04\n",
      "   1.6360954e-04 -1.9779936e-05 -1.4125885e-04]]\n",
      "linear.bias:\n",
      " [0.0002227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04706502e-03 -1.14922674e-04  3.07979681e-05  1.17859439e-04\n",
      "   1.70203639e-04 -3.16411824e-05 -1.37700466e-04]]\n",
      "linear.bias:\n",
      " [0.0002216]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429845e-03 -1.1732784e-04  3.2126416e-05  1.0180036e-04\n",
      "   1.7737983e-04 -4.0730527e-05 -1.3401147e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03970012e-03 -1.13240851e-04  3.27136077e-05  1.06765125e-04\n",
      "   1.82205578e-04 -5.24625648e-06 -1.31991197e-04]]\n",
      "linear.bias:\n",
      " [0.00022113]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03933108e-03 -1.07282394e-04  3.17172417e-05  7.33898778e-05\n",
      "   1.83884302e-04 -2.26932880e-05 -1.31574838e-04]]\n",
      "linear.bias:\n",
      " [0.00022166]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0394327e-03 -9.8568766e-05  3.0828978e-05  1.0704147e-04\n",
      "   1.7931241e-04  4.4311528e-06 -1.3370343e-04]]\n",
      "linear.bias:\n",
      " [0.00022169]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415886e-03 -9.0848247e-05  2.9688217e-05  9.3762006e-05\n",
      "   1.7399694e-04 -3.4161370e-05 -1.3668534e-04]]\n",
      "linear.bias:\n",
      " [0.00022246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04415487e-03 -8.66350820e-05  2.84216148e-05  1.07979366e-04\n",
      "   1.68620260e-04 -3.48044268e-05 -1.39688040e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476374e-03 -8.6602733e-05  2.7237373e-05  1.1605756e-04\n",
      "   1.6580563e-04 -1.8837631e-05 -1.4158455e-04]]\n",
      "linear.bias:\n",
      " [0.00022379]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0511589e-03 -8.9862304e-05  2.6435631e-05  9.4672301e-05\n",
      "   1.6630595e-04 -3.4415101e-05 -1.4182257e-04]]\n",
      "linear.bias:\n",
      " [0.0002245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0536087e-03 -9.4703719e-05  2.6135202e-05  9.8712466e-05\n",
      "   1.6730766e-04 -1.5489479e-05 -1.4172157e-04]]\n",
      "linear.bias:\n",
      " [0.00022484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0545981e-03 -1.0182913e-04  2.6694455e-05  1.0476814e-04\n",
      "   1.7056633e-04 -7.2425337e-06 -1.4028024e-04]]\n",
      "linear.bias:\n",
      " [0.000225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541972e-03 -1.0945303e-04  2.8279894e-05  9.5062613e-05\n",
      "   1.7623095e-04 -2.9234012e-05 -1.3726206e-04]]\n",
      "linear.bias:\n",
      " [0.00022485]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05249684e-03 -1.13275884e-04  2.98980449e-05  1.15201350e-04\n",
      "   1.78926071e-04 -1.29028613e-05 -1.35631402e-04]]\n",
      "linear.bias:\n",
      " [0.00022456]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485345e-03 -1.1342546e-04  3.1325329e-05  9.5683135e-05\n",
      "   1.8125457e-04 -3.1364034e-05 -1.3381348e-04]]\n",
      "linear.bias:\n",
      " [0.0002246]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457776e-03 -1.1030783e-04  3.2551310e-05  1.0873738e-04\n",
      "   1.8034062e-04 -1.7693583e-06 -1.3370533e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436687e-03 -1.0469688e-04  3.2680244e-05  7.3340045e-05\n",
      "   1.7695744e-04 -4.2818065e-05 -1.3485759e-04]]\n",
      "linear.bias:\n",
      " [0.00022482]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410190e-03 -9.6640208e-05  3.2344276e-05  1.0321182e-04\n",
      "   1.6794783e-04 -1.8675515e-05 -1.3845692e-04]]\n",
      "linear.bias:\n",
      " [0.00022453]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0395185e-03 -9.3332783e-05  3.1986056e-05  1.2898931e-04\n",
      "   1.6141181e-04  2.6845464e-06 -1.4072856e-04]]\n",
      "linear.bias:\n",
      " [0.00022428]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0394573e-03 -9.3395887e-05  3.1718107e-05  1.0181392e-04\n",
      "   1.5983045e-04 -2.9297798e-05 -1.4138079e-04]]\n",
      "linear.bias:\n",
      " [0.0002239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411468e-03 -9.7046563e-05  3.1175226e-05  8.0792262e-05\n",
      "   1.6099331e-04 -4.0977884e-05 -1.4071036e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429934e-03 -1.0170320e-04  3.1042309e-05  1.0032076e-04\n",
      "   1.6271128e-04 -2.0099296e-05 -1.3961435e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04563695e-03 -1.09776163e-04  3.11078948e-05  1.19419674e-04\n",
      "   1.66488549e-04 -6.56265638e-06 -1.37492651e-04]]\n",
      "linear.bias:\n",
      " [0.00022202]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04822149e-03 -1.15177616e-04  3.05526773e-05  9.76874944e-05\n",
      "   1.71194886e-04 -2.75358107e-05 -1.34876158e-04]]\n",
      "linear.bias:\n",
      " [0.00022157]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05029834e-03 -1.14600385e-04  2.95841746e-05  1.01032427e-04\n",
      "   1.73512715e-04 -1.22200581e-05 -1.33727153e-04]]\n",
      "linear.bias:\n",
      " [0.00022131]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05129380e-03 -1.11333546e-04  2.89403433e-05  9.63953644e-05\n",
      "   1.76698944e-04 -1.16098390e-05 -1.31991008e-04]]\n",
      "linear.bias:\n",
      " [0.00022153]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0515173e-03 -1.0850011e-04  2.8604269e-05  1.0434445e-04\n",
      "   1.7883228e-04 -9.2539294e-06 -1.3050392e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498823e-03 -1.0517973e-04  2.8264814e-05  8.5059110e-05\n",
      "   1.7994741e-04 -2.8415328e-05 -1.2957961e-04]]\n",
      "linear.bias:\n",
      " [0.00022235]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483022e-03 -9.8373726e-05  2.7916150e-05  1.1057005e-04\n",
      "   1.7652226e-04  4.9890732e-06 -1.3106277e-04]]\n",
      "linear.bias:\n",
      " [0.00022321]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465978e-03 -9.2555485e-05  2.7716202e-05  8.1947379e-05\n",
      "   1.7198044e-04 -3.8800899e-05 -1.3365949e-04]]\n",
      "linear.bias:\n",
      " [0.00022428]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04519515e-03 -9.08738075e-05  2.77546533e-05  1.00174024e-04\n",
      "   1.66678612e-04 -3.54449803e-05 -1.36722243e-04]]\n",
      "linear.bias:\n",
      " [0.0002248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435528e-03 -9.1182752e-05  2.8270540e-05  1.3454727e-04\n",
      "   1.6312764e-04 -1.8652645e-06 -1.3907715e-04]]\n",
      "linear.bias:\n",
      " [0.00022481]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431241e-03 -9.5185795e-05  2.8448696e-05  1.0831391e-04\n",
      "   1.6308531e-04 -1.8301938e-05 -1.4062795e-04]]\n",
      "linear.bias:\n",
      " [0.00022513]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444344e-03 -1.0123515e-04  2.9149656e-05  6.6102126e-05\n",
      "   1.6596778e-04 -6.3419488e-05 -1.4025609e-04]]\n",
      "linear.bias:\n",
      " [0.00022526]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469761e-03 -1.0629633e-04  2.9544432e-05  1.3043714e-04\n",
      "   1.6411497e-04 -2.7255519e-06 -1.4152838e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04887469e-03 -1.10694265e-04  3.00165539e-05  1.31639405e-04\n",
      "   1.66474885e-04 -6.84354018e-06 -1.41343393e-04]]\n",
      "linear.bias:\n",
      " [0.00022231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491123e-03 -1.1073150e-04  2.9198227e-05  5.8708421e-05\n",
      "   1.7015880e-04 -6.7552377e-05 -1.4101704e-04]]\n",
      "linear.bias:\n",
      " [0.00022078]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501855e-03 -1.0595558e-04  2.8649356e-05  1.0920671e-04\n",
      "   1.6740937e-04 -5.1291136e-06 -1.4282906e-04]]\n",
      "linear.bias:\n",
      " [0.0002185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504361e-03 -1.0061852e-04  2.9029718e-05  1.3317274e-04\n",
      "   1.6796941e-04  1.8242868e-05 -1.4269234e-04]]\n",
      "linear.bias:\n",
      " [0.00021644]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473989e-03 -9.5563460e-05  2.9377923e-05  6.2165105e-05\n",
      "   1.6943802e-04 -7.9151519e-05 -1.4407122e-04]]\n",
      "linear.bias:\n",
      " [0.00021534]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04584475e-03 -9.12719988e-05  2.93925859e-05  1.04254614e-04\n",
      "   1.66501821e-04 -5.55233637e-05 -1.46965511e-04]]\n",
      "linear.bias:\n",
      " [0.00021345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447695e-03 -8.9342117e-05  2.9421084e-05  1.5538077e-04\n",
      "   1.6573103e-04  3.0657102e-06 -1.4932275e-04]]\n",
      "linear.bias:\n",
      " [0.0002125]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04184437e-03 -8.91333984e-05  2.90296939e-05  1.10139255e-04\n",
      "   1.67703096e-04 -2.77865547e-05 -1.51916334e-04]]\n",
      "linear.bias:\n",
      " [0.0002127]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402995e-03 -9.3062270e-05  2.8738408e-05  5.2443436e-05\n",
      "   1.7337996e-04 -5.6365367e-05 -1.5253708e-04]]\n",
      "linear.bias:\n",
      " [0.00021378]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404001e-03 -9.5301868e-05  2.8832101e-05  1.1698512e-04\n",
      "   1.7452781e-04  9.9551835e-06 -1.5308522e-04]]\n",
      "linear.bias:\n",
      " [0.00021385]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421685e-03 -9.9594734e-05  2.9617551e-05  1.3590578e-04\n",
      "   1.7790573e-04  2.0853367e-05 -1.5251823e-04]]\n",
      "linear.bias:\n",
      " [0.00021451]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423845e-03 -1.0292215e-04  3.0301288e-05  6.2385159e-05\n",
      "   1.8134636e-04 -8.5212982e-05 -1.5301761e-04]]\n",
      "linear.bias:\n",
      " [0.00021571]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432804e-03 -1.0100596e-04  3.1180996e-05  1.1462802e-04\n",
      "   1.7870140e-04 -5.5576562e-05 -1.5509535e-04]]\n",
      "linear.bias:\n",
      " [0.00021589]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427183e-03 -1.0083108e-04  3.2141921e-05  1.6358073e-04\n",
      "   1.7795333e-04  7.2502262e-06 -1.5640949e-04]]\n",
      "linear.bias:\n",
      " [0.00021696]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04046904e-03 -9.74127688e-05  3.17408521e-05  1.07583284e-04\n",
      "   1.78371265e-04 -1.80809257e-05 -1.58334093e-04]]\n",
      "linear.bias:\n",
      " [0.00021837]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402581e-03 -9.7034310e-05  3.1913358e-05  4.4515953e-05\n",
      "   1.8144073e-04 -6.5358297e-05 -1.5820640e-04]]\n",
      "linear.bias:\n",
      " [0.00021949]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427121e-03 -9.5424555e-05  3.2388176e-05  1.2230105e-04\n",
      "   1.7771724e-04 -1.4167817e-06 -1.5793752e-04]]\n",
      "linear.bias:\n",
      " [0.00021868]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464790e-03 -9.6661715e-05  3.3025091e-05  1.6057881e-04\n",
      "   1.7835105e-04  1.5052672e-05 -1.5567946e-04]]\n",
      "linear.bias:\n",
      " [0.0002175]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455834e-03 -9.7269149e-05  3.3295153e-05  8.9242094e-05\n",
      "   1.8100091e-04 -7.5661970e-05 -1.5447589e-04]]\n",
      "linear.bias:\n",
      " [0.00021644]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444364e-03 -9.4604606e-05  3.3568758e-05  7.9603145e-05\n",
      "   1.8080043e-04 -6.7085668e-05 -1.5452494e-04]]\n",
      "linear.bias:\n",
      " [0.00021609]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439139e-03 -8.9191250e-05  3.3665514e-05  1.3192680e-04\n",
      "   1.7793676e-04  1.7111692e-05 -1.5543099e-04]]\n",
      "linear.bias:\n",
      " [0.00021638]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435039e-03 -8.5256630e-05  3.3883880e-05  1.0565452e-04\n",
      "   1.7644178e-04  6.9940907e-06 -1.5579973e-04]]\n",
      "linear.bias:\n",
      " [0.0002171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447955e-03 -8.5062573e-05  3.4558645e-05  5.9449707e-05\n",
      "   1.7852148e-04 -4.0807874e-05 -1.5403166e-04]]\n",
      "linear.bias:\n",
      " [0.00021744]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451699e-03 -8.7508677e-05  3.4623758e-05  9.8669130e-05\n",
      "   1.7991466e-04 -4.3629519e-05 -1.5085567e-04]]\n",
      "linear.bias:\n",
      " [0.00021729]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467068e-03 -9.3570197e-05  3.4231562e-05  1.5568115e-04\n",
      "   1.8171206e-04 -1.8248893e-05 -1.4735693e-04]]\n",
      "linear.bias:\n",
      " [0.00021731]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472410e-03 -9.9785029e-05  3.3109889e-05  1.2362076e-04\n",
      "   1.8238215e-04 -5.8534730e-05 -1.4541265e-04]]\n",
      "linear.bias:\n",
      " [0.00021839]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467464e-03 -1.0560716e-04  3.1837473e-05  9.4781113e-05\n",
      "   1.8291449e-04 -5.7042096e-05 -1.4397918e-04]]\n",
      "linear.bias:\n",
      " [0.00022028]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464297e-03 -1.0757247e-04  3.0714058e-05  1.0476985e-04\n",
      "   1.8001803e-04 -7.5406533e-06 -1.4431233e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477063e-03 -1.1028757e-04  2.9612931e-05  1.0049584e-04\n",
      "   1.7856005e-04  9.3054423e-06 -1.4327423e-04]]\n",
      "linear.bias:\n",
      " [0.00022364]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500069e-03 -1.1273329e-04  2.8762315e-05  7.5073702e-05\n",
      "   1.7701536e-04 -3.1757823e-05 -1.4149274e-04]]\n",
      "linear.bias:\n",
      " [0.00022424]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05190603e-03 -1.10992885e-04  2.79364922e-05  1.07258296e-04\n",
      "   1.72345084e-04 -2.18362238e-05 -1.40765260e-04]]\n",
      "linear.bias:\n",
      " [0.00022494]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05182570e-03 -1.07236614e-04  2.71626886e-05  1.21509569e-04\n",
      "   1.69382241e-04 -1.77037291e-05 -1.39428172e-04]]\n",
      "linear.bias:\n",
      " [0.00022663]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497868e-03 -1.0276732e-04  2.6724001e-05  1.0183511e-04\n",
      "   1.6716046e-04 -4.2685719e-05 -1.3758056e-04]]\n",
      "linear.bias:\n",
      " [0.00022815]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04755792e-03 -1.00645564e-04  2.67678079e-05  1.02118895e-04\n",
      "   1.66495112e-04 -3.39875260e-05 -1.35553695e-04]]\n",
      "linear.bias:\n",
      " [0.00022891]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451640e-03 -1.0059462e-04  2.7298143e-05  1.2003318e-04\n",
      "   1.6714355e-04  3.8385188e-06 -1.3331749e-04]]\n",
      "linear.bias:\n",
      " [0.00022914]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414376e-03 -1.0153001e-04  2.8114568e-05  8.1865466e-05\n",
      "   1.6835505e-04 -3.2553733e-05 -1.3183782e-04]]\n",
      "linear.bias:\n",
      " [0.00022919]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03854109e-03 -1.00904006e-04  2.94192141e-05  9.46435757e-05\n",
      "   1.68108629e-04 -2.00740833e-05 -1.31541805e-04]]\n",
      "linear.bias:\n",
      " [0.00022832]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03858323e-03 -1.03161045e-04  3.04219757e-05  1.25515988e-04\n",
      "   1.69277744e-04  6.57530836e-06 -1.31141307e-04]]\n",
      "linear.bias:\n",
      " [0.00022662]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381461e-03 -1.0328171e-04  3.0815678e-05  8.5974432e-05\n",
      "   1.6872758e-04 -5.9298505e-05 -1.3300376e-04]]\n",
      "linear.bias:\n",
      " [0.00022509]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0385413e-03 -1.0029257e-04  3.1153326e-05  9.4290212e-05\n",
      "   1.6582730e-04 -5.9737868e-05 -1.3653694e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391331e-03 -9.4537347e-05  3.1454045e-05  1.3812033e-04\n",
      "   1.6216196e-04 -8.2268452e-06 -1.4095768e-04]]\n",
      "linear.bias:\n",
      " [0.00022174]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407405e-03 -9.3166018e-05  3.1431806e-05  1.2134124e-04\n",
      "   1.6208962e-04 -7.6022552e-06 -1.4435549e-04]]\n",
      "linear.bias:\n",
      " [0.00022054]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438322e-03 -9.4738964e-05  3.1665793e-05  7.1423594e-05\n",
      "   1.6611426e-04 -4.9826755e-05 -1.4559417e-04]]\n",
      "linear.bias:\n",
      " [0.00021916]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461304e-03 -9.8470133e-05  3.1566295e-05  8.3637504e-05\n",
      "   1.7009671e-04 -4.3369415e-05 -1.4619940e-04]]\n",
      "linear.bias:\n",
      " [0.00021806]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475311e-03 -1.0302614e-04  3.1502947e-05  1.3365140e-04\n",
      "   1.7392589e-04  1.0542462e-06 -1.4627064e-04]]\n",
      "linear.bias:\n",
      " [0.00021738]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04759773e-03 -1.05772997e-04  3.07359114e-05  1.00806385e-04\n",
      "   1.76175789e-04 -2.47888565e-05 -1.47368191e-04]]\n",
      "linear.bias:\n",
      " [0.00021754]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460049e-03 -1.0924379e-04  2.9907227e-05  7.8355573e-05\n",
      "   1.7758066e-04 -3.3189059e-05 -1.4826497e-04]]\n",
      "linear.bias:\n",
      " [0.00021814]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445189e-03 -1.0888230e-04  2.9358795e-05  1.1040699e-04\n",
      "   1.7716331e-04  4.4111221e-06 -1.4938934e-04]]\n",
      "linear.bias:\n",
      " [0.00021884]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04443962e-03 -1.08479522e-04  2.89106847e-05  1.13655384e-04\n",
      "   1.79008188e-04  2.19436947e-06 -1.48872452e-04]]\n",
      "linear.bias:\n",
      " [0.00021947]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04495382e-03 -1.09248394e-04  2.87955536e-05  8.37760890e-05\n",
      "   1.81874639e-04 -4.03716804e-05 -1.47303857e-04]]\n",
      "linear.bias:\n",
      " [0.00021972]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446194e-03 -1.0615995e-04  2.8530332e-05  9.5583411e-05\n",
      "   1.8155969e-04 -2.9807623e-05 -1.4704982e-04]]\n",
      "linear.bias:\n",
      " [0.00022041]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442610e-03 -1.0343207e-04  2.7756894e-05  1.2881390e-04\n",
      "   1.8023950e-04  1.4952380e-05 -1.4731636e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422601e-03 -1.0043384e-04  2.7435122e-05  8.8248198e-05\n",
      "   1.7812992e-04 -4.2280262e-05 -1.4883274e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399502e-03 -9.9439851e-05  2.7292353e-05  8.2767430e-05\n",
      "   1.7641892e-04 -5.7288780e-05 -1.5011788e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0380164e-03 -9.6450560e-05  2.7560480e-05  1.3845829e-04\n",
      "   1.7172663e-04 -4.2530119e-06 -1.5200155e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0377080e-03 -9.5268028e-05  2.7883392e-05  1.2572568e-04\n",
      "   1.6976267e-04 -8.0582995e-06 -1.5255959e-04]]\n",
      "linear.bias:\n",
      " [0.00022376]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0393711e-03 -9.6755364e-05  2.8464150e-05  7.4448020e-05\n",
      "   1.7191726e-04 -5.6523917e-05 -1.5121800e-04]]\n",
      "linear.bias:\n",
      " [0.00022389]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418164e-03 -9.7244505e-05  2.8906577e-05  9.7013763e-05\n",
      "   1.7166210e-04 -2.7114571e-05 -1.5028039e-04]]\n",
      "linear.bias:\n",
      " [0.00022371]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452438e-03 -1.0161957e-04  2.9382227e-05  1.3359755e-04\n",
      "   1.7289941e-04  1.5347165e-05 -1.4830298e-04]]\n",
      "linear.bias:\n",
      " [0.00022323]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04750367e-03 -1.04627936e-04  2.99182720e-05  9.45441570e-05\n",
      "   1.74776302e-04 -3.92987786e-05 -1.46559993e-04]]\n",
      "linear.bias:\n",
      " [0.00022249]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478875e-03 -1.0819434e-04  3.0591360e-05  8.6782267e-05\n",
      "   1.7617655e-04 -5.1262290e-05 -1.4495516e-04]]\n",
      "linear.bias:\n",
      " [0.00022183]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474505e-03 -1.0806675e-04  3.1161071e-05  1.1775020e-04\n",
      "   1.7587430e-04 -1.2918761e-05 -1.4414851e-04]]\n",
      "linear.bias:\n",
      " [0.00022138]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474698e-03 -1.0865774e-04  3.1316336e-05  1.1154716e-04\n",
      "   1.7651920e-04 -9.0693111e-06 -1.4259263e-04]]\n",
      "linear.bias:\n",
      " [0.00022098]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479002e-03 -1.0989616e-04  3.1098218e-05  7.1871444e-05\n",
      "   1.7801744e-04 -3.6284564e-05 -1.4036168e-04]]\n",
      "linear.bias:\n",
      " [0.00022062]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477825e-03 -1.0655601e-04  3.0586703e-05  9.4698553e-05\n",
      "   1.7396685e-04 -6.6396824e-06 -1.4014984e-04]]\n",
      "linear.bias:\n",
      " [0.00022076]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468536e-03 -1.0416026e-04  3.0850159e-05  1.1768719e-04\n",
      "   1.7125948e-04  1.3510535e-06 -1.3881706e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466177e-03 -1.0458782e-04  3.1497115e-05  9.3681010e-05\n",
      "   1.7001320e-04 -4.2783624e-05 -1.3717405e-04]]\n",
      "linear.bias:\n",
      " [0.00022147]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462474e-03 -1.0152287e-04  3.1876691e-05  1.0459140e-04\n",
      "   1.6642794e-04 -3.6666002e-05 -1.3694230e-04]]\n",
      "linear.bias:\n",
      " [0.00022215]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464190e-03 -9.8785691e-05  3.1973217e-05  1.2666055e-04\n",
      "   1.6386021e-04  2.1645210e-06 -1.3705349e-04]]\n",
      "linear.bias:\n",
      " [0.00022291]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455231e-03 -9.7583375e-05  3.1428186e-05  8.3920379e-05\n",
      "   1.6383147e-04 -2.9688817e-05 -1.3784316e-04]]\n",
      "linear.bias:\n",
      " [0.00022329]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445138e-03 -9.8127348e-05  3.1330903e-05  7.9770034e-05\n",
      "   1.6438546e-04 -2.6927210e-05 -1.3823321e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04340224e-03 -1.00244644e-04  3.16370060e-05  1.10369532e-04\n",
      "   1.65464473e-04  7.00753662e-06 -1.38263233e-04]]\n",
      "linear.bias:\n",
      " [0.00022349]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439918e-03 -1.0458970e-04  3.1903590e-05  1.0183947e-04\n",
      "   1.6962791e-04 -5.8882179e-06 -1.3684348e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461115e-03 -1.1085058e-04  3.2439271e-05  7.8869627e-05\n",
      "   1.7542252e-04 -4.8310816e-05 -1.3390649e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04696932e-03 -1.12325637e-04  3.26019072e-05  1.14798575e-04\n",
      "   1.75111723e-04 -2.91983433e-05 -1.33677706e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461212e-03 -1.0744997e-04  3.2684573e-05  1.4323251e-04\n",
      "   1.7411026e-04  1.0093920e-05 -1.3449742e-04]]\n",
      "linear.bias:\n",
      " [0.00022272]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428606e-03 -9.7533863e-05  3.0963613e-05  6.6628927e-05\n",
      "   1.7241991e-04 -5.8226658e-05 -1.3832666e-04]]\n",
      "linear.bias:\n",
      " [0.00022312]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413793e-03 -8.8435125e-05  2.9506509e-05  9.3781186e-05\n",
      "   1.6565336e-04 -2.2357122e-05 -1.4402739e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413639e-03 -8.4034364e-05  2.8353699e-05  1.2734113e-04\n",
      "   1.6158870e-04  1.4429308e-05 -1.4801086e-04]]\n",
      "linear.bias:\n",
      " [0.0002211]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419617e-03 -8.3515355e-05  2.8013443e-05  1.0342469e-04\n",
      "   1.6281303e-04 -1.7356000e-05 -1.5012811e-04]]\n",
      "linear.bias:\n",
      " [0.00021979]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436233e-03 -8.6921449e-05  2.8134999e-05  6.7248031e-05\n",
      "   1.6777468e-04 -7.3753305e-05 -1.4984801e-04]]\n",
      "linear.bias:\n",
      " [0.0002186]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461025e-03 -9.0697598e-05  2.7883769e-05  1.3797951e-04\n",
      "   1.6974797e-04 -1.8724517e-05 -1.5002806e-04]]\n",
      "linear.bias:\n",
      " [0.0002166]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489529e-03 -9.7788252e-05  2.7879370e-05  1.5111295e-04\n",
      "   1.7440450e-04 -1.0795530e-05 -1.4894575e-04]]\n",
      "linear.bias:\n",
      " [0.00021495]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05086609e-03 -1.04252744e-04  2.72790985e-05  7.67242891e-05\n",
      "   1.77925860e-04 -6.92791364e-05 -1.49089654e-04]]\n",
      "linear.bias:\n",
      " [0.00021472]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0532535e-03 -1.0622097e-04  2.7021966e-05  8.8303030e-05\n",
      "   1.7532721e-04 -2.7329857e-05 -1.5112411e-04]]\n",
      "linear.bias:\n",
      " [0.00021452]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0533051e-03 -1.0858078e-04  2.7496128e-05  1.2548885e-04\n",
      "   1.7400387e-04  3.2391377e-05 -1.5200970e-04]]\n",
      "linear.bias:\n",
      " [0.00021464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484550e-03 -1.0693579e-04  2.8078546e-05  7.7166587e-05\n",
      "   1.7476789e-04 -5.2604089e-05 -1.5328053e-04]]\n",
      "linear.bias:\n",
      " [0.00021507]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440428e-03 -1.0179978e-04  2.8514924e-05  8.3669045e-05\n",
      "   1.7376394e-04 -7.6405049e-05 -1.5498699e-04]]\n",
      "linear.bias:\n",
      " [0.00021592]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0401444e-03 -9.3232971e-05  2.8756787e-05  1.4665400e-04\n",
      "   1.7160109e-04 -6.9044472e-06 -1.5722969e-04]]\n",
      "linear.bias:\n",
      " [0.00021764]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386235e-03 -8.7070504e-05  2.8959244e-05  1.3940282e-04\n",
      "   1.7233501e-04  2.9380089e-06 -1.5809108e-04]]\n",
      "linear.bias:\n",
      " [0.00021965]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381913e-03 -8.4248983e-05  2.9739635e-05  7.5405915e-05\n",
      "   1.7637800e-04 -5.0883311e-05 -1.5735315e-04]]\n",
      "linear.bias:\n",
      " [0.00022162]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374530e-03 -8.4547508e-05  3.0140689e-05  7.3651812e-05\n",
      "   1.8089359e-04 -5.7057914e-05 -1.5515501e-04]]\n",
      "linear.bias:\n",
      " [0.00022323]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0370298e-03 -8.8812885e-05  3.0443040e-05  1.4609027e-04\n",
      "   1.8127753e-04  6.4171327e-06 -1.5331518e-04]]\n",
      "linear.bias:\n",
      " [0.00022406]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0355366e-03 -9.3472343e-05  3.0329751e-05  1.2146201e-04\n",
      "   1.8185677e-04 -2.0315862e-05 -1.5219329e-04]]\n",
      "linear.bias:\n",
      " [0.00022528]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0357373e-03 -9.9681347e-05  3.0223926e-05  7.0956390e-05\n",
      "   1.8396610e-04 -7.4958829e-05 -1.4996318e-04]]\n",
      "linear.bias:\n",
      " [0.00022637]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03798183e-03 -1.05813866e-04  2.97192983e-05  1.24471422e-04\n",
      "   1.78558941e-04 -1.69178347e-05 -1.50420732e-04]]\n",
      "linear.bias:\n",
      " [0.0002261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414212e-03 -1.1019895e-04  2.8576207e-05  1.3043953e-04\n",
      "   1.7475749e-04  9.9113277e-07 -1.4973119e-04]]\n",
      "linear.bias:\n",
      " [0.00022522]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457807e-03 -1.1332190e-04  2.7764974e-05  7.7854769e-05\n",
      "   1.7240783e-04 -4.8791968e-05 -1.4845835e-04]]\n",
      "linear.bias:\n",
      " [0.00022427]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489860e-03 -1.0994930e-04  2.7260197e-05  8.4895692e-05\n",
      "   1.6808632e-04 -4.0990304e-05 -1.4768058e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510039e-03 -1.0262483e-04  2.7160922e-05  1.3323720e-04\n",
      "   1.6387094e-04  7.4690215e-06 -1.4704309e-04]]\n",
      "linear.bias:\n",
      " [0.00022295]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500061e-03 -9.5283365e-05  2.7131942e-05  1.0344727e-04\n",
      "   1.6401593e-04 -3.5744913e-05 -1.4557139e-04]]\n",
      "linear.bias:\n",
      " [0.00022175]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481096e-03 -9.1603149e-05  2.7691505e-05  8.1258324e-05\n",
      "   1.6619176e-04 -5.5477580e-05 -1.4318836e-04]]\n",
      "linear.bias:\n",
      " [0.00022084]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451666e-03 -9.0223875e-05  2.8001707e-05  1.0206004e-04\n",
      "   1.6914071e-04 -2.7945627e-05 -1.4047557e-04]]\n",
      "linear.bias:\n",
      " [0.00022032]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436736e-03 -9.3229508e-05  2.8235043e-05  1.2031962e-04\n",
      "   1.7393584e-04  1.2512266e-05 -1.3694265e-04]]\n",
      "linear.bias:\n",
      " [0.00022002]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411014e-03 -9.8200035e-05  2.8738072e-05  8.2833096e-05\n",
      "   1.7816415e-04 -3.6957550e-05 -1.3506688e-04]]\n",
      "linear.bias:\n",
      " [0.00022007]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0389263e-03 -9.9338598e-05  2.9243023e-05  8.6234890e-05\n",
      "   1.7838518e-04 -3.2682688e-05 -1.3544192e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371018e-03 -9.6949407e-05  2.9721010e-05  1.2516871e-04\n",
      "   1.7506712e-04  1.8700503e-05 -1.3747167e-04]]\n",
      "linear.bias:\n",
      " [0.0002203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0340624e-03 -9.3543465e-05  3.0212306e-05  8.7687935e-05\n",
      "   1.7052225e-04 -4.0872437e-05 -1.4155007e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0334806e-03 -9.5330885e-05  3.0152072e-05  8.3478131e-05\n",
      "   1.6653877e-04 -6.1095918e-05 -1.4509218e-04]]\n",
      "linear.bias:\n",
      " [0.00022122]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0335802e-03 -9.6806667e-05  3.0052213e-05  1.3474254e-04\n",
      "   1.6247258e-04 -1.1448814e-05 -1.4829496e-04]]\n",
      "linear.bias:\n",
      " [0.00022162]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0358596e-03 -9.9579614e-05  2.9764180e-05  1.2971440e-04\n",
      "   1.6304855e-04 -8.0539703e-06 -1.4928034e-04]]\n",
      "linear.bias:\n",
      " [0.00022182]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04011979e-03 -1.04214705e-04  2.96890703e-05  7.81255658e-05\n",
      "   1.68101775e-04 -5.13269624e-05 -1.48049745e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440369e-03 -1.0596378e-04  2.9732917e-05  8.1103695e-05\n",
      "   1.7192721e-04 -4.0292885e-05 -1.4713898e-04]]\n",
      "linear.bias:\n",
      " [0.00022203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473202e-03 -1.0530539e-04  2.9927125e-05  1.3211700e-04\n",
      "   1.7422224e-04  1.6739654e-05 -1.4651987e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481782e-03 -1.0351318e-04  2.9985722e-05  1.0534324e-04\n",
      "   1.7637027e-04 -2.9789207e-05 -1.4705407e-04]]\n",
      "linear.bias:\n",
      " [0.00022202]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475280e-03 -1.0300923e-04  2.9871298e-05  9.0081972e-05\n",
      "   1.7781252e-04 -4.8201422e-05 -1.4735562e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04686187e-03 -9.94397269e-05  2.98332816e-05  1.09792374e-04\n",
      "   1.77569236e-04 -1.90210121e-05 -1.48494946e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477762e-03 -9.8745353e-05  2.9837127e-05  1.1061589e-04\n",
      "   1.7880563e-04 -1.2358648e-05 -1.4821702e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503845e-03 -1.0028706e-04  3.0088921e-05  9.0421367e-05\n",
      "   1.8189693e-04 -4.2208099e-05 -1.4625746e-04]]\n",
      "linear.bias:\n",
      " [0.00022366]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05158286e-03 -9.84784419e-05  3.04964724e-05  1.02428196e-04\n",
      "   1.82244170e-04 -2.52160262e-05 -1.45578058e-04]]\n",
      "linear.bias:\n",
      " [0.00022381]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509182e-03 -9.8005454e-05  3.0749703e-05  1.2226460e-04\n",
      "   1.8188404e-04  5.1916450e-06 -1.4478141e-04]]\n",
      "linear.bias:\n",
      " [0.00022428]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492884e-03 -9.7265882e-05  3.1039672e-05  8.0423721e-05\n",
      "   1.8018903e-04 -3.1728545e-05 -1.4489608e-04]]\n",
      "linear.bias:\n",
      " [0.00022453]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474910e-03 -9.8390548e-05  3.1718551e-05  8.4264379e-05\n",
      "   1.7859823e-04 -3.2401367e-05 -1.4478511e-04]]\n",
      "linear.bias:\n",
      " [0.0002246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451621e-03 -1.0134590e-04  3.2351774e-05  1.2411134e-04\n",
      "   1.7710644e-04  4.2743159e-06 -1.4458725e-04]]\n",
      "linear.bias:\n",
      " [0.00022451]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04306499e-03 -1.05060615e-04  3.33385542e-05  1.06221065e-04\n",
      "   1.75786437e-04 -2.51073943e-05 -1.44186197e-04]]\n",
      "linear.bias:\n",
      " [0.00022442]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04198325e-03 -1.10782166e-04  3.35324694e-05  8.86467824e-05\n",
      "   1.74728659e-04 -4.24150858e-05 -1.43518075e-04]]\n",
      "linear.bias:\n",
      " [0.0002245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409282e-03 -1.1280232e-04  3.3772441e-05  1.0636293e-04\n",
      "   1.7222618e-04 -1.2159468e-05 -1.4378877e-04]]\n",
      "linear.bias:\n",
      " [0.00022458]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418982e-03 -1.1259405e-04  3.3348926e-05  1.0355521e-04\n",
      "   1.7253734e-04 -1.3995865e-05 -1.4215468e-04]]\n",
      "linear.bias:\n",
      " [0.00022448]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451319e-03 -1.1022425e-04  3.2147767e-05  8.8633496e-05\n",
      "   1.7433580e-04 -4.1721265e-05 -1.3933904e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478807e-03 -1.0452780e-04  3.0856529e-05  1.0761830e-04\n",
      "   1.7341180e-04 -2.1441087e-05 -1.3809220e-04]]\n",
      "linear.bias:\n",
      " [0.00022449]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487782e-03 -1.0050477e-04  2.9673718e-05  1.1657916e-04\n",
      "   1.7296488e-04  3.9245606e-07 -1.3688178e-04]]\n",
      "linear.bias:\n",
      " [0.00022536]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499822e-03 -9.8464261e-05  2.9042158e-05  8.2814033e-05\n",
      "   1.7301032e-04 -2.7188571e-05 -1.3533927e-04]]\n",
      "linear.bias:\n",
      " [0.00022615]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508640e-03 -9.8383047e-05  2.8908953e-05  8.7941116e-05\n",
      "   1.7357791e-04 -1.9708745e-05 -1.3399700e-04]]\n",
      "linear.bias:\n",
      " [0.00022654]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500852e-03 -9.9913203e-05  2.9365650e-05  1.2300705e-04\n",
      "   1.7356426e-04  8.5194188e-06 -1.3313799e-04]]\n",
      "linear.bias:\n",
      " [0.00022641]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469343e-03 -1.0108387e-04  2.9610792e-05  8.7986453e-05\n",
      "   1.7269362e-04 -5.2657335e-05 -1.3428666e-04]]\n",
      "linear.bias:\n",
      " [0.00022614]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442539e-03 -9.9276498e-05  2.9960753e-05  9.3403425e-05\n",
      "   1.6976257e-04 -5.7366855e-05 -1.3692054e-04]]\n",
      "linear.bias:\n",
      " [0.0002254]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419973e-03 -9.4786024e-05  3.0405166e-05  1.3523149e-04\n",
      "   1.6497506e-04 -1.1256601e-05 -1.4089263e-04]]\n",
      "linear.bias:\n",
      " [0.00022426]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0412449e-03 -9.4401687e-05  3.0422876e-05  1.1748954e-04\n",
      "   1.6377695e-04 -1.2875250e-05 -1.4354491e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431866e-03 -9.7001306e-05  3.0681458e-05  7.3877440e-05\n",
      "   1.6701984e-04 -5.2888288e-05 -1.4364709e-04]]\n",
      "linear.bias:\n",
      " [0.00022229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455780e-03 -9.8478624e-05  3.1073298e-05  9.2534938e-05\n",
      "   1.6802718e-04 -3.4470617e-05 -1.4437336e-04]]\n",
      "linear.bias:\n",
      " [0.00022114]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479445e-03 -1.0153456e-04  3.1491811e-05  1.3455015e-04\n",
      "   1.6943979e-04  1.5439295e-05 -1.4488267e-04]]\n",
      "linear.bias:\n",
      " [0.00021994]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473019e-03 -1.0335431e-04  3.1405325e-05  8.3376581e-05\n",
      "   1.7231972e-04 -4.9206279e-05 -1.4647891e-04]]\n",
      "linear.bias:\n",
      " [0.00021918]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04572182e-03 -1.01686346e-04  3.11576950e-05  8.07207034e-05\n",
      "   1.73025444e-04 -5.76264392e-05 -1.48567371e-04]]\n",
      "linear.bias:\n",
      " [0.00021849]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443985e-03 -9.6476433e-05  3.0861724e-05  1.3272789e-04\n",
      "   1.7152049e-04  9.0940739e-07 -1.5097768e-04]]\n",
      "linear.bias:\n",
      " [0.00021852]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447815e-03 -9.3404735e-05  3.0421392e-05  1.1838149e-04\n",
      "   1.7195825e-04  3.0635538e-06 -1.5241501e-04]]\n",
      "linear.bias:\n",
      " [0.0002192]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465640e-03 -9.4031326e-05  3.0526255e-05  6.7212444e-05\n",
      "   1.7640373e-04 -4.0312771e-05 -1.5199279e-04]]\n",
      "linear.bias:\n",
      " [0.00021964]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475646e-03 -9.6806973e-05  3.0247031e-05  8.9252280e-05\n",
      "   1.8068077e-04 -3.9218856e-05 -1.5040742e-04]]\n",
      "linear.bias:\n",
      " [0.00021956]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479320e-03 -1.0109729e-04  3.0149933e-05  1.4008075e-04\n",
      "   1.8473013e-04 -2.2572931e-06 -1.4889549e-04]]\n",
      "linear.bias:\n",
      " [0.00021948]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04700250e-03 -1.03530569e-04  2.93134744e-05  1.08038425e-04\n",
      "   1.87112557e-04 -3.38270693e-05 -1.48624240e-04]]\n",
      "linear.bias:\n",
      " [0.00022022]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447175e-03 -1.0685125e-04  2.8390108e-05  8.8072309e-05\n",
      "   1.8875711e-04 -3.8731618e-05 -1.4819733e-04]]\n",
      "linear.bias:\n",
      " [0.00022154]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427100e-03 -1.0596441e-04  2.7674401e-05  1.1184554e-04\n",
      "   1.8540230e-04  7.3673509e-06 -1.4987862e-04]]\n",
      "linear.bias:\n",
      " [0.00022289]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407314e-03 -1.0504418e-04  2.7339187e-05  9.4757706e-05\n",
      "   1.8135361e-04 -1.4606549e-05 -1.5106010e-04]]\n",
      "linear.bias:\n",
      " [0.00022361]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03837508e-03 -1.05601786e-04  2.81356388e-05  8.35879327e-05\n",
      "   1.79428491e-04 -4.72425818e-05 -1.50442240e-04]]\n",
      "linear.bias:\n",
      " [0.00022426]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363068e-03 -1.0393230e-04  2.9246918e-05  1.2571378e-04\n",
      "   1.7549272e-04 -2.7182385e-05 -1.5052019e-04]]\n",
      "linear.bias:\n",
      " [0.00022485]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0372096e-03 -1.0251354e-04  2.9755913e-05  1.3461466e-04\n",
      "   1.7451387e-04 -3.1890970e-05 -1.4899373e-04]]\n",
      "linear.bias:\n",
      " [0.00022522]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402044e-03 -1.0069714e-04  2.9090143e-05  9.7394906e-05\n",
      "   1.7509612e-04 -6.2774976e-05 -1.4637437e-04]]\n",
      "linear.bias:\n",
      " [0.00022523]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430526e-03 -9.6091295e-05  2.8591794e-05  9.9565645e-05\n",
      "   1.7352293e-04 -4.1502131e-05 -1.4524980e-04]]\n",
      "linear.bias:\n",
      " [0.00022491]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448247e-03 -9.4038951e-05  2.8606426e-05  1.2459299e-04\n",
      "   1.7271210e-04  9.6632939e-06 -1.4389052e-04]]\n",
      "linear.bias:\n",
      " [0.00022429]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452460e-03 -9.3875991e-05  2.9271589e-05  9.0715883e-05\n",
      "   1.7242924e-04 -1.9294044e-05 -1.4255755e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444267e-03 -9.6322750e-05  3.0597315e-05  7.7928598e-05\n",
      "   1.7349815e-04 -3.5430006e-05 -1.4037342e-04]]\n",
      "linear.bias:\n",
      " [0.0002223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430276e-03 -1.0045100e-04  3.1960233e-05  1.0488770e-04\n",
      "   1.7398670e-04 -1.2335309e-05 -1.3843965e-04]]\n",
      "linear.bias:\n",
      " [0.0002213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04341644e-03 -1.06516010e-04  3.32256495e-05  1.07913867e-04\n",
      "   1.75945301e-04 -1.07796905e-05 -1.35597613e-04]]\n",
      "linear.bias:\n",
      " [0.00022072]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460226e-03 -1.1269389e-04  3.3665630e-05  8.8596396e-05\n",
      "   1.7877495e-04 -3.0995627e-05 -1.3223675e-04]]\n",
      "linear.bias:\n",
      " [0.00022069]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04770251e-03 -1.12317925e-04  3.37232341e-05  1.11467845e-04\n",
      "   1.77315655e-04 -8.75832484e-07 -1.31476263e-04]]\n",
      "linear.bias:\n",
      " [0.00022098]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487806e-03 -1.0701654e-04  3.2284934e-05  7.8690922e-05\n",
      "   1.7313453e-04 -3.6373396e-05 -1.3254645e-04]]\n",
      "linear.bias:\n",
      " [0.0002219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494412e-03 -9.8459110e-05  3.0728312e-05  9.9418663e-05\n",
      "   1.6407567e-04 -1.6276101e-05 -1.3605153e-04]]\n",
      "linear.bias:\n",
      " [0.00022257]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489114e-03 -9.3530936e-05  3.0152871e-05  1.2279864e-04\n",
      "   1.5829853e-04 -2.3172470e-07 -1.3808650e-04]]\n",
      "linear.bias:\n",
      " [0.00022317]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485919e-03 -9.2607945e-05  2.9968613e-05  1.0274070e-04\n",
      "   1.5787568e-04 -3.4439709e-05 -1.3855680e-04]]\n",
      "linear.bias:\n",
      " [0.00022355]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472510e-03 -9.4636525e-05  3.0363104e-05  9.2143397e-05\n",
      "   1.5960776e-04 -4.4801178e-05 -1.3801176e-04]]\n",
      "linear.bias:\n",
      " [0.00022388]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454974e-03 -9.8321878e-05  3.0818839e-05  1.1408415e-04\n",
      "   1.6146262e-04 -1.6848477e-05 -1.3748686e-04]]\n",
      "linear.bias:\n",
      " [0.00022403]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444692e-03 -1.0432610e-04  3.1542015e-05  1.0809661e-04\n",
      "   1.6583766e-04 -1.7917799e-05 -1.3547495e-04]]\n",
      "linear.bias:\n",
      " [0.00022399]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452005e-03 -1.1209251e-04  3.2231565e-05  8.1397993e-05\n",
      "   1.7130375e-04 -3.8160659e-05 -1.3255684e-04]]\n",
      "linear.bias:\n",
      " [0.00022428]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458169e-03 -1.1580917e-04  3.2772441e-05  1.0041794e-04\n",
      "   1.7225131e-04 -6.1261671e-06 -1.3205125e-04]]\n",
      "linear.bias:\n",
      " [0.00022439]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471921e-03 -1.1373815e-04  3.2508528e-05  1.0513511e-04\n",
      "   1.7406505e-04 -2.0190505e-06 -1.3121481e-04]]\n",
      "linear.bias:\n",
      " [0.00022481]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469611e-03 -1.0635784e-04  3.2004205e-05  8.1667866e-05\n",
      "   1.7550038e-04 -4.1770734e-05 -1.3023554e-04]]\n",
      "linear.bias:\n",
      " [0.00022502]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466574e-03 -9.6389304e-05  3.1419957e-05  1.0808529e-04\n",
      "   1.7218472e-04 -2.3697872e-05 -1.3171221e-04]]\n",
      "linear.bias:\n",
      " [0.00022472]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471083e-03 -8.9812049e-05  3.0232841e-05  1.2273659e-04\n",
      "   1.6967354e-04  1.2314649e-06 -1.3290791e-04]]\n",
      "linear.bias:\n",
      " [0.00022494]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473913e-03 -8.7354412e-05  2.8988523e-05  8.3020117e-05\n",
      "   1.6845416e-04 -2.8870694e-05 -1.3487593e-04]]\n",
      "linear.bias:\n",
      " [0.0002258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480013e-03 -8.8664383e-05  2.8262797e-05  8.4934472e-05\n",
      "   1.6773959e-04 -2.3062099e-05 -1.3677136e-04]]\n",
      "linear.bias:\n",
      " [0.00022608]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475793e-03 -9.3569790e-05  2.8401060e-05  1.1908607e-04\n",
      "   1.6749375e-04  3.5923040e-06 -1.3809840e-04]]\n",
      "linear.bias:\n",
      " [0.00022567]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477363e-03 -1.0218723e-04  2.9382489e-05  1.1126553e-04\n",
      "   1.7101568e-04 -1.9276524e-05 -1.3815644e-04]]\n",
      "linear.bias:\n",
      " [0.00022547]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485606e-03 -1.1223202e-04  3.0284662e-05  7.8713390e-05\n",
      "   1.7564306e-04 -6.1056482e-05 -1.3723891e-04]]\n",
      "linear.bias:\n",
      " [0.00022545]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493051e-03 -1.1707213e-04  3.0785977e-05  1.1927189e-04\n",
      "   1.7299097e-04 -8.9756941e-06 -1.3926889e-04]]\n",
      "linear.bias:\n",
      " [0.00022478]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04763487e-03 -1.17436997e-04  3.12176744e-05  1.18649135e-04\n",
      "   1.71552863e-04  7.65808727e-06 -1.40502729e-04]]\n",
      "linear.bias:\n",
      " [0.00022434]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449453e-03 -1.0899278e-04  3.0191457e-05  5.0057482e-05\n",
      "   1.6997644e-04 -6.0123635e-05 -1.4261609e-04]]\n",
      "linear.bias:\n",
      " [0.00022328]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440624e-03 -9.7152886e-05  3.0097242e-05  1.0780767e-04\n",
      "   1.6273599e-04 -1.9780724e-05 -1.4615129e-04]]\n",
      "linear.bias:\n",
      " [0.00022084]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455690e-03 -8.9248904e-05  3.0199801e-05  1.4851964e-04\n",
      "   1.6005646e-04 -3.0464325e-06 -1.4697261e-04]]\n",
      "linear.bias:\n",
      " [0.00021848]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454477e-03 -8.3410130e-05  2.9780158e-05  9.2264236e-05\n",
      "   1.6241196e-04 -6.0103168e-05 -1.4777435e-04]]\n",
      "linear.bias:\n",
      " [0.00021751]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455541e-03 -8.2060738e-05  2.9389588e-05  7.4846299e-05\n",
      "   1.6574351e-04 -6.9578477e-05 -1.4821337e-04]]\n",
      "linear.bias:\n",
      " [0.0002168]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460693e-03 -8.3839295e-05  2.8322898e-05  1.2430026e-04\n",
      "   1.6974872e-04 -1.2541714e-06 -1.4796598e-04]]\n",
      "linear.bias:\n",
      " [0.00021666]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472272e-03 -8.9306843e-05  2.8147233e-05  1.3123218e-04\n",
      "   1.7683001e-04  1.5563885e-05 -1.4627998e-04]]\n",
      "linear.bias:\n",
      " [0.00021654]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460778e-03 -9.5754425e-05  2.8336743e-05  4.9715723e-05\n",
      "   1.8284282e-04 -7.2165996e-05 -1.4649220e-04]]\n",
      "linear.bias:\n",
      " [0.00021742]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04709924e-03 -1.01261416e-04  2.85810420e-05  1.01323909e-04\n",
      "   1.80622286e-04 -2.90333955e-05 -1.49488187e-04]]\n",
      "linear.bias:\n",
      " [0.00021655]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465375e-03 -1.0737580e-04  2.8626937e-05  1.5669207e-04\n",
      "   1.7811052e-04  3.3280874e-05 -1.5199911e-04]]\n",
      "linear.bias:\n",
      " [0.00021644]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414885e-03 -1.0507326e-04  2.7808119e-05  9.1344962e-05\n",
      "   1.7897460e-04 -6.5817847e-05 -1.5591923e-04]]\n",
      "linear.bias:\n",
      " [0.00021716]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0365129e-03 -9.9767734e-05  2.7080208e-05  7.6801851e-05\n",
      "   1.7841585e-04 -8.7574219e-05 -1.5994486e-04]]\n",
      "linear.bias:\n",
      " [0.00021864]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0330958e-03 -9.0549605e-05  2.6807867e-05  1.4844627e-04\n",
      "   1.7495037e-04  3.7704231e-06 -1.6389720e-04]]\n",
      "linear.bias:\n",
      " [0.00021948]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03106035e-03 -8.48428826e-05  2.71653735e-05  1.38679781e-04\n",
      "   1.74915069e-04  1.21056255e-05 -1.66136189e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0304190e-03 -8.2987470e-05  2.7969101e-05  6.4814019e-05\n",
      "   1.7962178e-04 -5.0730585e-05 -1.6603112e-04]]\n",
      "linear.bias:\n",
      " [0.00022154]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0319205e-03 -8.5891508e-05  2.8086006e-05  8.1857026e-05\n",
      "   1.8381556e-04 -5.4364682e-05 -1.6346549e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0354199e-03 -9.3254923e-05  2.7557477e-05  1.4853253e-04\n",
      "   1.8635437e-04 -8.9588793e-06 -1.6028239e-04]]\n",
      "linear.bias:\n",
      " [0.00022165]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400314e-03 -1.0107113e-04  2.6883890e-05  1.4487225e-04\n",
      "   1.9005066e-04 -1.9029754e-05 -1.5661908e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445559e-03 -1.0818354e-04  2.5804493e-05  8.2678816e-05\n",
      "   1.9250931e-04 -7.0729307e-05 -1.5329487e-04]]\n",
      "linear.bias:\n",
      " [0.00022301]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481762e-03 -1.1042214e-04  2.5014955e-05  9.8796183e-05\n",
      "   1.8649720e-04 -2.8085993e-05 -1.5291540e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500132e-03 -1.1293993e-04  2.4250696e-05  1.2556867e-04\n",
      "   1.8006218e-04  2.9394265e-05 -1.5273946e-04]]\n",
      "linear.bias:\n",
      " [0.00022362]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483337e-03 -1.1077800e-04  2.4126777e-05  7.6994962e-05\n",
      "   1.7543336e-04 -4.3738852e-05 -1.5272677e-04]]\n",
      "linear.bias:\n",
      " [0.00022396]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04724080e-03 -1.05681065e-04  2.50816702e-05  8.86525522e-05\n",
      "   1.70390529e-04 -6.69776637e-05 -1.52517707e-04]]\n",
      "linear.bias:\n",
      " [0.0002241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459292e-03 -9.7872537e-05  2.6722111e-05  1.4426133e-04\n",
      "   1.6655598e-04 -1.6544051e-05 -1.5198581e-04]]\n",
      "linear.bias:\n",
      " [0.00022406]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462678e-03 -9.3151531e-05  2.8352042e-05  1.3784507e-04\n",
      "   1.6674306e-04 -1.5969697e-05 -1.4970671e-04]]\n",
      "linear.bias:\n",
      " [0.00022386]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480179e-03 -9.2443464e-05  2.9782328e-05  8.1030026e-05\n",
      "   1.7066512e-04 -5.6793571e-05 -1.4602870e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486548e-03 -9.5303476e-05  3.0876698e-05  7.2686984e-05\n",
      "   1.7400352e-04 -5.2479918e-05 -1.4252201e-04]]\n",
      "linear.bias:\n",
      " [0.00022317]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497982e-03 -9.8368546e-05  3.2133114e-05  1.2916687e-04\n",
      "   1.7314107e-04  7.0018141e-06 -1.4104828e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482935e-03 -1.0124636e-04  3.3022916e-05  1.1434664e-04\n",
      "   1.7214732e-04 -1.1985367e-05 -1.4084498e-04]]\n",
      "linear.bias:\n",
      " [0.0002204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473850e-03 -1.0460093e-04  3.3437256e-05  6.7172194e-05\n",
      "   1.7224405e-04 -5.8933343e-05 -1.3976484e-04]]\n",
      "linear.bias:\n",
      " [0.00021905]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468472e-03 -1.0339816e-04  3.3240140e-05  1.1496138e-04\n",
      "   1.6654929e-04 -1.1611421e-05 -1.4147647e-04]]\n",
      "linear.bias:\n",
      " [0.00021767]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04808109e-03 -1.04552295e-04  3.31044321e-05  1.26690284e-04\n",
      "   1.63167279e-04 -8.16261490e-07 -1.41961122e-04]]\n",
      "linear.bias:\n",
      " [0.0002166]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485598e-03 -1.0593154e-04  3.2483673e-05  8.2642764e-05\n",
      "   1.6411960e-04 -3.8195034e-05 -1.4149780e-04]]\n",
      "linear.bias:\n",
      " [0.00021647]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476519e-03 -1.0635372e-04  3.1742755e-05  8.1355734e-05\n",
      "   1.6555430e-04 -3.4397573e-05 -1.4045210e-04]]\n",
      "linear.bias:\n",
      " [0.00021686]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454947e-03 -1.0591367e-04  3.0893545e-05  1.1856950e-04\n",
      "   1.6742368e-04  6.4754277e-06 -1.3888166e-04]]\n",
      "linear.bias:\n",
      " [0.00021772]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04339700e-03 -1.06546664e-04  3.04857040e-05  1.06429114e-04\n",
      "   1.70574291e-04 -1.19781835e-05 -1.37486844e-04]]\n",
      "linear.bias:\n",
      " [0.00021949]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04312680e-03 -1.08118846e-04  3.00729916e-05  7.47217418e-05\n",
      "   1.75029621e-04 -5.60779627e-05 -1.34938004e-04]]\n",
      "linear.bias:\n",
      " [0.00022126]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04334427e-03 -1.04423096e-04  2.91971883e-05  1.20963174e-04\n",
      "   1.71669337e-04 -6.80110679e-06 -1.36023096e-04]]\n",
      "linear.bias:\n",
      " [0.00022285]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04365591e-03 -1.02259066e-04  2.78392581e-05  1.14037168e-04\n",
      "   1.67979757e-04 -2.08877009e-06 -1.37649811e-04]]\n",
      "linear.bias:\n",
      " [0.00022496]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04499317e-03 -1.02365986e-04  2.69033517e-05  7.56123191e-05\n",
      "   1.66752041e-04 -3.64103726e-05 -1.37939380e-04]]\n",
      "linear.bias:\n",
      " [0.00022668]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464609e-03 -1.0062581e-04  2.6652426e-05  8.5842192e-05\n",
      "   1.6471444e-04 -2.6535679e-05 -1.3898210e-04]]\n",
      "linear.bias:\n",
      " [0.00022757]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465193e-03 -1.0118791e-04  2.7264263e-05  1.2694002e-04\n",
      "   1.6360711e-04  1.1639702e-05 -1.3936528e-04]]\n",
      "linear.bias:\n",
      " [0.00022802]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440346e-03 -1.0129636e-04  2.8161747e-05  9.9668214e-05\n",
      "   1.6567684e-04 -4.4020315e-05 -1.3958257e-04]]\n",
      "linear.bias:\n",
      " [0.00022726]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04096846e-03 -1.03614766e-04  2.93930898e-05  9.83670616e-05\n",
      "   1.68266386e-04 -6.14494929e-05 -1.39471565e-04]]\n",
      "linear.bias:\n",
      " [0.00022606]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381226e-03 -1.0253029e-04  3.0544052e-05  1.3224677e-04\n",
      "   1.6898636e-04 -2.9556835e-05 -1.4074151e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03739835e-03 -1.01435478e-04  3.04726582e-05  1.20770026e-04\n",
      "   1.71432825e-04 -2.68422082e-05 -1.40952339e-04]]\n",
      "linear.bias:\n",
      " [0.00022354]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0382552e-03 -1.0158151e-04  3.0082338e-05  8.7883185e-05\n",
      "   1.7458685e-04 -4.1312564e-05 -1.4025930e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0389411e-03 -9.8406672e-05  2.9799878e-05  9.1725444e-05\n",
      "   1.7579058e-04 -9.1299189e-06 -1.4055628e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418894e-03 -9.8976976e-05  2.9095225e-05  1.0614515e-04\n",
      "   1.7692849e-04  1.4156891e-05 -1.4027294e-04]]\n",
      "linear.bias:\n",
      " [0.00022204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447534e-03 -9.9904290e-05  2.8843951e-05  7.9327881e-05\n",
      "   1.7694481e-04 -3.1541160e-05 -1.4013787e-04]]\n",
      "linear.bias:\n",
      " [0.00022153]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475687e-03 -9.8305922e-05  2.9043960e-05  9.9562676e-05\n",
      "   1.7462276e-04 -3.3470827e-05 -1.4097957e-04]]\n",
      "linear.bias:\n",
      " [0.0002209]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491919e-03 -9.8597964e-05  2.9415914e-05  1.3958465e-04\n",
      "   1.7211567e-04 -4.2731990e-06 -1.4181486e-04]]\n",
      "linear.bias:\n",
      " [0.00022017]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487448e-03 -9.9777317e-05  2.9225252e-05  1.0326628e-04\n",
      "   1.7022228e-04 -3.4146124e-05 -1.4325020e-04]]\n",
      "linear.bias:\n",
      " [0.00022002]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469026e-03 -1.0397413e-04  2.9588040e-05  7.8650759e-05\n",
      "   1.6998626e-04 -4.0175066e-05 -1.4359842e-04]]\n",
      "linear.bias:\n",
      " [0.00022039]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04504894e-03 -1.05313506e-04  3.02326480e-05  1.06793377e-04\n",
      "   1.68116880e-04  1.21902485e-06 -1.44264690e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453670e-03 -1.0927687e-04  3.1368709e-05  1.1234058e-04\n",
      "   1.6958814e-04  3.6717070e-06 -1.4260566e-04]]\n",
      "linear.bias:\n",
      " [0.00022083]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469025e-03 -1.1236197e-04  3.2189138e-05  8.3838786e-05\n",
      "   1.7403046e-04 -3.3566816e-05 -1.3951313e-04]]\n",
      "linear.bias:\n",
      " [0.00022061]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475629e-03 -1.0915347e-04  3.2645559e-05  9.2070404e-05\n",
      "   1.7521974e-04 -2.2214754e-05 -1.3812070e-04]]\n",
      "linear.bias:\n",
      " [0.00022092]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477843e-03 -1.0624162e-04  3.2492058e-05  1.2023168e-04\n",
      "   1.7498438e-04  1.3524568e-05 -1.3750403e-04]]\n",
      "linear.bias:\n",
      " [0.00022121]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04693312e-03 -1.01029924e-04  3.15607103e-05  7.78519170e-05\n",
      "   1.72253116e-04 -3.97527983e-05 -1.39709504e-04]]\n",
      "linear.bias:\n",
      " [0.0002218]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453777e-03 -9.4104369e-05  3.1064668e-05  8.6373730e-05\n",
      "   1.6799942e-04 -4.0307837e-05 -1.4226080e-04]]\n",
      "linear.bias:\n",
      " [0.00022233]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434157e-03 -8.9751949e-05  3.0780368e-05  1.2497435e-04\n",
      "   1.6437742e-04 -5.2698160e-06 -1.4446942e-04]]\n",
      "linear.bias:\n",
      " [0.00022281]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431637e-03 -8.9406720e-05  3.1052645e-05  1.2153566e-04\n",
      "   1.6538403e-04 -1.8518560e-05 -1.4464963e-04]]\n",
      "linear.bias:\n",
      " [0.00022307]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443513e-03 -9.2225375e-05  3.1264935e-05  8.3532112e-05\n",
      "   1.7035429e-04 -6.5383836e-05 -1.4280358e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458538e-03 -9.4433060e-05  3.1638385e-05  1.0878681e-04\n",
      "   1.7196147e-04 -3.6716854e-05 -1.4254694e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485590e-03 -1.0076030e-04  3.1924224e-05  1.2685811e-04\n",
      "   1.7574709e-04  4.9691516e-06 -1.4138414e-04]]\n",
      "linear.bias:\n",
      " [0.00022184]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494225e-03 -1.0722115e-04  3.1958032e-05  7.7382661e-05\n",
      "   1.7794565e-04 -1.9017099e-05 -1.4139815e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498124e-03 -1.1375185e-04  3.1948177e-05  7.8351884e-05\n",
      "   1.7812819e-04 -1.8871993e-05 -1.4175955e-04]]\n",
      "linear.bias:\n",
      " [0.00022172]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04963395e-03 -1.12946160e-04  3.15912948e-05  1.26960804e-04\n",
      "   1.74948174e-04  1.26801315e-05 -1.43341793e-04]]\n",
      "linear.bias:\n",
      " [0.00022209]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475470e-03 -1.0475448e-04  2.9916484e-05  9.5030540e-05\n",
      "   1.7040377e-04 -4.8832662e-05 -1.4705778e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455811e-03 -9.4032468e-05  2.8478209e-05  9.9823745e-05\n",
      "   1.6465581e-04 -5.8948805e-05 -1.5133596e-04]]\n",
      "linear.bias:\n",
      " [0.00022338]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428294e-03 -8.7146174e-05  2.7594060e-05  1.2626624e-04\n",
      "   1.6086630e-04 -3.4087541e-05 -1.5454521e-04]]\n",
      "linear.bias:\n",
      " [0.00022376]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426530e-03 -8.5320607e-05  2.6246071e-05  1.2700081e-04\n",
      "   1.6285035e-04 -8.6981454e-06 -1.5501639e-04]]\n",
      "linear.bias:\n",
      " [0.00022478]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443161e-03 -8.7054563e-05  2.4978901e-05  8.8051820e-05\n",
      "   1.6941033e-04 -2.6835072e-05 -1.5330384e-04]]\n",
      "linear.bias:\n",
      " [0.00022553]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454967e-03 -9.3240778e-05  2.4475616e-05  7.7862991e-05\n",
      "   1.7655008e-04 -2.0125623e-05 -1.5084165e-04]]\n",
      "linear.bias:\n",
      " [0.0002257]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04594883e-03 -1.02663907e-04  2.46837280e-05  1.10057255e-04\n",
      "   1.83253404e-04  7.70734732e-06 -1.47999890e-04]]\n",
      "linear.bias:\n",
      " [0.00022516]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04614277e-03 -1.11715606e-04  2.52646532e-05  1.06557294e-04\n",
      "   1.89426995e-04 -2.47036678e-05 -1.44505786e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04567711e-03 -1.15659175e-04  2.61414825e-05  1.13980801e-04\n",
      "   1.92045074e-04 -3.37669262e-05 -1.42490768e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442465e-03 -1.1496716e-04  2.7154352e-05  1.2923677e-04\n",
      "   1.9172741e-04 -1.6213211e-05 -1.4201713e-04]]\n",
      "linear.bias:\n",
      " [0.00022136]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430290e-03 -1.1157232e-04  2.6896942e-05  7.9831036e-05\n",
      "   1.8881143e-04 -4.6236164e-05 -1.4347845e-04]]\n",
      "linear.bias:\n",
      " [0.00022091]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04102993e-03 -1.03632105e-04  2.63246238e-05  9.17524012e-05\n",
      "   1.79453404e-04 -1.79920116e-05 -1.47134662e-04]]\n",
      "linear.bias:\n",
      " [0.00022068]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0377421e-03 -9.8996374e-05  2.6296841e-05  1.1675484e-04\n",
      "   1.7134866e-04  8.6272848e-06 -1.4974839e-04]]\n",
      "linear.bias:\n",
      " [0.00022047]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03655620e-03 -9.76633964e-05  2.70208111e-05  9.82909405e-05\n",
      "   1.68698971e-04 -1.49424395e-05 -1.50137537e-04]]\n",
      "linear.bias:\n",
      " [0.00022028]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383370e-03 -9.9257391e-05  2.8030216e-05  7.0151073e-05\n",
      "   1.7005068e-04 -6.0217564e-05 -1.4796502e-04]]\n",
      "linear.bias:\n",
      " [0.00021959]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04090711e-03 -9.73925344e-05  2.87698022e-05  1.17821255e-04\n",
      "   1.68788232e-04 -2.23424649e-05 -1.46573075e-04]]\n",
      "linear.bias:\n",
      " [0.00021898]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450528e-03 -9.8652912e-05  2.9771893e-05  1.4067933e-04\n",
      "   1.7032240e-04 -6.6320681e-06 -1.4370967e-04]]\n",
      "linear.bias:\n",
      " [0.00021859]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04827108e-03 -1.00566715e-04  3.03269953e-05  8.74298566e-05\n",
      "   1.71627355e-04 -5.03260380e-05 -1.41831100e-04]]\n",
      "linear.bias:\n",
      " [0.00021911]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502964e-03 -9.8568526e-05  3.0786279e-05  7.7445693e-05\n",
      "   1.7106009e-04 -4.1656374e-05 -1.4085132e-04]]\n",
      "linear.bias:\n",
      " [0.00021974]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506338e-03 -9.8461976e-05  3.1268006e-05  1.1121013e-04\n",
      "   1.6997523e-04  5.9753766e-06 -1.3977544e-04]]\n",
      "linear.bias:\n",
      " [0.00022049]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05157366e-03 -1.01942336e-04  3.22246742e-05  1.02954582e-04\n",
      "   1.71557462e-04  4.05069704e-06 -1.37726252e-04]]\n",
      "linear.bias:\n",
      " [0.00022134]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05332397e-03 -1.07333646e-04  3.33342214e-05  7.03468104e-05\n",
      "   1.75043780e-04 -3.50737682e-05 -1.34177506e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05434388e-03 -1.07302534e-04  3.40131664e-05  1.00829915e-04\n",
      "   1.72083659e-04 -1.61296666e-05 -1.33393813e-04]]\n",
      "linear.bias:\n",
      " [0.00022214]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0527244e-03 -1.0600874e-04  3.4217501e-05  1.3133453e-04\n",
      "   1.6905306e-04  9.0081558e-06 -1.3276785e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483684e-03 -9.8380944e-05  3.2030268e-05  7.5807584e-05\n",
      "   1.6474334e-04 -5.2996602e-05 -1.3515571e-04]]\n",
      "linear.bias:\n",
      " [0.00022527]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441375e-03 -8.9302928e-05  3.0280900e-05  7.9251193e-05\n",
      "   1.5854118e-04 -5.1929539e-05 -1.3870657e-04]]\n",
      "linear.bias:\n",
      " [0.00022616]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403554e-03 -8.5545129e-05  2.8523425e-05  1.2262394e-04\n",
      "   1.5397130e-04 -5.8859951e-06 -1.4205389e-04]]\n",
      "linear.bias:\n",
      " [0.00022661]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386481e-03 -8.5709296e-05  2.7308419e-05  1.2598072e-04\n",
      "   1.5478312e-04 -8.1895387e-06 -1.4334379e-04]]\n",
      "linear.bias:\n",
      " [0.00022685]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0389715e-03 -8.9033863e-05  2.6501864e-05  9.4149145e-05\n",
      "   1.6014175e-04 -5.2024428e-05 -1.4244432e-04]]\n",
      "linear.bias:\n",
      " [0.00022671]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399288e-03 -9.6326454e-05  2.5655645e-05  9.2098358e-05\n",
      "   1.6620666e-04 -5.4466545e-05 -1.4133028e-04]]\n",
      "linear.bias:\n",
      " [0.00022624]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04090106e-03 -1.00884085e-04  2.52812970e-05  1.25758961e-04\n",
      "   1.70727595e-04 -1.21212724e-05 -1.41062512e-04]]\n",
      "linear.bias:\n",
      " [0.00022547]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04252168e-03 -1.07366664e-04  2.52554692e-05  1.11873997e-04\n",
      "   1.76021364e-04 -1.31843772e-05 -1.40085394e-04]]\n",
      "linear.bias:\n",
      " [0.00022478]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460333e-03 -1.1532043e-04  2.5502113e-05  7.4083131e-05\n",
      "   1.8297587e-04 -4.9283495e-05 -1.3759066e-04]]\n",
      "linear.bias:\n",
      " [0.00022398]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486706e-03 -1.1779970e-04  2.5483605e-05  1.0325499e-04\n",
      "   1.8157497e-04 -1.9022496e-05 -1.3844277e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05001323e-03 -1.11873735e-04  2.57781976e-05  1.29787571e-04\n",
      "   1.78347327e-04  1.37804818e-05 -1.39971220e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04905560e-03 -1.01006844e-04  2.53515736e-05  7.95428350e-05\n",
      "   1.73497290e-04 -5.31252881e-05 -1.43480735e-04]]\n",
      "linear.bias:\n",
      " [0.00022274]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475938e-03 -8.9018336e-05  2.5420644e-05  8.6993183e-05\n",
      "   1.6586600e-04 -6.1477098e-05 -1.4773069e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447826e-03 -8.2480357e-05  2.5742636e-05  1.3371048e-04\n",
      "   1.5997099e-04 -1.1484204e-05 -1.5081541e-04]]\n",
      "linear.bias:\n",
      " [0.00022245]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436085e-03 -8.0864309e-05  2.5915595e-05  1.2341232e-04\n",
      "   1.5934146e-04 -5.5667051e-06 -1.5161336e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439520e-03 -8.3644227e-05  2.6534326e-05  7.4895564e-05\n",
      "   1.6390842e-04 -4.2743843e-05 -1.5019609e-04]]\n",
      "linear.bias:\n",
      " [0.0002227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440447e-03 -9.0087538e-05  2.7175398e-05  8.3026403e-05\n",
      "   1.6995151e-04 -3.9215647e-05 -1.4716908e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444978e-03 -9.9546029e-05  2.8140141e-05  1.2656990e-04\n",
      "   1.7587858e-04 -4.8512375e-06 -1.4416300e-04]]\n",
      "linear.bias:\n",
      " [0.00022222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04518922e-03 -1.10305969e-04  2.92668337e-05  1.11078996e-04\n",
      "   1.81445648e-04 -2.23769384e-05 -1.41281605e-04]]\n",
      "linear.bias:\n",
      " [0.0002222]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448745e-03 -1.1948848e-04  3.0598243e-05  8.0509490e-05\n",
      "   1.8731912e-04 -4.7956499e-05 -1.3805693e-04]]\n",
      "linear.bias:\n",
      " [0.00022305]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430475e-03 -1.2065618e-04  3.1262916e-05  1.1045650e-04\n",
      "   1.8600623e-04 -1.4443842e-05 -1.3783074e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431291e-03 -1.1006590e-04  3.1077529e-05  1.1431681e-04\n",
      "   1.8172819e-04  6.9857651e-07 -1.3931880e-04]]\n",
      "linear.bias:\n",
      " [0.00022537]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442152e-03 -9.6186181e-05  2.9991375e-05  7.1269358e-05\n",
      "   1.7602142e-04 -4.7998623e-05 -1.4136202e-04]]\n",
      "linear.bias:\n",
      " [0.00022644]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460521e-03 -8.4037580e-05  2.9281837e-05  9.8725082e-05\n",
      "   1.6621043e-04 -3.4139914e-05 -1.4510087e-04]]\n",
      "linear.bias:\n",
      " [0.00022634]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498023e-03 -7.9396938e-05  2.8415228e-05  1.3656664e-04\n",
      "   1.5904916e-04  9.4282950e-07 -1.4756552e-04]]\n",
      "linear.bias:\n",
      " [0.00022556]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512675e-03 -8.1211329e-05  2.8152319e-05  1.1534490e-04\n",
      "   1.5814601e-04 -2.4773704e-05 -1.4801056e-04]]\n",
      "linear.bias:\n",
      " [0.00022433]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0542780e-03 -8.7210843e-05  2.7751950e-05  7.2393945e-05\n",
      "   1.6273528e-04 -6.8099900e-05 -1.4588216e-04]]\n",
      "linear.bias:\n",
      " [0.00022357]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0559551e-03 -9.5844451e-05  2.6515519e-05  1.0874907e-04\n",
      "   1.6811088e-04 -3.2021209e-05 -1.4293336e-04]]\n",
      "linear.bias:\n",
      " [0.00022183]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0564921e-03 -1.0649494e-04  2.6019548e-05  1.4001089e-04\n",
      "   1.7528587e-04  1.9418145e-05 -1.3945250e-04]]\n",
      "linear.bias:\n",
      " [0.00022079]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0523003e-03 -1.1020484e-04  2.4885574e-05  6.7153691e-05\n",
      "   1.8250577e-04 -5.8905123e-05 -1.3904498e-04]]\n",
      "linear.bias:\n",
      " [0.00022091]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04884384e-03 -1.09408604e-04  2.36778742e-05  8.87866481e-05\n",
      "   1.78850023e-04 -3.61259226e-05 -1.42428398e-04]]\n",
      "linear.bias:\n",
      " [0.00022067]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445309e-03 -1.0510837e-04  2.2948256e-05  1.4050881e-04\n",
      "   1.7242611e-04  2.8020615e-05 -1.4681491e-04]]\n",
      "linear.bias:\n",
      " [0.00022063]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0379623e-03 -9.9382676e-05  2.2240725e-05  9.0319751e-05\n",
      "   1.6856805e-04 -4.1059386e-05 -1.5238859e-04]]\n",
      "linear.bias:\n",
      " [0.00022112]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "Epoch [3500/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0310212e-03 -9.5766030e-05  2.2996706e-05  7.9197860e-05\n",
      "   1.6620952e-04 -7.3280760e-05 -1.5652392e-04]]\n",
      "linear.bias:\n",
      " [0.00022103]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0263588e-03 -8.9949805e-05  2.3865989e-05  1.3661607e-04\n",
      "   1.6673817e-04 -1.5747268e-05 -1.5877582e-04]]\n",
      "linear.bias:\n",
      " [0.0002206]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0253571e-03 -8.7818531e-05  2.4464382e-05  1.3992791e-04\n",
      "   1.7265131e-04 -3.0221781e-07 -1.5817594e-04]]\n",
      "linear.bias:\n",
      " [0.00022039]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0267922e-03 -8.8401539e-05  2.5453195e-05  8.9339323e-05\n",
      "   1.8241635e-04 -3.6552159e-05 -1.5555204e-04]]\n",
      "linear.bias:\n",
      " [0.00022019]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0323320e-03 -9.3870898e-05  2.6100675e-05  7.6509270e-05\n",
      "   1.9179918e-04 -4.4148586e-05 -1.5263015e-04]]\n",
      "linear.bias:\n",
      " [0.00021967]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0380503e-03 -9.8221790e-05  2.6773236e-05  1.2977728e-04\n",
      "   1.9385533e-04  3.9383522e-06 -1.5206766e-04]]\n",
      "linear.bias:\n",
      " [0.00021884]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426057e-03 -1.0129033e-04  2.6868369e-05  1.1772576e-04\n",
      "   1.9293292e-04 -8.8550705e-06 -1.5295467e-04]]\n",
      "linear.bias:\n",
      " [0.00021863]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475710e-03 -1.0424168e-04  2.6788119e-05  6.5789136e-05\n",
      "   1.9122778e-04 -5.7817397e-05 -1.5354480e-04]]\n",
      "linear.bias:\n",
      " [0.00021897]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0523968e-03 -1.0267720e-04  2.6486894e-05  1.0688802e-04\n",
      "   1.7922407e-04 -1.1940290e-05 -1.5702867e-04]]\n",
      "linear.bias:\n",
      " [0.00021927]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0562553e-03 -1.0280288e-04  2.7529095e-05  1.3304212e-04\n",
      "   1.7175777e-04  3.1211584e-06 -1.5795884e-04]]\n",
      "linear.bias:\n",
      " [0.00021937]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0567200e-03 -1.0165968e-04  2.8684519e-05  9.2069866e-05\n",
      "   1.6917294e-04 -5.5189244e-05 -1.5722908e-04]]\n",
      "linear.bias:\n",
      " [0.00021893]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0544996e-03 -1.0320321e-04  3.0132966e-05  8.7428663e-05\n",
      "   1.6786740e-04 -6.8580295e-05 -1.5573879e-04]]\n",
      "linear.bias:\n",
      " [0.0002187]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509887e-03 -9.8109042e-05  3.0872608e-05  1.2684331e-04\n",
      "   1.6680139e-04 -5.1478637e-06 -1.5391552e-04]]\n",
      "linear.bias:\n",
      " [0.00021921]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04938645e-03 -9.74881477e-05  3.17393169e-05  1.19228236e-04\n",
      "   1.70491287e-04  8.04073716e-06 -1.50287160e-04]]\n",
      "linear.bias:\n",
      " [0.00021967]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484059e-03 -1.0158597e-04  3.3351633e-05  7.3276460e-05\n",
      "   1.7856530e-04 -3.2006872e-05 -1.4496593e-04]]\n",
      "linear.bias:\n",
      " [0.00021973]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472906e-03 -1.0158296e-04  3.4913988e-05  9.1698334e-05\n",
      "   1.8200278e-04 -2.5102101e-05 -1.4119234e-04]]\n",
      "linear.bias:\n",
      " [0.00021996]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451453e-03 -1.0156118e-04  3.5988276e-05  1.3677868e-04\n",
      "   1.8294467e-04  9.4594579e-06 -1.3867118e-04]]\n",
      "linear.bias:\n",
      " [0.00022052]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420717e-03 -9.8772245e-05  3.5194222e-05  9.1991511e-05\n",
      "   1.8072568e-04 -4.5535762e-05 -1.3926583e-04]]\n",
      "linear.bias:\n",
      " [0.00022191]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0394547e-03 -9.2432849e-05  3.4505334e-05  8.7674816e-05\n",
      "   1.7478400e-04 -4.8361569e-05 -1.4169910e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0373828e-03 -9.0733913e-05  3.4097568e-05  1.1833604e-04\n",
      "   1.6880773e-04 -1.3074023e-05 -1.4420412e-04]]\n",
      "linear.bias:\n",
      " [0.00022428]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0380547e-03 -9.2563532e-05  3.3717803e-05  1.1510180e-04\n",
      "   1.6775180e-04 -1.4251028e-05 -1.4420986e-04]]\n",
      "linear.bias:\n",
      " [0.00022494]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413337e-03 -9.6534859e-05  3.3384727e-05  8.4078230e-05\n",
      "   1.7041722e-04 -4.5385463e-05 -1.4205965e-04]]\n",
      "linear.bias:\n",
      " [0.00022518]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434877e-03 -1.0232558e-04  3.3048738e-05  9.2995841e-05\n",
      "   1.7285444e-04 -3.5559537e-05 -1.4007007e-04]]\n",
      "linear.bias:\n",
      " [0.00022504]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04545220e-03 -1.08074324e-04  3.24332177e-05  1.24762999e-04\n",
      "   1.74950968e-04  8.05483796e-06 -1.38390606e-04]]\n",
      "linear.bias:\n",
      " [0.00022492]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466229e-03 -1.0926833e-04  3.0817162e-05  8.5394786e-05\n",
      "   1.7400442e-04 -3.5763373e-05 -1.3939643e-04]]\n",
      "linear.bias:\n",
      " [0.00022481]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474955e-03 -1.0638246e-04  2.9128767e-05  8.2411920e-05\n",
      "   1.7032388e-04 -3.0763425e-05 -1.4173541e-04]]\n",
      "linear.bias:\n",
      " [0.00022488]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487577e-03 -1.0155977e-04  2.8348833e-05  1.1805934e-04\n",
      "   1.6638696e-04  1.1877517e-05 -1.4426612e-04]]\n",
      "linear.bias:\n",
      " [0.0002246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04954792e-03 -1.00625984e-04  2.83702066e-05  1.06812040e-04\n",
      "   1.67122576e-04 -1.50213727e-05 -1.44983816e-04]]\n",
      "linear.bias:\n",
      " [0.00022362]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04976760e-03 -1.01334605e-04  2.97158203e-05  8.58089043e-05\n",
      "   1.71160340e-04 -6.54660107e-05 -1.43401456e-04]]\n",
      "linear.bias:\n",
      " [0.00022257]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496404e-03 -9.8388649e-05  3.0748797e-05  1.1781176e-04\n",
      "   1.7216802e-04 -4.2371394e-05 -1.4302183e-04]]\n",
      "linear.bias:\n",
      " [0.00022162]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482322e-03 -9.6813346e-05  3.1613850e-05  1.4252277e-04\n",
      "   1.7368840e-04 -1.3789286e-06 -1.4257498e-04]]\n",
      "linear.bias:\n",
      " [0.00022166]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443204e-03 -9.3522009e-05  3.1292970e-05  8.4979329e-05\n",
      "   1.7409584e-04 -2.9423662e-05 -1.4343992e-04]]\n",
      "linear.bias:\n",
      " [0.00022241]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405648e-03 -9.2429676e-05  3.1457013e-05  6.7446992e-05\n",
      "   1.7512993e-04 -2.4195229e-05 -1.4384923e-04]]\n",
      "linear.bias:\n",
      " [0.00022291]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371736e-03 -9.5648815e-05  3.1816613e-05  1.1192184e-04\n",
      "   1.7431838e-04  1.8971543e-05 -1.4414305e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03385258e-03 -1.00323115e-04  3.24354041e-05  1.03487509e-04\n",
      "   1.74765722e-04 -2.25740187e-05 -1.44348931e-04]]\n",
      "linear.bias:\n",
      " [0.00022272]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0330883e-03 -1.0818346e-04  3.2164575e-05  9.8048840e-05\n",
      "   1.7587010e-04 -5.1734634e-05 -1.4413790e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03304593e-03 -1.11212546e-04  3.15881880e-05  1.19845514e-04\n",
      "   1.74362998e-04 -3.61972889e-05 -1.45321828e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03672559e-03 -1.13397487e-04  2.96503003e-05  1.26334286e-04\n",
      "   1.75133304e-04 -1.25261195e-05 -1.45431506e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410828e-03 -1.1189487e-04  2.6944443e-05  8.6192245e-05\n",
      "   1.7743517e-04 -2.6784137e-05 -1.4441689e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04555523e-03 -1.08242064e-04  2.54151601e-05  9.03783293e-05\n",
      "   1.78425267e-04 -1.16197225e-06 -1.44077057e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487480e-03 -1.0589373e-04  2.4922971e-05  9.5618190e-05\n",
      "   1.8042777e-04  5.3865165e-08 -1.4219178e-04]]\n",
      "linear.bias:\n",
      " [0.00022318]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508102e-03 -1.0491191e-04  2.5415628e-05  9.9026096e-05\n",
      "   1.8334760e-04 -2.1926635e-05 -1.3877483e-04]]\n",
      "linear.bias:\n",
      " [0.0002227]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0511788e-03 -1.0431711e-04  2.5913268e-05  1.1916252e-04\n",
      "   1.8441313e-04 -2.1214175e-05 -1.3616287e-04]]\n",
      "linear.bias:\n",
      " [0.00022245]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490773e-03 -1.0264775e-04  2.6503512e-05  8.9457950e-05\n",
      "   1.8354983e-04 -5.4186890e-05 -1.3503458e-04]]\n",
      "linear.bias:\n",
      " [0.00022331]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04751787e-03 -9.67567830e-05  2.71806293e-05  1.07574466e-04\n",
      "   1.76680653e-04 -3.09790339e-05 -1.36877701e-04]]\n",
      "linear.bias:\n",
      " [0.0002239]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451362e-03 -9.1480557e-05  2.7764721e-05  1.2469727e-04\n",
      "   1.7025672e-04  6.4868655e-06 -1.3897425e-04]]\n",
      "linear.bias:\n",
      " [0.00022479]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420487e-03 -9.0275207e-05  2.8789200e-05  8.1247330e-05\n",
      "   1.6537964e-04 -2.8442159e-05 -1.4160205e-04]]\n",
      "linear.bias:\n",
      " [0.00022577]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396502e-03 -9.2966446e-05  3.0111974e-05  7.8426398e-05\n",
      "   1.6148943e-04 -2.8841136e-05 -1.4367868e-04]]\n",
      "linear.bias:\n",
      " [0.0002263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0382946e-03 -9.9136902e-05  3.1531072e-05  1.2141734e-04\n",
      "   1.5834071e-04  2.5695117e-06 -1.4501801e-04]]\n",
      "linear.bias:\n",
      " [0.00022641]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03916530e-03 -1.06687708e-04  3.26966947e-05  1.23469115e-04\n",
      "   1.60842465e-04 -1.14401355e-05 -1.44041653e-04]]\n",
      "linear.bias:\n",
      " [0.00022579]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420417e-03 -1.1548249e-04  3.3634013e-05  8.8658126e-05\n",
      "   1.6843496e-04 -6.6340253e-05 -1.4097898e-04]]\n",
      "linear.bias:\n",
      " [0.0002245]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04472076e-03 -1.15956944e-04  3.38994214e-05  1.09478882e-04\n",
      "   1.73173510e-04 -3.81567370e-05 -1.39986267e-04]]\n",
      "linear.bias:\n",
      " [0.00022335]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480341e-03 -1.0859494e-04  3.3457978e-05  1.4216927e-04\n",
      "   1.7623923e-04  2.6643735e-05 -1.4058688e-04]]\n",
      "linear.bias:\n",
      " [0.00022249]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468736e-03 -9.2158538e-05  3.1151892e-05  6.4085085e-05\n",
      "   1.8025030e-04 -4.4753520e-05 -1.4400363e-04]]\n",
      "linear.bias:\n",
      " [0.00022208]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461821e-03 -7.6980388e-05  2.9363488e-05  8.2621489e-05\n",
      "   1.7647342e-04 -4.0829822e-05 -1.4972601e-04]]\n",
      "linear.bias:\n",
      " [0.00022062]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442518e-03 -6.7805820e-05  2.8163631e-05  1.3564894e-04\n",
      "   1.7294026e-04 -1.4256730e-06 -1.5462752e-04]]\n",
      "linear.bias:\n",
      " [0.00021877]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420902e-03 -6.4773521e-05  2.7628192e-05  1.3185668e-04\n",
      "   1.7340809e-04 -1.3749912e-05 -1.5742495e-04]]\n",
      "linear.bias:\n",
      " [0.00021709]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409892e-03 -6.9139540e-05  2.7225451e-05  8.3786217e-05\n",
      "   1.7801716e-04 -6.0250699e-05 -1.5830174e-04]]\n",
      "linear.bias:\n",
      " [0.00021595]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404087e-03 -7.9265708e-05  2.6637948e-05  9.5834803e-05\n",
      "   1.8116870e-04 -4.3530301e-05 -1.5866870e-04]]\n",
      "linear.bias:\n",
      " [0.00021529]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406602e-03 -9.5890071e-05  2.5875273e-05  1.2736274e-04\n",
      "   1.8538440e-04  1.9174695e-07 -1.5779954e-04]]\n",
      "linear.bias:\n",
      " [0.00021469]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418011e-03 -1.1226868e-04  2.5970117e-05  1.0159649e-04\n",
      "   1.9022870e-04 -1.6085458e-05 -1.5641064e-04]]\n",
      "linear.bias:\n",
      " [0.00021451]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413633e-03 -1.2421074e-04  2.6472835e-05  8.1762424e-05\n",
      "   1.9428914e-04 -4.3905464e-05 -1.5374126e-04]]\n",
      "linear.bias:\n",
      " [0.00021544]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400347e-03 -1.2729263e-04  2.6302474e-05  1.2598548e-04\n",
      "   1.9096477e-04 -1.6316553e-05 -1.5305227e-04]]\n",
      "linear.bias:\n",
      " [0.00021701]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0375278e-03 -1.1952077e-04  2.6569263e-05  1.2225659e-04\n",
      "   1.8647153e-04 -2.1764528e-05 -1.5278402e-04]]\n",
      "linear.bias:\n",
      " [0.0002186]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363915e-03 -1.0947932e-04  2.6097590e-05  8.5610591e-05\n",
      "   1.8299471e-04 -5.1617688e-05 -1.5165626e-04]]\n",
      "linear.bias:\n",
      " [0.0002204]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0353703e-03 -9.6306409e-05  2.5875983e-05  1.0210142e-04\n",
      "   1.7621371e-04 -2.6740998e-05 -1.5184813e-04]]\n",
      "linear.bias:\n",
      " [0.0002222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363432e-03 -8.9146837e-05  2.5885774e-05  1.2508075e-04\n",
      "   1.7265156e-04  7.5533735e-06 -1.5044175e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0380301e-03 -8.7159060e-05  2.6789767e-05  1.0146563e-04\n",
      "   1.7409452e-04 -1.5797108e-05 -1.4705294e-04]]\n",
      "linear.bias:\n",
      " [0.00022404]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416249e-03 -9.0112087e-05  2.8007164e-05  7.9164136e-05\n",
      "   1.7755591e-04 -5.0941871e-05 -1.4231005e-04]]\n",
      "linear.bias:\n",
      " [0.00022384]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448546e-03 -9.3482384e-05  2.9486257e-05  1.1971846e-04\n",
      "   1.7620782e-04 -2.7642380e-05 -1.4004525e-04]]\n",
      "linear.bias:\n",
      " [0.00022274]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474875e-03 -9.9430123e-05  3.0089821e-05  1.3778219e-04\n",
      "   1.7547389e-04 -1.2138988e-05 -1.3776802e-04]]\n",
      "linear.bias:\n",
      " [0.00022212]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04860368e-03 -1.05483276e-04  2.97212464e-05  8.41290312e-05\n",
      "   1.73732638e-04 -4.84696648e-05 -1.36813687e-04]]\n",
      "linear.bias:\n",
      " [0.00022229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495619e-03 -1.0728416e-04  2.9300152e-05  7.8874727e-05\n",
      "   1.6773699e-04 -3.1812720e-05 -1.3831924e-04]]\n",
      "linear.bias:\n",
      " [0.00022227]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507030e-03 -1.0682629e-04  2.9530240e-05  1.1817373e-04\n",
      "   1.6140878e-04  2.2708991e-05 -1.4009314e-04]]\n",
      "linear.bias:\n",
      " [0.00022169]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472467e-03 -1.0231821e-04  2.9829936e-05  8.7528817e-05\n",
      "   1.6113579e-04 -3.5981833e-05 -1.4155892e-04]]\n",
      "linear.bias:\n",
      " [0.00022081]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435312e-03 -1.0028274e-04  3.0274323e-05  9.1093330e-05\n",
      "   1.6111380e-04 -5.3392891e-05 -1.4278344e-04]]\n",
      "linear.bias:\n",
      " [0.00022002]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03979837e-03 -1.00857316e-04  3.07174923e-05  1.25671198e-04\n",
      "   1.62607699e-04 -2.84159942e-05 -1.43488709e-04]]\n",
      "linear.bias:\n",
      " [0.00021967]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03866041e-03 -1.05711006e-04  3.07019072e-05  1.27314299e-04\n",
      "   1.68795363e-04 -2.38125685e-05 -1.42106408e-04]]\n",
      "linear.bias:\n",
      " [0.00022008]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396312e-03 -1.0995325e-04  2.9485405e-05  8.6344633e-05\n",
      "   1.7631831e-04 -4.5657031e-05 -1.3984935e-04]]\n",
      "linear.bias:\n",
      " [0.00022064]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406607e-03 -1.0982380e-04  2.8416953e-05  8.5721724e-05\n",
      "   1.7902344e-04 -1.8515197e-05 -1.3977526e-04]]\n",
      "linear.bias:\n",
      " [0.00022133]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415029e-03 -1.0537211e-04  2.7697462e-05  1.2120367e-04\n",
      "   1.7836933e-04  3.7082878e-05 -1.4114685e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400284e-03 -9.9474863e-05  2.7077635e-05  6.5248663e-05\n",
      "   1.7676377e-04 -4.7913789e-05 -1.4491015e-04]]\n",
      "linear.bias:\n",
      " [0.00022306]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396858e-03 -9.3713526e-05  2.7015689e-05  9.8912249e-05\n",
      "   1.6994137e-04 -6.5744578e-05 -1.5020792e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392551e-03 -9.0596463e-05  2.7118926e-05  1.6201776e-04\n",
      "   1.6537844e-04 -2.1239157e-05 -1.5454543e-04]]\n",
      "linear.bias:\n",
      " [0.00022306]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392705e-03 -8.9446832e-05  2.7603495e-05  1.3396605e-04\n",
      "   1.6742045e-04 -3.1867574e-05 -1.5662143e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410809e-03 -9.2627284e-05  2.7488828e-05  6.8248301e-05\n",
      "   1.7438439e-04 -6.7338464e-05 -1.5596976e-04]]\n",
      "linear.bias:\n",
      " [0.00022391]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436603e-03 -9.5288284e-05  2.7658225e-05  1.1394569e-04\n",
      "   1.7702120e-04  1.8855644e-07 -1.5525751e-04]]\n",
      "linear.bias:\n",
      " [0.00022225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479992e-03 -1.0174726e-04  2.8391307e-05  1.3244183e-04\n",
      "   1.8355259e-04  2.3513652e-05 -1.5206654e-04]]\n",
      "linear.bias:\n",
      " [0.00022039]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497255e-03 -1.0793401e-04  2.9655839e-05  6.6994013e-05\n",
      "   1.8807521e-04 -6.6161156e-05 -1.5100937e-04]]\n",
      "linear.bias:\n",
      " [0.00021908]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05133525e-03 -1.08355496e-04  3.02028602e-05  1.02762482e-04\n",
      "   1.82657634e-04 -5.21145412e-05 -1.53293528e-04]]\n",
      "linear.bias:\n",
      " [0.00021771]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508100e-03 -1.0290020e-04  3.0724812e-05  1.6213175e-04\n",
      "   1.7531101e-04  2.2064341e-06 -1.5634087e-04]]\n",
      "linear.bias:\n",
      " [0.00021685]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460787e-03 -9.1907474e-05  2.9730489e-05  1.1010280e-04\n",
      "   1.7081751e-04 -2.9148057e-05 -1.5993965e-04]]\n",
      "linear.bias:\n",
      " [0.00021663]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431808e-03 -8.6237553e-05  2.8933307e-05  5.3403361e-05\n",
      "   1.7078026e-04 -5.5696888e-05 -1.6091310e-04]]\n",
      "linear.bias:\n",
      " [0.00021717]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04153191e-03 -8.50217402e-05  2.82820329e-05  1.06228224e-04\n",
      "   1.70023326e-04  7.36905349e-07 -1.59862349e-04]]\n",
      "linear.bias:\n",
      " [0.00021673]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429388e-03 -8.7564840e-05  2.7974855e-05  1.3041825e-04\n",
      "   1.7426359e-04  1.3493253e-05 -1.5602940e-04]]\n",
      "linear.bias:\n",
      " [0.00021578]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446397e-03 -9.2018614e-05  2.8319131e-05  9.2077185e-05\n",
      "   1.8138024e-04 -4.4281420e-05 -1.5100936e-04]]\n",
      "linear.bias:\n",
      " [0.00021493]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456330e-03 -9.8012235e-05  2.8972236e-05  9.0400972e-05\n",
      "   1.8754551e-04 -6.0855404e-05 -1.4654336e-04]]\n",
      "linear.bias:\n",
      " [0.00021435]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459094e-03 -9.8676064e-05  2.9593701e-05  1.3918313e-04\n",
      "   1.8704442e-04 -1.0369451e-05 -1.4457933e-04]]\n",
      "linear.bias:\n",
      " [0.00021437]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448862e-03 -9.9980964e-05  2.9228488e-05  1.1366690e-04\n",
      "   1.8549783e-04 -1.4750037e-05 -1.4392234e-04]]\n",
      "linear.bias:\n",
      " [0.00021514]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456544e-03 -1.0164628e-04  2.8470453e-05  6.2078463e-05\n",
      "   1.8382580e-04 -4.0708393e-05 -1.4299256e-04]]\n",
      "linear.bias:\n",
      " [0.00021676]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461649e-03 -9.8382807e-05  2.7477610e-05  9.7804426e-05\n",
      "   1.7435996e-04 -5.2188298e-06 -1.4468016e-04]]\n",
      "linear.bias:\n",
      " [0.00021803]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04851660e-03 -9.82385172e-05  2.69356660e-05  1.14778784e-04\n",
      "   1.68270897e-04 -2.92660366e-06 -1.44224847e-04]]\n",
      "linear.bias:\n",
      " [0.00021899]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0514122e-03 -1.0244108e-04  2.7327758e-05  9.2703165e-05\n",
      "   1.6668244e-04 -4.4446486e-05 -1.4217422e-04]]\n",
      "linear.bias:\n",
      " [0.00021985]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0522576e-03 -1.0868233e-04  2.8311097e-05  1.0161935e-04\n",
      "   1.6558840e-04 -4.7913039e-05 -1.4000194e-04]]\n",
      "linear.bias:\n",
      " [0.00022044]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0521037e-03 -1.0825221e-04  2.9355757e-05  1.2876739e-04\n",
      "   1.6368003e-04 -1.0231426e-05 -1.3900707e-04]]\n",
      "linear.bias:\n",
      " [0.00022116]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04887551e-03 -1.06944724e-04  2.96130838e-05  1.03060040e-04\n",
      "   1.64061988e-04 -1.84503369e-05 -1.37849085e-04]]\n",
      "linear.bias:\n",
      " [0.00022218]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451424e-03 -1.0726643e-04  3.1056043e-05  7.1410192e-05\n",
      "   1.6787584e-04 -3.6698279e-05 -1.3504448e-04]]\n",
      "linear.bias:\n",
      " [0.00022366]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421684e-03 -1.0494492e-04  3.3140717e-05  1.0362345e-04\n",
      "   1.6835163e-04 -6.0832499e-06 -1.3360284e-04]]\n",
      "linear.bias:\n",
      " [0.00022443]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04265579e-03 -1.04991210e-04  3.49159345e-05  1.15360104e-04\n",
      "   1.71147709e-04 -6.53758707e-06 -1.30818487e-04]]\n",
      "linear.bias:\n",
      " [0.00022531]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441700e-03 -1.0435797e-04  3.5059042e-05  7.8849043e-05\n",
      "   1.7260821e-04 -4.6438017e-05 -1.2937191e-04]]\n",
      "linear.bias:\n",
      " [0.00022684]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456927e-03 -1.0088744e-04  3.4954523e-05  9.9406388e-05\n",
      "   1.6722659e-04 -2.6474685e-05 -1.3124850e-04]]\n",
      "linear.bias:\n",
      " [0.00022729]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496087e-03 -9.9383491e-05  3.3633314e-05  1.3140893e-04\n",
      "   1.6177089e-04  1.2640547e-05 -1.3382948e-04]]\n",
      "linear.bias:\n",
      " [0.00022714]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498343e-03 -9.6660267e-05  3.1396059e-05  8.2338585e-05\n",
      "   1.5860981e-04 -4.2538915e-05 -1.3750141e-04]]\n",
      "linear.bias:\n",
      " [0.00022589]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494229e-03 -9.6414435e-05  2.9529909e-05  7.0776528e-05\n",
      "   1.5601591e-04 -5.4607943e-05 -1.4120847e-04]]\n",
      "linear.bias:\n",
      " [0.00022438]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475742e-03 -9.7287040e-05  2.6819587e-05  1.2677077e-04\n",
      "   1.5731483e-04 -1.0229363e-05 -1.4263949e-04]]\n",
      "linear.bias:\n",
      " [0.00022247]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04757037e-03 -1.01990001e-04  2.49583736e-05  1.38946518e-04\n",
      "   1.63163000e-04 -1.46482125e-05 -1.41944896e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485823e-03 -1.0948344e-04  2.3828257e-05  9.5048657e-05\n",
      "   1.7191500e-04 -6.3020358e-05 -1.3984847e-04]]\n",
      "linear.bias:\n",
      " [0.0002194]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501317e-03 -1.1188037e-04  2.3186074e-05  9.3198949e-05\n",
      "   1.7796487e-04 -3.9853898e-05 -1.3903457e-04]]\n",
      "linear.bias:\n",
      " [0.0002191]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502500e-03 -1.1022836e-04  2.2988490e-05  1.2371877e-04\n",
      "   1.8008184e-04  2.4220957e-05 -1.3972686e-04]]\n",
      "linear.bias:\n",
      " [0.00021902]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487044e-03 -1.0716290e-04  2.3230372e-05  7.3925825e-05\n",
      "   1.8004603e-04 -2.8906561e-05 -1.4340926e-04]]\n",
      "linear.bias:\n",
      " [0.00022007]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473700e-03 -1.0115392e-04  2.4200752e-05  8.8474451e-05\n",
      "   1.7722529e-04 -3.2345048e-05 -1.4721205e-04]]\n",
      "linear.bias:\n",
      " [0.00022102]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448361e-03 -9.8045864e-05  2.6175021e-05  1.3551781e-04\n",
      "   1.7501862e-04 -6.1615956e-06 -1.5017109e-04]]\n",
      "linear.bias:\n",
      " [0.00022169]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431071e-03 -9.7077733e-05  2.8094888e-05  1.1588343e-04\n",
      "   1.7386579e-04 -3.2283471e-05 -1.5238825e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435114e-03 -9.9468132e-05  3.0002902e-05  8.4412211e-05\n",
      "   1.7618359e-04 -5.2273605e-05 -1.5258515e-04]]\n",
      "linear.bias:\n",
      " [0.00022462]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429330e-03 -9.9223231e-05  3.1929747e-05  1.0092815e-04\n",
      "   1.7676872e-04 -2.3630339e-05 -1.5323293e-04]]\n",
      "linear.bias:\n",
      " [0.00022587]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440203e-03 -1.0375921e-04  3.3909080e-05  1.2212247e-04\n",
      "   1.7973862e-04  5.2902669e-06 -1.5228827e-04]]\n",
      "linear.bias:\n",
      " [0.00022642]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466303e-03 -1.0631261e-04  3.5368997e-05  9.6583768e-05\n",
      "   1.8313450e-04 -2.1124717e-05 -1.5023757e-04]]\n",
      "linear.bias:\n",
      " [0.0002258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494352e-03 -1.1147248e-04  3.5780431e-05  8.2206359e-05\n",
      "   1.8547241e-04 -3.1902218e-05 -1.4817600e-04]]\n",
      "linear.bias:\n",
      " [0.00022523]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05071720e-03 -1.11605426e-04  3.58065809e-05  1.17510135e-04\n",
      "   1.82913864e-04  9.06518471e-06 -1.47926068e-04]]\n",
      "linear.bias:\n",
      " [0.00022491]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05097215e-03 -1.03935505e-04  3.48327667e-05  9.24634514e-05\n",
      "   1.78057322e-04 -2.27257224e-05 -1.48678722e-04]]\n",
      "linear.bias:\n",
      " [0.00022425]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497704e-03 -9.9543446e-05  3.4420576e-05  8.9999208e-05\n",
      "   1.7387357e-04 -3.8339829e-05 -1.4884672e-04]]\n",
      "linear.bias:\n",
      " [0.00022328]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480674e-03 -9.7671305e-05  3.4229033e-05  1.1880703e-04\n",
      "   1.7033660e-04 -1.7187516e-05 -1.4889985e-04]]\n",
      "linear.bias:\n",
      " [0.0002224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482405e-03 -9.8345779e-05  3.4042943e-05  1.1247087e-04\n",
      "   1.7088994e-04 -2.9890311e-05 -1.4682868e-04]]\n",
      "linear.bias:\n",
      " [0.00022104]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04966771e-03 -1.02294915e-04  3.34116412e-05  1.00609774e-04\n",
      "   1.73276741e-04 -2.35797579e-05 -1.44221878e-04]]\n",
      "linear.bias:\n",
      " [0.00022039]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489228e-03 -1.0707499e-04  3.2673663e-05  9.7067954e-05\n",
      "   1.7466354e-04 -3.5475314e-06 -1.4176212e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478708e-03 -1.1229583e-04  3.3025801e-05  8.5236461e-05\n",
      "   1.7795582e-04 -1.1323358e-05 -1.3774270e-04]]\n",
      "linear.bias:\n",
      " [0.00022016]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04494928e-03 -1.14207745e-04  3.29022259e-05  1.03404083e-04\n",
      "   1.78906077e-04 -7.36828088e-06 -1.34691581e-04]]\n",
      "linear.bias:\n",
      " [0.00022091]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425526e-03 -1.1094788e-04  3.1838110e-05  1.0225054e-04\n",
      "   1.8027733e-04 -2.4317664e-05 -1.3168241e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408260e-03 -1.0323028e-04  3.0574807e-05  1.1646525e-04\n",
      "   1.7894074e-04 -1.0563924e-05 -1.3075682e-04]]\n",
      "linear.bias:\n",
      " [0.00022437]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0393640e-03 -9.6272903e-05  2.8608316e-05  8.0224971e-05\n",
      "   1.7649015e-04 -3.7129008e-05 -1.3065148e-04]]\n",
      "linear.bias:\n",
      " [0.0002266]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0388043e-03 -9.0623158e-05  2.7031747e-05  1.0268331e-04\n",
      "   1.6856320e-04 -9.5421219e-06 -1.3337719e-04]]\n",
      "linear.bias:\n",
      " [0.00022766]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402413e-03 -9.0293295e-05  2.6011317e-05  1.1845783e-04\n",
      "   1.6398494e-04 -4.8436268e-06 -1.3400728e-04]]\n",
      "linear.bias:\n",
      " [0.00022785]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421530e-03 -9.4825504e-05  2.6078422e-05  9.4198229e-05\n",
      "   1.6416688e-04 -4.6377361e-05 -1.3326666e-04]]\n",
      "linear.bias:\n",
      " [0.00022822]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04412541e-03 -1.01077974e-04  2.61860278e-05  9.93250651e-05\n",
      "   1.64949190e-04 -4.86791505e-05 -1.32935325e-04]]\n",
      "linear.bias:\n",
      " [0.00022798]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469058e-03 -1.0453638e-04  2.6637021e-05  1.3501869e-04\n",
      "   1.6490427e-04 -8.0050158e-06 -1.3381522e-04]]\n",
      "linear.bias:\n",
      " [0.000227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466507e-03 -1.0770166e-04  2.6245252e-05  9.5915457e-05\n",
      "   1.6599485e-04 -2.9011251e-05 -1.3605789e-04]]\n",
      "linear.bias:\n",
      " [0.00022593]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459399e-03 -1.1286262e-04  2.6503038e-05  7.8457728e-05\n",
      "   1.6852740e-04 -1.8913273e-05 -1.3756612e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461959e-03 -1.1474924e-04  2.7696606e-05  1.0511004e-04\n",
      "   1.6963032e-04  1.9275318e-05 -1.3939566e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448213e-03 -1.1322363e-04  2.8698199e-05  8.2678474e-05\n",
      "   1.6920948e-04 -2.9356310e-05 -1.4185079e-04]]\n",
      "linear.bias:\n",
      " [0.00022124]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04406604e-03 -1.06832718e-04  3.01237651e-05  1.04350016e-04\n",
      "   1.68667495e-04 -3.56794590e-05 -1.44152596e-04]]\n",
      "linear.bias:\n",
      " [0.00021979]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425617e-03 -1.0192454e-04  3.1739270e-05  1.2419760e-04\n",
      "   1.6964284e-04 -1.6470129e-05 -1.4603091e-04]]\n",
      "linear.bias:\n",
      " [0.00021906]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04277185e-03 -1.00598656e-04  3.28827991e-05  1.02626524e-04\n",
      "   1.73944049e-04 -3.63338295e-05 -1.46247388e-04]]\n",
      "linear.bias:\n",
      " [0.00021841]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04243867e-03 -1.00317055e-04  3.32477466e-05  9.43225459e-05\n",
      "   1.77116963e-04 -2.98165032e-05 -1.46462524e-04]]\n",
      "linear.bias:\n",
      " [0.00021877]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04206789e-03 -1.00129204e-04  3.29149116e-05  1.09573106e-04\n",
      "   1.78692455e-04  1.01719561e-05 -1.47268933e-04]]\n",
      "linear.bias:\n",
      " [0.00021929]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04301143e-03 -1.00736412e-04  3.29699687e-05  9.20180755e-05\n",
      "   1.79326074e-04 -1.51205495e-05 -1.47522689e-04]]\n",
      "linear.bias:\n",
      " [0.00021956]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04596082e-03 -1.05378786e-04  3.23677596e-05  8.95186022e-05\n",
      "   1.80219475e-04 -3.84393024e-05 -1.47089420e-04]]\n",
      "linear.bias:\n",
      " [0.00021981]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04849611e-03 -1.05258885e-04  3.17479462e-05  1.21905716e-04\n",
      "   1.77515438e-04 -1.46854709e-05 -1.48387859e-04]]\n",
      "linear.bias:\n",
      " [0.00022041]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512879e-03 -1.0602025e-04  3.0748830e-05  1.1673369e-04\n",
      "   1.7621022e-04 -2.3080003e-05 -1.4853464e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512675e-03 -1.0638803e-04  3.0040863e-05  9.0503177e-05\n",
      "   1.7620245e-04 -4.1218271e-05 -1.4793822e-04]]\n",
      "linear.bias:\n",
      " [0.00022221]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499689e-03 -1.0339970e-04  2.9947825e-05  9.8636629e-05\n",
      "   1.7445898e-04 -1.3690953e-05 -1.4820654e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484799e-03 -1.0228722e-04  3.1257379e-05  1.0037866e-04\n",
      "   1.7610707e-04 -1.3766454e-05 -1.4601821e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04672171e-03 -1.02357146e-04  3.35024488e-05  9.51891197e-05\n",
      "   1.79629205e-04 -3.93295995e-05 -1.42111414e-04]]\n",
      "linear.bias:\n",
      " [0.00022328]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449438e-03 -9.8171455e-05  3.5273832e-05  1.2330814e-04\n",
      "   1.7976682e-04 -1.7795122e-05 -1.4013131e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434247e-03 -9.4712683e-05  3.5981386e-05  1.0101075e-04\n",
      "   1.7895245e-04 -3.5976569e-05 -1.3891717e-04]]\n",
      "linear.bias:\n",
      " [0.00022379]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445652e-03 -9.3397372e-05  3.5223198e-05  1.0050613e-04\n",
      "   1.7700913e-04 -2.1136462e-05 -1.3829450e-04]]\n",
      "linear.bias:\n",
      " [0.00022418]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473207e-03 -9.6445765e-05  3.3583074e-05  1.1013619e-04\n",
      "   1.7510389e-04 -3.3918059e-06 -1.3736443e-04]]\n",
      "linear.bias:\n",
      " [0.00022474]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509220e-03 -1.0142341e-04  3.2380551e-05  8.9120724e-05\n",
      "   1.7570968e-04 -2.4238791e-05 -1.3491120e-04]]\n",
      "linear.bias:\n",
      " [0.00022485]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528575e-03 -1.0594988e-04  3.0765437e-05  9.7125223e-05\n",
      "   1.7441505e-04 -1.4843054e-05 -1.3349336e-04]]\n",
      "linear.bias:\n",
      " [0.00022514]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0537037e-03 -1.1030829e-04  2.9660230e-05  1.1837164e-04\n",
      "   1.7227061e-04 -4.1977028e-06 -1.3220683e-04]]\n",
      "linear.bias:\n",
      " [0.00022521]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476366e-03 -1.0835129e-04  2.8177245e-05  7.8129087e-05\n",
      "   1.6849115e-04 -4.7192239e-05 -1.3273793e-04]]\n",
      "linear.bias:\n",
      " [0.00022585]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421599e-03 -1.0321341e-04  2.7019294e-05  9.0928646e-05\n",
      "   1.6088544e-04 -3.2304968e-05 -1.3547869e-04]]\n",
      "linear.bias:\n",
      " [0.00022566]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0378656e-03 -1.0052621e-04  2.6358110e-05  1.3124719e-04\n",
      "   1.5512049e-04  9.0363210e-06 -1.3747747e-04]]\n",
      "linear.bias:\n",
      " [0.0002251]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03197456e-03 -9.89508262e-05  2.62326339e-05  1.06105115e-04\n",
      "   1.56872731e-04 -2.42063325e-05 -1.38105112e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0294598e-03 -1.0010787e-04  2.6307112e-05  7.3057861e-05\n",
      "   1.6291627e-04 -6.0847793e-05 -1.3645341e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0294007e-03 -1.0010668e-04  2.6592466e-05  1.2132178e-04\n",
      "   1.6381724e-04 -8.2262668e-06 -1.3726935e-04]]\n",
      "linear.bias:\n",
      " [0.00021952]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0325635e-03 -1.0373359e-04  2.7192300e-05  1.3370336e-04\n",
      "   1.6985786e-04 -6.4637152e-07 -1.3554860e-04]]\n",
      "linear.bias:\n",
      " [0.00021746]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0367153e-03 -1.0660733e-04  2.6439324e-05  7.2583978e-05\n",
      "   1.7499598e-04 -5.0002560e-05 -1.3557266e-04]]\n",
      "linear.bias:\n",
      " [0.00021753]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406947e-03 -1.0338056e-04  2.5221194e-05  8.0967882e-05\n",
      "   1.7321533e-04 -3.5213925e-05 -1.3849192e-04]]\n",
      "linear.bias:\n",
      " [0.00021836]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451556e-03 -9.7879478e-05  2.4767609e-05  1.2967983e-04\n",
      "   1.7011628e-04  2.1003074e-05 -1.4179481e-04]]\n",
      "linear.bias:\n",
      " [0.00021931]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468048e-03 -9.3699768e-05  2.5098276e-05  9.0768437e-05\n",
      "   1.6632552e-04 -4.1697236e-05 -1.4723465e-04]]\n",
      "linear.bias:\n",
      " [0.00022112]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464570e-03 -9.2491871e-05  2.6051726e-05  8.4912186e-05\n",
      "   1.6326192e-04 -6.3973413e-05 -1.5179413e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435490e-03 -9.4407660e-05  2.7160357e-05  1.2661333e-04\n",
      "   1.6245362e-04 -2.5898757e-05 -1.5417022e-04]]\n",
      "linear.bias:\n",
      " [0.00022386]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423502e-03 -1.0058910e-04  2.7654181e-05  1.2297009e-04\n",
      "   1.6740801e-04 -2.3401779e-05 -1.5360297e-04]]\n",
      "linear.bias:\n",
      " [0.00022503]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04417664e-03 -1.08679924e-04  2.81085140e-05  9.12364267e-05\n",
      "   1.75798414e-04 -5.12877159e-05 -1.50749751e-04]]\n",
      "linear.bias:\n",
      " [0.0002257]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457233e-03 -1.1218216e-04  2.8596642e-05  9.6690725e-05\n",
      "   1.8148097e-04 -3.1215091e-05 -1.4923504e-04]]\n",
      "linear.bias:\n",
      " [0.0002263]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466138e-03 -1.1138750e-04  2.9149909e-05  1.2640406e-04\n",
      "   1.8401192e-04  2.7458318e-05 -1.4911548e-04]]\n",
      "linear.bias:\n",
      " [0.00022664]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457851e-03 -1.0623109e-04  2.9757884e-05  8.0344180e-05\n",
      "   1.8532522e-04 -2.9104249e-05 -1.5057526e-04]]\n",
      "linear.bias:\n",
      " [0.00022657]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459305e-03 -9.8454941e-05  3.0773306e-05  9.1839756e-05\n",
      "   1.8313168e-04 -3.9158724e-05 -1.5296623e-04]]\n",
      "linear.bias:\n",
      " [0.00022631]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442210e-03 -9.4019051e-05  3.2346048e-05  1.3139244e-04\n",
      "   1.8150774e-04 -1.4067198e-05 -1.5477891e-04]]\n",
      "linear.bias:\n",
      " [0.00022588]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435797e-03 -9.1764436e-05  3.3372915e-05  1.2124177e-04\n",
      "   1.8138248e-04 -2.5690311e-05 -1.5489975e-04]]\n",
      "linear.bias:\n",
      " [0.00022491]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451584e-03 -9.2239803e-05  3.4276894e-05  8.4771542e-05\n",
      "   1.8293614e-04 -6.0524926e-05 -1.5368375e-04]]\n",
      "linear.bias:\n",
      " [0.00022423]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04628340e-03 -9.06050846e-05  3.49221700e-05  1.10012974e-04\n",
      "   1.78872084e-04 -1.94854329e-05 -1.54120178e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487041e-03 -9.2955415e-05  3.5736295e-05  1.1892148e-04\n",
      "   1.7845395e-04  3.8899270e-06 -1.5237866e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0515151e-03 -9.8985962e-05  3.7004786e-05  9.0922964e-05\n",
      "   1.8089211e-04 -1.7837936e-05 -1.4931359e-04]]\n",
      "linear.bias:\n",
      " [0.00022031]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0535689e-03 -1.0683447e-04  3.8223490e-05  8.2349419e-05\n",
      "   1.8333689e-04 -3.4944369e-05 -1.4602629e-04]]\n",
      "linear.bias:\n",
      " [0.00021951]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0532178e-03 -1.0635662e-04  3.8489863e-05  1.2225460e-04\n",
      "   1.8119665e-04 -2.1636079e-06 -1.4467884e-04]]\n",
      "linear.bias:\n",
      " [0.00021956]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505943e-03 -1.0051088e-04  3.7207443e-05  9.5634008e-05\n",
      "   1.7634888e-04 -3.0202638e-05 -1.4556582e-04]]\n",
      "linear.bias:\n",
      " [0.00022039]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476940e-03 -9.6137475e-05  3.5299538e-05  9.1231836e-05\n",
      "   1.7104516e-04 -2.5357604e-05 -1.4657177e-04]]\n",
      "linear.bias:\n",
      " [0.00022153]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452629e-03 -9.4989249e-05  3.3891756e-05  1.1279042e-04\n",
      "   1.6774057e-04  2.7780825e-06 -1.4658224e-04]]\n",
      "linear.bias:\n",
      " [0.00022235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450812e-03 -9.7415912e-05  3.2894059e-05  9.9994482e-05\n",
      "   1.6990122e-04 -1.1699822e-05 -1.4399267e-04]]\n",
      "linear.bias:\n",
      " [0.00022251]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04700786e-03 -1.03058235e-04  3.27009184e-05  7.41886761e-05\n",
      "   1.75613299e-04 -5.40510082e-05 -1.39078140e-04]]\n",
      "linear.bias:\n",
      " [0.00022227]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04860531e-03 -1.03999075e-04  3.24324283e-05  1.07949701e-04\n",
      "   1.75588866e-04 -3.17989980e-05 -1.37059484e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488840e-03 -1.0510607e-04  3.2061300e-05  1.4643228e-04\n",
      "   1.7462582e-04  1.5986672e-05 -1.3572144e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447415e-03 -9.9777077e-05  2.9903476e-05  7.5705400e-05\n",
      "   1.7290289e-04 -5.0308186e-05 -1.3839077e-04]]\n",
      "linear.bias:\n",
      " [0.00022215]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403468e-03 -9.2599497e-05  2.8504728e-05  6.6631794e-05\n",
      "   1.6760094e-04 -5.7136098e-05 -1.4247827e-04]]\n",
      "linear.bias:\n",
      " [0.00022214]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0379321e-03 -8.5636748e-05  2.7062304e-05  1.4896168e-04\n",
      "   1.5798288e-04  2.4385281e-05 -1.4860180e-04]]\n",
      "linear.bias:\n",
      " [0.00022115]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0306087e-03 -7.9271384e-05  2.5904181e-05  1.1976063e-04\n",
      "   1.5676131e-04 -1.4074252e-05 -1.5450598e-04]]\n",
      "linear.bias:\n",
      " [0.00022045]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0270292e-03 -7.7763623e-05  2.5068768e-05  6.4654378e-05\n",
      "   1.6176855e-04 -8.4128551e-05 -1.5672491e-04]]\n",
      "linear.bias:\n",
      " [0.00021963]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0278808e-03 -8.9318419e-05  2.3789278e-05  1.3014514e-04\n",
      "   1.6792699e-04 -3.6922956e-05 -1.5733660e-04]]\n",
      "linear.bias:\n",
      " [0.00021791]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03139738e-03 -1.04237966e-04  2.21740411e-05  1.62544980e-04\n",
      "   1.80082599e-04  1.38383912e-05 -1.55080299e-04]]\n",
      "linear.bias:\n",
      " [0.00021734]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03240437e-03 -1.15568575e-04  2.02425599e-05  9.08601651e-05\n",
      "   1.92494146e-04 -3.67246284e-05 -1.54307345e-04]]\n",
      "linear.bias:\n",
      " [0.00021741]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03382184e-03 -1.20742705e-04  1.85005956e-05  6.63427491e-05\n",
      "   1.99580187e-04 -3.76264470e-05 -1.55292175e-04]]\n",
      "linear.bias:\n",
      " [0.00021827]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0370075e-03 -1.1837615e-04  1.7536087e-05  1.2726086e-04\n",
      "   1.9622552e-04  2.0602856e-05 -1.5775443e-04]]\n",
      "linear.bias:\n",
      " [0.00021884]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03786448e-03 -1.08706074e-04  1.65696583e-05  1.17144162e-04\n",
      "   1.89655897e-04 -2.05201868e-05 -1.61285439e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03825249e-03 -1.00642486e-04  1.71125248e-05  8.67998097e-05\n",
      "   1.86544828e-04 -8.40646826e-05 -1.62535041e-04]]\n",
      "linear.bias:\n",
      " [0.00022149]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0389921e-03 -8.9799039e-05  1.9178999e-05  1.3447841e-04\n",
      "   1.7840283e-04 -3.8161183e-05 -1.6544620e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419447e-03 -8.4036044e-05  2.0625586e-05  1.5082357e-04\n",
      "   1.7553338e-04  4.5046218e-06 -1.6560608e-04]]\n",
      "linear.bias:\n",
      " [0.0002231]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437493e-03 -8.4362509e-05  2.3065160e-05  8.2880630e-05\n",
      "   1.7684753e-04 -3.5233275e-05 -1.6383208e-04]]\n",
      "linear.bias:\n",
      " [0.00022378]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448815e-03 -8.9364927e-05  2.6543541e-05  6.8954614e-05\n",
      "   1.7994706e-04 -4.5765490e-05 -1.5938591e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454853e-03 -9.5921409e-05  2.9850293e-05  1.3200482e-04\n",
      "   1.8410975e-04 -1.6883720e-05 -1.5231065e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04623404e-03 -1.02293154e-04  3.22782580e-05  1.32072368e-04\n",
      "   1.87170328e-04 -3.15901088e-05 -1.45859944e-04]]\n",
      "linear.bias:\n",
      " [0.00022273]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475073e-03 -1.0818917e-04  3.3135260e-05  7.9451755e-05\n",
      "   1.8858191e-04 -7.6231445e-05 -1.4040539e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486344e-03 -1.0906630e-04  3.3597582e-05  1.1770950e-04\n",
      "   1.7914968e-04 -1.4484460e-05 -1.4021786e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04976143e-03 -1.10236004e-04  3.35956393e-05  1.16254014e-04\n",
      "   1.71314881e-04  1.05339132e-05 -1.39065538e-04]]\n",
      "linear.bias:\n",
      " [0.00022213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474176e-03 -1.0508452e-04  3.2414118e-05  5.4433483e-05\n",
      "   1.6270677e-04 -4.7263387e-05 -1.4001648e-04]]\n",
      "linear.bias:\n",
      " [0.00022192]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456583e-03 -9.6672607e-05  3.0778952e-05  8.8123154e-05\n",
      "   1.5214452e-04 -3.5908666e-05 -1.4220404e-04]]\n",
      "linear.bias:\n",
      " [0.00022074]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454881e-03 -9.1274451e-05  2.9285911e-05  1.4526845e-04\n",
      "   1.4541553e-04  3.5209523e-06 -1.4301864e-04]]\n",
      "linear.bias:\n",
      " [0.00021929]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408896e-03 -8.8665824e-05  2.8023573e-05  1.0201348e-04\n",
      "   1.5010254e-04 -4.9579492e-05 -1.4303588e-04]]\n",
      "linear.bias:\n",
      " [0.00021798]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0368220e-03 -8.8906534e-05  2.7111184e-05  7.0662434e-05\n",
      "   1.5997612e-04 -6.6847089e-05 -1.4126900e-04]]\n",
      "linear.bias:\n",
      " [0.0002168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352295e-03 -8.8953406e-05  2.6411826e-05  1.1512676e-04\n",
      "   1.6614095e-04  7.3186020e-06 -1.4171806e-04]]\n",
      "linear.bias:\n",
      " [0.00021574]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0356238e-03 -9.4151161e-05  2.6837786e-05  1.2091405e-04\n",
      "   1.7628864e-04  3.0511461e-05 -1.4058276e-04]]\n",
      "linear.bias:\n",
      " [0.00021518]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346073e-03 -9.8586577e-05  2.7349977e-05  4.4201835e-05\n",
      "   1.8424533e-04 -6.2482854e-05 -1.4263277e-04]]\n",
      "linear.bias:\n",
      " [0.00021606]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03703188e-03 -1.01408586e-04  2.85125825e-05  1.01109516e-04\n",
      "   1.82721909e-04 -3.52075513e-05 -1.47286089e-04]]\n",
      "linear.bias:\n",
      " [0.00021487]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392214e-03 -1.0399490e-04  2.9123332e-05  1.6855376e-04\n",
      "   1.7973805e-04  1.7742983e-05 -1.5208623e-04]]\n",
      "linear.bias:\n",
      " [0.0002148]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0353404e-03 -1.0037943e-04  2.8173470e-05  1.0991306e-04\n",
      "   1.7690117e-04 -5.7557030e-05 -1.5978952e-04]]\n",
      "linear.bias:\n",
      " [0.00021532]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0312749e-03 -9.8730176e-05  2.7055310e-05  6.1151666e-05\n",
      "   1.7637777e-04 -8.9807894e-05 -1.6623837e-04]]\n",
      "linear.bias:\n",
      " [0.00021719]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0310358e-03 -9.3485338e-05  2.6979429e-05  1.3860845e-04\n",
      "   1.7038461e-04  3.4669501e-06 -1.7215725e-04]]\n",
      "linear.bias:\n",
      " [0.00021708]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0333160e-03 -9.0020185e-05  2.7244252e-05  1.4856932e-04\n",
      "   1.7297994e-04  3.4067776e-05 -1.7400246e-04]]\n",
      "linear.bias:\n",
      " [0.00021757]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0340139e-03 -8.8029352e-05  2.8391893e-05  6.5794498e-05\n",
      "   1.8063576e-04 -7.3593590e-05 -1.7287572e-04]]\n",
      "linear.bias:\n",
      " [0.00021842]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346841e-03 -8.9310088e-05  2.9134124e-05  9.0148969e-05\n",
      "   1.8594475e-04 -8.3457984e-05 -1.6940973e-04]]\n",
      "linear.bias:\n",
      " [0.00021799]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0366716e-03 -8.9904803e-05  3.0341545e-05  1.9036417e-04\n",
      "   1.8710285e-04 -2.1561864e-06 -1.6607839e-04]]\n",
      "linear.bias:\n",
      " [0.0002168]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0329387e-03 -9.0190777e-05  3.0935877e-05  1.5188369e-04\n",
      "   1.8893836e-04 -1.9949955e-05 -1.6388010e-04]]\n",
      "linear.bias:\n",
      " [0.00021613]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0310913e-03 -9.0333662e-05  3.0802785e-05  5.2640215e-05\n",
      "   1.9154498e-04 -8.3317093e-05 -1.6125019e-04]]\n",
      "linear.bias:\n",
      " [0.00021613]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0334941e-03 -9.0711503e-05  3.1349053e-05  1.0465752e-04\n",
      "   1.8549641e-04 -1.4463149e-05 -1.6034361e-04]]\n",
      "linear.bias:\n",
      " [0.00021373]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0375335e-03 -9.4247735e-05  3.2119453e-05  1.4537682e-04\n",
      "   1.8110719e-04  2.4681940e-05 -1.5724391e-04]]\n",
      "linear.bias:\n",
      " [0.00021197]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397111e-03 -9.5344534e-05  3.1972264e-05  8.9076493e-05\n",
      "   1.7677226e-04 -6.3069601e-05 -1.5640585e-04]]\n",
      "linear.bias:\n",
      " [0.00021158]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410583e-03 -9.6768090e-05  3.1499865e-05  8.1638565e-05\n",
      "   1.7285673e-04 -8.5297565e-05 -1.5511201e-04]]\n",
      "linear.bias:\n",
      " [0.00021263]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427004e-03 -9.2829003e-05  3.0538282e-05  1.4522314e-04\n",
      "   1.6674210e-04 -9.1836046e-06 -1.5469590e-04]]\n",
      "linear.bias:\n",
      " [0.00021418]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04628911e-03 -9.24459382e-05  2.97520401e-05  1.43843165e-04\n",
      "   1.66618411e-04  1.51261265e-05 -1.52142529e-04]]\n",
      "linear.bias:\n",
      " [0.00021637]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460910e-03 -9.2582362e-05  2.9059251e-05  5.2403993e-05\n",
      "   1.7070572e-04 -5.8567653e-05 -1.5028597e-04]]\n",
      "linear.bias:\n",
      " [0.00021874]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481102e-03 -9.1541639e-05  2.9080862e-05  7.8550263e-05\n",
      "   1.7036959e-04 -3.6313213e-05 -1.4881685e-04]]\n",
      "linear.bias:\n",
      " [0.00021908]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492249e-03 -9.2260816e-05  2.9286928e-05  1.4885946e-04\n",
      "   1.7056624e-04  1.6377715e-05 -1.4654806e-04]]\n",
      "linear.bias:\n",
      " [0.00021938]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445389e-03 -9.2600858e-05  2.9540292e-05  1.1183189e-04\n",
      "   1.7435134e-04 -4.1627391e-05 -1.4580817e-04]]\n",
      "linear.bias:\n",
      " [0.00021985]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419083e-03 -9.8002500e-05  2.9709156e-05  7.3911651e-05\n",
      "   1.8050583e-04 -7.8601137e-05 -1.4404710e-04]]\n",
      "linear.bias:\n",
      " [0.00022068]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04134157e-03 -1.01694539e-04  2.99382355e-05  1.29520020e-04\n",
      "   1.76960733e-04 -1.01748155e-05 -1.46257866e-04]]\n",
      "linear.bias:\n",
      " [0.00022042]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04105286e-03 -1.05161744e-04  2.96355611e-05  1.22736397e-04\n",
      "   1.72728673e-04  1.04321243e-05 -1.48343810e-04]]\n",
      "linear.bias:\n",
      " [0.00022079]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420212e-03 -1.0823080e-04  2.9807601e-05  6.0515704e-05\n",
      "   1.7015351e-04 -3.3406839e-05 -1.4942598e-04]]\n",
      "linear.bias:\n",
      " [0.00022112]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04253192e-03 -1.06354055e-04  3.05389040e-05  7.80299451e-05\n",
      "   1.68352984e-04 -2.71061290e-05 -1.48526698e-04]]\n",
      "linear.bias:\n",
      " [0.00022041]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434310e-03 -1.0651127e-04  3.1678162e-05  1.3086027e-04\n",
      "   1.6763675e-04  7.3965384e-06 -1.4705214e-04]]\n",
      "linear.bias:\n",
      " [0.00021978]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440515e-03 -1.0197252e-04  3.2209053e-05  1.0883380e-04\n",
      "   1.6861499e-04 -2.9338957e-05 -1.4513625e-04]]\n",
      "linear.bias:\n",
      " [0.00021941]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462047e-03 -1.0299925e-04  3.2627606e-05  8.4429455e-05\n",
      "   1.7225184e-04 -4.7180441e-05 -1.4231229e-04]]\n",
      "linear.bias:\n",
      " [0.00021948]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471257e-03 -9.9585239e-05  3.2957163e-05  9.9526107e-05\n",
      "   1.7349531e-04 -1.7275288e-05 -1.4059982e-04]]\n",
      "linear.bias:\n",
      " [0.00021974]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04858133e-03 -1.01460486e-04  3.27586094e-05  1.16167139e-04\n",
      "   1.74610585e-04  1.10266792e-05 -1.38378455e-04]]\n",
      "linear.bias:\n",
      " [0.00022038]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485140e-03 -1.0199358e-04  3.2031570e-05  7.1059098e-05\n",
      "   1.7363044e-04 -4.5361245e-05 -1.3935434e-04]]\n",
      "linear.bias:\n",
      " [0.00022136]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482331e-03 -9.8215409e-05  3.1473766e-05  8.5280677e-05\n",
      "   1.6829529e-04 -4.3855180e-05 -1.4202658e-04]]\n",
      "linear.bias:\n",
      " [0.00022204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473152e-03 -9.7043529e-05  3.1163883e-05  1.2840217e-04\n",
      "   1.6373783e-04 -8.3806663e-06 -1.4432770e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478618e-03 -1.0062432e-04  3.0795050e-05  1.2187360e-04\n",
      "   1.6442077e-04 -1.4060133e-05 -1.4444925e-04]]\n",
      "linear.bias:\n",
      " [0.0002234]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501175e-03 -1.0766678e-04  3.0479201e-05  7.8790370e-05\n",
      "   1.6991430e-04 -5.4435357e-05 -1.4247105e-04]]\n",
      "linear.bias:\n",
      " [0.00022388]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508297e-03 -1.0982317e-04  2.9920826e-05  8.6814165e-05\n",
      "   1.7172903e-04 -4.0179628e-05 -1.4179143e-04]]\n",
      "linear.bias:\n",
      " [0.0002239]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0513687e-03 -1.0781418e-04  2.9500567e-05  1.2693123e-04\n",
      "   1.7140762e-04  1.6133923e-05 -1.4228084e-04]]\n",
      "linear.bias:\n",
      " [0.00022393]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04729517e-03 -1.01936275e-04  2.87595030e-05  9.12314572e-05\n",
      "   1.71227744e-04 -2.61419627e-05 -1.44328151e-04]]\n",
      "linear.bias:\n",
      " [0.00022374]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430447e-03 -9.9124249e-05  2.8987788e-05  8.4801344e-05\n",
      "   1.7232515e-04 -3.8626953e-05 -1.4542825e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0385500e-03 -9.8830307e-05  2.9386438e-05  1.0935546e-04\n",
      "   1.7356084e-04 -1.5748290e-05 -1.4631334e-04]]\n",
      "linear.bias:\n",
      " [0.00022228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0367964e-03 -1.0186807e-04  3.0476540e-05  1.1356991e-04\n",
      "   1.7861938e-04 -2.2926339e-05 -1.4471904e-04]]\n",
      "linear.bias:\n",
      " [0.00022145]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03702710e-03 -1.05960076e-04  3.10669930e-05  9.51565744e-05\n",
      "   1.84314442e-04 -4.56634953e-05 -1.42224439e-04]]\n",
      "linear.bias:\n",
      " [0.00022131]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03740662e-03 -1.05279425e-04  3.16284895e-05  1.13898524e-04\n",
      "   1.84945326e-04 -2.10582984e-05 -1.42143457e-04]]\n",
      "linear.bias:\n",
      " [0.00022139]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408165e-03 -1.0558333e-04  3.1247273e-05  1.1066063e-04\n",
      "   1.8653528e-04 -1.3955312e-05 -1.4126068e-04]]\n",
      "linear.bias:\n",
      " [0.00022228]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04575371e-03 -1.05660845e-04  3.02869157e-05  7.73192151e-05\n",
      "   1.86950303e-04 -3.28125825e-05 -1.40044882e-04]]\n",
      "linear.bias:\n",
      " [0.00022327]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500572e-03 -1.0037479e-04  2.9150573e-05  9.8361525e-05\n",
      "   1.7946251e-04  7.4414129e-07 -1.4198296e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05622481e-03 -9.85908555e-05  2.84852213e-05  1.07598804e-04\n",
      "   1.74968038e-04  3.47859691e-06 -1.41516881e-04]]\n",
      "linear.bias:\n",
      " [0.00022437]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0596778e-03 -9.7264383e-05  2.8991850e-05  9.2721442e-05\n",
      "   1.7273576e-04 -2.8040593e-05 -1.3932431e-04]]\n",
      "linear.bias:\n",
      " [0.00022394]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0604860e-03 -9.8663455e-05  3.0169442e-05  1.0591358e-04\n",
      "   1.7090030e-04 -3.1877284e-05 -1.3710120e-04]]\n",
      "linear.bias:\n",
      " [0.00022315]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0592411e-03 -1.0107348e-04  3.1023588e-05  1.2177702e-04\n",
      "   1.6903426e-04 -1.2295206e-05 -1.3525193e-04]]\n",
      "linear.bias:\n",
      " [0.00022345]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05231570e-03 -1.01562415e-04  3.17012345e-05  8.72964156e-05\n",
      "   1.67217571e-04 -3.20391337e-05 -1.34585513e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04540808e-03 -1.04254614e-04  3.25057044e-05  8.67174022e-05\n",
      "   1.65830745e-04 -1.55699436e-05 -1.33879279e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03949197e-03 -1.08636676e-04  3.36654884e-05  1.12404647e-04\n",
      "   1.65536374e-04  1.77337115e-05 -1.32854271e-04]]\n",
      "linear.bias:\n",
      " [0.00022413]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03433023e-03 -1.09984205e-04  3.33163589e-05  7.43524724e-05\n",
      "   1.65204416e-04 -3.48014655e-05 -1.34462534e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0307918e-03 -1.0864883e-04  3.3874388e-05  8.9933470e-05\n",
      "   1.6341847e-04 -4.3035296e-05 -1.3677057e-04]]\n",
      "linear.bias:\n",
      " [0.00022333]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03215233e-03 -1.04743747e-04  3.32355557e-05  1.27337757e-04\n",
      "   1.61137534e-04 -1.30267745e-05 -1.39366908e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03552744e-03 -1.04360261e-04  3.21049083e-05  1.17954645e-04\n",
      "   1.64390905e-04 -2.07011690e-05 -1.39438343e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417859e-03 -1.0712531e-04  3.1205684e-05  8.5972890e-05\n",
      "   1.7138082e-04 -4.7734513e-05 -1.3752698e-04]]\n",
      "linear.bias:\n",
      " [0.00022005]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472924e-03 -1.0500832e-04  3.0312862e-05  9.0986898e-05\n",
      "   1.7391649e-04 -2.8751536e-05 -1.3761528e-04]]\n",
      "linear.bias:\n",
      " [0.00021964]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05123024e-03 -1.03247134e-04  2.89103737e-05  1.23426609e-04\n",
      "   1.74433429e-04  2.39718720e-05 -1.38429590e-04]]\n",
      "linear.bias:\n",
      " [0.00021968]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0515014e-03 -9.9779936e-05  2.7432827e-05  7.9477482e-05\n",
      "   1.7368127e-04 -3.4059685e-05 -1.4216351e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0503914e-03 -9.8539684e-05  2.6506113e-05  8.5120591e-05\n",
      "   1.7283614e-04 -5.2800700e-05 -1.4498016e-04]]\n",
      "linear.bias:\n",
      " [0.00022092]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486771e-03 -9.4515068e-05  2.6251397e-05  1.3083442e-04\n",
      "   1.7024319e-04 -2.5244331e-05 -1.4821571e-04]]\n",
      "linear.bias:\n",
      " [0.00022165]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479415e-03 -9.5540257e-05  2.5971432e-05  1.3058458e-04\n",
      "   1.7227048e-04 -3.4439152e-05 -1.4925301e-04]]\n",
      "linear.bias:\n",
      " [0.00022251]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04838435e-03 -9.99033946e-05  2.54165952e-05  1.02235615e-04\n",
      "   1.77759299e-04 -4.56606722e-05 -1.48261039e-04]]\n",
      "linear.bias:\n",
      " [0.0002235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04778353e-03 -1.06471736e-04  2.55014456e-05  9.94079455e-05\n",
      "   1.83465076e-04 -2.53079761e-05 -1.46930659e-04]]\n",
      "linear.bias:\n",
      " [0.00022397]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04546547e-03 -1.12785565e-04  2.54545175e-05  1.11735149e-04\n",
      "   1.87340353e-04  1.25659008e-05 -1.46095757e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436157e-03 -1.1766093e-04  2.5905143e-05  7.5734046e-05\n",
      "   1.8878473e-04 -1.8716082e-05 -1.4555077e-04]]\n",
      "linear.bias:\n",
      " [0.00022438]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04225019e-03 -1.16341296e-04  2.63806396e-05  9.81287740e-05\n",
      "   1.83338809e-04 -1.17296204e-05 -1.47506042e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03910442e-03 -1.12261165e-04  2.71757963e-05  1.15190735e-04\n",
      "   1.79334864e-04 -2.58588407e-05 -1.47479848e-04]]\n",
      "linear.bias:\n",
      " [0.00022454]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386567e-03 -1.0866558e-04  2.7305983e-05  1.0955229e-04\n",
      "   1.7703527e-04 -4.7177029e-05 -1.4644759e-04]]\n",
      "linear.bias:\n",
      " [0.00022491]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03843177e-03 -1.01345395e-04  2.79720116e-05  1.20330282e-04\n",
      "   1.74440298e-04 -2.84026919e-05 -1.46486709e-04]]\n",
      "linear.bias:\n",
      " [0.00022484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405764e-03 -9.7985016e-05  2.8955325e-05  1.1249280e-04\n",
      "   1.7530720e-04 -2.1494681e-05 -1.4470005e-04]]\n",
      "linear.bias:\n",
      " [0.00022477]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445906e-03 -9.7922828e-05  2.9888984e-05  8.4498824e-05\n",
      "   1.7800526e-04 -3.3611377e-05 -1.4170034e-04]]\n",
      "linear.bias:\n",
      " [0.00022512]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476736e-03 -1.0050683e-04  3.1057796e-05  9.8898257e-05\n",
      "   1.7905366e-04 -6.7183428e-06 -1.3941768e-04]]\n",
      "linear.bias:\n",
      " [0.00022523]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0519431e-03 -1.0776439e-04  3.2153657e-05  1.1356705e-04\n",
      "   1.8055920e-04  8.0034170e-08 -1.3590870e-04]]\n",
      "linear.bias:\n",
      " [0.00022471]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0542617e-03 -1.1032273e-04  3.1775642e-05  6.6501409e-05\n",
      "   1.7724703e-04 -5.9954178e-05 -1.3579226e-04]]\n",
      "linear.bias:\n",
      " [0.00022486]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05527055e-03 -1.07529508e-04  3.08247327e-05  1.14434304e-04\n",
      "   1.62957396e-04 -2.14729735e-05 -1.40123375e-04]]\n",
      "linear.bias:\n",
      " [0.00022396]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0513290e-03 -1.0382518e-04  3.0420573e-05  1.3542890e-04\n",
      "   1.5458063e-04 -5.0748386e-06 -1.4213202e-04]]\n",
      "linear.bias:\n",
      " [0.00022336]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453803e-03 -9.7569922e-05  2.9316336e-05  8.5629596e-05\n",
      "   1.5525710e-04 -4.4978475e-05 -1.4224986e-04]]\n",
      "linear.bias:\n",
      " [0.00022261]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0395866e-03 -9.4654511e-05  2.8370587e-05  7.1600283e-05\n",
      "   1.5757458e-04 -4.1501655e-05 -1.4190731e-04]]\n",
      "linear.bias:\n",
      " [0.00022235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0340471e-03 -9.5093055e-05  2.7240292e-05  1.1666205e-04\n",
      "   1.6118656e-04 -1.5894111e-06 -1.4042288e-04]]\n",
      "linear.bias:\n",
      " [0.00022191]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0325137e-03 -9.9384350e-05  2.6590882e-05  1.2693829e-04\n",
      "   1.7005476e-04 -4.1434150e-06 -1.3644841e-04]]\n",
      "linear.bias:\n",
      " [0.00022131]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0317583e-03 -1.0676433e-04  2.5826514e-05  8.0057493e-05\n",
      "   1.7819979e-04 -5.3246684e-05 -1.3341034e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0321781e-03 -1.0865160e-04  2.5082340e-05  9.4466741e-05\n",
      "   1.7714578e-04 -3.6715093e-05 -1.3455577e-04]]\n",
      "linear.bias:\n",
      " [0.00022143]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0336888e-03 -1.0581343e-04  2.4329462e-05  1.3729684e-04\n",
      "   1.7199572e-04  2.0917727e-05 -1.3772266e-04]]\n",
      "linear.bias:\n",
      " [0.00022129]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03458646e-03 -1.00860285e-04  2.32947423e-05  9.13263793e-05\n",
      "   1.66265396e-04 -3.69891677e-05 -1.43438985e-04]]\n",
      "linear.bias:\n",
      " [0.00022179]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0360826e-03 -9.8492506e-05  2.2774784e-05  7.7992459e-05\n",
      "   1.6227459e-04 -6.2169012e-05 -1.4807997e-04]]\n",
      "linear.bias:\n",
      " [0.00022182]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0379257e-03 -9.2597133e-05  2.3096602e-05  1.2270923e-04\n",
      "   1.6084102e-04 -1.7080936e-05 -1.5076321e-04]]\n",
      "linear.bias:\n",
      " [0.00022163]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04296207e-03 -9.10825547e-05  2.36992710e-05  1.35705981e-04\n",
      "   1.65117017e-04 -1.31811885e-05 -1.50232037e-04]]\n",
      "linear.bias:\n",
      " [0.00022106]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495889e-03 -9.3191833e-05  2.4455299e-05  9.4103496e-05\n",
      "   1.7403609e-04 -5.2130556e-05 -1.4756688e-04]]\n",
      "linear.bias:\n",
      " [0.00022074]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0535830e-03 -9.7841570e-05  2.5841959e-05  8.5128551e-05\n",
      "   1.8244381e-04 -5.4125172e-05 -1.4480221e-04]]\n",
      "linear.bias:\n",
      " [0.00022025]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0561114e-03 -9.7247190e-05  2.6824828e-05  1.2633554e-04\n",
      "   1.8406882e-04 -4.6220957e-06 -1.4446989e-04]]\n",
      "linear.bias:\n",
      " [0.00021981]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0567521e-03 -9.6374672e-05  2.7059334e-05  1.0715483e-04\n",
      "   1.8348903e-04 -4.4280578e-06 -1.4566803e-04]]\n",
      "linear.bias:\n",
      " [0.00022004]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0556141e-03 -9.6423188e-05  2.8363145e-05  6.8230147e-05\n",
      "   1.8536315e-04 -3.7342394e-05 -1.4485279e-04]]\n",
      "linear.bias:\n",
      " [0.00021983]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541440e-03 -9.3252376e-05  2.9486735e-05  9.6904769e-05\n",
      "   1.7966473e-04 -1.6471184e-05 -1.4661667e-04]]\n",
      "linear.bias:\n",
      " [0.00021985]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510433e-03 -9.3662667e-05  3.1147898e-05  1.3406939e-04\n",
      "   1.7492908e-04  2.2914119e-06 -1.4722145e-04]]\n",
      "linear.bias:\n",
      " [0.00022007]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463110e-03 -9.5255855e-05  3.1959840e-05  9.7686854e-05\n",
      "   1.6943387e-04 -3.9568498e-05 -1.4893906e-04]]\n",
      "linear.bias:\n",
      " [0.00022069]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04053458e-03 -1.00256126e-04  3.32033560e-05  8.44593305e-05\n",
      "   1.65660400e-04 -5.07191326e-05 -1.49591957e-04]]\n",
      "linear.bias:\n",
      " [0.00022104]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346699e-03 -1.0682046e-04  3.4208755e-05  1.1128235e-04\n",
      "   1.6406273e-04 -1.9387691e-05 -1.4919099e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0331296e-03 -1.1460265e-04  3.5351524e-05  1.1567671e-04\n",
      "   1.6767471e-04 -1.9821162e-05 -1.4595821e-04]]\n",
      "linear.bias:\n",
      " [0.0002226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0357309e-03 -1.1806267e-04  3.4616740e-05  9.1561924e-05\n",
      "   1.7319815e-04 -4.1379870e-05 -1.4165434e-04]]\n",
      "linear.bias:\n",
      " [0.00022338]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0384643e-03 -1.1277466e-04  3.3131222e-05  9.4951465e-05\n",
      "   1.7578054e-04 -2.0212916e-05 -1.3920765e-04]]\n",
      "linear.bias:\n",
      " [0.00022409]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416581e-03 -1.0304715e-04  3.1825723e-05  1.2230236e-04\n",
      "   1.7571109e-04  2.2367061e-05 -1.3823919e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426901e-03 -9.2633360e-05  3.0730575e-05  7.4827010e-05\n",
      "   1.7359477e-04 -4.0362549e-05 -1.4033854e-04]]\n",
      "linear.bias:\n",
      " [0.00022553]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444623e-03 -8.9024274e-05  2.9950559e-05  8.7114640e-05\n",
      "   1.6832742e-04 -5.4135544e-05 -1.4361778e-04]]\n",
      "linear.bias:\n",
      " [0.0002256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460753e-03 -9.0345340e-05  2.9311526e-05  1.3105081e-04\n",
      "   1.6376337e-04 -3.0580828e-05 -1.4662310e-04]]\n",
      "linear.bias:\n",
      " [0.00022525]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487576e-03 -9.6646756e-05  2.8013519e-05  1.3395485e-04\n",
      "   1.6578678e-04 -2.9738698e-05 -1.4654323e-04]]\n",
      "linear.bias:\n",
      " [0.00022535]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0529849e-03 -1.0657920e-04  2.6448613e-05  9.4133953e-05\n",
      "   1.7292242e-04 -6.3834013e-05 -1.4417930e-04]]\n",
      "linear.bias:\n",
      " [0.00022545]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541304e-03 -1.1142274e-04  2.5500902e-05  9.8297402e-05\n",
      "   1.7656824e-04 -3.3206179e-05 -1.4259052e-04]]\n",
      "linear.bias:\n",
      " [0.00022532]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0546175e-03 -1.1150487e-04  2.4770836e-05  1.2629395e-04\n",
      "   1.7704863e-04  3.3711662e-05 -1.4250900e-04]]\n",
      "linear.bias:\n",
      " [0.000225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497269e-03 -1.0555395e-04  2.3599379e-05  5.9961414e-05\n",
      "   1.7842725e-04 -4.2042160e-05 -1.4491550e-04]]\n",
      "linear.bias:\n",
      " [0.00022554]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457843e-03 -9.6611664e-05  2.3894019e-05  9.1005932e-05\n",
      "   1.7224604e-04 -4.8734288e-05 -1.4937134e-04]]\n",
      "linear.bias:\n",
      " [0.00022457]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402390e-03 -9.1340829e-05  2.4873201e-05  1.4745646e-04\n",
      "   1.6706080e-04 -2.1730995e-05 -1.5301473e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374193e-03 -9.0748188e-05  2.5812855e-05  1.4297510e-04\n",
      "   1.6843468e-04 -3.7378282e-05 -1.5360737e-04]]\n",
      "linear.bias:\n",
      " [0.00022271]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0379228e-03 -9.4351541e-05  2.6281738e-05  8.9740803e-05\n",
      "   1.7600253e-04 -6.6855297e-05 -1.5139424e-04]]\n",
      "linear.bias:\n",
      " [0.00022243]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383021e-03 -9.5461663e-05  2.7026908e-05  8.7216606e-05\n",
      "   1.8175427e-04 -2.7935515e-05 -1.4998826e-04]]\n",
      "linear.bias:\n",
      " [0.0002224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0384504e-03 -9.8591234e-05  2.8421013e-05  1.2065783e-04\n",
      "   1.8718412e-04  3.6900172e-05 -1.4845902e-04]]\n",
      "linear.bias:\n",
      " [0.00022236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0367287e-03 -9.9461286e-05  2.9676674e-05  7.8545170e-05\n",
      "   1.9019256e-04 -2.0938751e-05 -1.4906928e-04]]\n",
      "linear.bias:\n",
      " [0.00022255]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352888e-03 -1.0180527e-04  3.1112879e-05  9.0347654e-05\n",
      "   1.8935220e-04 -4.9086040e-05 -1.4987004e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0344266e-03 -9.9063924e-05  3.2426280e-05  1.4218898e-04\n",
      "   1.8223943e-04 -2.5237794e-05 -1.5324165e-04]]\n",
      "linear.bias:\n",
      " [0.00022224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0358865e-03 -9.4928226e-05  3.2129228e-05  1.3381538e-04\n",
      "   1.7642617e-04 -4.0882522e-05 -1.5538232e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403986e-03 -9.3372139e-05  3.0613086e-05  9.7920965e-05\n",
      "   1.7605962e-04 -5.2430423e-05 -1.5461467e-04]]\n",
      "linear.bias:\n",
      " [0.00022143]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447409e-03 -9.4229945e-05  2.9333947e-05  9.0509260e-05\n",
      "   1.7639140e-04 -3.1149677e-05 -1.5373381e-04]]\n",
      "linear.bias:\n",
      " [0.00022107]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04656070e-03 -9.85643637e-05  2.91504130e-05  1.12325157e-04\n",
      "   1.78005968e-04  1.23159225e-05 -1.51788176e-04]]\n",
      "linear.bias:\n",
      " [0.00022054]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04689051e-03 -1.06070423e-04  2.97405240e-05  9.79632387e-05\n",
      "   1.81388430e-04 -1.27739295e-05 -1.48485822e-04]]\n",
      "linear.bias:\n",
      " [0.00021921]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463643e-03 -1.1391611e-04  3.1302246e-05  8.6144217e-05\n",
      "   1.8540569e-04 -4.8654147e-05 -1.4398529e-04]]\n",
      "linear.bias:\n",
      " [0.00021844]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439384e-03 -1.1225632e-04  3.2214532e-05  1.2388692e-04\n",
      "   1.8222013e-04 -3.0829025e-05 -1.4253095e-04]]\n",
      "linear.bias:\n",
      " [0.00021859]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405738e-03 -1.0868395e-04  3.2182801e-05  1.3657717e-04\n",
      "   1.8053300e-04 -1.7257040e-05 -1.4047883e-04]]\n",
      "linear.bias:\n",
      " [0.00021936]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03871862e-03 -1.03219274e-04  3.03508878e-05  8.39139466e-05\n",
      "   1.76678892e-04 -5.04587624e-05 -1.40197677e-04]]\n",
      "linear.bias:\n",
      " [0.00022091]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0369242e-03 -9.3849470e-05  2.8566816e-05  8.1658538e-05\n",
      "   1.6723500e-04 -3.1571697e-05 -1.4242467e-04]]\n",
      "linear.bias:\n",
      " [0.00022209]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0364973e-03 -8.9584551e-05  2.7401711e-05  1.1904592e-04\n",
      "   1.5948545e-04  1.4890222e-05 -1.4382559e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0365724e-03 -9.0500325e-05  2.7672215e-05  1.0893501e-04\n",
      "   1.5915684e-04 -2.9116527e-06 -1.4322883e-04]]\n",
      "linear.bias:\n",
      " [0.00022349]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399636e-03 -9.5504329e-05  2.8236836e-05  7.6634715e-05\n",
      "   1.6451505e-04 -5.6053435e-05 -1.3937335e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441669e-03 -9.9374010e-05  2.8912091e-05  1.0191724e-04\n",
      "   1.6739186e-04 -5.1469058e-05 -1.3721854e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489559e-03 -9.8326171e-05  2.9489724e-05  1.4806828e-04\n",
      "   1.6837046e-04 -5.8145961e-06 -1.3666092e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502954e-03 -9.6941862e-05  2.8972676e-05  9.8279408e-05\n",
      "   1.6972068e-04 -3.0633000e-05 -1.3827058e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504645e-03 -9.8433287e-05  2.9113467e-05  7.6265198e-05\n",
      "   1.7172824e-04 -2.2486684e-05 -1.3926651e-04]]\n",
      "linear.bias:\n",
      " [0.00022312]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497888e-03 -1.0205848e-04  2.9829560e-05  9.5923722e-05\n",
      "   1.7324730e-04  7.4599575e-06 -1.3999092e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05206063e-03 -1.07085434e-04  3.06673755e-05  9.66017978e-05\n",
      "   1.76163536e-04 -6.15794124e-06 -1.38773379e-04]]\n",
      "linear.bias:\n",
      " [0.00022207]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0531516e-03 -1.1256799e-04  3.2431828e-05  9.6752818e-05\n",
      "   1.8014279e-04 -4.0042538e-05 -1.3592385e-04]]\n",
      "linear.bias:\n",
      " [0.000221]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05322734e-03 -1.09997614e-04  3.36661651e-05  1.30579676e-04\n",
      "   1.80200776e-04 -2.71873687e-05 -1.35105554e-04]]\n",
      "linear.bias:\n",
      " [0.00022069]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04862044e-03 -1.02462975e-04  3.39102080e-05  1.07407264e-04\n",
      "   1.78746239e-04 -4.80384479e-05 -1.35726877e-04]]\n",
      "linear.bias:\n",
      " [0.00022168]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454061e-03 -9.0401962e-05  3.3693384e-05  1.0688824e-04\n",
      "   1.7453643e-04 -2.6267820e-05 -1.3834717e-04]]\n",
      "linear.bias:\n",
      " [0.000223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437056e-03 -8.4300198e-05  3.3100841e-05  9.8871875e-05\n",
      "   1.7214840e-04 -3.9879887e-07 -1.4020641e-04]]\n",
      "linear.bias:\n",
      " [0.00022462]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451595e-03 -8.4989020e-05  3.3312870e-05  8.1476377e-05\n",
      "   1.7388251e-04 -4.5943134e-06 -1.3902977e-04]]\n",
      "linear.bias:\n",
      " [0.00022522]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499789e-03 -9.2719187e-05  3.3252218e-05  7.8319295e-05\n",
      "   1.7694919e-04 -1.8279152e-05 -1.3662144e-04]]\n",
      "linear.bias:\n",
      " [0.0002249]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05410872e-03 -1.03645834e-04  3.33558164e-05  1.15803879e-04\n",
      "   1.77897091e-04 -8.05945638e-06 -1.34931382e-04]]\n",
      "linear.bias:\n",
      " [0.00022419]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05791900e-03 -1.13831564e-04  3.24568100e-05  1.02741578e-04\n",
      "   1.77702212e-04 -3.53258656e-05 -1.34045506e-04]]\n",
      "linear.bias:\n",
      " [0.00022398]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0601854e-03 -1.1546388e-04  3.1463365e-05  1.0885838e-04\n",
      "   1.7514062e-04 -2.0541036e-05 -1.3491006e-04]]\n",
      "linear.bias:\n",
      " [0.00022422]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0579812e-03 -1.1318345e-04  3.0541356e-05  9.3913841e-05\n",
      "   1.7392436e-04 -1.4552343e-05 -1.3499528e-04]]\n",
      "linear.bias:\n",
      " [0.0002255]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0536257e-03 -1.0899024e-04  2.9669971e-05  9.6060627e-05\n",
      "   1.7242844e-04 -2.1025971e-06 -1.3487427e-04]]\n",
      "linear.bias:\n",
      " [0.00022687]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04920950e-03 -1.06187515e-04  3.00204283e-05  9.40941172e-05\n",
      "   1.73359658e-04 -1.45097038e-05 -1.32760077e-04]]\n",
      "linear.bias:\n",
      " [0.00022747]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04448409e-03 -1.05629915e-04  3.11907897e-05  1.07590378e-04\n",
      "   1.73894732e-04 -2.55332925e-05 -1.30517816e-04]]\n",
      "linear.bias:\n",
      " [0.00022757]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0390383e-03 -1.0493325e-04  3.2153781e-05  1.2330740e-04\n",
      "   1.7408651e-04 -1.8162564e-05 -1.2918550e-04]]\n",
      "linear.bias:\n",
      " [0.00022788]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0349099e-03 -1.0361532e-04  3.1828884e-05  9.1091162e-05\n",
      "   1.7302546e-04 -4.2571068e-05 -1.2878599e-04]]\n",
      "linear.bias:\n",
      " [0.00022859]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0322846e-03 -9.7961281e-05  3.1222782e-05  9.1960588e-05\n",
      "   1.6828737e-04 -1.9482539e-05 -1.3103877e-04]]\n",
      "linear.bias:\n",
      " [0.00022858]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0342440e-03 -9.6571748e-05  3.0597410e-05  1.0985942e-04\n",
      "   1.6568018e-04  1.0867116e-05 -1.3292491e-04]]\n",
      "linear.bias:\n",
      " [0.00022706]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0379853e-03 -9.7931326e-05  3.0069357e-05  8.8017849e-05\n",
      "   1.6705501e-04 -2.0216059e-05 -1.3411534e-04]]\n",
      "linear.bias:\n",
      " [0.00022549]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04457361e-03 -1.03169354e-04  2.92332370e-05  9.17524012e-05\n",
      "   1.69389328e-04 -3.24927278e-05 -1.34612827e-04]]\n",
      "linear.bias:\n",
      " [0.00022321]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05079066e-03 -1.10187793e-04  2.85680744e-05  1.20263983e-04\n",
      "   1.72165717e-04 -1.15760195e-05 -1.34867587e-04]]\n",
      "linear.bias:\n",
      " [0.00022094]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0524179e-03 -1.1239423e-04  2.7886490e-05  9.6540869e-05\n",
      "   1.7320643e-04 -3.1063402e-05 -1.3622121e-04]]\n",
      "linear.bias:\n",
      " [0.00022019]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525791e-03 -1.0709571e-04  2.7088659e-05  9.7338969e-05\n",
      "   1.7170238e-04 -9.5217365e-06 -1.3880503e-04]]\n",
      "linear.bias:\n",
      " [0.00021973]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05211057e-03 -1.03254206e-04  2.75174516e-05  9.23364496e-05\n",
      "   1.72618791e-04 -1.13967399e-05 -1.39255208e-04]]\n",
      "linear.bias:\n",
      " [0.00021931]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04982255e-03 -1.02945749e-04  2.85152910e-05  1.02082886e-04\n",
      "   1.73847351e-04 -1.19323995e-05 -1.38809410e-04]]\n",
      "linear.bias:\n",
      " [0.00021894]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471585e-03 -1.0387741e-04  3.0614137e-05  1.0319440e-04\n",
      "   1.7731164e-04 -2.9129760e-05 -1.3665819e-04]]\n",
      "linear.bias:\n",
      " [0.00021903]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04481506e-03 -1.04533858e-04  3.18335624e-05  1.14312046e-04\n",
      "   1.79263763e-04 -1.62852211e-05 -1.35518043e-04]]\n",
      "linear.bias:\n",
      " [0.0002202]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435303e-03 -1.0607138e-04  3.1870317e-05  8.0355974e-05\n",
      "   1.8019811e-04 -3.4897053e-05 -1.3525192e-04]]\n",
      "linear.bias:\n",
      " [0.00022211]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04190782e-03 -1.02058293e-04  3.16722180e-05  1.01568134e-04\n",
      "   1.73340755e-04 -9.77459422e-07 -1.38583229e-04]]\n",
      "linear.bias:\n",
      " [0.00022384]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431383e-03 -1.0113042e-04  3.1761043e-05  1.0303662e-04\n",
      "   1.6943923e-04 -4.0828245e-06 -1.3933434e-04]]\n",
      "linear.bias:\n",
      " [0.00022474]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464544e-03 -1.0355433e-04  3.2251999e-05  8.9103603e-05\n",
      "   1.6876590e-04 -3.6126890e-05 -1.3770572e-04]]\n",
      "linear.bias:\n",
      " [0.00022534]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487265e-03 -1.0813056e-04  3.2900651e-05  1.0761616e-04\n",
      "   1.6842430e-04 -3.0286748e-05 -1.3612636e-04]]\n",
      "linear.bias:\n",
      " [0.00022588]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495707e-03 -1.1205491e-04  3.3393026e-05  1.2787174e-04\n",
      "   1.6782401e-04 -7.6406868e-06 -1.3539729e-04]]\n",
      "linear.bias:\n",
      " [0.00022658]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483133e-03 -1.0944300e-04  3.1386695e-05  8.4479034e-05\n",
      "   1.6803003e-04 -3.2295458e-05 -1.3532667e-04]]\n",
      "linear.bias:\n",
      " [0.00022656]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0470807e-03 -1.0295630e-04  2.9707973e-05  8.0398830e-05\n",
      "   1.6602044e-04 -9.0585763e-06 -1.3695573e-04]]\n",
      "linear.bias:\n",
      " [0.00022632]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458452e-03 -9.9463308e-05  2.8696748e-05  9.9711295e-05\n",
      "   1.6553450e-04  1.7260998e-05 -1.3770154e-04]]\n",
      "linear.bias:\n",
      " [0.00022546]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434422e-03 -1.0015096e-04  2.8740087e-05  8.4728395e-05\n",
      "   1.6878286e-04 -3.0468680e-05 -1.3709953e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409954e-03 -1.0303947e-04  2.9328956e-05  1.0558586e-04\n",
      "   1.7251704e-04 -4.3538297e-05 -1.3610900e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03974284e-03 -1.00269455e-04  2.94147612e-05  1.44955193e-04\n",
      "   1.72927263e-04 -1.43367870e-05 -1.37315001e-04]]\n",
      "linear.bias:\n",
      " [0.00022043]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374003e-03 -9.8054988e-05  2.8311544e-05  1.0757428e-04\n",
      "   1.7197542e-04 -3.9872972e-05 -1.3978835e-04]]\n",
      "linear.bias:\n",
      " [0.00022038]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386837e-03 -9.8544115e-05  2.6276601e-05  7.6751254e-05\n",
      "   1.7254867e-04 -3.6218706e-05 -1.4205847e-04]]\n",
      "linear.bias:\n",
      " [0.00022076]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410137e-03 -9.6162250e-05  2.5335648e-05  9.8598939e-05\n",
      "   1.7157625e-04  5.4879529e-06 -1.4450742e-04]]\n",
      "linear.bias:\n",
      " [0.00022089]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454447e-03 -9.7874428e-05  2.5275594e-05  1.0414219e-04\n",
      "   1.7490258e-04  1.4336300e-05 -1.4382997e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493334e-03 -1.0324243e-04  2.6086513e-05  7.8629440e-05\n",
      "   1.7943546e-04 -4.4230073e-05 -1.4180283e-04]]\n",
      "linear.bias:\n",
      " [0.00021985]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516603e-03 -1.0266779e-04  2.6654105e-05  1.0746700e-04\n",
      "   1.7658222e-04 -4.4352062e-05 -1.4244707e-04]]\n",
      "linear.bias:\n",
      " [0.00021941]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0522475e-03 -1.0271459e-04  2.7030354e-05  1.4157730e-04\n",
      "   1.7316920e-04 -1.4360672e-05 -1.4365403e-04]]\n",
      "linear.bias:\n",
      " [0.00021989]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05158705e-03 -1.02614875e-04  2.65520175e-05  9.97085954e-05\n",
      "   1.69231498e-04 -3.91885405e-05 -1.45877013e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499285e-03 -1.0533341e-04  2.6743344e-05  8.5164909e-05\n",
      "   1.6649792e-04 -3.0648935e-05 -1.4741349e-04]]\n",
      "linear.bias:\n",
      " [0.00022235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04679749e-03 -1.10538334e-04  2.80019376e-05  1.04314182e-04\n",
      "   1.64978628e-04  5.73374564e-06 -1.48076593e-04]]\n",
      "linear.bias:\n",
      " [0.00022276]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467726e-03 -1.1548394e-04  2.9217574e-05  1.0038554e-04\n",
      "   1.6896032e-04  3.6290253e-06 -1.4523338e-04]]\n",
      "linear.bias:\n",
      " [0.00022247]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04660157e-03 -1.18218755e-04  3.12281481e-05  7.88950783e-05\n",
      "   1.77808164e-04 -3.01872751e-05 -1.39397263e-04]]\n",
      "linear.bias:\n",
      " [0.00022177]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04616873e-03 -1.12234324e-04  3.25597139e-05  1.09437715e-04\n",
      "   1.81705531e-04 -2.12993727e-05 -1.35634938e-04]]\n",
      "linear.bias:\n",
      " [0.0002218]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0460017e-03 -9.8072524e-05  3.3499186e-05  1.3743996e-04\n",
      "   1.8274160e-04 -2.2132263e-06 -1.3389827e-04]]\n",
      "linear.bias:\n",
      " [0.00022226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444939e-03 -8.2643921e-05  3.2464064e-05  8.5189924e-05\n",
      "   1.8024926e-04 -5.1611667e-05 -1.3503224e-04]]\n",
      "linear.bias:\n",
      " [0.00022399]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431332e-03 -7.4543932e-05  3.1327727e-05  8.9586196e-05\n",
      "   1.7309136e-04 -5.1710893e-05 -1.3841459e-04]]\n",
      "linear.bias:\n",
      " [0.00022446]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451984e-03 -7.5563716e-05  2.9614375e-05  1.3137433e-04\n",
      "   1.6504239e-04 -1.3593737e-05 -1.4268766e-04]]\n",
      "linear.bias:\n",
      " [0.00022356]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475199e-03 -8.2039769e-05  2.8334123e-05  1.2318161e-04\n",
      "   1.6210577e-04 -1.6933836e-05 -1.4480492e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504959e-03 -9.2540635e-05  2.7559319e-05  7.8369078e-05\n",
      "   1.6387194e-04 -5.5194425e-05 -1.4483213e-04]]\n",
      "linear.bias:\n",
      " [0.00022285]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05145155e-03 -1.04742576e-04  2.65180352e-05  7.96508029e-05\n",
      "   1.66962287e-04 -4.46992017e-05 -1.44138015e-04]]\n",
      "linear.bias:\n",
      " [0.00022277]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512089e-03 -1.1292538e-04  2.5824798e-05  1.2597753e-04\n",
      "   1.6798785e-04  1.0946307e-05 -1.4406374e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476365e-03 -1.1498478e-04  2.5088810e-05  1.0004773e-04\n",
      "   1.7085354e-04 -2.6862108e-05 -1.4399283e-04]]\n",
      "linear.bias:\n",
      " [0.00022112]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427571e-03 -1.1286397e-04  2.4695453e-05  7.9046360e-05\n",
      "   1.7571849e-04 -5.1291965e-05 -1.4288482e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0380575e-03 -1.0580282e-04  2.4524079e-05  1.1693485e-04\n",
      "   1.7462992e-04 -2.0530486e-05 -1.4353670e-04]]\n",
      "linear.bias:\n",
      " [0.00021942]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03605178e-03 -1.02610451e-04  2.44213006e-05  1.29703636e-04\n",
      "   1.75698166e-04 -1.14243685e-05 -1.42637407e-04]]\n",
      "linear.bias:\n",
      " [0.00021924]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352317e-03 -1.0185681e-04  2.4638288e-05  9.0766931e-05\n",
      "   1.7663839e-04 -4.6713096e-05 -1.4164345e-04]]\n",
      "linear.bias:\n",
      " [0.00021953]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0347927e-03 -9.7020238e-05  2.5244228e-05  9.3182229e-05\n",
      "   1.7395942e-04 -3.1881751e-05 -1.4253145e-04]]\n",
      "linear.bias:\n",
      " [0.00021978]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346888e-03 -9.5021234e-05  2.5879666e-05  1.2074020e-04\n",
      "   1.7223750e-04  1.3693963e-05 -1.4313326e-04]]\n",
      "linear.bias:\n",
      " [0.00021978]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0339633e-03 -9.4992472e-05  2.7701173e-05  8.8885165e-05\n",
      "   1.7121196e-04 -2.7007438e-05 -1.4405294e-04]]\n",
      "linear.bias:\n",
      " [0.00022023]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0370133e-03 -9.9186873e-05  2.8938110e-05  8.5619897e-05\n",
      "   1.7162261e-04 -3.9228518e-05 -1.4417482e-04]]\n",
      "linear.bias:\n",
      " [0.00021997]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0398017e-03 -1.0512571e-04  3.0231786e-05  1.1764860e-04\n",
      "   1.7243376e-04 -1.5955136e-05 -1.4389504e-04]]\n",
      "linear.bias:\n",
      " [0.00021996]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04421948e-03 -1.11595364e-04  3.09132010e-05  1.16314193e-04\n",
      "   1.74576009e-04 -2.25121312e-05 -1.42268793e-04]]\n",
      "linear.bias:\n",
      " [0.00022017]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463952e-03 -1.1410218e-04  3.1665197e-05  9.5105323e-05\n",
      "   1.7806677e-04 -4.2140920e-05 -1.3967209e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473290e-03 -1.0865189e-04  3.1775486e-05  1.0837532e-04\n",
      "   1.7811576e-04 -1.6066260e-05 -1.3896567e-04]]\n",
      "linear.bias:\n",
      " [0.00022307]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04716653e-03 -1.03224134e-04  3.22911437e-05  1.00678575e-04\n",
      "   1.79313211e-04 -6.26160363e-06 -1.37341485e-04]]\n",
      "linear.bias:\n",
      " [0.0002254]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492923e-03 -9.9710203e-05  3.2625176e-05  8.0321101e-05\n",
      "   1.8206301e-04 -2.3941249e-05 -1.3393210e-04]]\n",
      "linear.bias:\n",
      " [0.00022728]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508100e-03 -9.2419614e-05  3.2871663e-05  1.1870162e-04\n",
      "   1.7675215e-04 -1.3568442e-06 -1.3450973e-04]]\n",
      "linear.bias:\n",
      " [0.00022809]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506823e-03 -8.7568027e-05  3.2824617e-05  9.8930235e-05\n",
      "   1.7098576e-04 -2.6643847e-05 -1.3609126e-04]]\n",
      "linear.bias:\n",
      " [0.00022903]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0522963e-03 -9.1207257e-05  3.2446129e-05  9.7984186e-05\n",
      "   1.6671160e-04 -3.3517917e-05 -1.3661681e-04]]\n",
      "linear.bias:\n",
      " [0.000229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0526598e-03 -9.7400902e-05  3.2661927e-05  1.2077029e-04\n",
      "   1.6381640e-04 -7.5053431e-06 -1.3668679e-04]]\n",
      "linear.bias:\n",
      " [0.0002283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05210091e-03 -1.06826919e-04  3.25792716e-05  1.01021404e-04\n",
      "   1.66703292e-04 -2.13143303e-05 -1.34919435e-04]]\n",
      "linear.bias:\n",
      " [0.00022723]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502306e-03 -1.1542665e-04  3.2411950e-05  9.1105714e-05\n",
      "   1.6896252e-04 -1.6647451e-05 -1.3372062e-04]]\n",
      "linear.bias:\n",
      " [0.00022627]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04857993e-03 -1.15105824e-04  3.19545616e-05  1.10234570e-04\n",
      "   1.68656974e-04  1.53106503e-05 -1.33972106e-04]]\n",
      "linear.bias:\n",
      " [0.00022518]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437284e-03 -1.0711806e-04  3.0319101e-05  6.8210909e-05\n",
      "   1.6759186e-04 -3.7682134e-05 -1.3660130e-04]]\n",
      "linear.bias:\n",
      " [0.00022375]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0390427e-03 -9.6200994e-05  2.9408280e-05  9.9661964e-05\n",
      "   1.6380132e-04 -3.7903868e-05 -1.3995319e-04]]\n",
      "linear.bias:\n",
      " [0.00022158]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386335e-03 -9.0605630e-05  2.7912565e-05  1.4477364e-04\n",
      "   1.6216534e-04 -1.1117820e-05 -1.4247755e-04]]\n",
      "linear.bias:\n",
      " [0.00021895]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0401848e-03 -8.9202578e-05  2.6332105e-05  1.1976293e-04\n",
      "   1.6422500e-04 -3.8612630e-05 -1.4448314e-04]]\n",
      "linear.bias:\n",
      " [0.0002177]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431545e-03 -9.4331124e-05  2.4743505e-05  9.1623093e-05\n",
      "   1.7010327e-04 -4.5402317e-05 -1.4471053e-04]]\n",
      "linear.bias:\n",
      " [0.00021725]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04509410e-03 -1.01411606e-04  2.35255884e-05  9.76542360e-05\n",
      "   1.75668785e-04 -1.65310339e-05 -1.44799167e-04]]\n",
      "linear.bias:\n",
      " [0.00021683]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04547024e-03 -1.09793604e-04  2.37284657e-05  1.07621840e-04\n",
      "   1.83386233e-04  1.58651164e-06 -1.42645949e-04]]\n",
      "linear.bias:\n",
      " [0.00021691]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442853e-03 -1.1542743e-04  2.4965560e-05  8.1389036e-05\n",
      "   1.8913335e-04 -2.4227573e-05 -1.4064593e-04]]\n",
      "linear.bias:\n",
      " [0.00021787]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04380026e-03 -1.14059156e-04  2.63375241e-05  1.08518791e-04\n",
      "   1.87338068e-04 -1.28383645e-05 -1.41522192e-04]]\n",
      "linear.bias:\n",
      " [0.00021895]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04168057e-03 -1.10707479e-04  2.77953222e-05  1.14324335e-04\n",
      "   1.83303229e-04 -1.92564657e-05 -1.42355886e-04]]\n",
      "linear.bias:\n",
      " [0.00022105]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03829009e-03 -1.06577216e-04  2.95713417e-05  9.81023040e-05\n",
      "   1.80257994e-04 -3.98027005e-05 -1.42192745e-04]]\n",
      "linear.bias:\n",
      " [0.00022361]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0360419e-03 -9.7817494e-05  3.0756117e-05  1.1050947e-04\n",
      "   1.7440096e-04 -1.6909067e-05 -1.4375801e-04]]\n",
      "linear.bias:\n",
      " [0.00022591]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0359895e-03 -9.3116600e-05  3.1893720e-05  9.8691176e-05\n",
      "   1.7154176e-04 -2.0587406e-05 -1.4345109e-04]]\n",
      "linear.bias:\n",
      " [0.00022821]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0378313e-03 -9.4309551e-05  3.3146360e-05  9.7279524e-05\n",
      "   1.7187024e-04 -1.9579951e-05 -1.4152717e-04]]\n",
      "linear.bias:\n",
      " [0.00022938]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04338606e-03 -1.00053978e-04  3.41252526e-05  1.05199855e-04\n",
      "   1.74631481e-04 -1.81735650e-05 -1.38470408e-04]]\n",
      "linear.bias:\n",
      " [0.00022954]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05034909e-03 -1.10351029e-04  3.47016794e-05  1.09635395e-04\n",
      "   1.77821988e-04 -2.54356455e-05 -1.34738948e-04]]\n",
      "linear.bias:\n",
      " [0.00022901]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0555028e-03 -1.1219791e-04  3.5487421e-05  1.1235804e-04\n",
      "   1.7792862e-04 -1.4664621e-05 -1.3337942e-04]]\n",
      "linear.bias:\n",
      " [0.00022764]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05513877e-03 -1.08286506e-04  3.52830211e-05  7.44723366e-05\n",
      "   1.79083800e-04 -3.49012116e-05 -1.31995999e-04]]\n",
      "linear.bias:\n",
      " [0.00022641]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0536294e-03 -9.9760560e-05  3.4611556e-05  1.0364232e-04\n",
      "   1.7027580e-04  4.2170941e-06 -1.3476353e-04]]\n",
      "linear.bias:\n",
      " [0.00022507]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05344411e-03 -9.50110843e-05  3.43291795e-05  1.04356586e-04\n",
      "   1.65019082e-04  2.56452677e-06 -1.35043476e-04]]\n",
      "linear.bias:\n",
      " [0.0002232]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525017e-03 -9.5085219e-05  3.4132314e-05  7.3917414e-05\n",
      "   1.6479321e-04 -4.1775580e-05 -1.3347513e-04]]\n",
      "linear.bias:\n",
      " [0.00022106]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497200e-03 -9.7523553e-05  3.4008171e-05  9.1616639e-05\n",
      "   1.6387280e-04 -4.0000679e-05 -1.3241032e-04]]\n",
      "linear.bias:\n",
      " [0.00021891]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462087e-03 -1.0047451e-04  3.3624292e-05  1.3759022e-04\n",
      "   1.6249121e-04 -1.2243108e-06 -1.3167744e-04]]\n",
      "linear.bias:\n",
      " [0.0002172]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410881e-03 -1.0049530e-04  3.1017255e-05  9.7340366e-05\n",
      "   1.6177655e-04 -3.2347016e-05 -1.3377228e-04]]\n",
      "linear.bias:\n",
      " [0.000217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03694887e-03 -1.02433085e-04  2.87184703e-05  8.04837910e-05\n",
      "   1.61917109e-04 -2.78841926e-05 -1.35905080e-04]]\n",
      "linear.bias:\n",
      " [0.00021706]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03380030e-03 -1.06169464e-04  2.73898713e-05  1.05818079e-04\n",
      "   1.62486307e-04  6.13538396e-06 -1.37264506e-04]]\n",
      "linear.bias:\n",
      " [0.00021733]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03451498e-03 -1.14256385e-04  2.66986535e-05  9.65572981e-05\n",
      "   1.69500578e-04 -4.62004573e-06 -1.36053815e-04]]\n",
      "linear.bias:\n",
      " [0.00021757]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352837e-03 -1.1928831e-04  2.6457206e-05  8.1256614e-05\n",
      "   1.7854015e-04 -3.8856000e-05 -1.3293891e-04]]\n",
      "linear.bias:\n",
      " [0.00021802]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03571941e-03 -1.14808994e-04  2.58683867e-05  1.17931821e-04\n",
      "   1.79605646e-04 -2.01192506e-05 -1.33449634e-04]]\n",
      "linear.bias:\n",
      " [0.0002191]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413593e-03 -1.0407742e-04  2.3455215e-05  1.1325392e-04\n",
      "   1.7691485e-04 -2.7952990e-05 -1.3668626e-04]]\n",
      "linear.bias:\n",
      " [0.00022165]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455576e-03 -9.4437630e-05  2.1493568e-05  1.0415805e-04\n",
      "   1.7430919e-04 -2.4611050e-05 -1.4012228e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477811e-03 -8.9568355e-05  2.0525624e-05  1.0238668e-04\n",
      "   1.7424108e-04 -1.0591655e-05 -1.4189875e-04]]\n",
      "linear.bias:\n",
      " [0.00022664]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487394e-03 -8.9245346e-05  2.1106707e-05  9.8041477e-05\n",
      "   1.7752688e-04 -1.5570124e-05 -1.4129189e-04]]\n",
      "linear.bias:\n",
      " [0.00022799]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0485759e-03 -9.2701594e-05  2.2844977e-05  1.0466721e-04\n",
      "   1.8205964e-04 -2.7502292e-05 -1.3912268e-04]]\n",
      "linear.bias:\n",
      " [0.00022852]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467985e-03 -9.8014112e-05  2.4700756e-05  1.3115710e-04\n",
      "   1.8537082e-04 -1.6210395e-05 -1.3739287e-04]]\n",
      "linear.bias:\n",
      " [0.00022855]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438365e-03 -1.0202720e-04  2.5714497e-05  9.1767230e-05\n",
      "   1.8584391e-04 -5.3876691e-05 -1.3744886e-04]]\n",
      "linear.bias:\n",
      " [0.00022903]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411167e-03 -1.0043092e-04  2.6663565e-05  1.0055410e-04\n",
      "   1.7906055e-04 -3.2658416e-05 -1.4087278e-04]]\n",
      "linear.bias:\n",
      " [0.00022856]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374482e-03 -1.0130551e-04  2.7774769e-05  1.3079999e-04\n",
      "   1.7239651e-04  1.7191494e-05 -1.4405933e-04]]\n",
      "linear.bias:\n",
      " [0.0002279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0331683e-03 -9.9403624e-05  2.9254745e-05  8.7965585e-05\n",
      "   1.6703972e-04 -3.5452525e-05 -1.4726649e-04]]\n",
      "linear.bias:\n",
      " [0.00022641]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0341841e-03 -1.0148734e-04  2.9800820e-05  7.4298761e-05\n",
      "   1.6450608e-04 -5.8859401e-05 -1.4902641e-04]]\n",
      "linear.bias:\n",
      " [0.00022416]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0357688e-03 -9.8454868e-05  3.0545176e-05  1.3206908e-04\n",
      "   1.6329315e-04 -7.1536924e-06 -1.4899524e-04]]\n",
      "linear.bias:\n",
      " [0.00022145]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399327e-03 -9.9378332e-05  3.1806485e-05  1.3227251e-04\n",
      "   1.6830357e-04 -9.1429793e-06 -1.4622838e-04]]\n",
      "linear.bias:\n",
      " [0.00021901]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455295e-03 -1.0441520e-04  3.2501703e-05  7.8908495e-05\n",
      "   1.7650795e-04 -5.2598989e-05 -1.4211558e-04]]\n",
      "linear.bias:\n",
      " [0.00021704]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05068716e-03 -1.02870654e-04  3.27726739e-05  8.90926894e-05\n",
      "   1.76702088e-04 -3.65310952e-05 -1.40953489e-04]]\n",
      "linear.bias:\n",
      " [0.00021594]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0542851e-03 -1.0156415e-04  3.2556269e-05  1.2914487e-04\n",
      "   1.7433843e-04  1.4859837e-05 -1.4090896e-04]]\n",
      "linear.bias:\n",
      " [0.00021564]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "Epoch [4000/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0536938e-03 -9.6484866e-05  3.1053998e-05  8.2485145e-05\n",
      "   1.7046741e-04 -3.6594352e-05 -1.4419085e-04]]\n",
      "linear.bias:\n",
      " [0.00021605]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0514639e-03 -9.3892158e-05  2.9976945e-05  7.8417899e-05\n",
      "   1.6658835e-04 -4.4840883e-05 -1.4691171e-04]]\n",
      "linear.bias:\n",
      " [0.00021688]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482024e-03 -9.3576855e-05  2.8860131e-05  1.2012112e-04\n",
      "   1.6309309e-04 -1.3755016e-05 -1.4863792e-04]]\n",
      "linear.bias:\n",
      " [0.00021785]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472548e-03 -9.7597032e-05  2.7872838e-05  1.1888139e-04\n",
      "   1.6544640e-04 -2.2161807e-05 -1.4783755e-04]]\n",
      "linear.bias:\n",
      " [0.00021849]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480187e-03 -1.0670133e-04  2.7228563e-05  9.6769385e-05\n",
      "   1.7231573e-04 -4.5682144e-05 -1.4481715e-04]]\n",
      "linear.bias:\n",
      " [0.00021976]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471790e-03 -1.1094137e-04  2.7298238e-05  1.0896373e-04\n",
      "   1.7643055e-04 -2.3228959e-05 -1.4305847e-04]]\n",
      "linear.bias:\n",
      " [0.00022067]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04374287e-03 -1.11487614e-04  2.73157893e-05  1.04887993e-04\n",
      "   1.81993586e-04 -7.64779543e-06 -1.40453863e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03943923e-03 -1.10732304e-04  2.81111606e-05  8.91736272e-05\n",
      "   1.88043268e-04 -1.84629498e-05 -1.36360322e-04]]\n",
      "linear.bias:\n",
      " [0.00022504]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371149e-03 -1.0351265e-04  2.9162820e-05  1.1011670e-04\n",
      "   1.8730834e-04 -2.8232971e-06 -1.3540761e-04]]\n",
      "linear.bias:\n",
      " [0.00022656]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0367074e-03 -9.3727620e-05  2.8637560e-05  8.7556349e-05\n",
      "   1.8311998e-04 -4.3798402e-05 -1.3628521e-04]]\n",
      "linear.bias:\n",
      " [0.00022817]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0375874e-03 -8.5512438e-05  2.8301689e-05  1.2530285e-04\n",
      "   1.7176398e-04 -2.6242606e-05 -1.4073169e-04]]\n",
      "linear.bias:\n",
      " [0.00022801]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396723e-03 -8.1550315e-05  2.8339422e-05  1.2868627e-04\n",
      "   1.6480339e-04 -3.5906483e-05 -1.4278085e-04]]\n",
      "linear.bias:\n",
      " [0.00022764]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417949e-03 -8.6204447e-05  2.7712897e-05  1.1112110e-04\n",
      "   1.6381143e-04 -3.4627235e-05 -1.4274677e-04]]\n",
      "linear.bias:\n",
      " [0.00022799]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454830e-03 -9.6380529e-05  2.7123584e-05  9.2494389e-05\n",
      "   1.6601321e-04 -1.7240667e-05 -1.4133722e-04]]\n",
      "linear.bias:\n",
      " [0.00022854]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476536e-03 -1.0902676e-04  2.7699778e-05  8.8314526e-05\n",
      "   1.7087316e-04  5.7612033e-06 -1.3855542e-04]]\n",
      "linear.bias:\n",
      " [0.00022835]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494442e-03 -1.2111221e-04  2.9749363e-05  8.2168473e-05\n",
      "   1.7835535e-04 -4.5984243e-06 -1.3368569e-04]]\n",
      "linear.bias:\n",
      " [0.00022703]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502171e-03 -1.2212642e-04  3.1483651e-05  1.1056785e-04\n",
      "   1.8006458e-04 -9.5721280e-06 -1.3138875e-04]]\n",
      "linear.bias:\n",
      " [0.00022584]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476055e-03 -1.0622881e-04  3.1929012e-05  9.3014489e-05\n",
      "   1.7599120e-04 -5.0818409e-05 -1.3289688e-04]]\n",
      "linear.bias:\n",
      " [0.00022454]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453605e-03 -8.7228720e-05  3.2120603e-05  1.1386891e-04\n",
      "   1.6784646e-04 -3.9105926e-05 -1.3713114e-04]]\n",
      "linear.bias:\n",
      " [0.0002229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451586e-03 -7.5951728e-05  3.2225216e-05  1.2785326e-04\n",
      "   1.6365630e-04 -1.2750788e-05 -1.3968998e-04]]\n",
      "linear.bias:\n",
      " [0.0002219]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450856e-03 -7.2459537e-05  3.2206219e-05  8.8768516e-05\n",
      "   1.6407932e-04 -3.0450470e-05 -1.4154216e-04]]\n",
      "linear.bias:\n",
      " [0.00022191]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461702e-03 -7.7808552e-05  3.1931333e-05  7.8456957e-05\n",
      "   1.6519213e-04 -1.8863109e-05 -1.4224264e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502995e-03 -9.0333808e-05  3.1042175e-05  1.0719239e-04\n",
      "   1.6696000e-04  7.4355685e-06 -1.4164965e-04]]\n",
      "linear.bias:\n",
      " [0.00022036]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05318124e-03 -1.09011744e-04  3.18064995e-05  9.72215203e-05\n",
      "   1.74135886e-04 -2.25609783e-05 -1.38975418e-04]]\n",
      "linear.bias:\n",
      " [0.00021915]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05298753e-03 -1.23191494e-04  3.20245563e-05  1.01371894e-04\n",
      "   1.79648108e-04 -2.98759405e-05 -1.36952716e-04]]\n",
      "linear.bias:\n",
      " [0.00021851]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05250522e-03 -1.27221894e-04  3.15598336e-05  1.20327764e-04\n",
      "   1.81907366e-04 -7.38246308e-06 -1.37153984e-04]]\n",
      "linear.bias:\n",
      " [0.00021863]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475317e-03 -1.1594790e-04  3.0463350e-05  8.0502112e-05\n",
      "   1.7829631e-04 -3.7245609e-05 -1.4137037e-04]]\n",
      "linear.bias:\n",
      " [0.00021966]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411922e-03 -9.6155432e-05  2.8581881e-05  9.8373057e-05\n",
      "   1.6933934e-04 -1.5873131e-05 -1.4701165e-04]]\n",
      "linear.bias:\n",
      " [0.00022197]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0376734e-03 -8.2505358e-05  2.7480834e-05  1.1222581e-04\n",
      "   1.6515385e-04 -9.5783198e-06 -1.4934616e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03811629e-03 -7.47524173e-05  2.68382573e-05  1.00632846e-04\n",
      "   1.67527163e-04 -4.23052625e-05 -1.47842860e-04]]\n",
      "linear.bias:\n",
      " [0.00022479]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411058e-03 -7.7065022e-05  2.5921179e-05  9.9881479e-05\n",
      "   1.7288273e-04 -4.8106915e-05 -1.4474624e-04]]\n",
      "linear.bias:\n",
      " [0.00022521]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465729e-03 -8.6623753e-05  2.4800858e-05  1.2155042e-04\n",
      "   1.7844069e-04 -2.4292387e-05 -1.4139609e-04]]\n",
      "linear.bias:\n",
      " [0.00022466]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05206028e-03 -1.00411555e-04  2.35445132e-05  1.21427409e-04\n",
      "   1.84586184e-04 -1.55156431e-05 -1.37774870e-04]]\n",
      "linear.bias:\n",
      " [0.00022416]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0535761e-03 -1.1134216e-04  2.2614915e-05  7.0793249e-05\n",
      "   1.8812546e-04 -4.6933441e-05 -1.3587277e-04]]\n",
      "linear.bias:\n",
      " [0.00022487]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05368416e-03 -1.16626274e-04  2.17966281e-05  9.98383839e-05\n",
      "   1.78475515e-04 -4.05024912e-06 -1.38922769e-04]]\n",
      "linear.bias:\n",
      " [0.00022458]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05033570e-03 -1.17067066e-04  2.15315777e-05  1.09240085e-04\n",
      "   1.71160180e-04  7.64157539e-06 -1.39943935e-04]]\n",
      "linear.bias:\n",
      " [0.00022409]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433327e-03 -1.1262042e-04  2.2537111e-05  7.7929413e-05\n",
      "   1.6481937e-04 -3.9165119e-05 -1.4049438e-04]]\n",
      "linear.bias:\n",
      " [0.00022365]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0389296e-03 -1.0446179e-04  2.5262509e-05  9.6964293e-05\n",
      "   1.5836189e-04 -4.2583997e-05 -1.4104355e-04]]\n",
      "linear.bias:\n",
      " [0.00022302]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0358130e-03 -9.9431170e-05  2.7896491e-05  1.3449890e-04\n",
      "   1.5430352e-04 -1.5214038e-05 -1.4119956e-04]]\n",
      "linear.bias:\n",
      " [0.00022199]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0362059e-03 -9.7007352e-05  2.9978723e-05  1.1533849e-04\n",
      "   1.5683235e-04 -3.1411208e-05 -1.3856604e-04]]\n",
      "linear.bias:\n",
      " [0.00022084]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0398848e-03 -9.8179189e-05  3.1678475e-05  8.5997526e-05\n",
      "   1.6413140e-04 -3.8998423e-05 -1.3375592e-04]]\n",
      "linear.bias:\n",
      " [0.00022026]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424420e-03 -1.0190977e-04  3.3472646e-05  9.2849063e-05\n",
      "   1.7088346e-04 -9.0008925e-06 -1.2985049e-04]]\n",
      "linear.bias:\n",
      " [0.0002195]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04798423e-03 -1.09798537e-04  3.44262589e-05  1.08374974e-04\n",
      "   1.77077352e-04  1.18435164e-05 -1.25707869e-04]]\n",
      "linear.bias:\n",
      " [0.00021882]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0526720e-03 -1.1223483e-04  3.3720709e-05  6.2604973e-05\n",
      "   1.7792977e-04 -5.2932726e-05 -1.2638097e-04]]\n",
      "linear.bias:\n",
      " [0.00021914]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0568028e-03 -1.0406061e-04  3.2284777e-05  1.2780220e-04\n",
      "   1.6578300e-04 -7.6326978e-06 -1.3282021e-04]]\n",
      "linear.bias:\n",
      " [0.00021873]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05629698e-03 -9.57870798e-05  2.91945616e-05  1.18641474e-04\n",
      "   1.55766029e-04 -1.71457596e-05 -1.40321950e-04]]\n",
      "linear.bias:\n",
      " [0.00021999]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0511419e-03 -9.1430033e-05  2.7249534e-05  8.1728132e-05\n",
      "   1.5238111e-04 -4.9205082e-05 -1.4530905e-04]]\n",
      "linear.bias:\n",
      " [0.00022159]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435448e-03 -8.9991401e-05  2.6088437e-05  8.5300489e-05\n",
      "   1.5386644e-04 -3.1895088e-05 -1.4758125e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371169e-03 -9.2575312e-05  2.5535381e-05  1.1724874e-04\n",
      "   1.6043923e-04  7.3783704e-06 -1.4622210e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03193626e-03 -1.01015663e-04  2.61313580e-05  1.05744286e-04\n",
      "   1.72597967e-04 -9.41764847e-06 -1.42297824e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0297702e-03 -1.1274458e-04  2.7511314e-05  8.0895785e-05\n",
      "   1.8804577e-04 -5.3890173e-05 -1.3567654e-04]]\n",
      "linear.bias:\n",
      " [0.00022312]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0287142e-03 -1.1919728e-04  2.8712859e-05  1.3062939e-04\n",
      "   1.8939149e-04 -2.4934723e-05 -1.3516081e-04]]\n",
      "linear.bias:\n",
      " [0.00022208]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0327417e-03 -1.1477884e-04  2.7811169e-05  1.2860990e-04\n",
      "   1.8552037e-04 -2.4730307e-05 -1.3830871e-04]]\n",
      "linear.bias:\n",
      " [0.0002216]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03934400e-03 -1.02060294e-04  2.54932420e-05  7.44320569e-05\n",
      "   1.77532595e-04 -5.58224201e-05 -1.43966259e-04]]\n",
      "linear.bias:\n",
      " [0.00022164]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458112e-03 -8.6906854e-05  2.4153929e-05  9.2677496e-05\n",
      "   1.6388101e-04 -1.5281410e-05 -1.5111742e-04]]\n",
      "linear.bias:\n",
      " [0.00022145]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528625e-03 -7.9734724e-05  2.3367427e-05  1.0826563e-04\n",
      "   1.5540082e-04  9.7829652e-06 -1.5524635e-04]]\n",
      "linear.bias:\n",
      " [0.0002208]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06065010e-03 -7.91629136e-05  2.33350638e-05  1.01481186e-04\n",
      "   1.55726608e-04 -1.54011941e-05 -1.53963090e-04]]\n",
      "linear.bias:\n",
      " [0.00021928]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0658861e-03 -8.3389030e-05  2.4850511e-05  8.7713626e-05\n",
      "   1.6387975e-04 -5.9232530e-05 -1.4822898e-04]]\n",
      "linear.bias:\n",
      " [0.00021792]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0671105e-03 -9.0592723e-05  2.6754995e-05  1.0858234e-04\n",
      "   1.7257172e-04 -5.9394908e-05 -1.4196358e-04]]\n",
      "linear.bias:\n",
      " [0.00021692]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0655661e-03 -9.8577730e-05  2.8952200e-05  1.3868813e-04\n",
      "   1.8203590e-04 -1.7703063e-05 -1.3605013e-04]]\n",
      "linear.bias:\n",
      " [0.00021743]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0577680e-03 -1.0415915e-04  3.0296391e-05  9.5469673e-05\n",
      "   1.8964458e-04 -2.8770090e-05 -1.3239318e-04]]\n",
      "linear.bias:\n",
      " [0.00021883]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501771e-03 -1.0280646e-04  3.1388703e-05  9.4890449e-05\n",
      "   1.8947388e-04 -8.2454426e-07 -1.3244005e-04]]\n",
      "linear.bias:\n",
      " [0.00022079]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417312e-03 -9.8123179e-05  3.1376330e-05  9.0521724e-05\n",
      "   1.8240097e-04 -9.7018774e-06 -1.3554843e-04]]\n",
      "linear.bias:\n",
      " [0.00022349]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03801349e-03 -9.75884541e-05  3.10437099e-05  1.03284685e-04\n",
      "   1.75063600e-04 -1.89939492e-05 -1.38279589e-04]]\n",
      "linear.bias:\n",
      " [0.00022569]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03805098e-03 -1.01915932e-04  2.98567484e-05  1.12391805e-04\n",
      "   1.69034727e-04 -3.22353371e-05 -1.40154370e-04]]\n",
      "linear.bias:\n",
      " [0.00022791]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04050909e-03 -1.10788416e-04  2.88108331e-05  1.19138640e-04\n",
      "   1.66374724e-04 -2.41044836e-05 -1.41064971e-04]]\n",
      "linear.bias:\n",
      " [0.00023014]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454789e-03 -1.2023657e-04  2.7636092e-05  9.3333168e-05\n",
      "   1.6881060e-04 -4.0867886e-05 -1.3931603e-04]]\n",
      "linear.bias:\n",
      " [0.00023098]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505046e-03 -1.1998630e-04  2.5974836e-05  9.7889868e-05\n",
      "   1.6990263e-04 -1.2055671e-05 -1.3881394e-04]]\n",
      "linear.bias:\n",
      " [0.00023126]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0556979e-03 -1.1092355e-04  2.6111489e-05  1.0543255e-04\n",
      "   1.7328045e-04  1.9237905e-06 -1.3691008e-04]]\n",
      "linear.bias:\n",
      " [0.00023009]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05734274e-03 -1.00784426e-04  2.73327296e-05  8.55193939e-05\n",
      "   1.76796093e-04 -3.69406407e-05 -1.33793030e-04]]\n",
      "linear.bias:\n",
      " [0.00022787]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0572367e-03 -8.7339169e-05  2.8901106e-05  1.1388853e-04\n",
      "   1.7336015e-04 -2.1204736e-05 -1.3400639e-04]]\n",
      "linear.bias:\n",
      " [0.00022516]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0538894e-03 -7.8671314e-05  3.0781557e-05  1.2527639e-04\n",
      "   1.7165639e-04 -1.1564763e-05 -1.3371055e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508886e-03 -7.6749646e-05  3.2418357e-05  8.7181375e-05\n",
      "   1.7269520e-04 -4.5973873e-05 -1.3372987e-04]]\n",
      "linear.bias:\n",
      " [0.00022237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04828947e-03 -8.20185378e-05  3.39363833e-05  1.00467245e-04\n",
      "   1.71295484e-04 -3.46086126e-05 -1.35152513e-04]]\n",
      "linear.bias:\n",
      " [0.00022044]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496016e-03 -9.4084564e-05  3.3883643e-05  1.3056959e-04\n",
      "   1.6968175e-04  8.8716115e-07 -1.3638606e-04]]\n",
      "linear.bias:\n",
      " [0.00021871]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04806258e-03 -1.08406915e-04  3.28715687e-05  8.61396984e-05\n",
      "   1.69294843e-04 -2.19659578e-05 -1.39006093e-04]]\n",
      "linear.bias:\n",
      " [0.00021809]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446821e-03 -1.1822320e-04  3.1380339e-05  7.6638513e-05\n",
      "   1.6771059e-04 -1.9227304e-05 -1.4182001e-04]]\n",
      "linear.bias:\n",
      " [0.00021777]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416186e-03 -1.1881775e-04  3.0426361e-05  1.0981414e-04\n",
      "   1.6438657e-04  1.4633391e-05 -1.4514651e-04]]\n",
      "linear.bias:\n",
      " [0.00021772]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04181014e-03 -1.14886876e-04  2.92156310e-05  9.69406756e-05\n",
      "   1.65571153e-04 -2.08217534e-05 -1.46616425e-04]]\n",
      "linear.bias:\n",
      " [0.00021744]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04280247e-03 -1.09239336e-04  2.83285917e-05  8.54027021e-05\n",
      "   1.71821099e-04 -6.27500340e-05 -1.45152007e-04]]\n",
      "linear.bias:\n",
      " [0.00021766]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438609e-03 -9.8602293e-05  2.7488706e-05  1.2375136e-04\n",
      "   1.7435770e-04 -3.3053700e-05 -1.4518699e-04]]\n",
      "linear.bias:\n",
      " [0.00021904]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466946e-03 -9.0562004e-05  2.6022983e-05  1.4424238e-04\n",
      "   1.7847314e-04  2.8799914e-06 -1.4412391e-04]]\n",
      "linear.bias:\n",
      " [0.00022147]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461893e-03 -8.5178923e-05  2.4583540e-05  7.1277558e-05\n",
      "   1.8157807e-04 -4.7153328e-05 -1.4454205e-04]]\n",
      "linear.bias:\n",
      " [0.00022484]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459506e-03 -8.6732456e-05  2.3730863e-05  7.4426542e-05\n",
      "   1.7837824e-04 -3.8231959e-05 -1.4663943e-04]]\n",
      "linear.bias:\n",
      " [0.00022669]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448563e-03 -9.5220785e-05  2.4140701e-05  1.3079301e-04\n",
      "   1.7234399e-04  7.2902694e-06 -1.4917925e-04]]\n",
      "linear.bias:\n",
      " [0.00022694]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04238989e-03 -1.04071885e-04  2.57166157e-05  1.19394630e-04\n",
      "   1.70271029e-04 -2.59288572e-05 -1.49966319e-04]]\n",
      "linear.bias:\n",
      " [0.00022621]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438090e-03 -1.1552176e-04  2.7208915e-05  8.7538938e-05\n",
      "   1.7304388e-04 -7.5022224e-05 -1.4803454e-04]]\n",
      "linear.bias:\n",
      " [0.00022555]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442934e-03 -1.1467635e-04  2.8984054e-05  1.1965791e-04\n",
      "   1.7245098e-04 -2.8492552e-05 -1.4749700e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445412e-03 -1.0828218e-04  3.0122530e-05  1.2861578e-04\n",
      "   1.7473286e-04  6.6797220e-06 -1.4544904e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451187e-03 -1.0027336e-04  3.1432581e-05  7.1506234e-05\n",
      "   1.7802401e-04 -3.0545365e-05 -1.4311621e-04]]\n",
      "linear.bias:\n",
      " [0.00022179]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458009e-03 -8.8985289e-05  3.3300956e-05  8.4945343e-05\n",
      "   1.7641752e-04 -1.8108454e-05 -1.4220059e-04]]\n",
      "linear.bias:\n",
      " [0.00022038]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488160e-03 -8.6532222e-05  3.4158453e-05  1.2234268e-04\n",
      "   1.7447023e-04 -3.0578303e-07 -1.4092597e-04]]\n",
      "linear.bias:\n",
      " [0.00021888]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05179625e-03 -8.91865566e-05  3.46110392e-05  1.04114195e-04\n",
      "   1.73606430e-04 -2.91467040e-05 -1.40206379e-04]]\n",
      "linear.bias:\n",
      " [0.00021847]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0555445e-03 -9.7498661e-05  3.4452183e-05  9.1580710e-05\n",
      "   1.7351784e-04 -3.7787751e-05 -1.3866645e-04]]\n",
      "linear.bias:\n",
      " [0.00021882]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0577294e-03 -1.0515237e-04  3.3610926e-05  1.0967752e-04\n",
      "   1.7137930e-04 -8.4236744e-06 -1.3813681e-04]]\n",
      "linear.bias:\n",
      " [0.00021962]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0560182e-03 -1.0830640e-04  3.2993354e-05  9.9635254e-05\n",
      "   1.7138201e-04 -3.5811936e-06 -1.3642326e-04]]\n",
      "linear.bias:\n",
      " [0.00022105]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525516e-03 -1.0772454e-04  3.2984331e-05  7.6219476e-05\n",
      "   1.7398129e-04 -2.4369032e-05 -1.3272648e-04]]\n",
      "linear.bias:\n",
      " [0.00022282]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487315e-03 -1.0130798e-04  3.2866075e-05  1.0261116e-04\n",
      "   1.7091694e-04 -9.5837368e-06 -1.3217145e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0477370e-03 -1.0030458e-04  3.2785185e-05  1.1909363e-04\n",
      "   1.6994786e-04 -1.5651010e-05 -1.3051370e-04]]\n",
      "linear.bias:\n",
      " [0.00022467]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474155e-03 -1.0098628e-04  3.1710319e-05  9.1269329e-05\n",
      "   1.6982149e-04 -5.4181059e-05 -1.2903876e-04]]\n",
      "linear.bias:\n",
      " [0.0002256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472372e-03 -9.6718053e-05  3.0524079e-05  1.0333834e-04\n",
      "   1.6504158e-04 -3.9460872e-05 -1.3070926e-04]]\n",
      "linear.bias:\n",
      " [0.00022596]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466655e-03 -9.5383119e-05  3.0223991e-05  1.2751127e-04\n",
      "   1.6266850e-04  4.3949294e-06 -1.3260955e-04]]\n",
      "linear.bias:\n",
      " [0.0002258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434220e-03 -9.6293414e-05  2.9433257e-05  8.3526669e-05\n",
      "   1.6266896e-04 -2.2471322e-05 -1.3601891e-04]]\n",
      "linear.bias:\n",
      " [0.00022566]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408588e-03 -9.9412624e-05  2.9233290e-05  7.1597882e-05\n",
      "   1.6379089e-04 -2.7350845e-05 -1.3863141e-04]]\n",
      "linear.bias:\n",
      " [0.00022481]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0387994e-03 -1.0468216e-04  2.9430959e-05  1.0593426e-04\n",
      "   1.6549819e-04 -1.7603634e-07 -1.4016892e-04]]\n",
      "linear.bias:\n",
      " [0.00022381]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408802e-03 -1.1274679e-04  3.0000543e-05  1.1537303e-04\n",
      "   1.7246025e-04 -1.1557384e-05 -1.3793512e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04308256e-03 -1.17006566e-04  2.95235732e-05  8.40217617e-05\n",
      "   1.80827890e-04 -5.37646047e-05 -1.34786562e-04]]\n",
      "linear.bias:\n",
      " [0.00022051]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435276e-03 -1.1094233e-04  2.8197643e-05  1.1717602e-04\n",
      "   1.7915791e-04 -3.2509015e-05 -1.3589188e-04]]\n",
      "linear.bias:\n",
      " [0.0002197]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432805e-03 -1.0030144e-04  2.7436095e-05  1.4856750e-04\n",
      "   1.7605764e-04  1.0162927e-05 -1.3845852e-04]]\n",
      "linear.bias:\n",
      " [0.00021945]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0412689e-03 -8.6012471e-05  2.5059859e-05  7.7241639e-05\n",
      "   1.7034276e-04 -4.6747111e-05 -1.4529352e-04]]\n",
      "linear.bias:\n",
      " [0.0002209]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0390484e-03 -7.7713135e-05  2.2906648e-05  6.3144165e-05\n",
      "   1.6435726e-04 -5.8054051e-05 -1.5098989e-04]]\n",
      "linear.bias:\n",
      " [0.00022246]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383892e-03 -7.7330726e-05  2.1583712e-05  1.5852443e-04\n",
      "   1.5797462e-04  1.8213759e-05 -1.5455180e-04]]\n",
      "linear.bias:\n",
      " [0.00022145]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0289450e-03 -8.2032893e-05  2.1608395e-05  1.3182839e-04\n",
      "   1.6269529e-04 -2.2327346e-05 -1.5621691e-04]]\n",
      "linear.bias:\n",
      " [0.0002203]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0237511e-03 -9.2072652e-05  2.1097334e-05  6.6821864e-05\n",
      "   1.7421259e-04 -9.0789064e-05 -1.5448380e-04]]\n",
      "linear.bias:\n",
      " [0.00021974]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02634041e-03 -1.02725186e-04  2.25553431e-05  1.33146037e-04\n",
      "   1.77468348e-04 -1.56241003e-05 -1.54898473e-04]]\n",
      "linear.bias:\n",
      " [0.00021684]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0325526e-03 -1.1606919e-04  2.4206120e-05  1.3963149e-04\n",
      "   1.8598433e-04  8.2441311e-06 -1.5273789e-04]]\n",
      "linear.bias:\n",
      " [0.00021494]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0373616e-03 -1.1845898e-04  2.4146910e-05  6.0906939e-05\n",
      "   1.9029620e-04 -5.7083453e-05 -1.5387998e-04]]\n",
      "linear.bias:\n",
      " [0.00021492]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436823e-03 -1.0743736e-04  2.4062443e-05  1.0057855e-04\n",
      "   1.8150191e-04 -1.6044738e-05 -1.5798472e-04]]\n",
      "linear.bias:\n",
      " [0.00021467]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483159e-03 -9.9701967e-05  2.5641904e-05  1.3737781e-04\n",
      "   1.7618116e-04  5.1245224e-06 -1.5868478e-04]]\n",
      "linear.bias:\n",
      " [0.00021516]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516002e-03 -9.4248055e-05  2.7799400e-05  1.0339466e-04\n",
      "   1.7256221e-04 -4.9363025e-05 -1.5850128e-04]]\n",
      "linear.bias:\n",
      " [0.00021609]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0523228e-03 -9.4796516e-05  3.0373751e-05  8.5872889e-05\n",
      "   1.7218267e-04 -7.0756614e-05 -1.5664114e-04]]\n",
      "linear.bias:\n",
      " [0.0002174]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506910e-03 -9.7773314e-05  3.1950716e-05  1.2161970e-04\n",
      "   1.7325385e-04 -2.7932540e-05 -1.5304940e-04]]\n",
      "linear.bias:\n",
      " [0.00021883]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510995e-03 -1.0520354e-04  3.3183216e-05  1.3045467e-04\n",
      "   1.7857994e-04 -1.8777500e-06 -1.4736068e-04]]\n",
      "linear.bias:\n",
      " [0.00022084]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0489289e-03 -1.1145296e-04  3.2974982e-05  6.4198466e-05\n",
      "   1.8105697e-04 -3.7174119e-05 -1.4396943e-04]]\n",
      "linear.bias:\n",
      " [0.00022338]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04616606e-03 -1.10456014e-04  3.21547996e-05  8.23029332e-05\n",
      "   1.74326182e-04 -1.69592859e-05 -1.43664889e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429205e-03 -1.1197155e-04  3.2066513e-05  1.3195816e-04\n",
      "   1.6893692e-04  2.3075911e-05 -1.4301918e-04]]\n",
      "linear.bias:\n",
      " [0.00022678]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03498390e-03 -1.02055346e-04  2.99085714e-05  8.08512268e-05\n",
      "   1.67363702e-04 -6.08482951e-05 -1.44479927e-04]]\n",
      "linear.bias:\n",
      " [0.00022728]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0276242e-03 -9.0119116e-05  2.8300481e-05  9.4040515e-05\n",
      "   1.6210234e-04 -6.6217472e-05 -1.4768350e-04]]\n",
      "linear.bias:\n",
      " [0.00022699]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0271717e-03 -8.5941698e-05  2.5450743e-05  1.3369258e-04\n",
      "   1.6151885e-04 -1.8766263e-05 -1.4921352e-04]]\n",
      "linear.bias:\n",
      " [0.00022601]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0295840e-03 -8.6607106e-05  2.2405769e-05  1.1914807e-04\n",
      "   1.6682396e-04 -1.4000143e-05 -1.4776952e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0357057e-03 -9.1638787e-05  2.0029973e-05  7.7696648e-05\n",
      "   1.7810822e-04 -4.7625923e-05 -1.4302164e-04]]\n",
      "linear.bias:\n",
      " [0.00022292]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431659e-03 -9.5825068e-05  1.8570192e-05  9.5645810e-05\n",
      "   1.8378027e-04 -2.8986358e-05 -1.4039839e-04]]\n",
      "linear.bias:\n",
      " [0.00022064]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479048e-03 -1.0232583e-04  1.8018041e-05  1.4392228e-04\n",
      "   1.8628877e-04  2.3599472e-05 -1.3888156e-04]]\n",
      "linear.bias:\n",
      " [0.00021858]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04985107e-03 -1.06636486e-04  1.75654277e-05  9.74110444e-05\n",
      "   1.84982069e-04 -4.73019027e-05 -1.41765719e-04]]\n",
      "linear.bias:\n",
      " [0.00021844]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502404e-03 -1.0536816e-04  1.7917639e-05  9.2002003e-05\n",
      "   1.7776756e-04 -6.5066728e-05 -1.4689531e-04]]\n",
      "linear.bias:\n",
      " [0.00021855]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0479661e-03 -9.9564510e-05  1.9207660e-05  1.3194214e-04\n",
      "   1.6636544e-04 -1.6889313e-05 -1.5270851e-04]]\n",
      "linear.bias:\n",
      " [0.00021866]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04677712e-03 -9.94199290e-05  2.09658247e-05  1.18437216e-04\n",
      "   1.61360338e-04 -1.43657317e-05 -1.55826463e-04]]\n",
      "linear.bias:\n",
      " [0.00021948]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496702e-03 -1.0373796e-04  2.2916354e-05  7.7929028e-05\n",
      "   1.6338375e-04 -4.9937076e-05 -1.5517416e-04]]\n",
      "linear.bias:\n",
      " [0.00021973]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05047645e-03 -1.09495515e-04  2.55832929e-05  9.83870268e-05\n",
      "   1.70371626e-04 -4.16239272e-05 -1.50397187e-04]]\n",
      "linear.bias:\n",
      " [0.00021947]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491302e-03 -1.1472770e-04  2.8373712e-05  1.4007985e-04\n",
      "   1.7802326e-04 -2.7523820e-06 -1.4541534e-04]]\n",
      "linear.bias:\n",
      " [0.00021899]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04638829e-03 -1.11066816e-04  2.85170372e-05  9.46753134e-05\n",
      "   1.82801523e-04 -3.47921996e-05 -1.43128374e-04]]\n",
      "linear.bias:\n",
      " [0.00022003]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437651e-03 -1.0227214e-04  2.8546756e-05  8.9047462e-05\n",
      "   1.8261618e-04 -1.8918108e-05 -1.4323143e-04]]\n",
      "linear.bias:\n",
      " [0.00022145]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406082e-03 -9.6056741e-05  2.9030196e-05  1.1806007e-04\n",
      "   1.8099898e-04  1.6779595e-05 -1.4378117e-04]]\n",
      "linear.bias:\n",
      " [0.00022273]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0361482e-03 -9.2300106e-05  3.0549330e-05  8.6745800e-05\n",
      "   1.7825876e-04 -3.9884253e-05 -1.4513581e-04]]\n",
      "linear.bias:\n",
      " [0.00022364]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0358182e-03 -9.6634802e-05  3.1276995e-05  9.0751360e-05\n",
      "   1.7503157e-04 -5.6069057e-05 -1.4660176e-04]]\n",
      "linear.bias:\n",
      " [0.00022372]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0360485e-03 -9.7886674e-05  3.2697673e-05  1.3210195e-04\n",
      "   1.6973205e-04 -2.5638688e-05 -1.4932948e-04]]\n",
      "linear.bias:\n",
      " [0.0002233]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03883434e-03 -1.02766295e-04  3.33106618e-05  1.24371567e-04\n",
      "   1.71320033e-04 -3.40696861e-05 -1.49067448e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452060e-03 -1.0807778e-04  3.2477645e-05  9.4970055e-05\n",
      "   1.7766861e-04 -3.6105685e-05 -1.4623333e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0518262e-03 -1.0733644e-04  3.1272870e-05  9.5877011e-05\n",
      "   1.7997036e-04  3.8555227e-06 -1.4555937e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0569431e-03 -1.0719630e-04  3.1384287e-05  9.5793104e-05\n",
      "   1.8276981e-04  9.2981118e-06 -1.4300398e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0580641e-03 -1.0489544e-04  3.2527194e-05  7.8095451e-05\n",
      "   1.8360962e-04 -3.6766192e-05 -1.3987461e-04]]\n",
      "linear.bias:\n",
      " [0.00022054]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0574169e-03 -9.6092474e-05  3.3091186e-05  1.1847722e-04\n",
      "   1.7563700e-04 -2.5105139e-05 -1.4020840e-04]]\n",
      "linear.bias:\n",
      " [0.00021971]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0529527e-03 -8.9726920e-05  3.3538225e-05  1.4223068e-04\n",
      "   1.6892998e-04 -1.2922525e-05 -1.4058709e-04]]\n",
      "linear.bias:\n",
      " [0.00021994]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455870e-03 -8.6945423e-05  3.2984401e-05  9.0800677e-05\n",
      "   1.6336562e-04 -5.7331730e-05 -1.4259056e-04]]\n",
      "linear.bias:\n",
      " [0.00022088]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392652e-03 -9.0312489e-05  3.2383257e-05  7.8896570e-05\n",
      "   1.6029527e-04 -5.5012337e-05 -1.4405069e-04]]\n",
      "linear.bias:\n",
      " [0.00022173]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0333398e-03 -9.8683297e-05  3.1345859e-05  1.1646071e-04\n",
      "   1.5916857e-04 -7.3178271e-06 -1.4436728e-04]]\n",
      "linear.bias:\n",
      " [0.00022275]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0321133e-03 -1.1084959e-04  3.0850017e-05  1.1871269e-04\n",
      "   1.6482893e-04 -4.0768928e-06 -1.4151461e-04]]\n",
      "linear.bias:\n",
      " [0.00022341]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0357718e-03 -1.2378165e-04  3.0667077e-05  9.1062844e-05\n",
      "   1.7578025e-04 -3.7935835e-05 -1.3589744e-04]]\n",
      "linear.bias:\n",
      " [0.00022327]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396219e-03 -1.2545104e-04  2.9753201e-05  9.4260889e-05\n",
      "   1.8220082e-04 -2.6299986e-05 -1.3272426e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443381e-03 -1.1453215e-04  2.7703154e-05  1.2311339e-04\n",
      "   1.8178998e-04  1.6486654e-05 -1.3347330e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483231e-03 -9.6898817e-05  2.4850509e-05  7.5303251e-05\n",
      "   1.7683947e-04 -3.6918264e-05 -1.3835556e-04]]\n",
      "linear.bias:\n",
      " [0.00022528]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0526876e-03 -7.8367717e-05  2.3517227e-05  8.6586057e-05\n",
      "   1.6837289e-04 -3.9692484e-05 -1.4482306e-04]]\n",
      "linear.bias:\n",
      " [0.0002252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0551186e-03 -6.7526656e-05  2.3078223e-05  1.2838835e-04\n",
      "   1.6096218e-04 -7.5550706e-06 -1.5032681e-04]]\n",
      "linear.bias:\n",
      " [0.00022463]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05474365e-03 -6.79067962e-05  2.39146011e-05  1.17147276e-04\n",
      "   1.61455057e-04 -2.70617438e-05 -1.52270135e-04]]\n",
      "linear.bias:\n",
      " [0.00022412]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0558999e-03 -8.0023281e-05  2.4474750e-05  9.6107746e-05\n",
      "   1.6725688e-04 -5.5745597e-05 -1.5146406e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05522643e-03 -9.76018564e-05  2.56312524e-05  1.07931715e-04\n",
      "   1.73775363e-04 -4.45248043e-05 -1.50015505e-04]]\n",
      "linear.bias:\n",
      " [0.00022301]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525457e-03 -1.1820268e-04  2.7429851e-05  1.3259512e-04\n",
      "   1.8151039e-04 -9.1789152e-06 -1.4737871e-04]]\n",
      "linear.bias:\n",
      " [0.00022266]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445102e-03 -1.2643996e-04  2.9488790e-05  9.1630092e-05\n",
      "   1.8659678e-04 -3.2293770e-05 -1.4585376e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0366266e-03 -1.2347091e-04  3.0856929e-05  9.0562840e-05\n",
      "   1.8644681e-04 -7.6434062e-06 -1.4670532e-04]]\n",
      "linear.bias:\n",
      " [0.00022375]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0309784e-03 -1.0838836e-04  3.2335174e-05  1.0455429e-04\n",
      "   1.8407400e-04  1.7832837e-05 -1.4805264e-04]]\n",
      "linear.bias:\n",
      " [0.00022481]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0302516e-03 -9.0039728e-05  3.2445809e-05  8.5129446e-05\n",
      "   1.8012723e-04 -2.3138135e-05 -1.4901628e-04]]\n",
      "linear.bias:\n",
      " [0.00022478]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0354723e-03 -8.0538019e-05  3.1980202e-05  9.9429657e-05\n",
      "   1.7802975e-04 -3.5232981e-05 -1.4889571e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441284e-03 -8.0778875e-05  3.0610630e-05  1.3072031e-04\n",
      "   1.7726560e-04 -2.1146963e-05 -1.4776339e-04]]\n",
      "linear.bias:\n",
      " [0.00022306]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0523187e-03 -8.6621774e-05  2.9248467e-05  1.1067650e-04\n",
      "   1.7992257e-04 -4.7488233e-05 -1.4542733e-04]]\n",
      "linear.bias:\n",
      " [0.00022296]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05763576e-03 -9.56661024e-05  2.83545705e-05  1.01132064e-04\n",
      "   1.82700285e-04 -4.61259551e-05 -1.42984121e-04]]\n",
      "linear.bias:\n",
      " [0.00022361]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0596442e-03 -1.0452586e-04  2.7429089e-05  1.1962808e-04\n",
      "   1.8320297e-04 -9.2460068e-06 -1.4137047e-04]]\n",
      "linear.bias:\n",
      " [0.00022444]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0562151e-03 -1.0933839e-04  2.7233622e-05  8.8023575e-05\n",
      "   1.8180827e-04 -1.6044864e-05 -1.4054510e-04]]\n",
      "linear.bias:\n",
      " [0.00022569]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512786e-03 -1.0867924e-04  2.8016022e-05  9.2023940e-05\n",
      "   1.7649500e-04 -2.1422238e-07 -1.4132334e-04]]\n",
      "linear.bias:\n",
      " [0.00022681]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456778e-03 -1.0938607e-04  2.9946557e-05  9.7142125e-05\n",
      "   1.7324720e-04 -7.8925768e-06 -1.3983682e-04]]\n",
      "linear.bias:\n",
      " [0.00022733]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400607e-03 -1.1115098e-04  3.3003325e-05  9.7697099e-05\n",
      "   1.7296645e-04 -3.9169438e-05 -1.3616971e-04]]\n",
      "linear.bias:\n",
      " [0.00022704]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363702e-03 -1.0589167e-04  3.5086567e-05  1.2485204e-04\n",
      "   1.6940436e-04 -2.5267185e-05 -1.3473429e-04]]\n",
      "linear.bias:\n",
      " [0.00022654]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0356099e-03 -1.0101213e-04  3.5280598e-05  1.0646013e-04\n",
      "   1.6777449e-04 -4.0682185e-05 -1.3320579e-04]]\n",
      "linear.bias:\n",
      " [0.00022633]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0389673e-03 -9.8246623e-05  3.3682114e-05  9.8021344e-05\n",
      "   1.6592926e-04 -2.5702866e-05 -1.3279896e-04]]\n",
      "linear.bias:\n",
      " [0.0002264]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458085e-03 -1.0038182e-04  3.1522748e-05  1.0579500e-04\n",
      "   1.6602250e-04  6.4964916e-06 -1.3201129e-04]]\n",
      "linear.bias:\n",
      " [0.00022546]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0533404e-03 -1.0447023e-04  2.9990151e-05  7.7156044e-05\n",
      "   1.6904787e-04 -1.7795626e-05 -1.3086802e-04]]\n",
      "linear.bias:\n",
      " [0.00022411]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05903437e-03 -1.10282184e-04  2.89181207e-05  9.28352092e-05\n",
      "   1.69780178e-04 -1.55673697e-05 -1.30871093e-04]]\n",
      "linear.bias:\n",
      " [0.0002224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0614384e-03 -1.1283781e-04  2.7858350e-05  1.2121769e-04\n",
      "   1.7001554e-04 -6.7241663e-06 -1.3078382e-04]]\n",
      "linear.bias:\n",
      " [0.00022136]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05538336e-03 -1.09439825e-04  2.64966220e-05  8.78043356e-05\n",
      "   1.69175386e-04 -4.50746084e-05 -1.33102207e-04]]\n",
      "linear.bias:\n",
      " [0.00022167]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499118e-03 -1.0153245e-04  2.5643532e-05  9.5899268e-05\n",
      "   1.6525456e-04 -3.2639829e-05 -1.3734626e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437655e-03 -9.7627650e-05  2.5588681e-05  1.2709519e-04\n",
      "   1.6265457e-04  1.0253298e-05 -1.4063445e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383762e-03 -9.6844335e-05  2.6942545e-05  9.5207804e-05\n",
      "   1.6513010e-04 -2.9088638e-05 -1.4252652e-04]]\n",
      "linear.bias:\n",
      " [0.00022123]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383136e-03 -1.0075124e-04  2.7796004e-05  8.7082895e-05\n",
      "   1.6998620e-04 -4.1935273e-05 -1.4328734e-04]]\n",
      "linear.bias:\n",
      " [0.0002198]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374309e-03 -1.0703638e-04  2.8803688e-05  1.1194634e-04\n",
      "   1.7466515e-04 -1.7833288e-05 -1.4384177e-04]]\n",
      "linear.bias:\n",
      " [0.00021851]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03887590e-03 -1.14372255e-04  2.92268014e-05  1.10792280e-04\n",
      "   1.80288131e-04 -1.31382112e-05 -1.43030222e-04]]\n",
      "linear.bias:\n",
      " [0.00021811]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417595e-03 -1.1910902e-04  2.8722628e-05  7.9807432e-05\n",
      "   1.8704463e-04 -3.1475345e-05 -1.4080493e-04]]\n",
      "linear.bias:\n",
      " [0.0002185]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437716e-03 -1.1350408e-04  2.7604305e-05  1.0777058e-04\n",
      "   1.8496758e-04  2.3179928e-06 -1.4187925e-04]]\n",
      "linear.bias:\n",
      " [0.0002196]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04450749e-03 -1.01208076e-04  2.64758910e-05  9.63828570e-05\n",
      "   1.79574025e-04 -2.63182592e-05 -1.43933488e-04]]\n",
      "linear.bias:\n",
      " [0.00022109]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432913e-03 -9.2554626e-05  2.5852845e-05  1.0334318e-04\n",
      "   1.7409756e-04 -3.3785302e-05 -1.4584417e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403335e-03 -8.9296234e-05  2.6050335e-05  1.2359861e-04\n",
      "   1.7082412e-04 -1.8106346e-05 -1.4610525e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03868544e-03 -9.17085490e-05  2.66616316e-05  1.03136605e-04\n",
      "   1.72929664e-04 -4.01543039e-05 -1.44185760e-04]]\n",
      "linear.bias:\n",
      " [0.00022454]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03936438e-03 -9.93871072e-05  2.69696229e-05  1.05352054e-04\n",
      "   1.75864814e-04 -3.12693010e-05 -1.41729717e-04]]\n",
      "linear.bias:\n",
      " [0.00022479]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425629e-03 -1.1121224e-04  2.6805890e-05  1.1460115e-04\n",
      "   1.7935580e-04 -2.7944006e-06 -1.3891731e-04]]\n",
      "linear.bias:\n",
      " [0.00022476]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04624545e-03 -1.21314304e-04  2.64935461e-05  7.96397653e-05\n",
      "   1.82256917e-04 -2.03967156e-05 -1.35961687e-04]]\n",
      "linear.bias:\n",
      " [0.00022499]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481382e-03 -1.2054513e-04  2.6016380e-05  1.0183166e-04\n",
      "   1.7687016e-04  9.4917232e-07 -1.3644918e-04]]\n",
      "linear.bias:\n",
      " [0.00022519]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04617560e-03 -1.11064626e-04  2.56089588e-05  9.56243966e-05\n",
      "   1.71753956e-04 -2.84222806e-05 -1.35645154e-04]]\n",
      "linear.bias:\n",
      " [0.00022411]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04329363e-03 -9.72712878e-05  2.54286788e-05  1.13709946e-04\n",
      "   1.63540535e-04 -2.27319561e-05 -1.36677132e-04]]\n",
      "linear.bias:\n",
      " [0.00022264]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04338059e-03 -8.91461677e-05  2.57588636e-05  1.09107976e-04\n",
      "   1.60050724e-04 -3.60833619e-05 -1.35248221e-04]]\n",
      "linear.bias:\n",
      " [0.00022156]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0454607e-03 -8.8238841e-05  2.5981464e-05  1.0008728e-04\n",
      "   1.6036513e-04 -3.2113621e-05 -1.3258203e-04]]\n",
      "linear.bias:\n",
      " [0.0002211]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465741e-03 -9.0241621e-05  2.7028687e-05  1.0043844e-04\n",
      "   1.6327619e-04 -1.3965837e-07 -1.2992135e-04]]\n",
      "linear.bias:\n",
      " [0.00022068]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0499682e-03 -9.8671379e-05  2.9041592e-05  7.9137601e-05\n",
      "   1.7230539e-04 -7.6679407e-06 -1.2489725e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516110e-03 -1.0782050e-04  3.1174259e-05  9.6825359e-05\n",
      "   1.7721059e-04 -3.3695833e-06 -1.2212688e-04]]\n",
      "linear.bias:\n",
      " [0.00022095]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0533829e-03 -1.1183564e-04  3.1267278e-05  1.0882649e-04\n",
      "   1.7393680e-04 -2.0220728e-05 -1.2612432e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516334e-03 -1.0614127e-04  3.1103667e-05  1.0872551e-04\n",
      "   1.6783696e-04 -2.8021364e-05 -1.3266344e-04]]\n",
      "linear.bias:\n",
      " [0.00022621]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468260e-03 -1.0094493e-04  3.0899944e-05  1.0451013e-04\n",
      "   1.6235941e-04 -1.9873505e-05 -1.3949827e-04]]\n",
      "linear.bias:\n",
      " [0.00022883]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451974e-03 -1.0254361e-04  3.0701121e-05  9.8870260e-05\n",
      "   1.6265323e-04 -2.7824794e-05 -1.4267612e-04]]\n",
      "linear.bias:\n",
      " [0.00022992]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04432239e-03 -1.06188505e-04  3.13604651e-05  1.12942391e-04\n",
      "   1.66408267e-04 -2.00992181e-05 -1.44147591e-04]]\n",
      "linear.bias:\n",
      " [0.00022938]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04757317e-03 -1.11893925e-04  3.18423845e-05  1.01298632e-04\n",
      "   1.75286448e-04 -3.81195205e-05 -1.42374905e-04]]\n",
      "linear.bias:\n",
      " [0.00022839]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05032139e-03 -1.10605484e-04  3.22144660e-05  1.15532814e-04\n",
      "   1.80058341e-04 -1.31451343e-05 -1.42367484e-04]]\n",
      "linear.bias:\n",
      " [0.00022698]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0534198e-03 -1.0867378e-04  3.1800046e-05  8.9968147e-05\n",
      "   1.8536602e-04 -2.1924076e-05 -1.4105247e-04]]\n",
      "linear.bias:\n",
      " [0.00022521]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0540116e-03 -1.0164727e-04  3.1982810e-05  9.8842953e-05\n",
      "   1.8538450e-04  5.4713237e-06 -1.4193954e-04]]\n",
      "linear.bias:\n",
      " [0.00022361]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509320e-03 -9.3067909e-05  3.3227694e-05  8.8871173e-05\n",
      "   1.8365965e-04 -2.1648533e-05 -1.4188002e-04]]\n",
      "linear.bias:\n",
      " [0.00022116]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468244e-03 -8.7269138e-05  3.4422632e-05  1.1132706e-04\n",
      "   1.7996090e-04 -1.9306721e-05 -1.4269471e-04]]\n",
      "linear.bias:\n",
      " [0.0002192]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445610e-03 -8.8189889e-05  3.5064724e-05  1.1815016e-04\n",
      "   1.7835631e-04 -2.2955704e-05 -1.4248797e-04]]\n",
      "linear.bias:\n",
      " [0.00021795]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434799e-03 -9.3595525e-05  3.4109216e-05  1.0511861e-04\n",
      "   1.7690589e-04 -3.1116804e-05 -1.4276491e-04]]\n",
      "linear.bias:\n",
      " [0.00021784]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450766e-03 -1.0191888e-04  3.1468313e-05  9.3625160e-05\n",
      "   1.7529522e-04 -1.7196595e-05 -1.4312875e-04]]\n",
      "linear.bias:\n",
      " [0.00021928]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04588899e-03 -1.12576665e-04  2.91905544e-05  1.00517063e-04\n",
      "   1.74171248e-04 -2.16240187e-06 -1.42765275e-04]]\n",
      "linear.bias:\n",
      " [0.00022082]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448649e-03 -1.2047956e-04  2.8276128e-05  9.3690680e-05\n",
      "   1.7687056e-04 -1.6052971e-05 -1.3974804e-04]]\n",
      "linear.bias:\n",
      " [0.00022247]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448563e-03 -1.1617056e-04  2.7688471e-05  1.0172531e-04\n",
      "   1.7747814e-04 -2.5551442e-05 -1.3746414e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427700e-03 -1.0352905e-04  2.7051177e-05  1.2670807e-04\n",
      "   1.7513284e-04 -6.2348554e-06 -1.3696952e-04]]\n",
      "linear.bias:\n",
      " [0.00022602]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396560e-03 -9.3238697e-05  2.6288089e-05  8.5549400e-05\n",
      "   1.7113055e-04 -3.9832848e-05 -1.3795601e-04]]\n",
      "linear.bias:\n",
      " [0.00022792]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0372618e-03 -8.9917499e-05  2.5866137e-05  8.6597247e-05\n",
      "   1.6666137e-04 -2.9003686e-05 -1.3997751e-04]]\n",
      "linear.bias:\n",
      " [0.0002286]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402707e-03 -9.4483847e-05  2.4939085e-05  1.1607062e-04\n",
      "   1.6393987e-04  6.5652403e-06 -1.4109678e-04]]\n",
      "linear.bias:\n",
      " [0.00022819]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436466e-03 -1.0529770e-04  2.5304918e-05  1.0143081e-04\n",
      "   1.6833373e-04 -1.4419393e-05 -1.3914143e-04]]\n",
      "linear.bias:\n",
      " [0.00022731]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04622741e-03 -1.16872376e-04  2.74287559e-05  8.53458914e-05\n",
      "   1.76586414e-04 -5.74147198e-05 -1.34325193e-04]]\n",
      "linear.bias:\n",
      " [0.0002255]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466287e-03 -1.1767015e-04  2.8765657e-05  1.2819434e-04\n",
      "   1.7547613e-04 -3.7170536e-05 -1.3360323e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04415847e-03 -1.05890416e-04  2.97355073e-05  1.46832142e-04\n",
      "   1.72913598e-04 -9.43278246e-06 -1.35288239e-04]]\n",
      "linear.bias:\n",
      " [0.00022267]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400047e-03 -9.0328365e-05  2.8468803e-05  7.2384726e-05\n",
      "   1.6983546e-04 -4.9016555e-05 -1.3947603e-04]]\n",
      "linear.bias:\n",
      " [0.00022311]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0371382e-03 -7.7064207e-05  2.7743827e-05  7.3104042e-05\n",
      "   1.6114280e-04 -2.8076096e-05 -1.4582864e-04]]\n",
      "linear.bias:\n",
      " [0.00022222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0390828e-03 -7.2884766e-05  2.6515963e-05  1.2110325e-04\n",
      "   1.5524047e-04  2.0149628e-05 -1.4953683e-04]]\n",
      "linear.bias:\n",
      " [0.0002204]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404916e-03 -7.4034317e-05  2.7075801e-05  1.1458052e-04\n",
      "   1.6005940e-04 -1.1073151e-05 -1.5000983e-04]]\n",
      "linear.bias:\n",
      " [0.00021876]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463374e-03 -8.3665087e-05  2.7859529e-05  8.6798100e-05\n",
      "   1.7234329e-04 -6.9355578e-05 -1.4650894e-04]]\n",
      "linear.bias:\n",
      " [0.00021702]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510747e-03 -9.8602788e-05  2.8563496e-05  1.1571512e-04\n",
      "   1.8277633e-04 -5.4355525e-05 -1.4342993e-04]]\n",
      "linear.bias:\n",
      " [0.00021623]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0535627e-03 -1.1271763e-04  2.9038378e-05  1.5028272e-04\n",
      "   1.9117686e-04 -9.5661999e-06 -1.4139643e-04]]\n",
      "linear.bias:\n",
      " [0.00021654]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05388497e-03 -1.16167765e-04  2.77410709e-05  9.49801251e-05\n",
      "   1.94158958e-04 -4.18360396e-05 -1.43021214e-04]]\n",
      "linear.bias:\n",
      " [0.00021914]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0527683e-03 -1.0876153e-04  2.6172962e-05  9.3772775e-05\n",
      "   1.8729801e-04 -1.6845714e-05 -1.4809855e-04]]\n",
      "linear.bias:\n",
      " [0.00022174]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04814197e-03 -1.03875478e-04  2.53065664e-05  1.14248636e-04\n",
      "   1.79509894e-04  1.19285360e-05 -1.52354478e-04]]\n",
      "linear.bias:\n",
      " [0.00022486]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420368e-03 -1.0168222e-04  2.5527368e-05  9.7597658e-05\n",
      "   1.7315126e-04 -2.7955557e-05 -1.5453366e-04]]\n",
      "linear.bias:\n",
      " [0.00022611]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0357149e-03 -1.0374529e-04  2.6933059e-05  9.7419863e-05\n",
      "   1.7090725e-04 -4.7454123e-05 -1.5465650e-04]]\n",
      "linear.bias:\n",
      " [0.00022673]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02997723e-03 -1.08302847e-04  2.85102324e-05  1.20658835e-04\n",
      "   1.70890475e-04 -3.36572848e-05 -1.53759771e-04]]\n",
      "linear.bias:\n",
      " [0.00022651]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03021355e-03 -1.14611976e-04  2.96553226e-05  1.21781683e-04\n",
      "   1.76334754e-04 -2.33782084e-05 -1.49868079e-04]]\n",
      "linear.bias:\n",
      " [0.0002258]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346888e-03 -1.1974349e-04  2.9461351e-05  9.0994530e-05\n",
      "   1.8371402e-04 -3.7633639e-05 -1.4449400e-04]]\n",
      "linear.bias:\n",
      " [0.00022515]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396831e-03 -1.1417319e-04  2.8644366e-05  9.3820956e-05\n",
      "   1.8577353e-04 -5.4790362e-06 -1.4210292e-04]]\n",
      "linear.bias:\n",
      " [0.00022457]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04601949e-03 -1.00876525e-04  2.87440398e-05  1.08394539e-04\n",
      "   1.85110141e-04  1.68492916e-05 -1.40307660e-04]]\n",
      "linear.bias:\n",
      " [0.00022379]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495763e-03 -9.0169677e-05  2.9955188e-05  7.5057185e-05\n",
      "   1.8240511e-04 -4.9067123e-05 -1.3938569e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0529580e-03 -8.0137739e-05  3.1259999e-05  1.1088879e-04\n",
      "   1.7029872e-04 -5.0513732e-05 -1.4251802e-04]]\n",
      "linear.bias:\n",
      " [0.00022044]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0538104e-03 -7.6388838e-05  3.3061973e-05  1.5010162e-04\n",
      "   1.6257103e-04 -2.3693830e-05 -1.4403934e-04]]\n",
      "linear.bias:\n",
      " [0.00021956]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512451e-03 -8.2493338e-05  3.4380711e-05  1.2047024e-04\n",
      "   1.6196453e-04 -4.3098589e-05 -1.4450910e-04]]\n",
      "linear.bias:\n",
      " [0.00021928]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505446e-03 -9.7282391e-05  3.4833956e-05  7.9915109e-05\n",
      "   1.6743546e-04 -4.4240845e-05 -1.4280321e-04]]\n",
      "linear.bias:\n",
      " [0.00022032]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475825e-03 -1.1322138e-04  3.5110788e-05  8.6465712e-05\n",
      "   1.7215796e-04 -5.1226089e-06 -1.4076511e-04]]\n",
      "linear.bias:\n",
      " [0.00022126]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438584e-03 -1.2295348e-04  3.5099056e-05  9.7293349e-05\n",
      "   1.7730851e-04  1.5333304e-05 -1.3741972e-04]]\n",
      "linear.bias:\n",
      " [0.00022263]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04396895e-03 -1.21114936e-04  3.26667323e-05  7.37978044e-05\n",
      "   1.78596616e-04 -3.24609209e-05 -1.35590788e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04281178e-03 -1.08704764e-04  3.00791780e-05  1.18743272e-04\n",
      "   1.71744410e-04 -2.55922023e-05 -1.36993796e-04]]\n",
      "linear.bias:\n",
      " [0.00022499]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0432319e-03 -9.7492113e-05  2.6977374e-05  1.3237624e-04\n",
      "   1.6709814e-04 -3.0344698e-05 -1.3720791e-04]]\n",
      "linear.bias:\n",
      " [0.00022625]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0451677e-03 -9.1801965e-05  2.4130135e-05  1.0466269e-04\n",
      "   1.6701504e-04 -6.1879909e-05 -1.3540128e-04]]\n",
      "linear.bias:\n",
      " [0.00022764]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04722066e-03 -8.41661822e-05  2.28298832e-05  1.07444626e-04\n",
      "   1.65128426e-04 -4.53165121e-05 -1.35916896e-04]]\n",
      "linear.bias:\n",
      " [0.00022759]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0491238e-03 -8.3180341e-05  2.2409518e-05  1.2294060e-04\n",
      "   1.6599386e-04  4.7249341e-07 -1.3616815e-04]]\n",
      "linear.bias:\n",
      " [0.00022676]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500505e-03 -9.0285044e-05  2.3800381e-05  9.5513686e-05\n",
      "   1.7313275e-04 -1.2746684e-05 -1.3434564e-04]]\n",
      "linear.bias:\n",
      " [0.00022602]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494872e-03 -1.0085135e-04  2.6435053e-05  8.4805484e-05\n",
      "   1.8129655e-04 -2.8056009e-05 -1.3105926e-04]]\n",
      "linear.bias:\n",
      " [0.00022483]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04866258e-03 -1.04627594e-04  2.89418240e-05  1.17099305e-04\n",
      "   1.81365918e-04  7.25547579e-07 -1.31922978e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04599248e-03 -1.03013714e-04  2.94740803e-05  8.16517713e-05\n",
      "   1.75536959e-04 -4.31288245e-05 -1.36545874e-04]]\n",
      "linear.bias:\n",
      " [0.00022259]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434471e-03 -9.6223746e-05  2.9835197e-05  9.9350458e-05\n",
      "   1.6283235e-04 -2.9805447e-05 -1.4437290e-04]]\n",
      "linear.bias:\n",
      " [0.00022148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429888e-03 -9.7011965e-05  3.0059622e-05  1.1976002e-04\n",
      "   1.5486291e-04 -3.4818731e-07 -1.4967787e-04]]\n",
      "linear.bias:\n",
      " [0.00022022]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04574719e-03 -1.01325706e-04  3.10212781e-05  9.84850049e-05\n",
      "   1.55148649e-04 -1.89812145e-05 -1.51144806e-04]]\n",
      "linear.bias:\n",
      " [0.00021882]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510918e-03 -1.1024219e-04  3.2070460e-05  6.8013978e-05\n",
      "   1.6292243e-04 -5.4519638e-05 -1.4828885e-04]]\n",
      "linear.bias:\n",
      " [0.00021757]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05415098e-03 -1.10888381e-04  3.20873696e-05  1.14755436e-04\n",
      "   1.72241547e-04 -1.67731487e-05 -1.43161436e-04]]\n",
      "linear.bias:\n",
      " [0.00021696]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528758e-03 -1.0737951e-04  3.2255939e-05  1.2993081e-04\n",
      "   1.8274460e-04 -4.6948508e-06 -1.3718964e-04]]\n",
      "linear.bias:\n",
      " [0.00021719]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490466e-03 -9.6495874e-05  3.0492049e-05  7.2932409e-05\n",
      "   1.8728880e-04 -5.8257021e-05 -1.3505944e-04]]\n",
      "linear.bias:\n",
      " [0.00021845]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466545e-03 -8.3825616e-05  2.8522261e-05  1.1177167e-04\n",
      "   1.7632017e-04 -1.2444638e-05 -1.3925633e-04]]\n",
      "linear.bias:\n",
      " [0.0002188]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459963e-03 -7.9223719e-05  2.6971498e-05  1.2246757e-04\n",
      "   1.6791173e-04  6.9886974e-06 -1.4259203e-04]]\n",
      "linear.bias:\n",
      " [0.00021964]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446113e-03 -8.3124520e-05  2.7356191e-05  9.0715184e-05\n",
      "   1.6674130e-04 -2.9932426e-05 -1.4353343e-04]]\n",
      "linear.bias:\n",
      " [0.0002204]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464090e-03 -9.6054813e-05  2.7678860e-05  8.5069776e-05\n",
      "   1.6767679e-04 -4.2781834e-05 -1.4277485e-04]]\n",
      "linear.bias:\n",
      " [0.00022003]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471633e-03 -1.1059106e-04  2.8219638e-05  1.1278792e-04\n",
      "   1.6883941e-04 -1.8111341e-05 -1.4195511e-04]]\n",
      "linear.bias:\n",
      " [0.00021969]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0457030e-03 -1.1974739e-04  2.8870949e-05  1.1674860e-04\n",
      "   1.7173866e-04 -1.0167476e-05 -1.3987269e-04]]\n",
      "linear.bias:\n",
      " [0.00022071]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04066206e-03 -1.21653546e-04  2.94260062e-05  8.12874932e-05\n",
      "   1.75858906e-04 -3.33538192e-05 -1.37051698e-04]]\n",
      "linear.bias:\n",
      " [0.00022188]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03592256e-03 -1.13812865e-04  2.94525289e-05  8.92619209e-05\n",
      "   1.75435678e-04 -9.03150612e-06 -1.36337345e-04]]\n",
      "linear.bias:\n",
      " [0.00022399]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0330986e-03 -1.0056186e-04  2.9738332e-05  1.1773010e-04\n",
      "   1.7166875e-04  2.4263618e-05 -1.3717257e-04]]\n",
      "linear.bias:\n",
      " [0.00022563]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0289523e-03 -8.6728396e-05  2.9779823e-05  6.7850226e-05\n",
      "   1.6706614e-04 -5.4287601e-05 -1.4086450e-04]]\n",
      "linear.bias:\n",
      " [0.0002271]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0298539e-03 -7.7726552e-05  3.0088451e-05  1.1946184e-04\n",
      "   1.5499590e-04 -3.6071393e-05 -1.4779705e-04]]\n",
      "linear.bias:\n",
      " [0.00022659]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346785e-03 -8.0960286e-05  2.9642726e-05  1.5522975e-04\n",
      "   1.5082271e-04 -8.5244155e-06 -1.5145939e-04]]\n",
      "linear.bias:\n",
      " [0.00022638]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0344352e-03 -8.9063898e-05  2.8934890e-05  1.0159887e-04\n",
      "   1.5994468e-04 -4.2246378e-05 -1.5130776e-04]]\n",
      "linear.bias:\n",
      " [0.00022541]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374767e-03 -1.0329066e-04  2.7486651e-05  6.3329782e-05\n",
      "   1.7313696e-04 -4.8488513e-05 -1.4879802e-04]]\n",
      "linear.bias:\n",
      " [0.00022375]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0407446e-03 -1.0983746e-04  2.6932208e-05  1.0820248e-04\n",
      "   1.8404637e-04 -7.0870010e-07 -1.4564711e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04582449e-03 -1.15524075e-04  2.62217090e-05  1.16689196e-04\n",
      "   1.93606247e-04  1.78419668e-06 -1.41380617e-04]]\n",
      "linear.bias:\n",
      " [0.00021889]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04394008e-03 -1.09853165e-04  2.45105803e-05  6.28839407e-05\n",
      "   1.96631998e-04 -6.26433248e-05 -1.41458033e-04]]\n",
      "linear.bias:\n",
      " [0.00021814]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04227522e-03 -9.22319014e-05  2.34826275e-05  1.21271776e-04\n",
      "   1.81678130e-04 -1.22237325e-05 -1.48502178e-04]]\n",
      "linear.bias:\n",
      " [0.00021641]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429975e-03 -8.0580059e-05  2.3004370e-05  1.3693498e-04\n",
      "   1.7052954e-04 -2.4292385e-06 -1.5351453e-04]]\n",
      "linear.bias:\n",
      " [0.00021538]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434225e-03 -7.6075929e-05  2.3766130e-05  9.2222464e-05\n",
      "   1.6587118e-04 -4.6662321e-05 -1.5569291e-04]]\n",
      "linear.bias:\n",
      " [0.00021498]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413728e-03 -8.0538572e-05  2.5119713e-05  7.7092765e-05\n",
      "   1.6357155e-04 -5.4148441e-05 -1.5610784e-04]]\n",
      "linear.bias:\n",
      " [0.00021488]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391504e-03 -8.9958863e-05  2.5401985e-05  1.2074737e-04\n",
      "   1.6550007e-04 -1.3592617e-05 -1.5324904e-04]]\n",
      "linear.bias:\n",
      " [0.0002148]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04156684e-03 -1.03413004e-04  2.61274436e-05  1.27676234e-04\n",
      "   1.74409564e-04 -1.75816349e-05 -1.47301340e-04]]\n",
      "linear.bias:\n",
      " [0.00021445]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440694e-03 -1.1751272e-04  2.6168696e-05  8.4154424e-05\n",
      "   1.8351982e-04 -5.7480516e-05 -1.4132110e-04]]\n",
      "linear.bias:\n",
      " [0.0002152]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04515755e-03 -1.18975164e-04  2.54140214e-05  1.04724517e-04\n",
      "   1.81462092e-04 -2.23506759e-05 -1.39603653e-04]]\n",
      "linear.bias:\n",
      " [0.0002172]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452559e-03 -1.0878860e-04  2.5471403e-05  1.2440985e-04\n",
      "   1.7663937e-04  1.5025333e-05 -1.3912804e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430703e-03 -9.7172117e-05  2.5498426e-05  6.5186439e-05\n",
      "   1.7028631e-04 -5.3089971e-05 -1.4223241e-04]]\n",
      "linear.bias:\n",
      " [0.00022368]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04350771e-03 -8.56670667e-05  2.70823693e-05  1.14831266e-04\n",
      "   1.57976217e-04 -2.66163770e-05 -1.47493483e-04]]\n",
      "linear.bias:\n",
      " [0.00022431]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468037e-03 -8.1928338e-05  2.8239057e-05  1.3605518e-04\n",
      "   1.5465506e-04 -1.7438597e-05 -1.4864883e-04]]\n",
      "linear.bias:\n",
      " [0.00022567]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494918e-03 -8.5087231e-05  2.8639208e-05  1.0344884e-04\n",
      "   1.5975881e-04 -4.7711350e-05 -1.4678355e-04]]\n",
      "linear.bias:\n",
      " [0.00022716]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500334e-03 -9.3537092e-05  2.9626954e-05  8.5106803e-05\n",
      "   1.6884389e-04 -4.6882182e-05 -1.4337990e-04]]\n",
      "linear.bias:\n",
      " [0.00022823]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04768237e-03 -1.05019455e-04  3.11118674e-05  1.05162719e-04\n",
      "   1.77236114e-04 -8.82751556e-06 -1.39907366e-04]]\n",
      "linear.bias:\n",
      " [0.0002284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04672951e-03 -1.17816242e-04  3.27962262e-05  9.85094885e-05\n",
      "   1.86772610e-04 -1.25473125e-05 -1.34345551e-04]]\n",
      "linear.bias:\n",
      " [0.00022722]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04669202e-03 -1.15562616e-04  3.28088827e-05  1.03338505e-04\n",
      "   1.90398219e-04 -4.39002724e-06 -1.32099900e-04]]\n",
      "linear.bias:\n",
      " [0.00022643]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0458701e-03 -9.7391021e-05  3.0986361e-05  8.4125051e-05\n",
      "   1.8303281e-04 -3.7365506e-05 -1.3586179e-04]]\n",
      "linear.bias:\n",
      " [0.00022625]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449699e-03 -7.7063574e-05  2.9125093e-05  1.2118580e-04\n",
      "   1.6763261e-04 -1.2776582e-05 -1.4350488e-04]]\n",
      "linear.bias:\n",
      " [0.00022529]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0461459e-03 -6.7204390e-05  2.7825243e-05  1.1726931e-04\n",
      "   1.5886397e-04 -2.6731537e-05 -1.4822691e-04]]\n",
      "linear.bias:\n",
      " [0.00022415]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493246e-03 -7.0676128e-05  2.6423286e-05  9.9661302e-05\n",
      "   1.5639687e-04 -4.4462897e-05 -1.5034883e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0546461e-03 -8.6381238e-05  2.4823672e-05  8.7270979e-05\n",
      "   1.5945772e-04 -4.0227249e-05 -1.5001466e-04]]\n",
      "linear.bias:\n",
      " [0.00022323]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0564931e-03 -1.0602487e-04  2.4569115e-05  1.0872608e-04\n",
      "   1.6640806e-04 -8.2191000e-06 -1.4671906e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0548615e-03 -1.2250700e-04  2.5956022e-05  1.1181000e-04\n",
      "   1.7807119e-04 -8.1622456e-06 -1.4047470e-04]]\n",
      "linear.bias:\n",
      " [0.0002217]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500331e-03 -1.3014510e-04  2.7588845e-05  8.0420927e-05\n",
      "   1.9023717e-04 -4.3193671e-05 -1.3332558e-04]]\n",
      "linear.bias:\n",
      " [0.00022092]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04332610e-03 -1.26203289e-04  2.82420551e-05  1.12749716e-04\n",
      "   1.91120736e-04 -1.73226144e-05 -1.30981090e-04]]\n",
      "linear.bias:\n",
      " [0.00022049]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0372672e-03 -1.0464493e-04  2.7363227e-05  1.2128692e-04\n",
      "   1.8274781e-04 -8.0352638e-06 -1.3406067e-04]]\n",
      "linear.bias:\n",
      " [0.00022224]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0322554e-03 -8.3831335e-05  2.5058886e-05  7.1722781e-05\n",
      "   1.7143774e-04 -4.9486691e-05 -1.3948434e-04]]\n",
      "linear.bias:\n",
      " [0.00022542]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0288093e-03 -7.2523580e-05  2.3156614e-05  8.6326014e-05\n",
      "   1.5711543e-04 -4.0569950e-05 -1.4622787e-04]]\n",
      "linear.bias:\n",
      " [0.00022695]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0303989e-03 -7.1293834e-05  2.0956484e-05  1.2753331e-04\n",
      "   1.4952438e-04 -4.9738919e-06 -1.4929852e-04]]\n",
      "linear.bias:\n",
      " [0.00022645]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0345627e-03 -8.1599079e-05  2.0186586e-05  1.2777279e-04\n",
      "   1.5136570e-04 -2.3342127e-05 -1.4893331e-04]]\n",
      "linear.bias:\n",
      " [0.000226]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425571e-03 -9.6795957e-05  1.9850902e-05  9.4586234e-05\n",
      "   1.6146159e-04 -7.8045297e-05 -1.4475014e-04]]\n",
      "linear.bias:\n",
      " [0.00022559]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04895991e-03 -1.05512685e-04  2.17854886e-05  1.09299544e-04\n",
      "   1.72730928e-04 -3.96546457e-05 -1.41643293e-04]]\n",
      "linear.bias:\n",
      " [0.00022442]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05356227e-03 -1.14553084e-04  2.39960900e-05  1.22898957e-04\n",
      "   1.84940232e-04  2.04228090e-05 -1.38571384e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05088879e-03 -1.10563444e-04  2.61033711e-05  6.32176962e-05\n",
      "   1.91163810e-04 -2.19275607e-05 -1.39680385e-04]]\n",
      "linear.bias:\n",
      " [0.00022502]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478855e-03 -1.0040746e-04  2.7812850e-05  8.3630308e-05\n",
      "   1.8496120e-04 -1.7453567e-05 -1.4466989e-04]]\n",
      "linear.bias:\n",
      " [0.00022552]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426419e-03 -9.3716852e-05  3.0511197e-05  1.3486722e-04\n",
      "   1.7793989e-04  7.1606682e-06 -1.4933369e-04]]\n",
      "linear.bias:\n",
      " [0.0002257]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03552733e-03 -8.98827129e-05  3.24689317e-05  1.07818436e-04\n",
      "   1.72261352e-04 -4.58664290e-05 -1.53894027e-04]]\n",
      "linear.bias:\n",
      " [0.00022559]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0324845e-03 -9.3790717e-05  3.3479129e-05  9.0559908e-05\n",
      "   1.7223951e-04 -7.0741175e-05 -1.5536795e-04]]\n",
      "linear.bias:\n",
      " [0.00022496]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346901e-03 -9.8812889e-05  3.2294978e-05  1.3045367e-04\n",
      "   1.7345454e-04 -2.6229798e-05 -1.5537116e-04]]\n",
      "linear.bias:\n",
      " [0.00022358]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0415100e-03 -1.0581123e-04  3.0405530e-05  1.2939062e-04\n",
      "   1.8049267e-04 -1.5989372e-05 -1.5173802e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483928e-03 -1.1267665e-04  2.7735305e-05  7.6965633e-05\n",
      "   1.8779266e-04 -4.1646370e-05 -1.4733701e-04]]\n",
      "linear.bias:\n",
      " [0.00021968]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541152e-03 -1.1088789e-04  2.4758956e-05  9.3327719e-05\n",
      "   1.8403976e-04 -9.1702495e-06 -1.4670930e-04]]\n",
      "linear.bias:\n",
      " [0.00021855]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05698372e-03 -1.05290135e-04  2.27631917e-05  1.11361165e-04\n",
      "   1.80675095e-04  8.79921754e-06 -1.44500387e-04]]\n",
      "linear.bias:\n",
      " [0.00021862]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541680e-03 -9.8806391e-05  2.3087045e-05  8.1538601e-05\n",
      "   1.7575207e-04 -4.8042763e-05 -1.4313479e-04]]\n",
      "linear.bias:\n",
      " [0.00021868]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487080e-03 -9.0023255e-05  2.4582343e-05  1.0194254e-04\n",
      "   1.6863653e-04 -5.2234060e-05 -1.4246917e-04]]\n",
      "linear.bias:\n",
      " [0.00021847]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409945e-03 -8.6568107e-05  2.6725722e-05  1.4992584e-04\n",
      "   1.6389799e-04 -1.8686434e-05 -1.4095612e-04]]\n",
      "linear.bias:\n",
      " [0.00021827]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0349776e-03 -8.9764602e-05  2.9014102e-05  1.2041231e-04\n",
      "   1.6375161e-04 -4.1231793e-05 -1.3959441e-04]]\n",
      "linear.bias:\n",
      " [0.00022026]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03146979e-03 -1.00387064e-04  3.08736780e-05  8.79553263e-05\n",
      "   1.68500017e-04 -4.29315151e-05 -1.36451214e-04]]\n",
      "linear.bias:\n",
      " [0.00022286]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0321493e-03 -1.0932337e-04  3.2261738e-05  9.3857394e-05\n",
      "   1.7114685e-04 -2.2033273e-06 -1.3511413e-04]]\n",
      "linear.bias:\n",
      " [0.00022439]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0375037e-03 -1.2024873e-04  3.3200984e-05  9.1858448e-05\n",
      "   1.7640092e-04  7.4268955e-06 -1.3165925e-04]]\n",
      "linear.bias:\n",
      " [0.00022523]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483998e-03 -1.1362581e-04  3.2091262e-05  7.7260018e-05\n",
      "   1.7755643e-04 -2.5322284e-05 -1.3029986e-04]]\n",
      "linear.bias:\n",
      " [0.0002249]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0576738e-03 -1.0062156e-04  3.1270931e-05  1.2051470e-04\n",
      "   1.6938009e-04 -1.5787462e-05 -1.3327737e-04]]\n",
      "linear.bias:\n",
      " [0.00022406]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0611281e-03 -8.7816916e-05  3.0017021e-05  1.1728546e-04\n",
      "   1.6340858e-04 -3.8809681e-05 -1.3627995e-04]]\n",
      "linear.bias:\n",
      " [0.00022385]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0611170e-03 -8.0572347e-05  2.9809087e-05  1.0845339e-04\n",
      "   1.6150123e-04 -4.2146137e-05 -1.3794283e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0594421e-03 -7.9397905e-05  3.0379531e-05  1.0177665e-04\n",
      "   1.6431510e-04 -1.9399886e-05 -1.3792499e-04]]\n",
      "linear.bias:\n",
      " [0.00022533]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0562354e-03 -8.8006505e-05  3.1847700e-05  9.5527656e-05\n",
      "   1.7090305e-04  8.2386941e-07 -1.3608061e-04]]\n",
      "linear.bias:\n",
      " [0.00022662]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0559171e-03 -1.0176032e-04  3.3250668e-05  8.8956083e-05\n",
      "   1.7877243e-04 -5.9595266e-07 -1.3256205e-04]]\n",
      "linear.bias:\n",
      " [0.00022642]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541324e-03 -1.1676434e-04  3.5517176e-05  9.1566260e-05\n",
      "   1.8491018e-04 -2.7006297e-05 -1.2879366e-04]]\n",
      "linear.bias:\n",
      " [0.00022543]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502009e-03 -1.1892980e-04  3.7241327e-05  1.3897757e-04\n",
      "   1.8074291e-04 -9.0714111e-06 -1.2998490e-04]]\n",
      "linear.bias:\n",
      " [0.00022453]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04176207e-03 -1.08879074e-04  3.50587579e-05  9.34897107e-05\n",
      "   1.74465938e-04 -6.75252668e-05 -1.35011782e-04]]\n",
      "linear.bias:\n",
      " [0.000224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0360805e-03 -9.3457638e-05  3.2602162e-05  1.0422053e-04\n",
      "   1.6123113e-04 -4.6477740e-05 -1.4367393e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0366734e-03 -8.4993233e-05  2.8993431e-05  1.2971020e-04\n",
      "   1.5377972e-04  2.1716078e-06 -1.4994254e-04]]\n",
      "linear.bias:\n",
      " [0.00022175]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0382923e-03 -8.4663981e-05  2.6891559e-05  9.5997952e-05\n",
      "   1.5652603e-04 -1.1137698e-05 -1.5211948e-04]]\n",
      "linear.bias:\n",
      " [0.00022068]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0426333e-03 -9.1691167e-05  2.5310801e-05  5.3460310e-05\n",
      "   1.6936053e-04 -4.8549529e-05 -1.4805552e-04]]\n",
      "linear.bias:\n",
      " [0.00021916]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496170e-03 -9.6856573e-05  2.4714998e-05  1.3028913e-04\n",
      "   1.7617499e-04  9.8173623e-06 -1.4432571e-04]]\n",
      "linear.bias:\n",
      " [0.00021534]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05273910e-03 -1.03054022e-04  2.54327024e-05  1.21175275e-04\n",
      "   1.81554016e-04 -2.61906098e-05 -1.43142723e-04]]\n",
      "linear.bias:\n",
      " [0.000213]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05133606e-03 -1.08458145e-04  2.68725944e-05  8.46189942e-05\n",
      "   1.87169804e-04 -7.17942094e-05 -1.42250821e-04]]\n",
      "linear.bias:\n",
      " [0.00021307]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500615e-03 -1.0547669e-04  2.7885895e-05  1.3538019e-04\n",
      "   1.7858177e-04 -1.1873406e-05 -1.4673371e-04]]\n",
      "linear.bias:\n",
      " [0.00021341]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482162e-03 -1.0031741e-04  2.7481861e-05  1.0916032e-04\n",
      "   1.7071029e-04 -8.2743636e-06 -1.5144533e-04]]\n",
      "linear.bias:\n",
      " [0.00021563]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04948424e-03 -1.00502366e-04  2.81070843e-05  7.06547726e-05\n",
      "   1.68891740e-04 -3.49246839e-05 -1.52067805e-04]]\n",
      "linear.bias:\n",
      " [0.00021708]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487329e-03 -1.0223060e-04  2.8791996e-05  9.9830009e-05\n",
      "   1.6950905e-04 -2.3156401e-05 -1.5004305e-04]]\n",
      "linear.bias:\n",
      " [0.00021811]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466727e-03 -1.0637191e-04  3.1194519e-05  1.2153946e-04\n",
      "   1.7511405e-04 -2.4152563e-05 -1.4523399e-04]]\n",
      "linear.bias:\n",
      " [0.00021959]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459019e-03 -1.1138013e-04  3.2702123e-05  1.0658370e-04\n",
      "   1.8137076e-04 -4.9765040e-05 -1.3968925e-04]]\n",
      "linear.bias:\n",
      " [0.0002212]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04640669e-03 -1.09135559e-04  3.34990000e-05  1.14854316e-04\n",
      "   1.83287440e-04 -3.00639094e-05 -1.37341878e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453548e-03 -1.0091026e-04  3.4172543e-05  1.1779069e-04\n",
      "   1.8163068e-04  9.2296195e-06 -1.3821742e-04]]\n",
      "linear.bias:\n",
      " [0.00022554]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431769e-03 -8.7161709e-05  3.3405206e-05  5.2278105e-05\n",
      "   1.7451479e-04 -3.7554229e-05 -1.4307503e-04]]\n",
      "linear.bias:\n",
      " [0.00022765]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423646e-03 -8.4206367e-05  3.1945550e-05  9.6542484e-05\n",
      "   1.6040736e-04 -1.5258871e-05 -1.4899878e-04]]\n",
      "linear.bias:\n",
      " [0.00022653]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455303e-03 -9.1496011e-05  3.0606079e-05  1.3360106e-04\n",
      "   1.5310910e-04 -1.1349677e-05 -1.5102200e-04]]\n",
      "linear.bias:\n",
      " [0.00022414]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04936608e-03 -1.02792656e-04  2.84356993e-05  1.15996321e-04\n",
      "   1.56303213e-04 -5.13380146e-05 -1.49039421e-04]]\n",
      "linear.bias:\n",
      " [0.00022117]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516542e-03 -1.1260184e-04  2.6911752e-05  9.2076771e-05\n",
      "   1.6771714e-04 -5.8165781e-05 -1.4452614e-04]]\n",
      "linear.bias:\n",
      " [0.0002196]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0518910e-03 -1.1171992e-04  2.5054613e-05  1.1145826e-04\n",
      "   1.7646576e-04 -1.2643963e-05 -1.4140971e-04]]\n",
      "linear.bias:\n",
      " [0.00021901]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478634e-03 -1.0662475e-04  2.3543735e-05  1.0197495e-04\n",
      "   1.8656437e-04  6.4350952e-06 -1.3717776e-04]]\n",
      "linear.bias:\n",
      " [0.0002193]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416204e-03 -9.9272846e-05  2.3926119e-05  7.1613918e-05\n",
      "   1.9080083e-04 -3.5040786e-05 -1.3370859e-04]]\n",
      "linear.bias:\n",
      " [0.00021984]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0376869e-03 -9.0264308e-05  2.4169842e-05  1.1681592e-04\n",
      "   1.8115937e-04 -1.0822725e-05 -1.3598353e-04]]\n",
      "linear.bias:\n",
      " [0.0002195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363219e-03 -8.5853266e-05  2.4156187e-05  1.0980409e-04\n",
      "   1.7207151e-04 -3.1332405e-05 -1.3867930e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0372775e-03 -8.8866960e-05  2.4062327e-05  9.8533186e-05\n",
      "   1.6765809e-04 -3.3605447e-05 -1.3960106e-04]]\n",
      "linear.bias:\n",
      " [0.00022209]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405083e-03 -9.7606520e-05  2.3712051e-05  1.0941942e-04\n",
      "   1.6482186e-04 -6.4850065e-06 -1.3963369e-04]]\n",
      "linear.bias:\n",
      " [0.00022262]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468168e-03 -1.0955407e-04  2.4299330e-05  9.3698844e-05\n",
      "   1.6743499e-04 -1.7183345e-05 -1.3638470e-04]]\n",
      "linear.bias:\n",
      " [0.00022256]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0509106e-03 -1.2389990e-04  2.6193962e-05  9.9377299e-05\n",
      "   1.7147919e-04 -2.0757574e-05 -1.3224987e-04]]\n",
      "linear.bias:\n",
      " [0.00022194]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05350895e-03 -1.23231745e-04  2.78788266e-05  1.10371584e-04\n",
      "   1.73296474e-04 -3.77528704e-06 -1.29661290e-04]]\n",
      "linear.bias:\n",
      " [0.00022194]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0517612e-03 -1.0275504e-04  2.8528266e-05  6.9015456e-05\n",
      "   1.6841499e-04 -4.9314938e-05 -1.3184134e-04]]\n",
      "linear.bias:\n",
      " [0.00022222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0490381e-03 -8.1038525e-05  2.8908962e-05  1.0930529e-04\n",
      "   1.5840821e-04 -2.3399074e-05 -1.3705294e-04]]\n",
      "linear.bias:\n",
      " [0.00022081]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478495e-03 -7.0339534e-05  2.9202616e-05  1.3342647e-04\n",
      "   1.5400026e-04 -3.9301613e-06 -1.4009712e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422671e-03 -7.2122093e-05  2.9066516e-05  9.3317183e-05\n",
      "   1.5877011e-04 -3.6176236e-05 -1.4113501e-04]]\n",
      "linear.bias:\n",
      " [0.00022025]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0396665e-03 -8.4745596e-05  2.8357894e-05  7.5865697e-05\n",
      "   1.6568329e-04 -3.7275709e-05 -1.4034924e-04]]\n",
      "linear.bias:\n",
      " [0.00021959]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03866635e-03 -1.01750964e-04  2.83199370e-05  1.10289402e-04\n",
      "   1.71749605e-04 -5.45610601e-06 -1.39052805e-04]]\n",
      "linear.bias:\n",
      " [0.00021871]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411596e-03 -1.2058102e-04  2.8792439e-05  1.1124665e-04\n",
      "   1.8078508e-04 -1.4451278e-05 -1.3571008e-04]]\n",
      "linear.bias:\n",
      " [0.00021793]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04485778e-03 -1.21052006e-04  2.80494769e-05  8.67024210e-05\n",
      "   1.85277502e-04 -3.74696901e-05 -1.34714035e-04]]\n",
      "linear.bias:\n",
      " [0.00021888]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04689237e-03 -1.10632849e-04  2.69114043e-05  1.11976886e-04\n",
      "   1.80536445e-04 -7.68081736e-06 -1.37589857e-04]]\n",
      "linear.bias:\n",
      " [0.00022058]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0453165e-03 -9.8314595e-05  2.6325628e-05  9.0519810e-05\n",
      "   1.7519265e-04 -1.6708409e-05 -1.4035260e-04]]\n",
      "linear.bias:\n",
      " [0.00022294]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423010e-03 -9.0831039e-05  2.7172302e-05  9.1066846e-05\n",
      "   1.7208219e-04 -1.8764009e-05 -1.4162372e-04]]\n",
      "linear.bias:\n",
      " [0.00022451]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0412824e-03 -9.1005946e-05  2.8115957e-05  1.0695994e-04\n",
      "   1.7164875e-04 -1.3652430e-05 -1.4087794e-04]]\n",
      "linear.bias:\n",
      " [0.00022509]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433441e-03 -9.6073476e-05  2.9971385e-05  1.0629873e-04\n",
      "   1.7661559e-04 -3.9125349e-05 -1.3652540e-04]]\n",
      "linear.bias:\n",
      " [0.00022505]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435894e-03 -1.0073699e-04  3.1301905e-05  1.2090578e-04\n",
      "   1.7948146e-04 -2.8279890e-05 -1.3371235e-04]]\n",
      "linear.bias:\n",
      " [0.00022557]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0435985e-03 -1.0834449e-04  3.1028845e-05  1.0848224e-04\n",
      "   1.8084569e-04 -2.3485169e-05 -1.3222694e-04]]\n",
      "linear.bias:\n",
      " [0.00022605]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04508002e-03 -1.06913649e-04  3.06998518e-05  1.03592974e-04\n",
      "   1.78429749e-04  1.95188113e-06 -1.33525667e-04]]\n",
      "linear.bias:\n",
      " [0.00022619]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0465640e-03 -1.0268109e-04  2.9846185e-05  6.5654443e-05\n",
      "   1.7316111e-04 -3.4974932e-05 -1.3451400e-04]]\n",
      "linear.bias:\n",
      " [0.00022521]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471073e-03 -9.5034236e-05  2.9357849e-05  1.1278209e-04\n",
      "   1.6261850e-04 -1.7552289e-05 -1.3759492e-04]]\n",
      "linear.bias:\n",
      " [0.00022321]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501987e-03 -9.2849645e-05  2.9485333e-05  1.3230360e-04\n",
      "   1.5785242e-04 -2.6484258e-05 -1.3750649e-04]]\n",
      "linear.bias:\n",
      " [0.00022141]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05147844e-03 -9.80274781e-05  2.87474359e-05  1.06052066e-04\n",
      "   1.61351272e-04 -5.84142617e-05 -1.34713890e-04]]\n",
      "linear.bias:\n",
      " [0.00022062]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507213e-03 -1.0415374e-04  2.8331817e-05  9.1251102e-05\n",
      "   1.6713627e-04 -4.4548062e-05 -1.3207401e-04]]\n",
      "linear.bias:\n",
      " [0.00022075]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04991021e-03 -1.04361032e-04  2.81223802e-05  1.15139075e-04\n",
      "   1.69522638e-04  1.56913411e-05 -1.31877096e-04]]\n",
      "linear.bias:\n",
      " [0.00022059]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0455122e-03 -1.0442159e-04  2.7617540e-05  7.0236376e-05\n",
      "   1.6940995e-04 -2.5150312e-05 -1.3555786e-04]]\n",
      "linear.bias:\n",
      " [0.00022073]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430728e-03 -1.0099412e-04  2.8359449e-05  8.3855870e-05\n",
      "   1.6727383e-04 -2.0331978e-05 -1.4005091e-04]]\n",
      "linear.bias:\n",
      " [0.00022029]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04000140e-03 -1.00688216e-04  2.97785100e-05  1.30721193e-04\n",
      "   1.66124868e-04  6.41512270e-06 -1.43667770e-04]]\n",
      "linear.bias:\n",
      " [0.00021933]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406197e-03 -1.0293097e-04  3.1204814e-05  1.0705656e-04\n",
      "   1.6932731e-04 -3.0566021e-05 -1.4587036e-04]]\n",
      "linear.bias:\n",
      " [0.00021988]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0433957e-03 -1.1204402e-04  3.2406282e-05  8.0761965e-05\n",
      "   1.7603995e-04 -4.7578949e-05 -1.4632425e-04]]\n",
      "linear.bias:\n",
      " [0.00022092]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04422844e-03 -1.10550245e-04  3.30549046e-05  1.08950015e-04\n",
      "   1.78843009e-04 -1.28059910e-05 -1.47559113e-04]]\n",
      "linear.bias:\n",
      " [0.00022271]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459333e-03 -1.0789331e-04  3.2769862e-05  1.1267174e-04\n",
      "   1.8382697e-04 -5.1821553e-06 -1.4636193e-04]]\n",
      "linear.bias:\n",
      " [0.00022487]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0481869e-03 -1.0586931e-04  3.2361302e-05  8.1341292e-05\n",
      "   1.8994941e-04 -3.5147597e-05 -1.4345381e-04]]\n",
      "linear.bias:\n",
      " [0.00022627]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05001964e-03 -9.66704029e-05  3.16178957e-05  1.08674074e-04\n",
      "   1.84618082e-04 -8.16804459e-06 -1.45026570e-04]]\n",
      "linear.bias:\n",
      " [0.00022752]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528987e-03 -9.0978545e-05  3.1315092e-05  1.0827845e-04\n",
      "   1.8190609e-04 -2.2258788e-05 -1.4387256e-04]]\n",
      "linear.bias:\n",
      " [0.00022724]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0555317e-03 -9.2752118e-05  3.0491956e-05  1.0007760e-04\n",
      "   1.8060557e-04 -4.1656320e-05 -1.4157078e-04]]\n",
      "linear.bias:\n",
      " [0.00022643]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0547596e-03 -9.5157011e-05  2.9614383e-05  1.2069233e-04\n",
      "   1.7717676e-04 -2.2466842e-05 -1.4016120e-04]]\n",
      "linear.bias:\n",
      " [0.00022598]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05458766e-03 -9.78982134e-05  2.82049696e-05  1.02636826e-04\n",
      "   1.74606306e-04 -3.11859440e-05 -1.37750729e-04]]\n",
      "linear.bias:\n",
      " [0.00022557]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05240510e-03 -1.03096005e-04  2.72974648e-05  1.07873304e-04\n",
      "   1.71334774e-04 -1.62139586e-05 -1.35858223e-04]]\n",
      "linear.bias:\n",
      " [0.00022465]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0474527e-03 -1.0909054e-04  2.7608530e-05  8.7382949e-05\n",
      "   1.7117446e-04 -2.6854474e-05 -1.3245091e-04]]\n",
      "linear.bias:\n",
      " [0.00022409]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04276673e-03 -1.08087464e-04  2.80584518e-05  1.06580759e-04\n",
      "   1.66884303e-04 -3.30503281e-06 -1.32024405e-04]]\n",
      "linear.bias:\n",
      " [0.00022303]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0419963e-03 -1.1075846e-04  2.8978546e-05  9.3615483e-05\n",
      "   1.6665224e-04 -1.9991065e-05 -1.2942954e-04]]\n",
      "linear.bias:\n",
      " [0.00022207]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0424113e-03 -1.0631044e-04  2.9719353e-05  1.0995462e-04\n",
      "   1.6300533e-04 -6.3822581e-06 -1.2912578e-04]]\n",
      "linear.bias:\n",
      " [0.00022093]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459748e-03 -1.0648707e-04  3.1032414e-05  9.3493130e-05\n",
      "   1.6384553e-04 -3.4084238e-05 -1.2718530e-04]]\n",
      "linear.bias:\n",
      " [0.00022018]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05043023e-03 -9.98281175e-05  3.16885998e-05  1.02019425e-04\n",
      "   1.60648648e-04 -1.45458398e-05 -1.28826752e-04]]\n",
      "linear.bias:\n",
      " [0.00021979]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0517363e-03 -9.8540135e-05  3.2986110e-05  1.0164932e-04\n",
      "   1.5997374e-04  2.5359004e-06 -1.3026617e-04]]\n",
      "linear.bias:\n",
      " [0.00022085]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0539270e-03 -1.0347746e-04  3.4829052e-05  6.8962807e-05\n",
      "   1.6469338e-04 -2.1311138e-05 -1.3000556e-04]]\n",
      "linear.bias:\n",
      " [0.00022237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0531372e-03 -1.0864727e-04  3.6296893e-05  1.0392179e-04\n",
      "   1.6836671e-04 -1.4925334e-05 -1.2951279e-04]]\n",
      "linear.bias:\n",
      " [0.00022346]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04943500e-03 -1.10270266e-04  3.66368949e-05  1.24791142e-04\n",
      "   1.72178494e-04 -1.02347949e-05 -1.29601482e-04]]\n",
      "linear.bias:\n",
      " [0.00022557]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425549e-03 -1.0222279e-04  3.3372300e-05  8.0219252e-05\n",
      "   1.7437112e-04 -5.5502547e-05 -1.3209161e-04]]\n",
      "linear.bias:\n",
      " [0.00022775]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374086e-03 -8.9775385e-05  2.9762683e-05  1.0433584e-04\n",
      "   1.6603891e-04 -2.8868759e-05 -1.3981368e-04]]\n",
      "linear.bias:\n",
      " [0.0002283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346008e-03 -8.5585154e-05  2.6354523e-05  1.3233491e-04\n",
      "   1.6149727e-04  4.7169815e-06 -1.4511871e-04]]\n",
      "linear.bias:\n",
      " [0.00022795]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03330659e-03 -8.91132004e-05  2.41199941e-05  1.05074745e-04\n",
      "   1.64955360e-04 -2.04367043e-05 -1.46428429e-04]]\n",
      "linear.bias:\n",
      " [0.00022706]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0368299e-03 -9.6870615e-05  2.2696819e-05  6.8202280e-05\n",
      "   1.7420645e-04 -6.7832865e-05 -1.4345451e-04]]\n",
      "linear.bias:\n",
      " [0.00022541]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0442012e-03 -1.0381670e-04  2.2768514e-05  1.3469302e-04\n",
      "   1.7247249e-04 -1.0861255e-05 -1.4474128e-04]]\n",
      "linear.bias:\n",
      " [0.00022166]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0517018e-03 -1.1243586e-04  2.3607461e-05  1.3331114e-04\n",
      "   1.7183633e-04 -1.2062628e-05 -1.4539047e-04]]\n",
      "linear.bias:\n",
      " [0.00021913]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0524987e-03 -1.1139435e-04  2.5230498e-05  7.0253911e-05\n",
      "   1.6996831e-04 -6.1240004e-05 -1.4667111e-04]]\n",
      "linear.bias:\n",
      " [0.00021798]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0524977e-03 -9.7022617e-05  2.6405436e-05  9.4768300e-05\n",
      "   1.6420736e-04 -2.4395591e-05 -1.4892180e-04]]\n",
      "linear.bias:\n",
      " [0.00021781]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0506045e-03 -8.9353067e-05  2.8861248e-05  1.3104441e-04\n",
      "   1.6213689e-04  2.5676538e-05 -1.4876733e-04]]\n",
      "linear.bias:\n",
      " [0.00021794]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439025e-03 -8.2805702e-05  3.1650445e-05  7.3062212e-05\n",
      "   1.6641912e-04 -5.4494001e-05 -1.4880997e-04]]\n",
      "linear.bias:\n",
      " [0.00021919]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0377999e-03 -8.2661500e-05  3.3098029e-05  8.0366146e-05\n",
      "   1.7241492e-04 -6.4969849e-05 -1.4646372e-04]]\n",
      "linear.bias:\n",
      " [0.00022088]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0323285e-03 -8.9080895e-05  3.3873039e-05  1.4581086e-04\n",
      "   1.7627804e-04 -5.9222548e-06 -1.4461242e-04]]\n",
      "linear.bias:\n",
      " [0.00022241]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0296623e-03 -9.7862932e-05  3.3139338e-05  1.3177271e-04\n",
      "   1.8067336e-04 -6.1693181e-06 -1.4305113e-04]]\n",
      "linear.bias:\n",
      " [0.00022464]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0292532e-03 -1.0431976e-04  3.0437262e-05  5.1015508e-05\n",
      "   1.8360659e-04 -5.2137850e-05 -1.4236235e-04]]\n",
      "linear.bias:\n",
      " [0.00022722]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03478204e-03 -1.07916174e-04  2.88482970e-05  1.11568515e-04\n",
      "   1.73590539e-04  1.12156886e-05 -1.44831589e-04]]\n",
      "linear.bias:\n",
      " [0.00022583]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04258081e-03 -1.09594825e-04  2.68981785e-05  1.30721892e-04\n",
      "   1.67387581e-04  1.34285756e-05 -1.44886246e-04]]\n",
      "linear.bias:\n",
      " [0.00022287]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476111e-03 -1.0398288e-04  2.5307725e-05  7.5294221e-05\n",
      "   1.6358162e-04 -7.7916025e-05 -1.4493773e-04]]\n",
      "linear.bias:\n",
      " [0.00021935]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0547859e-03 -9.2332150e-05  2.4768895e-05  1.0766178e-04\n",
      "   1.5909092e-04 -5.4203243e-05 -1.4622751e-04]]\n",
      "linear.bias:\n",
      " [0.00021561]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0596621e-03 -8.6753709e-05  2.5327123e-05  1.3466706e-04\n",
      "   1.6044697e-04 -1.6451377e-06 -1.4573860e-04]]\n",
      "linear.bias:\n",
      " [0.00021338]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0600294e-03 -8.8625238e-05  2.6676213e-05  9.8124256e-05\n",
      "   1.7192414e-04 -1.0337972e-05 -1.4250561e-04]]\n",
      "linear.bias:\n",
      " [0.00021281]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0577596e-03 -9.5648342e-05  2.9312527e-05  7.2992596e-05\n",
      "   1.8515020e-04 -1.9001247e-05 -1.3757247e-04]]\n",
      "linear.bias:\n",
      " [0.00021286]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0530989e-03 -9.9770317e-05  3.0944189e-05  1.1072070e-04\n",
      "   1.9001935e-04  1.3265417e-06 -1.3413883e-04]]\n",
      "linear.bias:\n",
      " [0.00021405]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441716e-03 -9.7095515e-05  3.1953085e-05  9.6041935e-05\n",
      "   1.8565127e-04 -4.5287725e-05 -1.3553649e-04]]\n",
      "linear.bias:\n",
      " [0.00021742]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363496e-03 -8.7809400e-05  3.3002812e-05  1.2084652e-04\n",
      "   1.7450500e-04 -3.9092502e-05 -1.4028848e-04]]\n",
      "linear.bias:\n",
      " [0.00022131]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0310914e-03 -8.3749124e-05  3.2750933e-05  1.3541017e-04\n",
      "   1.6556568e-04 -1.5845717e-05 -1.4418148e-04]]\n",
      "linear.bias:\n",
      " [0.00022596]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0291587e-03 -8.6067368e-05  3.2372682e-05  9.2776885e-05\n",
      "   1.6392604e-04 -3.7072146e-05 -1.4471843e-04]]\n",
      "linear.bias:\n",
      " [0.00022986]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352168e-03 -9.5819967e-05  3.0955383e-05  7.6999713e-05\n",
      "   1.6650872e-04 -3.2221065e-05 -1.4383497e-04]]\n",
      "linear.bias:\n",
      " [0.00023136]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0471500e-03 -1.1252339e-04  2.8378616e-05  1.0708928e-04\n",
      "   1.7084149e-04  2.0649168e-06 -1.4155824e-04]]\n",
      "linear.bias:\n",
      " [0.00023128]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06114126e-03 -1.28018364e-04  2.62140184e-05  1.05479594e-04\n",
      "   1.79607363e-04 -1.40812899e-05 -1.35949536e-04]]\n",
      "linear.bias:\n",
      " [0.00022891]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0695306e-03 -1.2569470e-04  2.4600953e-05  8.3614083e-05\n",
      "   1.8564041e-04 -4.1034276e-05 -1.3227876e-04]]\n",
      "linear.bias:\n",
      " [0.00022562]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0715069e-03 -1.1162836e-04  2.3091405e-05  1.2081614e-04\n",
      "   1.7914888e-04 -7.9203528e-06 -1.3303215e-04]]\n",
      "linear.bias:\n",
      " [0.00022209]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0629944e-03 -9.0192596e-05  2.1080956e-05  9.1775401e-05\n",
      "   1.6981499e-04 -3.5327983e-05 -1.3672606e-04]]\n",
      "linear.bias:\n",
      " [0.00022006]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525995e-03 -7.4682437e-05  2.0247906e-05  9.6342737e-05\n",
      "   1.6193010e-04 -2.4912839e-05 -1.3954747e-04]]\n",
      "linear.bias:\n",
      " [0.00021794]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0418657e-03 -7.1114242e-05  2.0813946e-05  1.1128081e-04\n",
      "   1.5884012e-04 -9.3852905e-06 -1.3971518e-04]]\n",
      "linear.bias:\n",
      " [0.00021661]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0355548e-03 -7.8795892e-05  2.2867134e-05  9.6500997e-05\n",
      "   1.6265974e-04 -3.4603348e-05 -1.3778162e-04]]\n",
      "linear.bias:\n",
      " [0.00021599]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0341519e-03 -9.6021169e-05  2.3651888e-05  9.6520969e-05\n",
      "   1.6799489e-04 -3.3120836e-05 -1.3491968e-04]]\n",
      "linear.bias:\n",
      " [0.00021572]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03360380e-03 -1.13885035e-04  2.46809050e-05  1.18902768e-04\n",
      "   1.73072258e-04  2.16963599e-06 -1.32893358e-04]]\n",
      "linear.bias:\n",
      " [0.00021605]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352202e-03 -1.2718723e-04  2.4775800e-05  8.3310355e-05\n",
      "   1.7517572e-04 -3.2593871e-05 -1.3416703e-04]]\n",
      "linear.bias:\n",
      " [0.00021837]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0359907e-03 -1.2740052e-04  2.4163302e-05  9.6611395e-05\n",
      "   1.7052004e-04 -1.8303483e-05 -1.3803084e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392085e-03 -1.1246491e-04  2.3666071e-05  1.1664181e-04\n",
      "   1.6580653e-04  2.8917657e-06 -1.4209261e-04]]\n",
      "linear.bias:\n",
      " [0.00022534]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0463780e-03 -9.9891389e-05  2.3853616e-05  9.6661432e-05\n",
      "   1.6884475e-04 -2.0433810e-05 -1.4219469e-04]]\n",
      "linear.bias:\n",
      " [0.00022731]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0513826e-03 -9.2949718e-05  2.5419624e-05  9.1807524e-05\n",
      "   1.7520468e-04 -3.3856286e-05 -1.4037819e-04]]\n",
      "linear.bias:\n",
      " [0.00022822]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0531455e-03 -9.0509471e-05  2.7811971e-05  1.1824711e-04\n",
      "   1.8145400e-04 -1.0765749e-05 -1.3823519e-04]]\n",
      "linear.bias:\n",
      " [0.00022875]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05470757e-03 -9.18504375e-05  3.03973084e-05  1.01729056e-04\n",
      "   1.88638151e-04 -2.70561304e-05 -1.34788977e-04]]\n",
      "linear.bias:\n",
      " [0.00022893]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0535198e-03 -9.3315575e-05  3.2739026e-05  1.0814310e-04\n",
      "   1.9108820e-04 -1.4590857e-05 -1.3373290e-04]]\n",
      "linear.bias:\n",
      " [0.00022794]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0521531e-03 -9.8033590e-05  3.3117514e-05  9.2449343e-05\n",
      "   1.8750917e-04 -1.4922205e-05 -1.3524684e-04]]\n",
      "linear.bias:\n",
      " [0.00022734]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0496095e-03 -1.0310187e-04  3.3869299e-05  9.7328535e-05\n",
      "   1.7998746e-04 -1.5003934e-06 -1.3802410e-04]]\n",
      "linear.bias:\n",
      " [0.00022651]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04987633e-03 -1.11787995e-04  3.48687900e-05  9.98584437e-05\n",
      "   1.75120542e-04 -1.50564592e-05 -1.37757728e-04]]\n",
      "linear.bias:\n",
      " [0.00022489]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0482850e-03 -1.1692590e-04  3.4598208e-05  1.0985573e-04\n",
      "   1.6950732e-04 -2.3396689e-05 -1.3765648e-04]]\n",
      "linear.bias:\n",
      " [0.00022459]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04421668e-03 -1.15580056e-04  3.40305232e-05  1.04535386e-04\n",
      "   1.67021251e-04 -2.74442882e-05 -1.36359988e-04]]\n",
      "linear.bias:\n",
      " [0.00022577]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413919e-03 -1.0175381e-04  3.2551397e-05  1.0890059e-04\n",
      "   1.6285569e-04 -3.5225275e-06 -1.3752939e-04]]\n",
      "linear.bias:\n",
      " [0.00022713]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437897e-03 -9.2903872e-05  3.1692402e-05  8.6154258e-05\n",
      "   1.6571621e-04 -1.8184201e-05 -1.3461687e-04]]\n",
      "linear.bias:\n",
      " [0.00022748]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512875e-03 -9.3366194e-05  3.0341131e-05  9.2852839e-05\n",
      "   1.6949461e-04 -1.4232566e-05 -1.3135209e-04]]\n",
      "linear.bias:\n",
      " [0.00022634]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0555253e-03 -9.8011726e-05  2.9948995e-05  1.1418143e-04\n",
      "   1.7343934e-04 -9.4538918e-06 -1.2726549e-04]]\n",
      "linear.bias:\n",
      " [0.00022531]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05284876e-03 -1.00208694e-04  2.98567302e-05  7.66301819e-05\n",
      "   1.75017994e-04 -4.98935879e-05 -1.26207218e-04]]\n",
      "linear.bias:\n",
      " [0.00022555]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0488944e-03 -9.5800795e-05  2.9042038e-05  1.0997943e-04\n",
      "   1.6385359e-04 -2.5289799e-05 -1.3055225e-04]]\n",
      "linear.bias:\n",
      " [0.00022519]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0431894e-03 -9.6440250e-05  2.9377066e-05  1.3653441e-04\n",
      "   1.5738397e-04  7.2983967e-06 -1.3325064e-04]]\n",
      "linear.bias:\n",
      " [0.00022544]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0335814e-03 -9.7032360e-05  2.9061895e-05  7.4379808e-05\n",
      "   1.5810681e-04 -5.3410538e-05 -1.3637863e-04]]\n",
      "linear.bias:\n",
      " [0.00022509]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0285376e-03 -9.7075012e-05  2.8997099e-05  7.4580843e-05\n",
      "   1.5602782e-04 -5.2297448e-05 -1.4170814e-04]]\n",
      "linear.bias:\n",
      " [0.00022389]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0286549e-03 -9.5496282e-05  2.9902809e-05  1.3089113e-04\n",
      "   1.5648223e-04 -2.7344904e-06 -1.4622345e-04]]\n",
      "linear.bias:\n",
      " [0.00022136]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0328294e-03 -9.7312964e-05  3.1235970e-05  1.2621284e-04\n",
      "   1.6491114e-04 -8.5041320e-06 -1.4671902e-04]]\n",
      "linear.bias:\n",
      " [0.00021878]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408513e-03 -1.0500669e-04  3.1920441e-05  8.0455866e-05\n",
      "   1.8002087e-04 -4.8943475e-05 -1.4372240e-04]]\n",
      "linear.bias:\n",
      " [0.00021676]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475196e-03 -1.0434897e-04  3.2278131e-05  9.8489050e-05\n",
      "   1.8458015e-04 -3.0493497e-05 -1.4396961e-04]]\n",
      "linear.bias:\n",
      " [0.00021552]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05353328e-03 -1.03823004e-04  3.19576175e-05  1.32111061e-04\n",
      "   1.86317222e-04  1.59237406e-05 -1.45090438e-04]]\n",
      "linear.bias:\n",
      " [0.00021586]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0557986e-03 -9.9168166e-05  3.0320642e-05  7.0973409e-05\n",
      "   1.8278103e-04 -4.2562206e-05 -1.5071800e-04]]\n",
      "linear.bias:\n",
      " [0.00021793]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0569480e-03 -8.9333298e-05  2.9225201e-05  7.9530080e-05\n",
      "   1.7342436e-04 -4.4403932e-05 -1.5743819e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0542242e-03 -8.4810395e-05  2.8723993e-05  1.3473694e-04\n",
      "   1.6794489e-04 -4.8225229e-06 -1.6051003e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507468e-03 -8.8762397e-05  2.8558057e-05  1.2910466e-04\n",
      "   1.7279488e-04 -2.3198905e-05 -1.5931972e-04]]\n",
      "linear.bias:\n",
      " [0.00022397]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "Epoch [4500/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0500187e-03 -9.8082804e-05  2.7774828e-05  8.1406382e-05\n",
      "   1.8447211e-04 -7.5002921e-05 -1.5462295e-04]]\n",
      "linear.bias:\n",
      " [0.00022494]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04877725e-03 -1.00574136e-04  2.76384053e-05  1.15855873e-04\n",
      "   1.83478391e-04 -2.88760166e-05 -1.54044639e-04]]\n",
      "linear.bias:\n",
      " [0.00022405]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04574556e-03 -1.02092235e-04  2.78204316e-05  1.30826593e-04\n",
      "   1.84533186e-04  1.18547578e-05 -1.52295441e-04]]\n",
      "linear.bias:\n",
      " [0.00022442]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399217e-03 -1.0317102e-04  2.9512996e-05  7.8204488e-05\n",
      "   1.8444653e-04 -3.9976945e-05 -1.5137518e-04]]\n",
      "linear.bias:\n",
      " [0.00022446]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352760e-03 -9.9900833e-05  3.2223867e-05  9.4455892e-05\n",
      "   1.7984392e-04 -3.9112059e-05 -1.5156528e-04]]\n",
      "linear.bias:\n",
      " [0.00022391]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0354348e-03 -1.0272934e-04  3.3664448e-05  1.3260938e-04\n",
      "   1.7673790e-04 -7.6402684e-06 -1.5124983e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03813550e-03 -1.04747276e-04  3.29548020e-05  1.05585910e-04\n",
      "   1.75945184e-04 -2.20907496e-05 -1.49745960e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04266929e-03 -1.11046415e-04  3.20486542e-05  7.21535980e-05\n",
      "   1.77671609e-04 -4.44914513e-05 -1.46272869e-04]]\n",
      "linear.bias:\n",
      " [0.00022156]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0464176e-03 -1.1039211e-04  3.1320742e-05  1.0066473e-04\n",
      "   1.7287710e-04 -9.9305835e-06 -1.4506918e-04]]\n",
      "linear.bias:\n",
      " [0.0002213]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04813371e-03 -1.07512395e-04  3.18819766e-05  1.16712472e-04\n",
      "   1.72282438e-04 -5.64426819e-06 -1.40978154e-04]]\n",
      "linear.bias:\n",
      " [0.00022107]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0495264e-03 -1.0270346e-04  3.1417319e-05  9.1045345e-05\n",
      "   1.7412714e-04 -3.4450026e-05 -1.3594917e-04]]\n",
      "linear.bias:\n",
      " [0.00022144]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504808e-03 -9.1860689e-05  3.0613468e-05  1.0268356e-04\n",
      "   1.7112971e-04 -1.4426127e-05 -1.3378811e-04]]\n",
      "linear.bias:\n",
      " [0.00022208]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0533943e-03 -8.9091052e-05  2.9591076e-05  1.0473332e-04\n",
      "   1.6988251e-04 -3.7018926e-06 -1.3064878e-04]]\n",
      "linear.bias:\n",
      " [0.00022294]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0567976e-03 -9.3764327e-05  2.9061350e-05  8.3839463e-05\n",
      "   1.7199692e-04 -2.1888669e-05 -1.2732044e-04]]\n",
      "linear.bias:\n",
      " [0.00022372]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05650048e-03 -1.00980265e-04  2.94444326e-05  9.62401100e-05\n",
      "   1.71457068e-04 -1.10580240e-05 -1.25661201e-04]]\n",
      "linear.bias:\n",
      " [0.00022413]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05467567e-03 -1.10270630e-04  3.04986734e-05  1.19697834e-04\n",
      "   1.69735591e-04  4.75129309e-06 -1.25018181e-04]]\n",
      "linear.bias:\n",
      " [0.0002242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04288454e-03 -1.05607316e-04  2.94517067e-05  7.30401080e-05\n",
      "   1.64082041e-04 -5.76377788e-05 -1.29989712e-04]]\n",
      "linear.bias:\n",
      " [0.00022515]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0332615e-03 -9.4838564e-05  2.8337652e-05  1.0605334e-04\n",
      "   1.5100504e-04 -2.3401462e-05 -1.3868348e-04]]\n",
      "linear.bias:\n",
      " [0.00022542]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02865719e-03 -9.07963840e-05  2.75869588e-05  1.21831894e-04\n",
      "   1.47250801e-04 -2.45901538e-06 -1.42947334e-04]]\n",
      "linear.bias:\n",
      " [0.00022595]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02897617e-03 -9.25836066e-05  2.69683715e-05  1.01112106e-04\n",
      "   1.54098612e-04 -2.85464212e-05 -1.43523270e-04]]\n",
      "linear.bias:\n",
      " [0.00022584]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0333225e-03 -1.0112567e-04  2.6277961e-05  8.9573172e-05\n",
      "   1.6613241e-04 -4.0242146e-05 -1.4108344e-04]]\n",
      "linear.bias:\n",
      " [0.00022485]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03762746e-03 -1.11969726e-04  2.57769589e-05  1.06222593e-04\n",
      "   1.77893555e-04 -1.69002851e-05 -1.38620846e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0412369e-03 -1.1945167e-04  2.5904343e-05  1.0748595e-04\n",
      "   1.8890275e-04 -5.0136678e-06 -1.3581522e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04451377e-03 -1.05468695e-04  2.62715312e-05  8.40222128e-05\n",
      "   1.91207873e-04 -4.15525064e-05 -1.36669900e-04]]\n",
      "linear.bias:\n",
      " [0.00022306]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472519e-03 -8.6879991e-05  2.6148433e-05  1.2513081e-04\n",
      "   1.8041499e-04 -1.7341748e-05 -1.4313702e-04]]\n",
      "linear.bias:\n",
      " [0.00022235]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504427e-03 -7.4711701e-05  2.6503922e-05  1.2014687e-04\n",
      "   1.7315504e-04 -3.3543161e-05 -1.4772239e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0564466e-03 -7.7220233e-05  2.6495358e-05  1.0567158e-04\n",
      "   1.7295871e-04 -3.6075689e-05 -1.4946844e-04]]\n",
      "linear.bias:\n",
      " [0.00022229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0602989e-03 -8.8260538e-05  2.7387036e-05  1.0546848e-04\n",
      "   1.7501527e-04 -1.5831787e-05 -1.4935626e-04]]\n",
      "linear.bias:\n",
      " [0.00022284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06207887e-03 -1.01347076e-04  3.02284407e-05  9.80387777e-05\n",
      "   1.82821837e-04 -1.90065875e-05 -1.45317637e-04]]\n",
      "linear.bias:\n",
      " [0.00022304]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0601678e-03 -1.1535589e-04  3.2517262e-05  1.0163036e-04\n",
      "   1.8857127e-04 -1.3447812e-05 -1.4142097e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0535102e-03 -1.1814428e-04  3.4606852e-05  1.0843455e-04\n",
      "   1.8961343e-04 -9.0834419e-07 -1.3937782e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04158174e-03 -1.05739426e-04  3.44249747e-05  6.16856269e-05\n",
      "   1.84279284e-04 -5.11615035e-05 -1.41198645e-04]]\n",
      "linear.bias:\n",
      " [0.00022545]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0321144e-03 -9.0842448e-05  3.3041953e-05  1.2709742e-04\n",
      "   1.6346079e-04  2.1487540e-06 -1.4906038e-04]]\n",
      "linear.bias:\n",
      " [0.00022479]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0273053e-03 -8.2741695e-05  3.1769647e-05  1.3800843e-04\n",
      "   1.5261049e-04  5.5794640e-06 -1.5240547e-04]]\n",
      "linear.bias:\n",
      " [0.0002236]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0236914e-03 -8.1405742e-05  3.0850406e-05  7.8196914e-05\n",
      "   1.5630366e-04 -5.9037735e-05 -1.5045062e-04]]\n",
      "linear.bias:\n",
      " [0.00022224]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0270408e-03 -8.9039953e-05  2.7462918e-05  7.8730307e-05\n",
      "   1.6502313e-04 -6.0520590e-05 -1.4468881e-04]]\n",
      "linear.bias:\n",
      " [0.00022011]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0326786e-03 -1.0305376e-04  2.4267658e-05  1.3542324e-04\n",
      "   1.7217493e-04  1.5079604e-06 -1.3971160e-04]]\n",
      "linear.bias:\n",
      " [0.0002188]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03853119e-03 -1.18912445e-04  2.09827704e-05  1.11383677e-04\n",
      "   1.79477167e-04 -4.53398570e-07 -1.36397910e-04]]\n",
      "linear.bias:\n",
      " [0.0002197]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421030e-03 -1.2346715e-04  1.8152590e-05  4.7374386e-05\n",
      "   1.8313213e-04 -5.9293525e-05 -1.3497596e-04]]\n",
      "linear.bias:\n",
      " [0.00022231]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469842e-03 -1.1061395e-04  1.6995215e-05  1.2593568e-04\n",
      "   1.6900527e-04  1.0757962e-05 -1.4096421e-04]]\n",
      "linear.bias:\n",
      " [0.00022167]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0436469e-03 -9.6242235e-05  1.8732579e-05  1.3138502e-04\n",
      "   1.5588077e-04 -1.8733163e-05 -1.4833437e-04]]\n",
      "linear.bias:\n",
      " [0.00022109]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0428427e-03 -8.9792193e-05  2.0404292e-05  8.2929371e-05\n",
      "   1.5302475e-04 -8.5747575e-05 -1.5135594e-04]]\n",
      "linear.bias:\n",
      " [0.00022147]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422092e-03 -8.9242523e-05  2.2355587e-05  1.0407839e-04\n",
      "   1.5750984e-04 -5.8935515e-05 -1.5079080e-04]]\n",
      "linear.bias:\n",
      " [0.00022091]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0412218e-03 -9.1889713e-05  2.5459371e-05  1.3126542e-04\n",
      "   1.6891405e-04  6.6232715e-06 -1.4830346e-04]]\n",
      "linear.bias:\n",
      " [0.00022071]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0421186e-03 -9.9444587e-05  2.9395249e-05  9.4111849e-05\n",
      "   1.8560808e-04  2.4061314e-06 -1.4317858e-04]]\n",
      "linear.bias:\n",
      " [0.00022082]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459721e-03 -1.0948836e-04  3.3611552e-05  5.8212303e-05\n",
      "   2.0013373e-04 -3.9012295e-05 -1.3670643e-04]]\n",
      "linear.bias:\n",
      " [0.00022063]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04903802e-03 -1.11535381e-04  3.65768683e-05  1.20398625e-04\n",
      "   1.97436369e-04 -4.53187386e-06 -1.36451054e-04]]\n",
      "linear.bias:\n",
      " [0.00022015]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0501338e-03 -1.0708835e-04  3.7327682e-05  1.0589193e-04\n",
      "   1.8785757e-04 -4.5900313e-05 -1.4062671e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05243316e-03 -9.56981239e-05  3.73896473e-05  1.14743496e-04\n",
      "   1.75165318e-04 -4.01603320e-05 -1.47283703e-04]]\n",
      "linear.bias:\n",
      " [0.00022108]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0563745e-03 -8.9946094e-05  3.6190693e-05  1.1490434e-04\n",
      "   1.6488596e-04 -1.7277489e-05 -1.5287354e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0590014e-03 -9.0992544e-05  3.4472298e-05  8.8703935e-05\n",
      "   1.6407135e-04 -2.3245306e-05 -1.5400026e-04]]\n",
      "linear.bias:\n",
      " [0.00022406]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0576820e-03 -9.6959404e-05  3.4524532e-05  9.3364411e-05\n",
      "   1.6673948e-04 -1.5711481e-05 -1.5206744e-04]]\n",
      "linear.bias:\n",
      " [0.00022444]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05365843e-03 -1.07459775e-04  3.59657606e-05  1.12489026e-04\n",
      "   1.72003056e-04 -1.28679458e-05 -1.48085150e-04]]\n",
      "linear.bias:\n",
      " [0.00022419]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497486e-03 -1.1448364e-04  3.6189827e-05  9.2874565e-05\n",
      "   1.7907449e-04 -4.1070365e-05 -1.4268993e-04]]\n",
      "linear.bias:\n",
      " [0.00022426]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04483264e-03 -1.10358946e-04  3.56194796e-05  1.09554967e-04\n",
      "   1.81239724e-04 -2.06604018e-05 -1.40053089e-04]]\n",
      "linear.bias:\n",
      " [0.00022492]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447587e-03 -1.0794395e-04  3.3142071e-05  1.1014601e-04\n",
      "   1.8238489e-04 -1.0068930e-05 -1.3762260e-04]]\n",
      "linear.bias:\n",
      " [0.00022552]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452757e-03 -1.0528221e-04  2.9982450e-05  7.1458344e-05\n",
      "   1.8221635e-04 -3.5222267e-05 -1.3479158e-04]]\n",
      "linear.bias:\n",
      " [0.00022576]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0441536e-03 -9.6186850e-05  2.6481868e-05  1.0331822e-04\n",
      "   1.6885923e-04  1.7362399e-06 -1.3763625e-04]]\n",
      "linear.bias:\n",
      " [0.00022567]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04667386e-03 -9.28711670e-05  2.43179729e-05  1.10732275e-04\n",
      "   1.62419121e-04 -7.84489657e-07 -1.36183371e-04]]\n",
      "linear.bias:\n",
      " [0.00022469]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504813e-03 -9.6743977e-05  2.3505638e-05  8.0100617e-05\n",
      "   1.6394735e-04 -4.7154434e-05 -1.3240932e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0543312e-03 -9.7425938e-05  2.3696402e-05  1.0161639e-04\n",
      "   1.6117240e-04 -3.8287530e-05 -1.3177124e-04]]\n",
      "linear.bias:\n",
      " [0.00022179]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0568900e-03 -1.0140101e-04  2.4880699e-05  1.2969729e-04\n",
      "   1.6180926e-04 -1.3266144e-06 -1.3088605e-04]]\n",
      "linear.bias:\n",
      " [0.00021999]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05020148e-03 -1.05534586e-04  2.63951260e-05  9.13812837e-05\n",
      "   1.63128061e-04 -2.56839812e-05 -1.33071357e-04]]\n",
      "linear.bias:\n",
      " [0.00021927]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0452304e-03 -1.1206796e-04  2.8303126e-05  8.5295018e-05\n",
      "   1.6606698e-04 -1.9353351e-05 -1.3447116e-04]]\n",
      "linear.bias:\n",
      " [0.00021832]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400319e-03 -1.1013683e-04  3.1216259e-05  1.2064366e-04\n",
      "   1.6716764e-04  1.6966913e-05 -1.3665999e-04]]\n",
      "linear.bias:\n",
      " [0.00021716]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0355589e-03 -1.0038722e-04  3.2420739e-05  7.6169614e-05\n",
      "   1.6833907e-04 -4.9328402e-05 -1.4214021e-04]]\n",
      "linear.bias:\n",
      " [0.00021763]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0325350e-03 -8.6699671e-05  3.3785705e-05  9.3335315e-05\n",
      "   1.6706009e-04 -5.5461045e-05 -1.4803118e-04]]\n",
      "linear.bias:\n",
      " [0.00021896]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0342866e-03 -8.4228072e-05  3.3835702e-05  1.4081830e-04\n",
      "   1.6824392e-04 -2.1673484e-05 -1.5258696e-04]]\n",
      "linear.bias:\n",
      " [0.00022016]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0385655e-03 -8.9310408e-05  3.3584878e-05  1.2644110e-04\n",
      "   1.7740692e-04 -3.1156822e-05 -1.5305667e-04]]\n",
      "linear.bias:\n",
      " [0.00022125]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450737e-03 -9.9373516e-05  3.3020489e-05  8.2963204e-05\n",
      "   1.9089515e-04 -5.8181977e-05 -1.5038071e-04]]\n",
      "linear.bias:\n",
      " [0.00022283]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493126e-03 -1.0220698e-04  3.2246993e-05  1.1037756e-04\n",
      "   1.8971371e-04 -7.6361575e-06 -1.5203684e-04]]\n",
      "linear.bias:\n",
      " [0.00022395]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0531164e-03 -1.0576634e-04  3.0908319e-05  1.0125340e-04\n",
      "   1.8960470e-04  5.6338831e-06 -1.5158141e-04]]\n",
      "linear.bias:\n",
      " [0.00022435]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0563406e-03 -1.0924842e-04  2.9807645e-05  7.3411647e-05\n",
      "   1.8827069e-04 -3.4241653e-05 -1.4923104e-04]]\n",
      "linear.bias:\n",
      " [0.00022258]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0588594e-03 -1.0351444e-04  2.8677892e-05  1.1447592e-04\n",
      "   1.7727977e-04 -2.0986168e-05 -1.5016881e-04]]\n",
      "linear.bias:\n",
      " [0.0002216]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0566998e-03 -9.7808188e-05  2.7991129e-05  1.2694695e-04\n",
      "   1.6968921e-04 -2.5773013e-05 -1.4957240e-04]]\n",
      "linear.bias:\n",
      " [0.00022162]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0511144e-03 -9.5234747e-05  2.8181496e-05  1.0507213e-04\n",
      "   1.6829110e-04 -5.3180403e-05 -1.4614045e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04433985e-03 -9.78152166e-05  2.90844673e-05  1.09158944e-04\n",
      "   1.69489431e-04 -4.28957574e-05 -1.41906406e-04]]\n",
      "linear.bias:\n",
      " [0.00022195]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03736168e-03 -1.03849256e-04  3.10039322e-05  1.18582269e-04\n",
      "   1.73737848e-04 -5.88476178e-06 -1.37544892e-04]]\n",
      "linear.bias:\n",
      " [0.00022224]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0318476e-03 -1.1057162e-04  3.1260213e-05  7.8323283e-05\n",
      "   1.7685907e-04 -1.0244345e-05 -1.3440852e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0324622e-03 -1.1339463e-04  3.1256179e-05  8.1269631e-05\n",
      "   1.7444846e-04 -1.8284472e-06 -1.3327344e-04]]\n",
      "linear.bias:\n",
      " [0.00022449]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402731e-03 -1.1206752e-04  3.1210977e-05  1.0853888e-04\n",
      "   1.6853296e-04 -1.8170880e-06 -1.3335125e-04]]\n",
      "linear.bias:\n",
      " [0.00022453]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04943675e-03 -1.10733235e-04  3.07760965e-05  9.57439770e-05\n",
      "   1.66066748e-04 -3.95017960e-05 -1.31705106e-04]]\n",
      "linear.bias:\n",
      " [0.00022427]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05769583e-03 -9.89691835e-05  2.94898455e-05  1.13847724e-04\n",
      "   1.60029391e-04 -2.89338022e-05 -1.33079971e-04]]\n",
      "linear.bias:\n",
      " [0.00022403]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0589254e-03 -9.2548784e-05  2.8950255e-05  1.2024761e-04\n",
      "   1.5894418e-04 -1.2080076e-05 -1.3341574e-04]]\n",
      "linear.bias:\n",
      " [0.00022381]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0582826e-03 -9.4207397e-05  2.9108714e-05  7.9370329e-05\n",
      "   1.6486802e-04 -4.0508057e-05 -1.3218660e-04]]\n",
      "linear.bias:\n",
      " [0.00022392]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0563461e-03 -9.9629025e-05  2.9244902e-05  8.3588478e-05\n",
      "   1.7012883e-04 -2.5599609e-05 -1.3170826e-04]]\n",
      "linear.bias:\n",
      " [0.0002231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05301128e-03 -1.06965905e-04  2.95120353e-05  1.21021665e-04\n",
      "   1.72153625e-04  1.63885488e-05 -1.33042122e-04]]\n",
      "linear.bias:\n",
      " [0.00022237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444165e-03 -1.1239045e-04  2.9007730e-05  8.0366226e-05\n",
      "   1.7185493e-04 -4.4823959e-05 -1.3855609e-04]]\n",
      "linear.bias:\n",
      " [0.0002214]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0348960e-03 -1.1093387e-04  2.8507464e-05  9.2501017e-05\n",
      "   1.6724349e-04 -4.8957379e-05 -1.4500591e-04]]\n",
      "linear.bias:\n",
      " [0.00022083]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0282089e-03 -1.0318166e-04  2.7931361e-05  1.3449648e-04\n",
      "   1.6153370e-04 -5.8464029e-06 -1.5236103e-04]]\n",
      "linear.bias:\n",
      " [0.00022032]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0270253e-03 -9.8788842e-05  2.7513592e-05  1.2046021e-04\n",
      "   1.6530970e-04 -1.4203349e-05 -1.5484515e-04]]\n",
      "linear.bias:\n",
      " [0.00021925]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0309448e-03 -1.0041041e-04  2.7599783e-05  7.8108140e-05\n",
      "   1.7690839e-04 -6.0926686e-05 -1.5272964e-04]]\n",
      "linear.bias:\n",
      " [0.00021767]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03613443e-03 -9.71433838e-05  2.81759731e-05  1.08240216e-04\n",
      "   1.81726617e-04 -3.07750925e-05 -1.52601075e-04]]\n",
      "linear.bias:\n",
      " [0.00021686]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04217802e-03 -1.01800266e-04  2.79650940e-05  1.39405194e-04\n",
      "   1.86950798e-04  1.41431265e-05 -1.51336775e-04]]\n",
      "linear.bias:\n",
      " [0.00021706]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0450920e-03 -1.0258731e-04  2.6651736e-05  7.3043622e-05\n",
      "   1.8703777e-04 -5.1776089e-05 -1.5421231e-04]]\n",
      "linear.bias:\n",
      " [0.00021938]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0480259e-03 -9.5949443e-05  2.5731608e-05  8.0308200e-05\n",
      "   1.7765201e-04 -3.9800208e-05 -1.5925098e-04]]\n",
      "linear.bias:\n",
      " [0.00022178]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475967e-03 -9.3326795e-05  2.6035805e-05  1.3893288e-04\n",
      "   1.7171989e-04  4.6620698e-06 -1.6068351e-04]]\n",
      "linear.bias:\n",
      " [0.00022333]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0486884e-03 -9.6628326e-05  2.7566297e-05  1.3326846e-04\n",
      "   1.7436022e-04 -1.4130306e-05 -1.5788652e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05155283e-03 -1.05113344e-04  2.88504089e-05  7.45038196e-05\n",
      "   1.82731936e-04 -7.28518426e-05 -1.52044784e-04]]\n",
      "linear.bias:\n",
      " [0.00022361]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0557958e-03 -1.0628160e-04  2.9648789e-05  1.1812389e-04\n",
      "   1.7792820e-04 -2.4057848e-05 -1.5031507e-04]]\n",
      "linear.bias:\n",
      " [0.0002222]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0544143e-03 -1.0293803e-04  3.0290132e-05  1.3405990e-04\n",
      "   1.7604984e-04  8.9110363e-06 -1.4737963e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04737189e-03 -1.00045785e-04  3.05573158e-05  6.54159739e-05\n",
      "   1.75407680e-04 -4.82480464e-05 -1.46196937e-04]]\n",
      "linear.bias:\n",
      " [0.00022273]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0398718e-03 -9.3596107e-05  3.0249561e-05  8.2251107e-05\n",
      "   1.7015186e-04 -4.2853491e-05 -1.4569645e-04]]\n",
      "linear.bias:\n",
      " [0.00022171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0338780e-03 -9.4347852e-05  2.9875526e-05  1.4247085e-04\n",
      "   1.6525276e-04 -2.8188879e-07 -1.4481481e-04]]\n",
      "linear.bias:\n",
      " [0.0002205]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0315385e-03 -9.9267374e-05  2.9080536e-05  1.2397833e-04\n",
      "   1.6567759e-04 -1.8545008e-05 -1.4376652e-04]]\n",
      "linear.bias:\n",
      " [0.00022125]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0339711e-03 -1.0967187e-04  2.8427363e-05  7.1020404e-05\n",
      "   1.7364736e-04 -7.0794755e-05 -1.3936232e-04]]\n",
      "linear.bias:\n",
      " [0.00022193]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0384950e-03 -1.1361566e-04  2.8128085e-05  1.1633894e-04\n",
      "   1.6798731e-04 -1.3586810e-05 -1.4124626e-04]]\n",
      "linear.bias:\n",
      " [0.00022193]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467700e-03 -1.1238495e-04  2.6515927e-05  1.2635284e-04\n",
      "   1.6765486e-04  3.3151864e-06 -1.3973788e-04]]\n",
      "linear.bias:\n",
      " [0.00022161]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0518223e-03 -1.0472402e-04  2.5496010e-05  6.6824723e-05\n",
      "   1.6854479e-04 -5.6187106e-05 -1.3861271e-04]]\n",
      "linear.bias:\n",
      " [0.00022102]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0576939e-03 -9.1528338e-05  2.4664885e-05  1.0359459e-04\n",
      "   1.6234099e-04 -2.1054941e-05 -1.4102300e-04]]\n",
      "linear.bias:\n",
      " [0.00021986]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0608886e-03 -8.5206564e-05  2.5570356e-05  1.3876466e-04\n",
      "   1.6125590e-04  7.2640905e-06 -1.4082948e-04]]\n",
      "linear.bias:\n",
      " [0.00021914]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0519125e-03 -8.5568157e-05  2.7363678e-05  6.5368622e-05\n",
      "   1.6656342e-04 -6.1117607e-05 -1.4220111e-04]]\n",
      "linear.bias:\n",
      " [0.0002191]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447568e-03 -9.3929979e-05  2.8548628e-05  9.4561801e-05\n",
      "   1.6564499e-04 -3.2939250e-05 -1.4578784e-04]]\n",
      "linear.bias:\n",
      " [0.00021783]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0360621e-03 -1.0673448e-04  3.0377769e-05  1.4192029e-04\n",
      "   1.6655916e-04  2.0493782e-05 -1.4768913e-04]]\n",
      "linear.bias:\n",
      " [0.00021637]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0255215e-03 -1.0909596e-04  3.0577856e-05  8.2038488e-05\n",
      "   1.7146612e-04 -5.7410129e-05 -1.5230020e-04]]\n",
      "linear.bias:\n",
      " [0.00021692]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0187866e-03 -1.0284916e-04  3.0150761e-05  8.1240411e-05\n",
      "   1.7333854e-04 -6.0541672e-05 -1.5728954e-04]]\n",
      "linear.bias:\n",
      " [0.00021897]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0197293e-03 -9.3819064e-05  2.8212804e-05  1.4181937e-04\n",
      "   1.7723012e-04  4.4818444e-06 -1.5943685e-04]]\n",
      "linear.bias:\n",
      " [0.00022082]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0257195e-03 -8.7017128e-05  2.6669473e-05  1.3067330e-04\n",
      "   1.8699629e-04  5.2801338e-06 -1.5854689e-04]]\n",
      "linear.bias:\n",
      " [0.00022279]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0340483e-03 -8.3856619e-05  2.5624542e-05  6.4089712e-05\n",
      "   1.9821963e-04 -4.8774640e-05 -1.5620816e-04]]\n",
      "linear.bias:\n",
      " [0.00022425]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446224e-03 -8.5033054e-05  2.5785557e-05  1.0844064e-04\n",
      "   1.9145913e-04 -1.7459108e-05 -1.5714869e-04]]\n",
      "linear.bias:\n",
      " [0.00022402]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0557917e-03 -9.4086536e-05  2.5579793e-05  1.4471520e-04\n",
      "   1.8556198e-04  2.2127660e-06 -1.5646755e-04]]\n",
      "linear.bias:\n",
      " [0.0002238]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0620079e-03 -1.0375532e-04  2.5833566e-05  1.0170463e-04\n",
      "   1.8052405e-04 -5.0752824e-05 -1.5562041e-04]]\n",
      "linear.bias:\n",
      " [0.00022361]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0621498e-03 -1.1331067e-04  2.6314759e-05  9.6615986e-05\n",
      "   1.7469937e-04 -5.6814075e-05 -1.5427190e-04]]\n",
      "linear.bias:\n",
      " [0.00022344]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0569296e-03 -1.1172851e-04  2.7114180e-05  1.2960884e-04\n",
      "   1.6649994e-04 -1.2886932e-05 -1.5365178e-04]]\n",
      "linear.bias:\n",
      " [0.00022328]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04823231e-03 -1.04885563e-04  2.77419385e-05  1.07183965e-04\n",
      "   1.67705046e-04 -1.23140999e-05 -1.49172381e-04]]\n",
      "linear.bias:\n",
      " [0.00022252]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0395421e-03 -1.0141578e-04  3.0625972e-05  7.5453790e-05\n",
      "   1.7466526e-04 -3.8608079e-05 -1.4124629e-04]]\n",
      "linear.bias:\n",
      " [0.00022152]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0317311e-03 -9.3972689e-05  3.3992448e-05  1.0662703e-04\n",
      "   1.7534570e-04 -1.0193111e-05 -1.3567429e-04]]\n",
      "linear.bias:\n",
      " [0.00022031]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02978887e-03 -9.10663803e-05  3.63338877e-05  1.14459464e-04\n",
      "   1.78673596e-04 -2.62219100e-06 -1.28933490e-04]]\n",
      "linear.bias:\n",
      " [0.00022015]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0327210e-03 -8.7790409e-05  3.6034337e-05  7.1584815e-05\n",
      "   1.7858518e-04 -4.3361022e-05 -1.2656150e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430694e-03 -8.8349407e-05  3.3543223e-05  1.0476200e-04\n",
      "   1.6215240e-04 -1.3074070e-05 -1.3183006e-04]]\n",
      "linear.bias:\n",
      " [0.00022395]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05539546e-03 -9.65959043e-05  3.20597937e-05  1.21848716e-04\n",
      "   1.52215478e-04 -6.97451333e-06 -1.33904963e-04]]\n",
      "linear.bias:\n",
      " [0.00022406]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06642349e-03 -1.09353736e-04  2.99638559e-05  9.31365867e-05\n",
      "   1.52801105e-04 -4.28239000e-05 -1.33242778e-04]]\n",
      "linear.bias:\n",
      " [0.00022353]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0700620e-03 -1.2074328e-04  2.8220546e-05  9.7320728e-05\n",
      "   1.5527036e-04 -3.8975799e-05 -1.3283669e-04]]\n",
      "linear.bias:\n",
      " [0.00022211]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0681589e-03 -1.2045019e-04  2.6613689e-05  1.2564570e-04\n",
      "   1.5610349e-04  8.0205136e-06 -1.3431988e-04]]\n",
      "linear.bias:\n",
      " [0.00022114]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05191185e-03 -1.05589264e-04  2.56042349e-05  7.64211873e-05\n",
      "   1.62812692e-04 -3.77714096e-05 -1.36932096e-04]]\n",
      "linear.bias:\n",
      " [0.00021996]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0364539e-03 -8.7927961e-05  2.5822137e-05  8.5266132e-05\n",
      "   1.6634268e-04 -3.5746179e-05 -1.3984204e-04]]\n",
      "linear.bias:\n",
      " [0.00021859]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0231982e-03 -7.8557998e-05  2.6715146e-05  1.3161371e-04\n",
      "   1.7039030e-04 -2.2616769e-06 -1.4195863e-04]]\n",
      "linear.bias:\n",
      " [0.00021672]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0152343e-03 -7.5955584e-05  2.6296073e-05  1.1035607e-04\n",
      "   1.7660824e-04 -2.1646914e-05 -1.4427809e-04]]\n",
      "linear.bias:\n",
      " [0.00021692]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0138808e-03 -8.4210289e-05  2.5294588e-05  8.0841390e-05\n",
      "   1.8535486e-04 -4.7701818e-05 -1.4499271e-04]]\n",
      "linear.bias:\n",
      " [0.0002171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02177390e-03 -9.82836937e-05  2.36165979e-05  1.21966805e-04\n",
      "   1.82661199e-04 -1.44177502e-05 -1.49501517e-04]]\n",
      "linear.bias:\n",
      " [0.00021569]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0325282e-03 -1.1464805e-04  2.2237560e-05  1.2521849e-04\n",
      "   1.8249878e-04 -1.2755427e-05 -1.5214660e-04]]\n",
      "linear.bias:\n",
      " [0.00021537]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437729e-03 -1.2396893e-04  2.0854353e-05  7.2697236e-05\n",
      "   1.8169977e-04 -5.6328197e-05 -1.5413435e-04]]\n",
      "linear.bias:\n",
      " [0.00021665]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0542449e-03 -1.1927797e-04  2.0322825e-05  9.4518095e-05\n",
      "   1.7334368e-04 -2.1369615e-05 -1.5767718e-04]]\n",
      "linear.bias:\n",
      " [0.00021844]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0610746e-03 -1.1292113e-04  2.2270258e-05  1.2267828e-04\n",
      "   1.7079125e-04  3.0934152e-06 -1.5678845e-04]]\n",
      "linear.bias:\n",
      " [0.00022036]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05749432e-03 -1.04679246e-04  2.65735835e-05  1.04201739e-04\n",
      "   1.75387409e-04 -3.59278783e-05 -1.52815977e-04]]\n",
      "linear.bias:\n",
      " [0.00022146]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0515447e-03 -1.0328521e-04  3.1501499e-05  9.8247037e-05\n",
      "   1.8219196e-04 -4.9316332e-05 -1.4730672e-04]]\n",
      "linear.bias:\n",
      " [0.00022308]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439144e-03 -9.5747906e-05  3.6296653e-05  1.2510794e-04\n",
      "   1.8352194e-04 -1.7174305e-05 -1.4449086e-04]]\n",
      "linear.bias:\n",
      " [0.00022454]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0370413e-03 -8.9293659e-05  3.9064456e-05  1.0243447e-04\n",
      "   1.8307439e-04 -2.4791121e-05 -1.4243685e-04]]\n",
      "linear.bias:\n",
      " [0.00022617]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346484e-03 -9.0867827e-05  3.9169001e-05  9.5489704e-05\n",
      "   1.8098338e-04 -1.6452675e-05 -1.4076049e-04]]\n",
      "linear.bias:\n",
      " [0.00022764]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03800755e-03 -1.01973310e-04  3.82348699e-05  1.06746564e-04\n",
      "   1.78607050e-04 -1.02231170e-05 -1.38603020e-04]]\n",
      "linear.bias:\n",
      " [0.00022801]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459146e-03 -1.1296520e-04  3.5829180e-05  9.5408999e-05\n",
      "   1.7764389e-04 -3.1405536e-05 -1.3473601e-04]]\n",
      "linear.bias:\n",
      " [0.00022835]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05478265e-03 -1.14354065e-04  3.28708775e-05  1.14014561e-04\n",
      "   1.72446409e-04 -6.31373950e-06 -1.34366463e-04]]\n",
      "linear.bias:\n",
      " [0.00022802]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0535446e-03 -1.0524101e-04  2.9083560e-05  8.6954205e-05\n",
      "   1.7044095e-04 -1.7890270e-05 -1.3319506e-04]]\n",
      "linear.bias:\n",
      " [0.00022677]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493337e-03 -1.0017376e-04  2.6810012e-05  9.5037241e-05\n",
      "   1.6760579e-04 -6.6723069e-06 -1.3282886e-04]]\n",
      "linear.bias:\n",
      " [0.0002247]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04443508e-03 -1.00575940e-04  2.66085553e-05  1.06026346e-04\n",
      "   1.69125822e-04 -1.24895232e-05 -1.29755892e-04]]\n",
      "linear.bias:\n",
      " [0.00022125]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0391000e-03 -1.0279824e-04  2.7796405e-05  9.3462499e-05\n",
      "   1.7340861e-04 -3.5873862e-05 -1.2554842e-04]]\n",
      "linear.bias:\n",
      " [0.00021941]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0348232e-03 -9.7480501e-05  2.8909664e-05  1.1544679e-04\n",
      "   1.7022785e-04 -7.7148143e-06 -1.2652203e-04]]\n",
      "linear.bias:\n",
      " [0.00021839]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0350667e-03 -9.6934309e-05  2.9103618e-05  8.8473185e-05\n",
      "   1.6645899e-04 -2.8879063e-05 -1.2968428e-04]]\n",
      "linear.bias:\n",
      " [0.00022001]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0355565e-03 -9.9129786e-05  2.8920358e-05  9.1224800e-05\n",
      "   1.6196090e-04 -1.3679036e-05 -1.3381508e-04]]\n",
      "linear.bias:\n",
      " [0.00022115]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403950e-03 -1.0850657e-04  2.8331535e-05  1.0329402e-04\n",
      "   1.6180695e-04 -2.3861903e-06 -1.3543329e-04]]\n",
      "linear.bias:\n",
      " [0.00022154]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498372e-03 -1.2134990e-04  2.8426708e-05  9.3754679e-05\n",
      "   1.6911898e-04 -2.2590086e-05 -1.3257794e-04]]\n",
      "linear.bias:\n",
      " [0.00022126]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05780608e-03 -1.21390622e-04  2.75128477e-05  1.09294575e-04\n",
      "   1.71627995e-04 -7.31636828e-06 -1.32579196e-04]]\n",
      "linear.bias:\n",
      " [0.00022132]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0578216e-03 -1.1347851e-04  2.6937323e-05  7.7969904e-05\n",
      "   1.7446240e-04 -2.9365114e-05 -1.3242936e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05408416e-03 -9.34925411e-05  2.52982154e-05  1.07485925e-04\n",
      "   1.67383652e-04  4.58531576e-06 -1.36335075e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0497569e-03 -8.5237181e-05  2.5986330e-05  9.2218732e-05\n",
      "   1.6876796e-04 -1.9547431e-05 -1.3734750e-04]]\n",
      "linear.bias:\n",
      " [0.00022501]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0446914e-03 -8.6191081e-05  2.7839911e-05  1.0320622e-04\n",
      "   1.7199293e-04 -2.6676365e-05 -1.3671945e-04]]\n",
      "linear.bias:\n",
      " [0.00022502]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04327186e-03 -9.82491183e-05  2.92320074e-05  1.21395235e-04\n",
      "   1.77922164e-04 -2.30561855e-05 -1.34446280e-04]]\n",
      "linear.bias:\n",
      " [0.00022375]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04262750e-03 -1.13969021e-04  2.87460643e-05  1.01997415e-04\n",
      "   1.82541480e-04 -3.93314622e-05 -1.33759924e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0440357e-03 -1.2049536e-04  2.8120197e-05  1.1034123e-04\n",
      "   1.8037102e-04 -8.6542932e-06 -1.3706219e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0430015e-03 -1.0746421e-04  2.6870541e-05  7.7766075e-05\n",
      "   1.7451213e-04 -1.0594721e-05 -1.4191637e-04]]\n",
      "linear.bias:\n",
      " [0.00022423]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0420609e-03 -9.8815784e-05  2.6873380e-05  8.6778120e-05\n",
      "   1.6953518e-04  1.5667747e-06 -1.4550488e-04]]\n",
      "linear.bias:\n",
      " [0.00022527]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449393e-03 -9.6185453e-05  2.7897435e-05  8.8502609e-05\n",
      "   1.7053213e-04 -1.4919303e-05 -1.4468197e-04]]\n",
      "linear.bias:\n",
      " [0.00022461]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0449329e-03 -9.9301033e-05  3.0274543e-05  1.0658504e-04\n",
      "   1.7399201e-04 -2.7903943e-05 -1.4185421e-04]]\n",
      "linear.bias:\n",
      " [0.0002237]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04691531e-03 -1.09270346e-04  3.17183076e-05  1.22867947e-04\n",
      "   1.78541188e-04 -3.23962922e-05 -1.38206859e-04]]\n",
      "linear.bias:\n",
      " [0.00022288]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04354834e-03 -1.16764328e-04  3.26625195e-05  1.13969305e-04\n",
      "   1.82696691e-04 -3.71171882e-05 -1.35529655e-04]]\n",
      "linear.bias:\n",
      " [0.00022342]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413920e-03 -1.0928231e-04  3.2548563e-05  1.1222300e-04\n",
      "   1.8380646e-04 -7.1497325e-06 -1.3539683e-04]]\n",
      "linear.bias:\n",
      " [0.00022454]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0405077e-03 -9.9846417e-05  2.9996592e-05  5.9673093e-05\n",
      "   1.8152496e-04 -2.1998503e-05 -1.3703936e-04]]\n",
      "linear.bias:\n",
      " [0.00022652]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0401295e-03 -8.8566012e-05  2.7513437e-05  9.8523444e-05\n",
      "   1.6837973e-04  1.7844863e-05 -1.4256613e-04]]\n",
      "linear.bias:\n",
      " [0.00022702]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0412786e-03 -8.5555446e-05  2.6692038e-05  1.0919179e-04\n",
      "   1.6349200e-04 -5.0663239e-06 -1.4367585e-04]]\n",
      "linear.bias:\n",
      " [0.00022554]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0473276e-03 -8.9120258e-05  2.6437359e-05  9.3662427e-05\n",
      "   1.6759918e-04 -6.5243228e-05 -1.3966684e-04]]\n",
      "linear.bias:\n",
      " [0.00022325]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0539572e-03 -1.0053826e-04  2.6345406e-05  1.2341038e-04\n",
      "   1.7167669e-04 -5.8408757e-05 -1.3685285e-04]]\n",
      "linear.bias:\n",
      " [0.00022086]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05673331e-03 -1.10456815e-04  2.64195551e-05  1.45242579e-04\n",
      "   1.76090965e-04 -1.94987952e-05 -1.35275506e-04]]\n",
      "linear.bias:\n",
      " [0.00021968]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04894175e-03 -1.10301255e-04  2.52504306e-05  9.06956411e-05\n",
      "   1.78877570e-04 -3.25298897e-05 -1.36260089e-04]]\n",
      "linear.bias:\n",
      " [0.00021957]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417231e-03 -1.0296055e-04  2.4066981e-05  7.8472352e-05\n",
      "   1.7549949e-04  1.9573963e-06 -1.3999008e-04]]\n",
      "linear.bias:\n",
      " [0.00022012]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346692e-03 -9.9499448e-05  2.3818184e-05  9.3402421e-05\n",
      "   1.7173112e-04  2.6881793e-05 -1.4223292e-04]]\n",
      "linear.bias:\n",
      " [0.00022126]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0275953e-03 -1.0358954e-04  2.5694162e-05  7.3365773e-05\n",
      "   1.7316056e-04 -3.5654473e-05 -1.4281383e-04]]\n",
      "linear.bias:\n",
      " [0.00022197]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0234361e-03 -1.0344416e-04  2.8880257e-05  1.1021518e-04\n",
      "   1.7103719e-04 -4.9483755e-05 -1.4452335e-04]]\n",
      "linear.bias:\n",
      " [0.00022196]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0278984e-03 -9.8501550e-05  3.0095509e-05  1.5359060e-04\n",
      "   1.6961676e-04 -2.5755444e-05 -1.4709074e-04]]\n",
      "linear.bias:\n",
      " [0.00022163]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0356080e-03 -9.2804112e-05  2.9363329e-05  1.1543542e-04\n",
      "   1.7061940e-04 -4.9193000e-05 -1.4939737e-04]]\n",
      "linear.bias:\n",
      " [0.00022294]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0448248e-03 -9.6875527e-05  2.8464478e-05  7.5110198e-05\n",
      "   1.7732622e-04 -5.1503306e-05 -1.4919063e-04]]\n",
      "linear.bias:\n",
      " [0.00022509]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05424039e-03 -9.94433358e-05  2.83493118e-05  1.01267324e-04\n",
      "   1.77292473e-04 -4.21900040e-07 -1.50768785e-04]]\n",
      "linear.bias:\n",
      " [0.00022638]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0620991e-03 -1.0430056e-04  3.0592950e-05  1.0900222e-04\n",
      "   1.8304563e-04  1.3294711e-05 -1.4796092e-04]]\n",
      "linear.bias:\n",
      " [0.00022657]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0580077e-03 -1.0587250e-04  3.4430042e-05  7.1843417e-05\n",
      "   1.8661108e-04 -5.0076531e-05 -1.4575101e-04]]\n",
      "linear.bias:\n",
      " [0.00022513]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0507371e-03 -9.8839133e-05  3.6648598e-05  1.1221445e-04\n",
      "   1.7625190e-04 -4.5854820e-05 -1.4821951e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0411865e-03 -9.4694638e-05  3.8319366e-05  1.5376178e-04\n",
      "   1.6629315e-04 -1.4617504e-05 -1.5067525e-04]]\n",
      "linear.bias:\n",
      " [0.00022306]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0301120e-03 -8.7571680e-05  3.6122598e-05  9.4131727e-05\n",
      "   1.6195164e-04 -4.9404054e-05 -1.5347538e-04]]\n",
      "linear.bias:\n",
      " [0.00022326]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0279246e-03 -9.0781461e-05  3.2177886e-05  6.5411994e-05\n",
      "   1.6245602e-04 -4.4878998e-05 -1.5450221e-04]]\n",
      "linear.bias:\n",
      " [0.0002228]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03141728e-03 -1.00081052e-04  2.66279440e-05  1.07402244e-04\n",
      "   1.71709602e-04 -3.27581802e-07 -1.49145140e-04]]\n",
      "linear.bias:\n",
      " [0.00022076]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0398696e-03 -1.1291494e-04  2.2159204e-05  1.2300778e-04\n",
      "   1.8734236e-04  3.1775746e-06 -1.3943911e-04]]\n",
      "linear.bias:\n",
      " [0.00021763]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467885e-03 -1.1605306e-04  1.6979435e-05  6.6867062e-05\n",
      "   1.9514303e-04 -7.4078351e-05 -1.3469787e-04]]\n",
      "linear.bias:\n",
      " [0.00021546]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05427008e-03 -1.02590224e-04  1.31386860e-05  1.32244968e-04\n",
      "   1.81515396e-04 -1.99049246e-05 -1.39675278e-04]]\n",
      "linear.bias:\n",
      " [0.00021253]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0566271e-03 -8.8438108e-05  9.9364788e-06  1.4008812e-04\n",
      "   1.6597455e-04 -5.6891295e-06 -1.4636082e-04]]\n",
      "linear.bias:\n",
      " [0.00021184]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04898284e-03 -8.41727087e-05  1.11875825e-05  7.65326622e-05\n",
      "   1.59726158e-04 -4.99056223e-05 -1.50800843e-04]]\n",
      "linear.bias:\n",
      " [0.0002122]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0402809e-03 -8.2828650e-05  1.4789240e-05  6.9715708e-05\n",
      "   1.5938202e-04 -5.1038351e-05 -1.5072332e-04]]\n",
      "linear.bias:\n",
      " [0.00021284]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0333727e-03 -8.7147440e-05  1.9348730e-05  1.2415581e-04\n",
      "   1.6334467e-04 -1.0244643e-05 -1.4709568e-04]]\n",
      "linear.bias:\n",
      " [0.00021342]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0309111e-03 -9.7303309e-05  2.5442736e-05  1.3465185e-04\n",
      "   1.7449033e-04 -1.9539337e-05 -1.4041767e-04]]\n",
      "linear.bias:\n",
      " [0.00021459]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0296816e-03 -1.0994457e-04  2.9276729e-05  7.8086232e-05\n",
      "   1.8348248e-04 -6.9029244e-05 -1.3585722e-04]]\n",
      "linear.bias:\n",
      " [0.00021792]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0304349e-03 -1.1382110e-04  3.2211552e-05  1.2185640e-04\n",
      "   1.7467354e-04 -1.1673241e-05 -1.3913523e-04]]\n",
      "linear.bias:\n",
      " [0.00022125]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381571e-03 -1.0810152e-04  3.1123174e-05  1.1784407e-04\n",
      "   1.6745586e-04  1.1215625e-06 -1.4220267e-04]]\n",
      "linear.bias:\n",
      " [0.00022587]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0492948e-03 -1.0452345e-04  2.9892824e-05  7.7778692e-05\n",
      "   1.6651559e-04 -2.7699680e-05 -1.4205989e-04]]\n",
      "linear.bias:\n",
      " [0.00022906]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0585265e-03 -1.0503727e-04  2.9343702e-05  8.4173560e-05\n",
      "   1.6636086e-04 -2.0929607e-05 -1.4122926e-04]]\n",
      "linear.bias:\n",
      " [0.00023127]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06380391e-03 -1.09435205e-04  3.05201829e-05  1.22334255e-04\n",
      "   1.67312959e-04  6.26354449e-06 -1.39579992e-04]]\n",
      "linear.bias:\n",
      " [0.00023229]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0561948e-03 -1.0441674e-04  3.2436426e-05  9.4107891e-05\n",
      "   1.7275463e-04 -5.1041658e-05 -1.3821630e-04]]\n",
      "linear.bias:\n",
      " [0.0002306]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468944e-03 -9.4581745e-05  3.5293888e-05  1.0588204e-04\n",
      "   1.7290658e-04 -5.0945000e-05 -1.3972237e-04]]\n",
      "linear.bias:\n",
      " [0.00022744]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0383853e-03 -8.5931300e-05  3.6621808e-05  1.4098687e-04\n",
      "   1.7104458e-04 -1.4517274e-05 -1.4223010e-04]]\n",
      "linear.bias:\n",
      " [0.0002246]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0335587e-03 -8.3790947e-05  3.6172416e-05  1.0642006e-04\n",
      "   1.7186109e-04 -2.9672283e-05 -1.4407672e-04]]\n",
      "linear.bias:\n",
      " [0.00022269]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0347381e-03 -9.3272727e-05  3.4772645e-05  7.9110621e-05\n",
      "   1.7649546e-04 -2.5660036e-05 -1.4404148e-04]]\n",
      "linear.bias:\n",
      " [0.0002213]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0417796e-03 -1.1138338e-04  3.2973461e-05  1.0160296e-04\n",
      "   1.8061567e-04  7.7934565e-06 -1.4306705e-04]]\n",
      "linear.bias:\n",
      " [0.00021939]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0508308e-03 -1.1805133e-04  2.9370134e-05  9.0331319e-05\n",
      "   1.8065711e-04 -2.3965084e-05 -1.4265756e-04]]\n",
      "linear.bias:\n",
      " [0.00021801]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0569950e-03 -1.1244836e-04  2.5631045e-05  1.1465716e-04\n",
      "   1.7499492e-04 -1.5514241e-05 -1.4514306e-04]]\n",
      "linear.bias:\n",
      " [0.00021741]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0575036e-03 -1.0230079e-04  2.2456205e-05  1.0934487e-04\n",
      "   1.7253325e-04 -2.9949162e-05 -1.4568538e-04]]\n",
      "linear.bias:\n",
      " [0.00021786]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0567061e-03 -9.5702191e-05  2.1137341e-05  9.6308395e-05\n",
      "   1.7592266e-04 -3.1911193e-05 -1.4356300e-04]]\n",
      "linear.bias:\n",
      " [0.00021957]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0520981e-03 -9.5446667e-05  2.0934174e-05  1.1197760e-04\n",
      "   1.8018953e-04 -2.7114311e-06 -1.4037176e-04]]\n",
      "linear.bias:\n",
      " [0.00022111]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0443045e-03 -9.6255717e-05  2.3097571e-05  8.9256682e-05\n",
      "   1.8658493e-04 -1.7339757e-05 -1.3599661e-04]]\n",
      "linear.bias:\n",
      " [0.0002225]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0353284e-03 -1.0034059e-04  2.6918366e-05  9.9117948e-05\n",
      "   1.8888163e-04 -2.1202486e-05 -1.3277428e-04]]\n",
      "linear.bias:\n",
      " [0.00022309]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0338170e-03 -9.9031007e-05  2.9212830e-05  1.3066620e-04\n",
      "   1.8375216e-04  2.9275252e-06 -1.3343303e-04]]\n",
      "linear.bias:\n",
      " [0.00022297]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0303297e-03 -9.0480746e-05  2.9116027e-05  8.6639200e-05\n",
      "   1.7159690e-04 -5.3098651e-05 -1.3940208e-04]]\n",
      "linear.bias:\n",
      " [0.00022319]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0334401e-03 -8.5864849e-05  2.8648934e-05  8.6770560e-05\n",
      "   1.5731622e-04 -5.7154612e-05 -1.4744300e-04]]\n",
      "linear.bias:\n",
      " [0.00022142]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437663e-03 -9.1287147e-05  2.6251933e-05  1.2238779e-04\n",
      "   1.4876015e-04 -2.1635369e-05 -1.5298260e-04]]\n",
      "linear.bias:\n",
      " [0.00021949]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0570188e-03 -1.0343462e-04  2.3832854e-05  1.2631413e-04\n",
      "   1.5408974e-04 -1.1781209e-05 -1.5221095e-04]]\n",
      "linear.bias:\n",
      " [0.00021808]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0638620e-03 -1.1145653e-04  2.2215405e-05  8.1440012e-05\n",
      "   1.7324385e-04 -4.7623613e-05 -1.4621984e-04]]\n",
      "linear.bias:\n",
      " [0.0002178]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0652603e-03 -1.0808310e-04  2.1369004e-05  8.1065489e-05\n",
      "   1.8715169e-04 -3.1732634e-05 -1.4182860e-04]]\n",
      "linear.bias:\n",
      " [0.00021821]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0622611e-03 -9.6770957e-05  2.0787320e-05  1.3716298e-04\n",
      "   1.8819512e-04  3.6089223e-05 -1.4169446e-04]]\n",
      "linear.bias:\n",
      " [0.00021891]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0504082e-03 -8.2404149e-05  2.0186557e-05  8.2165214e-05\n",
      "   1.8736935e-04 -5.0795730e-05 -1.4691529e-04]]\n",
      "linear.bias:\n",
      " [0.00022052]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0362559e-03 -7.8995079e-05  2.1257860e-05  9.6248026e-05\n",
      "   1.7851053e-04 -7.7212280e-05 -1.5329417e-04]]\n",
      "linear.bias:\n",
      " [0.00022066]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0219837e-03 -8.3979015e-05  2.3568226e-05  1.4552113e-04\n",
      "   1.7153523e-04 -3.1105468e-05 -1.5875086e-04]]\n",
      "linear.bias:\n",
      " [0.00022111]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0152645e-03 -9.4931471e-05  2.5147201e-05  1.3904760e-04\n",
      "   1.7498748e-04 -1.3032130e-05 -1.5924861e-04]]\n",
      "linear.bias:\n",
      " [0.00022218]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0154987e-03 -1.0873525e-04  2.6573563e-05  7.7698176e-05\n",
      "   1.8647638e-04 -3.9740193e-05 -1.5567450e-04]]\n",
      "linear.bias:\n",
      " [0.00022314]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0253745e-03 -1.1669543e-04  2.8698569e-05  8.4149709e-05\n",
      "   1.9094109e-04 -1.7968172e-05 -1.5313386e-04]]\n",
      "linear.bias:\n",
      " [0.00022169]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0422316e-03 -1.1818408e-04  2.9794588e-05  1.2258586e-04\n",
      "   1.8936585e-04  2.0210648e-05 -1.5196831e-04]]\n",
      "linear.bias:\n",
      " [0.00022006]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05640339e-03 -1.03743914e-04  2.95750924e-05  8.52860539e-05\n",
      "   1.82893258e-04 -3.66953755e-05 -1.54383059e-04]]\n",
      "linear.bias:\n",
      " [0.00021925]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0642604e-03 -9.1791087e-05  2.9870302e-05  8.7666078e-05\n",
      "   1.7547527e-04 -4.7801437e-05 -1.5631359e-04]]\n",
      "linear.bias:\n",
      " [0.00021918]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0664067e-03 -8.5806023e-05  3.0899475e-05  1.2436748e-04\n",
      "   1.7069781e-04 -1.7596603e-05 -1.5649488e-04]]\n",
      "linear.bias:\n",
      " [0.00021945]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0659843e-03 -8.8645000e-05  3.0750834e-05  1.1506028e-04\n",
      "   1.7600425e-04 -1.8200661e-05 -1.5265575e-04]]\n",
      "linear.bias:\n",
      " [0.00022003]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0611408e-03 -9.4482457e-05  3.2265267e-05  8.9519352e-05\n",
      "   1.8648616e-04 -3.7285812e-05 -1.4579267e-04]]\n",
      "linear.bias:\n",
      " [0.00022055]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0516963e-03 -9.9916695e-05  3.3553559e-05  1.0127973e-04\n",
      "   1.9229238e-04 -1.4944160e-05 -1.4022599e-04]]\n",
      "linear.bias:\n",
      " [0.00022201]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397187e-03 -1.0601366e-04  3.5057838e-05  1.1493706e-04\n",
      "   1.9401631e-04  5.7431535e-06 -1.3531877e-04]]\n",
      "linear.bias:\n",
      " [0.00022432]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0270929e-03 -1.0455669e-04  3.4289162e-05  5.6523229e-05\n",
      "   1.8766956e-04 -4.8047907e-05 -1.3577244e-04]]\n",
      "linear.bias:\n",
      " [0.00022706]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02308171e-03 -1.00136414e-04  3.06158654e-05  1.20509227e-04\n",
      "   1.61077667e-04  8.81147207e-06 -1.44350633e-04]]\n",
      "linear.bias:\n",
      " [0.00022754]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0260678e-03 -9.7408665e-05  2.7568656e-05  1.3365070e-04\n",
      "   1.4757349e-04  8.4862913e-06 -1.4804972e-04]]\n",
      "linear.bias:\n",
      " [0.00022665]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0292751e-03 -9.6691881e-05  2.5473622e-05  7.4837459e-05\n",
      "   1.5253700e-04 -7.0522809e-05 -1.4726329e-04]]\n",
      "linear.bias:\n",
      " [0.00022417]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03521650e-03 -9.06273563e-05  2.25351196e-05  1.05263825e-04\n",
      "   1.63990000e-04 -5.28284254e-05 -1.43144163e-04]]\n",
      "linear.bias:\n",
      " [0.00022062]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0392673e-03 -9.0551046e-05  2.1010675e-05  1.3950019e-04\n",
      "   1.7915262e-04 -6.4431551e-06 -1.3810757e-04]]\n",
      "linear.bias:\n",
      " [0.00021775]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429232e-03 -9.6862968e-05  1.9396302e-05  9.7575576e-05\n",
      "   1.9202569e-04 -2.2444310e-05 -1.3592775e-04]]\n",
      "linear.bias:\n",
      " [0.00021749]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444135e-03 -9.5494142e-05  1.9438405e-05  8.2320556e-05\n",
      "   1.9496644e-04 -1.7709741e-05 -1.3719429e-04]]\n",
      "linear.bias:\n",
      " [0.00021827]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0434348e-03 -9.0681664e-05  2.1440530e-05  1.1981699e-04\n",
      "   1.8610182e-04  9.7678294e-06 -1.4286563e-04]]\n",
      "linear.bias:\n",
      " [0.00021863]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404272e-03 -8.9852103e-05  2.4066467e-05  9.1169975e-05\n",
      "   1.7505234e-04 -5.2735901e-05 -1.4990913e-04]]\n",
      "linear.bias:\n",
      " [0.00021929]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0366206e-03 -9.2769733e-05  2.6749312e-05  9.8493612e-05\n",
      "   1.6550884e-04 -7.2693911e-05 -1.5607773e-04]]\n",
      "linear.bias:\n",
      " [0.00021988]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0331363e-03 -9.7992030e-05  2.9631929e-05  1.3905976e-04\n",
      "   1.6154090e-04 -2.5581448e-05 -1.6052301e-04]]\n",
      "linear.bias:\n",
      " [0.00022109]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0346880e-03 -1.0671568e-04  3.1559659e-05  1.1853443e-04\n",
      "   1.6827542e-04 -2.2251937e-05 -1.5978218e-04]]\n",
      "linear.bias:\n",
      " [0.00022183]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0423939e-03 -1.1705311e-04  3.3561631e-05  7.2508439e-05\n",
      "   1.8214232e-04 -5.5109042e-05 -1.5449962e-04]]\n",
      "linear.bias:\n",
      " [0.00022117]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04721135e-03 -1.12777547e-04  3.39367871e-05  1.10672816e-04\n",
      "   1.87324535e-04 -1.12764828e-05 -1.50479565e-04]]\n",
      "linear.bias:\n",
      " [0.00022057]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525228e-03 -1.0553187e-04  3.3186625e-05  1.1084929e-04\n",
      "   1.9387699e-04 -1.5996238e-06 -1.4468604e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0549997e-03 -9.6670781e-05  3.1144398e-05  6.1703264e-05\n",
      "   1.9230040e-04 -5.1448846e-05 -1.4237507e-04]]\n",
      "linear.bias:\n",
      " [0.00022119]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0579071e-03 -8.4150161e-05  2.8123148e-05  1.2376611e-04\n",
      "   1.7209697e-04  1.9285217e-06 -1.4707270e-04]]\n",
      "linear.bias:\n",
      " [0.00022026]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0598252e-03 -8.2401464e-05  2.7524829e-05  1.3879567e-04\n",
      "   1.6148106e-04 -2.4589394e-06 -1.4801962e-04]]\n",
      "linear.bias:\n",
      " [0.00021908]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505432e-03 -9.3310096e-05  2.8356435e-05  7.9330217e-05\n",
      "   1.6201021e-04 -6.1820116e-05 -1.4687428e-04]]\n",
      "linear.bias:\n",
      " [0.00021735]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0410391e-03 -1.0689694e-04  2.8684350e-05  7.8054698e-05\n",
      "   1.6401014e-04 -5.6391069e-05 -1.4412329e-04]]\n",
      "linear.bias:\n",
      " [0.00021714]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0335920e-03 -1.1370508e-04  2.9290099e-05  1.3378572e-04\n",
      "   1.6323091e-04  1.6025369e-06 -1.4270474e-04]]\n",
      "linear.bias:\n",
      " [0.00021795]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0317601e-03 -1.1362256e-04  2.8154454e-05  1.1585020e-04\n",
      "   1.6672854e-04 -8.1755488e-06 -1.4027723e-04]]\n",
      "linear.bias:\n",
      " [0.00022036]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352115e-03 -1.1111763e-04  2.6493019e-05  6.7344081e-05\n",
      "   1.7638539e-04 -5.5268556e-05 -1.3458534e-04]]\n",
      "linear.bias:\n",
      " [0.00022219]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403685e-03 -1.0096904e-04  2.4359784e-05  1.1789080e-04\n",
      "   1.6747785e-04 -6.9627640e-07 -1.3683084e-04]]\n",
      "linear.bias:\n",
      " [0.00022351]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462480e-03 -9.8739627e-05  2.3456956e-05  1.2230552e-04\n",
      "   1.6441045e-04  2.9506648e-06 -1.3675177e-04]]\n",
      "linear.bias:\n",
      " [0.00022503]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05232548e-03 -1.04741164e-04  2.43319846e-05  8.38519627e-05\n",
      "   1.69541017e-04 -4.57166716e-05 -1.34927395e-04]]\n",
      "linear.bias:\n",
      " [0.0002264]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05865253e-03 -1.06662395e-04  2.64222199e-05  9.21549654e-05\n",
      "   1.70077969e-04 -4.07362277e-05 -1.36389615e-04]]\n",
      "linear.bias:\n",
      " [0.00022662]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0621116e-03 -1.0274235e-04  2.9325201e-05  1.3450306e-04\n",
      "   1.6736673e-04  9.7967641e-06 -1.3991685e-04]]\n",
      "linear.bias:\n",
      " [0.00022615]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0571728e-03 -9.9105986e-05  3.1412044e-05  8.8202461e-05\n",
      "   1.6823626e-04 -3.1844214e-05 -1.4536739e-04]]\n",
      "linear.bias:\n",
      " [0.00022505]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502025e-03 -1.0005804e-04  3.4967481e-05  8.0658639e-05\n",
      "   1.7046618e-04 -3.9498562e-05 -1.4916465e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0408976e-03 -1.0431023e-04  3.7998216e-05  1.1729382e-04\n",
      "   1.7221000e-04 -6.2615909e-06 -1.5193140e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03871559e-03 -1.09755805e-04  4.04168750e-05  1.21597543e-04\n",
      "   1.79582828e-04 -1.26944833e-05 -1.50635242e-04]]\n",
      "linear.bias:\n",
      " [0.00021953]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0427167e-03 -1.0939251e-04  3.9107894e-05  8.8501103e-05\n",
      "   1.9077129e-04 -4.5826921e-05 -1.4670921e-04]]\n",
      "linear.bias:\n",
      " [0.00021807]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445488e-03 -9.9545192e-05  3.7260103e-05  1.1872970e-04\n",
      "   1.8769532e-04 -1.9502952e-05 -1.4776726e-04]]\n",
      "linear.bias:\n",
      " [0.0002171]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493535e-03 -9.2137110e-05  3.3885568e-05  1.0679760e-04\n",
      "   1.8369258e-04 -2.3626770e-05 -1.4912838e-04]]\n",
      "linear.bias:\n",
      " [0.00021758]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0539105e-03 -9.1524351e-05  2.9392790e-05  9.4179581e-05\n",
      "   1.7947669e-04 -2.4783405e-05 -1.4961956e-04]]\n",
      "linear.bias:\n",
      " [0.00021937]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05333596e-03 -9.70010879e-05  2.66036404e-05  1.01456564e-04\n",
      "   1.76938134e-04 -9.31294198e-06 -1.48407125e-04]]\n",
      "linear.bias:\n",
      " [0.00022131]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0518332e-03 -1.0509769e-04  2.6668711e-05  9.8482582e-05\n",
      "   1.8095470e-04 -2.1770524e-05 -1.4290644e-04]]\n",
      "linear.bias:\n",
      " [0.00022239]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04674511e-03 -1.14463284e-04  2.63907114e-05  1.08419881e-04\n",
      "   1.83142663e-04 -1.65191595e-05 -1.37823401e-04]]\n",
      "linear.bias:\n",
      " [0.00022369]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04249257e-03 -1.11701302e-04  2.74152771e-05  1.06254956e-04\n",
      "   1.82288655e-04 -1.40435695e-05 -1.34205373e-04]]\n",
      "linear.bias:\n",
      " [0.00022487]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0389925e-03 -9.8013908e-05  2.9613386e-05  9.3187475e-05\n",
      "   1.7869406e-04 -1.4068568e-05 -1.3190701e-04]]\n",
      "linear.bias:\n",
      " [0.00022593]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414070e-03 -9.1121758e-05  3.0728235e-05  1.0046724e-04\n",
      "   1.7460337e-04 -1.1657601e-05 -1.2971614e-04]]\n",
      "linear.bias:\n",
      " [0.00022586]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0472782e-03 -9.2172952e-05  3.1742173e-05  1.0557797e-04\n",
      "   1.7288454e-04 -2.3820628e-05 -1.2592906e-04]]\n",
      "linear.bias:\n",
      " [0.00022479]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0550267e-03 -9.6536853e-05  3.0548294e-05  1.0764616e-04\n",
      "   1.6981187e-04 -1.9548534e-05 -1.2549697e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05606578e-03 -1.03652514e-04  2.87814346e-05  9.55296200e-05\n",
      "   1.67064602e-04 -1.46722778e-05 -1.28287371e-04]]\n",
      "linear.bias:\n",
      " [0.00022431]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05494820e-03 -1.13470953e-04  2.82858673e-05  1.02697515e-04\n",
      "   1.64483339e-04 -4.04525144e-06 -1.31182227e-04]]\n",
      "linear.bias:\n",
      " [0.0002244]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04737200e-03 -1.18498414e-04  2.86981303e-05  8.79493964e-05\n",
      "   1.67797771e-04 -2.35440784e-05 -1.31368550e-04]]\n",
      "linear.bias:\n",
      " [0.00022415]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03904773e-03 -1.11042078e-04  2.88472747e-05  1.11979745e-04\n",
      "   1.66418235e-04 -8.18925764e-06 -1.34500631e-04]]\n",
      "linear.bias:\n",
      " [0.00022359]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0363534e-03 -1.0695117e-04  2.9320443e-05  1.0235797e-04\n",
      "   1.6976696e-04 -3.2030373e-05 -1.3459567e-04]]\n",
      "linear.bias:\n",
      " [0.00022274]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03620905e-03 -9.46747386e-05  2.91756060e-05  1.09911576e-04\n",
      "   1.69685751e-04 -1.30105873e-05 -1.37773633e-04]]\n",
      "linear.bias:\n",
      " [0.00022231]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397567e-03 -8.8238470e-05  2.9690373e-05  9.5871874e-05\n",
      "   1.7412224e-04 -2.6176764e-05 -1.3749770e-04]]\n",
      "linear.bias:\n",
      " [0.00022193]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483519e-03 -9.1608876e-05  2.8353914e-05  1.0570298e-04\n",
      "   1.7658027e-04 -1.6552580e-05 -1.3790335e-04]]\n",
      "linear.bias:\n",
      " [0.00022056]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05867279e-03 -1.02233709e-04  2.68035474e-05  1.01599086e-04\n",
      "   1.80530507e-04 -1.47291885e-05 -1.37376439e-04]]\n",
      "linear.bias:\n",
      " [0.00022001]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0649791e-03 -1.1404342e-04  2.5388366e-05  1.0075925e-04\n",
      "   1.8222387e-04 -1.1731500e-05 -1.3660449e-04]]\n",
      "linear.bias:\n",
      " [0.00022054]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0643997e-03 -1.1853651e-04  2.4401579e-05  9.1553149e-05\n",
      "   1.8193689e-04 -1.8763283e-05 -1.3497256e-04]]\n",
      "linear.bias:\n",
      " [0.00022238]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05842971e-03 -1.08813561e-04  2.36862488e-05  1.18935604e-04\n",
      "   1.72684217e-04  9.77043237e-06 -1.37028575e-04]]\n",
      "linear.bias:\n",
      " [0.00022472]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0409865e-03 -9.6457763e-05  2.5236035e-05  8.7202250e-05\n",
      "   1.6312787e-04 -5.0251452e-05 -1.4173619e-04]]\n",
      "linear.bias:\n",
      " [0.00022615]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0241407e-03 -8.9182737e-05  2.6841510e-05  9.2325950e-05\n",
      "   1.5513567e-04 -6.6601788e-05 -1.4590402e-04]]\n",
      "linear.bias:\n",
      " [0.00022709]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0184308e-03 -8.9668087e-05  2.7612266e-05  1.2470158e-04\n",
      "   1.5521122e-04 -2.1295557e-05 -1.4709485e-04]]\n",
      "linear.bias:\n",
      " [0.00022691]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.01958029e-03 -9.56555959e-05  2.82803685e-05  1.21080055e-04\n",
      "   1.66103084e-04 -1.68692113e-05 -1.42486460e-04]]\n",
      "linear.bias:\n",
      " [0.00022572]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02722587e-03 -1.03779465e-04  2.92482891e-05  8.67989875e-05\n",
      "   1.84014731e-04 -5.07459044e-05 -1.34102811e-04]]\n",
      "linear.bias:\n",
      " [0.00022363]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0355703e-03 -1.0257379e-04  3.0164774e-05  1.0594630e-04\n",
      "   1.8840491e-04 -2.4370414e-05 -1.3236357e-04]]\n",
      "linear.bias:\n",
      " [0.00022174]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498600e-03 -9.6652693e-05  2.9246385e-05  1.3027148e-04\n",
      "   1.8417805e-04  2.0876198e-05 -1.3584741e-04]]\n",
      "linear.bias:\n",
      " [0.00022072]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0592226e-03 -9.1406051e-05  2.8248523e-05  6.4773762e-05\n",
      "   1.7630335e-04 -5.1589835e-05 -1.4465587e-04]]\n",
      "linear.bias:\n",
      " [0.00022118]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0678339e-03 -8.6961008e-05  2.8214854e-05  9.4656374e-05\n",
      "   1.5846470e-04 -4.0352155e-05 -1.5607587e-04]]\n",
      "linear.bias:\n",
      " [0.00022022]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0691804e-03 -9.0282338e-05  2.9153874e-05  1.4922729e-04\n",
      "   1.4743183e-04  3.6289348e-06 -1.6220931e-04]]\n",
      "linear.bias:\n",
      " [0.00022039]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0573955e-03 -9.6551390e-05  3.0259813e-05  1.0037808e-04\n",
      "   1.6063840e-04 -4.6451885e-05 -1.6155682e-04]]\n",
      "linear.bias:\n",
      " [0.00022054]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0459280e-03 -1.0903965e-04  3.1821699e-05  6.6516070e-05\n",
      "   1.8126573e-04 -6.6347115e-05 -1.5633834e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0368595e-03 -1.0881570e-04  3.3501990e-05  1.3758430e-04\n",
      "   1.8915194e-04  1.5578764e-05 -1.5373722e-04]]\n",
      "linear.bias:\n",
      " [0.00021876]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0302392e-03 -9.9571109e-05  3.1790372e-05  1.1046974e-04\n",
      "   1.9318771e-04 -2.4027504e-06 -1.5488488e-04]]\n",
      "linear.bias:\n",
      " [0.00021873]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0281669e-03 -9.5070907e-05  3.0565450e-05  5.8975020e-05\n",
      "   1.9920281e-04 -5.8615515e-05 -1.5309930e-04]]\n",
      "linear.bias:\n",
      " [0.00021836]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0319423e-03 -8.7357999e-05  2.8994338e-05  1.2798596e-04\n",
      "   1.7988207e-04 -6.0092862e-06 -1.5742991e-04]]\n",
      "linear.bias:\n",
      " [0.00021665]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403668e-03 -8.7837696e-05  2.7544591e-05  1.3964040e-04\n",
      "   1.7033701e-04  1.0264162e-06 -1.5768418e-04]]\n",
      "linear.bias:\n",
      " [0.00021545]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525654e-03 -9.2347036e-05  2.7074186e-05  9.0839414e-05\n",
      "   1.7032548e-04 -4.6818841e-05 -1.5419077e-04]]\n",
      "linear.bias:\n",
      " [0.00021506]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0575975e-03 -1.0282534e-04  2.7309827e-05  7.7901706e-05\n",
      "   1.7294854e-04 -5.4065000e-05 -1.4868264e-04]]\n",
      "linear.bias:\n",
      " [0.0002154]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0613260e-03 -1.0470380e-04  2.7422002e-05  1.1863088e-04\n",
      "   1.7069833e-04 -1.0755441e-05 -1.4496542e-04]]\n",
      "linear.bias:\n",
      " [0.00021639]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0593781e-03 -1.0625098e-04  2.8906061e-05  1.1361070e-04\n",
      "   1.7339023e-04 -9.2892824e-06 -1.4002915e-04]]\n",
      "linear.bias:\n",
      " [0.00021867]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528034e-03 -1.0195228e-04  3.0421699e-05  7.2464158e-05\n",
      "   1.7845555e-04 -3.7276011e-05 -1.3427013e-04]]\n",
      "linear.bias:\n",
      " [0.00022176]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0445504e-03 -9.0745030e-05  3.1065716e-05  1.0025178e-04\n",
      "   1.6914625e-04 -5.1818788e-06 -1.3499217e-04]]\n",
      "linear.bias:\n",
      " [0.00022454]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0400512e-03 -8.8764144e-05  3.1893123e-05  1.1565488e-04\n",
      "   1.6393597e-04  1.4266943e-06 -1.3309477e-04]]\n",
      "linear.bias:\n",
      " [0.00022635]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0368840e-03 -9.6255331e-05  3.3694512e-05  8.4274798e-05\n",
      "   1.6598348e-04 -4.0784344e-05 -1.3037749e-04]]\n",
      "linear.bias:\n",
      " [0.00022867]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0406096e-03 -1.0624402e-04  3.4916604e-05  9.5690528e-05\n",
      "   1.6432015e-04 -3.2729491e-05 -1.3073692e-04]]\n",
      "linear.bias:\n",
      " [0.00022868]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0468466e-03 -1.0671293e-04  3.5754209e-05  1.3075676e-04\n",
      "   1.6194792e-04  1.8035847e-05 -1.3348473e-04]]\n",
      "linear.bias:\n",
      " [0.00022697]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462611e-03 -9.2296039e-05  3.3918197e-05  7.3203599e-05\n",
      "   1.6248676e-04 -4.6703550e-05 -1.4024282e-04]]\n",
      "linear.bias:\n",
      " [0.00022438]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437986e-03 -8.5297892e-05  3.1290569e-05  8.1000435e-05\n",
      "   1.6377644e-04 -6.1606945e-05 -1.4582551e-04]]\n",
      "linear.bias:\n",
      " [0.00022101]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0403591e-03 -8.7024753e-05  2.8311737e-05  1.3883135e-04\n",
      "   1.6611686e-04 -1.3943150e-05 -1.4977269e-04]]\n",
      "linear.bias:\n",
      " [0.00021832]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399579e-03 -9.7010015e-05  2.5396617e-05  1.3509209e-04\n",
      "   1.7747619e-04 -1.0765265e-05 -1.4939182e-04]]\n",
      "linear.bias:\n",
      " [0.00021625]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413448e-03 -1.1027041e-04  2.2968141e-05  6.7281762e-05\n",
      "   1.9013110e-04 -5.8030033e-05 -1.4809135e-04]]\n",
      "linear.bias:\n",
      " [0.00021612]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0437841e-03 -1.1259958e-04  2.1371070e-05  9.9890880e-05\n",
      "   1.8243791e-04 -6.2387589e-06 -1.5290741e-04]]\n",
      "linear.bias:\n",
      " [0.00021531]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0429166e-03 -1.1252507e-04  2.1666045e-05  1.2380244e-04\n",
      "   1.7813030e-04  1.5631662e-05 -1.5406180e-04]]\n",
      "linear.bias:\n",
      " [0.00021562]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0399263e-03 -1.0833609e-04  2.3219360e-05  8.0807280e-05\n",
      "   1.7416525e-04 -5.1297735e-05 -1.5505693e-04]]\n",
      "linear.bias:\n",
      " [0.0002166]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0385220e-03 -9.7468735e-05  2.6482412e-05  9.3358947e-05\n",
      "   1.6939106e-04 -6.1595900e-05 -1.5610173e-04]]\n",
      "linear.bias:\n",
      " [0.00021817]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0352560e-03 -9.1646187e-05  2.9316594e-05  1.4714709e-04\n",
      "   1.6695398e-04 -1.2901935e-05 -1.5572250e-04]]\n",
      "linear.bias:\n",
      " [0.00022098]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0359061e-03 -9.3227311e-05  3.1964541e-05  1.3585870e-04\n",
      "   1.7470552e-04 -1.1206257e-05 -1.5093676e-04]]\n",
      "linear.bias:\n",
      " [0.00022386]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397128e-03 -1.0096560e-04  3.3567194e-05  6.8564033e-05\n",
      "   1.8730650e-04 -5.2223229e-05 -1.4392442e-04]]\n",
      "linear.bias:\n",
      " [0.00022645]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04494498e-03 -1.03522012e-04  3.44132786e-05  1.03166516e-04\n",
      "   1.78516959e-04  7.23256744e-06 -1.45305778e-04]]\n",
      "linear.bias:\n",
      " [0.00022739]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0523726e-03 -1.0582483e-04  3.5401543e-05  1.1141185e-04\n",
      "   1.7095405e-04  8.4819030e-06 -1.4402358e-04]]\n",
      "linear.bias:\n",
      " [0.00022615]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0568477e-03 -1.0154617e-04  3.4540906e-05  8.3824634e-05\n",
      "   1.6865127e-04 -4.8203168e-05 -1.3979145e-04]]\n",
      "linear.bias:\n",
      " [0.00022223]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05871609e-03 -9.06041678e-05  3.33988210e-05  1.05265804e-04\n",
      "   1.62523371e-04 -4.92999679e-05 -1.37386858e-04]]\n",
      "linear.bias:\n",
      " [0.00021871]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0578237e-03 -8.3342180e-05  3.2499520e-05  1.3647083e-04\n",
      "   1.5931512e-04 -1.4725538e-05 -1.3502419e-04]]\n",
      "linear.bias:\n",
      " [0.00021658]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0542672e-03 -8.6520857e-05  3.0230041e-05  1.0665892e-04\n",
      "   1.6299021e-04 -2.5232202e-05 -1.3266808e-04]]\n",
      "linear.bias:\n",
      " [0.00021642]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0476346e-03 -9.8129545e-05  2.9618608e-05  7.0120994e-05\n",
      "   1.7255184e-04 -3.7500158e-05 -1.2940734e-04]]\n",
      "linear.bias:\n",
      " [0.00021801]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04177615e-03 -1.03148050e-04  2.88098017e-05  1.09344226e-04\n",
      "   1.68456376e-04  8.31987199e-06 -1.31867695e-04]]\n",
      "linear.bias:\n",
      " [0.0002198]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03724981e-03 -1.12755275e-04  2.83299669e-05  9.05569832e-05\n",
      "   1.65243968e-04 -2.04832904e-05 -1.36902221e-04]]\n",
      "linear.bias:\n",
      " [0.00022281]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0350831e-03 -1.1678499e-04  2.9212606e-05  1.0642130e-04\n",
      "   1.6147055e-04 -1.9124574e-05 -1.4232192e-04]]\n",
      "linear.bias:\n",
      " [0.00022412]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04074611e-03 -1.18413154e-04  2.90817934e-05  1.02843755e-04\n",
      "   1.66415019e-04 -4.10324610e-05 -1.42915873e-04]]\n",
      "linear.bias:\n",
      " [0.0002253]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04913907e-03 -1.05752966e-04  2.77380786e-05  1.21321544e-04\n",
      "   1.71996115e-04 -2.06914719e-05 -1.44118923e-04]]\n",
      "linear.bias:\n",
      " [0.00022531]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05762936e-03 -9.59375247e-05  2.57179272e-05  1.01619895e-04\n",
      "   1.79083989e-04 -3.27728485e-05 -1.43326150e-04]]\n",
      "linear.bias:\n",
      " [0.00022532]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06338947e-03 -9.06547866e-05  2.42962888e-05  1.07248765e-04\n",
      "   1.84610049e-04 -1.21596058e-05 -1.42772347e-04]]\n",
      "linear.bias:\n",
      " [0.00022498]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0624934e-03 -9.0332367e-05  2.3946994e-05  1.0221162e-04\n",
      "   1.8917063e-04 -8.2111492e-06 -1.4112686e-04]]\n",
      "linear.bias:\n",
      " [0.00022432]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0560348e-03 -9.5050658e-05  2.5576524e-05  9.3016330e-05\n",
      "   1.9244979e-04 -2.6052907e-05 -1.3831785e-04]]\n",
      "linear.bias:\n",
      " [0.00022268]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04622275e-03 -9.97336683e-05  2.76247320e-05  1.16486415e-04\n",
      "   1.88919686e-04 -1.17498876e-05 -1.38066505e-04]]\n",
      "linear.bias:\n",
      " [0.00022154]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0373694e-03 -1.0490992e-04  2.8406725e-05  8.3249761e-05\n",
      "   1.8234804e-04 -3.6242105e-05 -1.3996029e-04]]\n",
      "linear.bias:\n",
      " [0.00022228]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02959468e-03 -1.01868914e-04  2.91750384e-05  9.62283302e-05\n",
      "   1.67138831e-04 -8.11725113e-06 -1.45805956e-04]]\n",
      "linear.bias:\n",
      " [0.00022295]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0305612e-03 -1.0358199e-04  2.9653687e-05  9.9989942e-05\n",
      "   1.6068733e-04 -1.0714213e-05 -1.4614472e-04]]\n",
      "linear.bias:\n",
      " [0.00022214]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03902246e-03 -1.09723056e-04  2.99196636e-05  8.97380523e-05\n",
      "   1.62845565e-04 -4.24197133e-05 -1.41604876e-04]]\n",
      "linear.bias:\n",
      " [0.00022071]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456068e-03 -1.0668175e-04  3.0623076e-05  1.1766412e-04\n",
      "   1.6334029e-04 -2.6942418e-05 -1.3866577e-04]]\n",
      "linear.bias:\n",
      " [0.00021942]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0475831e-03 -9.9852383e-05  3.1791398e-05  1.2825817e-04\n",
      "   1.6880329e-04 -1.7132308e-05 -1.3353296e-04]]\n",
      "linear.bias:\n",
      " [0.00022037]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0493054e-03 -9.8649194e-05  3.0913277e-05  7.7325283e-05\n",
      "   1.7415520e-04 -5.1089977e-05 -1.2987330e-04]]\n",
      "linear.bias:\n",
      " [0.00022334]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0498804e-03 -9.1496309e-05  2.9245328e-05  9.3554772e-05\n",
      "   1.6725200e-04 -2.0898815e-05 -1.3223824e-04]]\n",
      "linear.bias:\n",
      " [0.00022532]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0487416e-03 -8.9181784e-05  2.9359140e-05  1.3441179e-04\n",
      "   1.6288535e-04  2.4534003e-05 -1.3325989e-04]]\n",
      "linear.bias:\n",
      " [0.00022568]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0404246e-03 -8.3464576e-05  2.8248778e-05  6.8056608e-05\n",
      "   1.6240741e-04 -6.1699568e-05 -1.3813126e-04]]\n",
      "linear.bias:\n",
      " [0.00022601]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0374452e-03 -8.6493106e-05  2.7312954e-05  1.1733800e-04\n",
      "   1.5147010e-04 -3.4836161e-05 -1.4745980e-04]]\n",
      "linear.bias:\n",
      " [0.00022348]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0397113e-03 -9.6478027e-05  2.6215304e-05  1.4131681e-04\n",
      "   1.5414179e-04 -5.4157863e-06 -1.5073917e-04]]\n",
      "linear.bias:\n",
      " [0.00022191]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04376127e-03 -1.08953740e-04  2.55378691e-05  1.00351346e-04\n",
      "   1.71167485e-04 -3.21198968e-05 -1.48430860e-04]]\n",
      "linear.bias:\n",
      " [0.00022049]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456359e-03 -1.2504456e-04  2.6133946e-05  8.1320592e-05\n",
      "   1.8814715e-04 -2.9314127e-05 -1.4506211e-04]]\n",
      "linear.bias:\n",
      " [0.00021922]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04548107e-03 -1.24049664e-04  2.61579862e-05  1.21979654e-04\n",
      "   1.94619963e-04  1.84260316e-05 -1.44735648e-04]]\n",
      "linear.bias:\n",
      " [0.00021984]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439497e-03 -1.0602252e-04  2.4335095e-05  8.1402555e-05\n",
      "   1.9357035e-04 -3.1548952e-05 -1.4990366e-04]]\n",
      "linear.bias:\n",
      " [0.00022181]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0447421e-03 -8.0787388e-05  2.3136170e-05  1.0440431e-04\n",
      "   1.8147049e-04 -2.8283681e-05 -1.5832379e-04]]\n",
      "linear.bias:\n",
      " [0.00022324]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0483684e-03 -7.1692877e-05  2.1778251e-05  1.3443099e-04\n",
      "   1.7337638e-04 -6.2321578e-06 -1.6362801e-04]]\n",
      "linear.bias:\n",
      " [0.00022452]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04901160e-03 -7.72499116e-05  2.22941453e-05  1.04348845e-04\n",
      "   1.75861045e-04 -3.78067343e-05 -1.63838704e-04]]\n",
      "linear.bias:\n",
      " [0.00022497]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0530290e-03 -9.6810763e-05  2.2452092e-05  7.9894555e-05\n",
      "   1.8401351e-04 -4.7150847e-05 -1.6097230e-04]]\n",
      "linear.bias:\n",
      " [0.00022537]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05302071e-03 -1.16146024e-04  2.52479877e-05  1.15020273e-04\n",
      "   1.90051127e-04 -1.69402701e-05 -1.56233946e-04]]\n",
      "linear.bias:\n",
      " [0.00022467]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0469405e-03 -1.2707847e-04  2.7922837e-05  1.1599425e-04\n",
      "   1.9711030e-04 -1.8629735e-05 -1.4972860e-04]]\n",
      "linear.bias:\n",
      " [0.00022404]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0386525e-03 -1.1832499e-04  3.0485598e-05  8.3917759e-05\n",
      "   1.9912129e-04 -3.9442239e-05 -1.4530754e-04]]\n",
      "linear.bias:\n",
      " [0.00022382]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0301268e-03 -1.0085972e-04  3.2396914e-05  1.1064028e-04\n",
      "   1.8659318e-04 -2.6834714e-06 -1.4651497e-04]]\n",
      "linear.bias:\n",
      " [0.00022327]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0264697e-03 -8.9083449e-05  3.4444973e-05  1.0768206e-04\n",
      "   1.7777190e-04 -9.4769030e-06 -1.4468824e-04]]\n",
      "linear.bias:\n",
      " [0.00022242]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0322382e-03 -8.5366300e-05  3.5279194e-05  8.5995416e-05\n",
      "   1.7510619e-04 -5.0617331e-05 -1.3920212e-04]]\n",
      "linear.bias:\n",
      " [0.00022059]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0425170e-03 -9.3441195e-05  3.5128698e-05  1.0791450e-04\n",
      "   1.7014441e-04 -5.0425293e-05 -1.3487737e-04]]\n",
      "linear.bias:\n",
      " [0.00021787]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05626183e-03 -1.03679224e-04  3.24445064e-05  1.38152915e-04\n",
      "   1.64233614e-04 -1.94320928e-05 -1.32450179e-04]]\n",
      "linear.bias:\n",
      " [0.00021649]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0621770e-03 -1.1150931e-04  2.7274193e-05  9.4859184e-05\n",
      "   1.6031388e-04 -4.2788095e-05 -1.3287159e-04]]\n",
      "linear.bias:\n",
      " [0.00021774]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0641055e-03 -1.0716826e-04  2.3119223e-05  8.2560204e-05\n",
      "   1.5434608e-04 -1.9119954e-05 -1.3522861e-04]]\n",
      "linear.bias:\n",
      " [0.00021959]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.06123369e-03 -1.03073820e-04  2.07585472e-05  1.03506856e-04\n",
      "   1.50822001e-04  2.30741280e-05 -1.36130635e-04]]\n",
      "linear.bias:\n",
      " [0.00022053]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0456656e-03 -9.5677598e-05  2.1540533e-05  7.6972647e-05\n",
      "   1.5837709e-04 -3.3137811e-05 -1.3460520e-04]]\n",
      "linear.bias:\n",
      " [0.00022174]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0311983e-03 -9.2888935e-05  2.3213623e-05  9.1092807e-05\n",
      "   1.6634339e-04 -5.1324008e-05 -1.3333537e-04]]\n",
      "linear.bias:\n",
      " [0.00022211]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0201744e-03 -9.0415902e-05  2.5790867e-05  1.4654729e-04\n",
      "   1.6954509e-04 -1.9905201e-05 -1.3524939e-04]]\n",
      "linear.bias:\n",
      " [0.00022102]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0131014e-03 -9.4356328e-05  2.6931939e-05  1.2555342e-04\n",
      "   1.7423410e-04 -4.3467106e-05 -1.3743802e-04]]\n",
      "linear.bias:\n",
      " [0.00022182]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0138546e-03 -1.0033556e-04  2.5242976e-05  1.0047636e-04\n",
      "   1.8049283e-04 -4.4169967e-05 -1.4001956e-04]]\n",
      "linear.bias:\n",
      " [0.00022398]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02251628e-03 -1.04877385e-04  2.21031460e-05  1.08854816e-04\n",
      "   1.78727394e-04 -2.33591345e-06 -1.45920203e-04]]\n",
      "linear.bias:\n",
      " [0.0002252]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0359958e-03 -1.1294615e-04  1.9245834e-05  9.3010247e-05\n",
      "   1.8299332e-04 -1.5291960e-06 -1.4676353e-04]]\n",
      "linear.bias:\n",
      " [0.00022523]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0466552e-03 -1.2232910e-04  1.8860841e-05  7.9385922e-05\n",
      "   1.8814165e-04 -2.4085137e-05 -1.4439288e-04]]\n",
      "linear.bias:\n",
      " [0.00022525]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0526148e-03 -1.1623092e-04  2.0165175e-05  1.2213964e-04\n",
      "   1.8239231e-04 -7.3052506e-06 -1.4567285e-04]]\n",
      "linear.bias:\n",
      " [0.00022456]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04922603e-03 -9.88392276e-05  2.22932358e-05  1.05527404e-04\n",
      "   1.74355489e-04 -4.88687729e-05 -1.47330022e-04]]\n",
      "linear.bias:\n",
      " [0.00022393]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444298e-03 -8.7758075e-05  2.5231782e-05  1.1526103e-04\n",
      "   1.6844552e-04 -5.4094900e-05 -1.4805851e-04]]\n",
      "linear.bias:\n",
      " [0.00022265]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0381236e-03 -8.3926141e-05  2.9188601e-05  1.2186683e-04\n",
      "   1.6988162e-04 -2.7662199e-05 -1.4664268e-04]]\n",
      "linear.bias:\n",
      " [0.00022293]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03498914e-03 -8.90546435e-05  3.31372867e-05  1.05742314e-04\n",
      "   1.78618429e-04 -2.02694464e-05 -1.41747092e-04]]\n",
      "linear.bias:\n",
      " [0.00022427]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0388568e-03 -1.0490361e-04  3.5248158e-05  8.7667438e-05\n",
      "   1.8713169e-04 -2.2328626e-05 -1.3630127e-04]]\n",
      "linear.bias:\n",
      " [0.00022511]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04633323e-03 -1.13612514e-04  3.54728945e-05  1.08156455e-04\n",
      "   1.85335099e-04  1.11928130e-05 -1.35692244e-04]]\n",
      "linear.bias:\n",
      " [0.00022586]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0512777e-03 -1.0616216e-04  3.2408687e-05  6.8943496e-05\n",
      "   1.7763146e-04 -3.4436493e-05 -1.3986290e-04]]\n",
      "linear.bias:\n",
      " [0.00022619]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541003e-03 -9.0833135e-05  2.8614613e-05  1.1266461e-04\n",
      "   1.5971671e-04 -2.3692301e-05 -1.4792242e-04]]\n",
      "linear.bias:\n",
      " [0.00022576]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0598863e-03 -8.6416083e-05  2.4864055e-05  1.3105939e-04\n",
      "   1.5453367e-04 -3.4951790e-05 -1.4947981e-04]]\n",
      "linear.bias:\n",
      " [0.00022573]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05750421e-03 -8.90635565e-05  2.17127599e-05  1.13688766e-04\n",
      "   1.64402285e-04 -4.51437190e-05 -1.45768223e-04]]\n",
      "linear.bias:\n",
      " [0.0002257]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0529973e-03 -9.8744786e-05  2.0048459e-05  9.7598531e-05\n",
      "   1.7955215e-04 -3.2126543e-05 -1.3994540e-04]]\n",
      "linear.bias:\n",
      " [0.00022676]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04552356e-03 -1.12194153e-04  1.97743993e-05  1.14090188e-04\n",
      "   1.93842847e-04  1.45950435e-05 -1.34070156e-04]]\n",
      "linear.bias:\n",
      " [0.00022736]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0322452e-03 -1.1324672e-04  1.9268973e-05  6.3385203e-05\n",
      "   1.9840350e-04 -2.7053622e-05 -1.3471572e-04]]\n",
      "linear.bias:\n",
      " [0.00022861]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02277205e-03 -1.07469416e-04  1.95141638e-05  9.83972350e-05\n",
      "   1.84593955e-04 -2.21372102e-06 -1.42310033e-04]]\n",
      "linear.bias:\n",
      " [0.0002283]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.01991708e-03 -1.03985178e-04  2.02712527e-05  1.17062686e-04\n",
      "   1.74020490e-04 -1.80524603e-05 -1.46555991e-04]]\n",
      "linear.bias:\n",
      " [0.00022585]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.02416344e-03 -1.03527302e-04  2.12407376e-05  1.06197345e-04\n",
      "   1.72922373e-04 -6.81384481e-05 -1.45390251e-04]]\n",
      "linear.bias:\n",
      " [0.0002222]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0314996e-03 -9.4621035e-05  2.2514749e-05  1.2591766e-04\n",
      "   1.6871646e-04 -4.5036242e-05 -1.4716102e-04]]\n",
      "linear.bias:\n",
      " [0.00021963]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414821e-03 -9.2928487e-05  2.4132420e-05  1.2755101e-04\n",
      "   1.7362190e-04 -8.4755011e-06 -1.4494197e-04]]\n",
      "linear.bias:\n",
      " [0.00021913]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0510804e-03 -9.9046876e-05  2.6113954e-05  8.4071653e-05\n",
      "   1.8246257e-04 -1.6143069e-05 -1.4124085e-04]]\n",
      "linear.bias:\n",
      " [0.00021941]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05602958e-03 -1.08326960e-04  2.94903293e-05  7.58661990e-05\n",
      "   1.88471255e-04 -1.05636755e-05 -1.37960655e-04]]\n",
      "linear.bias:\n",
      " [0.00021965]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0593846e-03 -1.0763764e-04  3.2835782e-05  1.2171738e-04\n",
      "   1.8084384e-04  2.0753185e-05 -1.4019827e-04]]\n",
      "linear.bias:\n",
      " [0.00022024]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0544391e-03 -9.7872449e-05  3.3742846e-05  8.3575120e-05\n",
      "   1.6995396e-04 -5.4260978e-05 -1.4808335e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0467313e-03 -9.2724185e-05  3.4375989e-05  9.3064358e-05\n",
      "   1.5986455e-04 -8.1539685e-05 -1.5448206e-04]]\n",
      "linear.bias:\n",
      " [0.0002233]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0387675e-03 -8.8168927e-05  3.3858651e-05  1.5327720e-04\n",
      "   1.6010932e-04 -2.3112520e-05 -1.5577406e-04]]\n",
      "linear.bias:\n",
      " [0.00022425]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0324362e-03 -8.6859458e-05  3.2110514e-05  1.4008617e-04\n",
      "   1.7344452e-04 -1.5686119e-05 -1.5253708e-04]]\n",
      "linear.bias:\n",
      " [0.00022401]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0302780e-03 -9.3213566e-05  3.0344610e-05  7.1956572e-05\n",
      "   1.9353638e-04 -5.1024355e-05 -1.4586578e-04]]\n",
      "linear.bias:\n",
      " [0.00022343]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0323300e-03 -9.9443947e-05  2.8025295e-05  1.0468920e-04\n",
      "   1.8966802e-04  7.1699942e-06 -1.4799973e-04]]\n",
      "linear.bias:\n",
      " [0.00022218]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0390391e-03 -1.0717795e-04  2.6134512e-05  1.1103485e-04\n",
      "   1.8592927e-04  9.5709156e-06 -1.4826372e-04]]\n",
      "linear.bias:\n",
      " [0.00022033]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04699656e-03 -1.13554044e-04  2.52690552e-05  7.52454507e-05\n",
      "   1.79596071e-04 -5.31675651e-05 -1.48576233e-04]]\n",
      "linear.bias:\n",
      " [0.00021867]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05267065e-03 -1.06392086e-04  2.43750910e-05  1.07772481e-04\n",
      "   1.64683181e-04 -4.09883578e-05 -1.51233820e-04]]\n",
      "linear.bias:\n",
      " [0.00021826]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0541385e-03 -1.0246913e-04  2.4230460e-05  1.3414232e-04\n",
      "   1.5831244e-04 -8.4271851e-06 -1.5108667e-04]]\n",
      "linear.bias:\n",
      " [0.00021971]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0550427e-03 -9.8107957e-05  2.4101579e-05  9.7913347e-05\n",
      "   1.6594224e-04 -3.4327895e-05 -1.4584820e-04]]\n",
      "linear.bias:\n",
      " [0.00022139]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0532158e-03 -1.0035761e-04  2.4880668e-05  8.6510932e-05\n",
      "   1.7485110e-04 -2.9673922e-05 -1.3957187e-04]]\n",
      "linear.bias:\n",
      " [0.00022253]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04825792e-03 -1.07044849e-04  2.71490499e-05  1.09251894e-04\n",
      "   1.82610558e-04  9.70604196e-06 -1.33578083e-04]]\n",
      "linear.bias:\n",
      " [0.00022356]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0414888e-03 -1.0532422e-04  2.7284568e-05  6.6051522e-05\n",
      "   1.8261671e-04 -3.4645636e-05 -1.3360930e-04]]\n",
      "linear.bias:\n",
      " [0.00022485]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03547156e-03 -9.50215399e-05  2.71384033e-05  1.01377125e-04\n",
      "   1.67889026e-04 -2.11481602e-05 -1.39144264e-04]]\n",
      "linear.bias:\n",
      " [0.00022564]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0341391e-03 -9.4090239e-05  2.7655336e-05  1.4058975e-04\n",
      "   1.5883705e-04 -9.7838110e-06 -1.4152039e-04]]\n",
      "linear.bias:\n",
      " [0.00022454]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0372982e-03 -9.7508142e-05  2.8192342e-05  1.1699258e-04\n",
      "   1.5977475e-04 -4.4330634e-05 -1.3975755e-04]]\n",
      "linear.bias:\n",
      " [0.00022354]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0444331e-03 -1.1013123e-04  2.7804037e-05  8.8898181e-05\n",
      "   1.6865345e-04 -5.7588601e-05 -1.3493429e-04]]\n",
      "linear.bias:\n",
      " [0.00022337]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0519597e-03 -1.1461313e-04  2.7648946e-05  1.0441684e-04\n",
      "   1.7277173e-04 -1.6004436e-05 -1.3421591e-04]]\n",
      "linear.bias:\n",
      " [0.00022249]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05591223e-03 -1.12579793e-04  2.75951279e-05  1.03854225e-04\n",
      "   1.78256218e-04  1.23955524e-05 -1.32131172e-04]]\n",
      "linear.bias:\n",
      " [0.00022352]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0511724e-03 -9.4545307e-05  2.7356886e-05  4.7014266e-05\n",
      "   1.7785108e-04 -3.7700476e-05 -1.3428125e-04]]\n",
      "linear.bias:\n",
      " [0.00022519]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0494861e-03 -7.7155331e-05  2.7602196e-05  1.0473821e-04\n",
      "   1.6326259e-04 -5.9212471e-06 -1.4190494e-04]]\n",
      "linear.bias:\n",
      " [0.00022339]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0528585e-03 -7.3856892e-05  2.8989416e-05  1.4071871e-04\n",
      "   1.5826037e-04 -9.6503709e-06 -1.4389574e-04]]\n",
      "linear.bias:\n",
      " [0.00022104]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04888645e-03 -8.61409790e-05  3.03913803e-05  1.06211955e-04\n",
      "   1.63331861e-04 -6.40977960e-05 -1.44061865e-04]]\n",
      "linear.bias:\n",
      " [0.00021929]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0439419e-03 -1.0164004e-04  3.2867756e-05  8.8461551e-05\n",
      "   1.7338227e-04 -7.0733222e-05 -1.4315904e-04]]\n",
      "linear.bias:\n",
      " [0.00021881]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0401164e-03 -1.0779190e-04  3.5099856e-05  1.2557516e-04\n",
      "   1.7687996e-04  1.6453851e-07 -1.4561914e-04]]\n",
      "linear.bias:\n",
      " [0.00021985]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.03913189e-03 -1.03482285e-04  3.36445373e-05  9.34952550e-05\n",
      "   1.77736016e-04  1.45596250e-05 -1.49869898e-04]]\n",
      "linear.bias:\n",
      " [0.00022189]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0462312e-03 -1.0160868e-04  3.2061536e-05  5.3652697e-05\n",
      "   1.8217218e-04 -1.7830735e-05 -1.4832712e-04]]\n",
      "linear.bias:\n",
      " [0.00022225]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0525050e-03 -9.7435259e-05  3.0159519e-05  1.1220873e-04\n",
      "   1.7705909e-04  1.4223588e-06 -1.4699239e-04]]\n",
      "linear.bias:\n",
      " [0.00022185]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0600736e-03 -9.8436009e-05  2.8974942e-05  1.3800235e-04\n",
      "   1.7680904e-04 -1.9199235e-05 -1.4216994e-04]]\n",
      "linear.bias:\n",
      " [0.00022038]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0617983e-03 -1.0013144e-04  2.5510086e-05  8.4740663e-05\n",
      "   1.7530969e-04 -9.0232330e-05 -1.4016272e-04]]\n",
      "linear.bias:\n",
      " [0.00022016]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0639234e-03 -9.3643299e-05  2.3157081e-05  1.1654259e-04\n",
      "   1.6176265e-04 -4.1939846e-05 -1.4427448e-04]]\n",
      "linear.bias:\n",
      " [0.00021959]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0612907e-03 -9.4789735e-05  2.2123819e-05  1.3826016e-04\n",
      "   1.5584989e-04  2.1293778e-05 -1.4596715e-04]]\n",
      "linear.bias:\n",
      " [0.00022019]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0478414e-03 -9.1613350e-05  2.2072027e-05  4.8620772e-05\n",
      "   1.6529438e-04 -4.0349802e-05 -1.4720832e-04]]\n",
      "linear.bias:\n",
      " [0.00021999]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0362522e-03 -9.5252151e-05  2.2167742e-05  5.6944838e-05\n",
      "   1.7473094e-04 -4.6452224e-05 -1.4474841e-04]]\n",
      "linear.bias:\n",
      " [0.00021722]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0292918e-03 -9.5712887e-05  2.4163452e-05  1.6882220e-04\n",
      "   1.7124649e-04  2.9198323e-05 -1.4584752e-04]]\n",
      "linear.bias:\n",
      " [0.00021363]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0155562e-03 -8.7725421e-05  2.6532707e-05  1.4079826e-04\n",
      "   1.7358629e-04 -6.0123799e-05 -1.5065234e-04]]\n",
      "linear.bias:\n",
      " [0.00021298]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0103382e-03 -8.3224484e-05  2.6212885e-05  9.1057547e-05\n",
      "   1.8503814e-04 -1.2349461e-04 -1.5176434e-04]]\n",
      "linear.bias:\n",
      " [0.00021534]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0339504e-03 -7.9252379e-05  2.5558065e-05  1.7051329e-04\n",
      "   1.7772267e-04 -2.0854437e-05 -1.6104706e-04]]\n",
      "linear.bias:\n",
      " [0.00021526]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0553219e-03 -8.5468862e-05  2.5988842e-05  1.4116413e-04\n",
      "   1.7778864e-04  1.4587891e-05 -1.6784959e-04]]\n",
      "linear.bias:\n",
      " [0.0002174]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0739119e-03 -9.3500734e-05  2.7732476e-05  3.0761512e-05\n",
      "   1.8580572e-04 -4.3902113e-05 -1.7076332e-04]]\n",
      "linear.bias:\n",
      " [0.00022007]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.08263257e-03 -1.11946305e-04  3.02705284e-05  7.42307675e-05\n",
      "   1.83048236e-04 -9.23715925e-06 -1.68809551e-04]]\n",
      "linear.bias:\n",
      " [0.00021877]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0810681e-03 -1.2502348e-04  3.2281332e-05  1.6393248e-04\n",
      "   1.8813874e-04  1.3090723e-05 -1.5720687e-04]]\n",
      "linear.bias:\n",
      " [0.00021834]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0484691e-03 -1.1517386e-04  3.3376815e-05  1.0054731e-04\n",
      "   1.9109358e-04 -1.0366243e-04 -1.5315544e-04]]\n",
      "linear.bias:\n",
      " [0.00021721]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008693\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.01857225e-03 -9.20379098e-05  3.42694148e-05  1.12959824e-04\n",
      "   1.80641364e-04 -1.01713020e-04 -1.55341651e-04]]\n",
      "linear.bias:\n",
      " [0.00021731]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0027230e-03 -6.9182279e-05  3.2910171e-05  1.5963224e-04\n",
      "   1.6850192e-04 -4.7420835e-06 -1.6112508e-04]]\n",
      "linear.bias:\n",
      " [0.00021666]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.93822468e-04 -5.92108809e-05  3.07066512e-05  1.19679535e-04\n",
      "   1.63905672e-04  2.42020506e-05 -1.65223115e-04]]\n",
      "linear.bias:\n",
      " [0.0002183]\n",
      "\n",
      "Test loss: 0.006388, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-9.9882542e-04 -6.8423076e-05  3.0773404e-05  4.4478846e-05\n",
      "   1.7355867e-04 -2.5090641e-05 -1.5946338e-04]]\n",
      "linear.bias:\n",
      " [0.00022014]\n",
      "\n",
      "Test loss: 0.006387, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0237253e-03 -9.4134106e-05  2.8988517e-05  7.6718556e-05\n",
      "   1.8157376e-04 -1.8758103e-05 -1.4885514e-04]]\n",
      "linear.bias:\n",
      " [0.0002192]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05301815e-03 -1.28176922e-04  2.67498490e-05  1.54085777e-04\n",
      "   1.88035614e-04  1.42195095e-05 -1.37387309e-04]]\n",
      "linear.bias:\n",
      " [0.00021799]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0721642e-03 -1.4024215e-04  2.0285896e-05  1.1181316e-04\n",
      "   1.8869090e-04 -6.8431284e-05 -1.3577414e-04]]\n",
      "linear.bias:\n",
      " [0.00021949]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0785910e-03 -1.2045319e-04  1.5261719e-05  1.1218694e-04\n",
      "   1.7420680e-04 -6.4171581e-05 -1.4021684e-04]]\n",
      "linear.bias:\n",
      " [0.00022048]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0773384e-03 -8.8808651e-05  1.1099339e-05  1.2617059e-04\n",
      "   1.5699730e-04 -1.2872562e-05 -1.4724632e-04]]\n",
      "linear.bias:\n",
      " [0.00022248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0615122e-03 -7.2288378e-05  1.1599503e-05  8.9071822e-05\n",
      "   1.5407497e-04 -1.7464543e-05 -1.5053713e-04]]\n",
      "linear.bias:\n",
      " [0.00022391]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0413436e-03 -7.2366849e-05  1.5815884e-05  6.6663037e-05\n",
      "   1.6264874e-04 -3.3847282e-05 -1.4707491e-04]]\n",
      "linear.bias:\n",
      " [0.00022446]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0237643e-03 -8.4022213e-05  2.2868477e-05  1.0593973e-04\n",
      "   1.7159367e-04 -1.3343697e-05 -1.4146685e-04]]\n",
      "linear.bias:\n",
      " [0.00022271]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0136693e-03 -1.0497597e-04  3.0419786e-05  1.3009459e-04\n",
      "   1.8588708e-04 -1.7961909e-05 -1.3200364e-04]]\n",
      "linear.bias:\n",
      " [0.00022039]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0116791e-03 -1.1884722e-04  3.3884622e-05  9.7260752e-05\n",
      "   1.9364626e-04 -6.0882092e-05 -1.2693689e-04]]\n",
      "linear.bias:\n",
      " [0.00022054]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0337235e-03 -1.1147614e-04  3.0819272e-05  1.2305268e-04\n",
      "   1.7925334e-04 -2.1408989e-05 -1.3388526e-04]]\n",
      "linear.bias:\n",
      " [0.0002218]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0584558e-03 -9.9319048e-05  2.4053694e-05  9.6233984e-05\n",
      "   1.6207450e-04 -2.1128817e-05 -1.4347414e-04]]\n",
      "linear.bias:\n",
      " [0.0002248]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0783917e-03 -9.4431991e-05  1.9887459e-05  8.1400001e-05\n",
      "   1.5196530e-04 -1.4479225e-05 -1.4952275e-04]]\n",
      "linear.bias:\n",
      " [0.00022675]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0842752e-03 -9.5488162e-05  1.8483051e-05  1.0031413e-04\n",
      "   1.5126787e-04 -1.8524985e-05 -1.4914694e-04]]\n",
      "linear.bias:\n",
      " [0.00022664]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0792610e-03 -1.0489842e-04  1.9639507e-05  1.0544317e-04\n",
      "   1.6436924e-04 -4.9378232e-05 -1.4192036e-04]]\n",
      "linear.bias:\n",
      " [0.00022579]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0637023e-03 -1.1291323e-04  2.1070533e-05  1.3007504e-04\n",
      "   1.7826162e-04 -4.5044286e-05 -1.3472150e-04]]\n",
      "linear.bias:\n",
      " [0.00022428]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0416774e-03 -1.0420762e-04  2.2062499e-05  1.3665484e-04\n",
      "   1.8658490e-04 -9.5789874e-06 -1.3277517e-04]]\n",
      "linear.bias:\n",
      " [0.00022367]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0193697e-03 -9.0093185e-05  2.0684161e-05  7.2983494e-05\n",
      "   1.8640142e-04 -4.0496241e-05 -1.3591028e-04]]\n",
      "linear.bias:\n",
      " [0.00022424]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0114849e-03 -8.5491869e-05  1.9295056e-05  9.6717020e-05\n",
      "   1.6853820e-04 -6.0315142e-06 -1.4573828e-04]]\n",
      "linear.bias:\n",
      " [0.00022176]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0154442e-03 -8.9503003e-05  1.7648003e-05  1.1617662e-04\n",
      "   1.6009463e-04 -2.3693060e-06 -1.4904891e-04]]\n",
      "linear.bias:\n",
      " [0.00021802]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0257819e-03 -9.8449207e-05  1.7301727e-05  9.8749311e-05\n",
      "   1.6331962e-04 -4.1322888e-05 -1.4695775e-04]]\n",
      "linear.bias:\n",
      " [0.00021466]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0361002e-03 -1.1076959e-04  1.7437949e-05  9.5329553e-05\n",
      "   1.6982309e-04 -4.8686972e-05 -1.4432552e-04]]\n",
      "linear.bias:\n",
      " [0.000212]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04617246e-03 -1.13743234e-04  1.78805149e-05  1.28608430e-04\n",
      "   1.72187516e-04 -7.56522059e-06 -1.44506077e-04]]\n",
      "linear.bias:\n",
      " [0.00021074]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.04963616e-03 -1.10234221e-04  1.92957104e-05  1.07023254e-04\n",
      "   1.76135742e-04 -1.30799326e-05 -1.44489313e-04]]\n",
      "linear.bias:\n",
      " [0.00021261]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0505803e-03 -1.0391914e-04  2.2185841e-05  7.4745461e-05\n",
      "   1.8452444e-04 -3.4778663e-05 -1.4172291e-04]]\n",
      "linear.bias:\n",
      " [0.00021579]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0502087e-03 -8.7542074e-05  2.4023710e-05  1.0700946e-04\n",
      "   1.7909156e-04 -1.7401180e-06 -1.4358453e-04]]\n",
      "linear.bias:\n",
      " [0.00021979]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.05338404e-03 -7.88460384e-05  2.68080130e-05  1.10364665e-04\n",
      "   1.78221075e-04 -1.04584951e-05 -1.41708486e-04]]\n",
      "linear.bias:\n",
      " [0.00022301]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0570384e-03 -8.4751009e-05  2.9371036e-05  9.4569557e-05\n",
      "   1.7881070e-04 -3.9645143e-05 -1.3879957e-04]]\n",
      "linear.bias:\n",
      " [0.00022516]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0584128e-03 -9.8294382e-05  3.2402440e-05  1.1317612e-04\n",
      "   1.7593836e-04 -2.9905001e-05 -1.3735339e-04]]\n",
      "linear.bias:\n",
      " [0.00022634]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0540074e-03 -1.1236124e-04  3.5006004e-05  1.1944002e-04\n",
      "   1.7409911e-04 -1.1470425e-05 -1.3635548e-04]]\n",
      "linear.bias:\n",
      " [0.00022854]\n",
      "\n",
      "Test loss: 0.006386, Train loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0438747e-03 -1.1667887e-04  3.3763856e-05  7.4283111e-05\n",
      "   1.7460091e-04 -3.2432610e-05 -1.3567324e-04]]\n",
      "linear.bias:\n",
      " [0.00022938]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n",
      "Epoch [5000/5000], Loss: 0.008692\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight:\n",
      " [[-1.0334103e-03 -1.0707454e-04  3.2034757e-05  8.9628746e-05\n",
      "   1.6478110e-04 -3.8917678e-06 -1.4020683e-04]]\n",
      "linear.bias:\n",
      " [0.00022939]\n",
      "\n",
      "Test loss: 0.006385, Train loss: 0.008692\n"
     ]
    }
   ],
   "execution_count": 870
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Looking at the weight, which is negative, the model picked up a mean reversion adoption.",
   "id": "3d59a254c16e1ff8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Test Trading performance\n",
    "* Create trade results from test data"
   ],
   "id": "989016e0270bb908"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.103500Z",
     "start_time": "2025-11-07T13:51:35.096128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trade_results = pl.DataFrame({\n",
    "    'y_hat': y_hat.squeeze(),\n",
    "    'y': Y_test.squeeze(),\n",
    "}).with_columns(\n",
    "    (pl.col('y_hat').sign()==pl.col('y').sign()).alias('is_won'),\n",
    "    pl.col('y_hat').sign().alias('signal'),\n",
    ").with_columns(\n",
    "    (pl.col('signal') * pl.col('y')).alias('trade_log_return')\n",
    "    ).with_columns(\n",
    "        pl.col('trade_log_return').cum_sum().alias('equity_curve')\n",
    "    )\n",
    "trade_results"
   ],
   "id": "13cb199752ed99c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (2_657, 6)\n",
       "┌───────────┬───────────┬────────┬────────┬──────────────────┬──────────────┐\n",
       "│ y_hat     ┆ y         ┆ is_won ┆ signal ┆ trade_log_return ┆ equity_curve │\n",
       "│ ---       ┆ ---       ┆ ---    ┆ ---    ┆ ---              ┆ ---          │\n",
       "│ f32       ┆ f32       ┆ bool   ┆ f32    ┆ f32              ┆ f32          │\n",
       "╞═══════════╪═══════════╪════════╪════════╪══════════════════╪══════════════╡\n",
       "│ -0.002318 ┆ -0.006746 ┆ true   ┆ -1.0   ┆ 0.006746         ┆ 0.006746     │\n",
       "│ 0.00053   ┆ -0.009977 ┆ false  ┆ 1.0    ┆ -0.009977        ┆ -0.003231    │\n",
       "│ 0.001189  ┆ 0.007165  ┆ true   ┆ 1.0    ┆ 0.007165         ┆ 0.003934     │\n",
       "│ -0.000483 ┆ 0.005752  ┆ false  ┆ -1.0   ┆ -0.005752        ┆ -0.001817    │\n",
       "│ -0.000464 ┆ -0.015257 ┆ true   ┆ -1.0   ┆ 0.015257         ┆ 0.013439     │\n",
       "│ …         ┆ …         ┆ …      ┆ …      ┆ …                ┆ …            │\n",
       "│ 0.000955  ┆ -0.000422 ┆ false  ┆ 1.0    ┆ -0.000422        ┆ 1.245924     │\n",
       "│ 0.00015   ┆ 0.005611  ┆ true   ┆ 1.0    ┆ 0.005611         ┆ 1.251534     │\n",
       "│ -0.000264 ┆ 0.000919  ┆ false  ┆ -1.0   ┆ -0.000919        ┆ 1.250615     │\n",
       "│ 0.000177  ┆ -0.01579  ┆ false  ┆ 1.0    ┆ -0.01579         ┆ 1.234825     │\n",
       "│ 0.001614  ┆ 0.000479  ┆ true   ┆ 1.0    ┆ 0.000479         ┆ 1.235304     │\n",
       "└───────────┴───────────┴────────┴────────┴──────────────────┴──────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_657, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>y_hat</th><th>y</th><th>is_won</th><th>signal</th><th>trade_log_return</th><th>equity_curve</th></tr><tr><td>f32</td><td>f32</td><td>bool</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>-0.002318</td><td>-0.006746</td><td>true</td><td>-1.0</td><td>0.006746</td><td>0.006746</td></tr><tr><td>0.00053</td><td>-0.009977</td><td>false</td><td>1.0</td><td>-0.009977</td><td>-0.003231</td></tr><tr><td>0.001189</td><td>0.007165</td><td>true</td><td>1.0</td><td>0.007165</td><td>0.003934</td></tr><tr><td>-0.000483</td><td>0.005752</td><td>false</td><td>-1.0</td><td>-0.005752</td><td>-0.001817</td></tr><tr><td>-0.000464</td><td>-0.015257</td><td>true</td><td>-1.0</td><td>0.015257</td><td>0.013439</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0.000955</td><td>-0.000422</td><td>false</td><td>1.0</td><td>-0.000422</td><td>1.245924</td></tr><tr><td>0.00015</td><td>0.005611</td><td>true</td><td>1.0</td><td>0.005611</td><td>1.251534</td></tr><tr><td>-0.000264</td><td>0.000919</td><td>false</td><td>-1.0</td><td>-0.000919</td><td>1.250615</td></tr><tr><td>0.000177</td><td>-0.01579</td><td>false</td><td>1.0</td><td>-0.01579</td><td>1.234825</td></tr><tr><td>0.001614</td><td>0.000479</td><td>true</td><td>1.0</td><td>0.000479</td><td>1.235304</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 871
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.243443Z",
     "start_time": "2025-11-07T13:51:35.143328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot equity curve\n",
    "# Convert the Series to a NumPy array for plotting\n",
    "y = trade_results['equity_curve'].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(y)\n",
    "plt.title(\"Equity Curve\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Equity\")\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "cdd15c9299fa973a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 872
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.340127Z",
     "start_time": "2025-11-07T13:51:35.333237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# performance checking\n",
    "trade_results = trade_results.with_columns(\n",
    "    (pl.col('equity_curve')-pl.col('equity_curve').cum_max()).alias('drawdown_log')\n",
    ")\n",
    "trade_results"
   ],
   "id": "4b8d56cc8198e1d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (2_657, 7)\n",
       "┌───────────┬───────────┬────────┬────────┬──────────────────┬──────────────┬──────────────┐\n",
       "│ y_hat     ┆ y         ┆ is_won ┆ signal ┆ trade_log_return ┆ equity_curve ┆ drawdown_log │\n",
       "│ ---       ┆ ---       ┆ ---    ┆ ---    ┆ ---              ┆ ---          ┆ ---          │\n",
       "│ f32       ┆ f32       ┆ bool   ┆ f32    ┆ f32              ┆ f32          ┆ f32          │\n",
       "╞═══════════╪═══════════╪════════╪════════╪══════════════════╪══════════════╪══════════════╡\n",
       "│ -0.002318 ┆ -0.006746 ┆ true   ┆ -1.0   ┆ 0.006746         ┆ 0.006746     ┆ 0.0          │\n",
       "│ 0.00053   ┆ -0.009977 ┆ false  ┆ 1.0    ┆ -0.009977        ┆ -0.003231    ┆ -0.009977    │\n",
       "│ 0.001189  ┆ 0.007165  ┆ true   ┆ 1.0    ┆ 0.007165         ┆ 0.003934     ┆ -0.002812    │\n",
       "│ -0.000483 ┆ 0.005752  ┆ false  ┆ -1.0   ┆ -0.005752        ┆ -0.001817    ┆ -0.008564    │\n",
       "│ -0.000464 ┆ -0.015257 ┆ true   ┆ -1.0   ┆ 0.015257         ┆ 0.013439     ┆ 0.0          │\n",
       "│ …         ┆ …         ┆ …      ┆ …      ┆ …                ┆ …            ┆ …            │\n",
       "│ 0.000955  ┆ -0.000422 ┆ false  ┆ 1.0    ┆ -0.000422        ┆ 1.245924     ┆ -0.094122    │\n",
       "│ 0.00015   ┆ 0.005611  ┆ true   ┆ 1.0    ┆ 0.005611         ┆ 1.251534     ┆ -0.088511    │\n",
       "│ -0.000264 ┆ 0.000919  ┆ false  ┆ -1.0   ┆ -0.000919        ┆ 1.250615     ┆ -0.089431    │\n",
       "│ 0.000177  ┆ -0.01579  ┆ false  ┆ 1.0    ┆ -0.01579         ┆ 1.234825     ┆ -0.105221    │\n",
       "│ 0.001614  ┆ 0.000479  ┆ true   ┆ 1.0    ┆ 0.000479         ┆ 1.235304     ┆ -0.104742    │\n",
       "└───────────┴───────────┴────────┴────────┴──────────────────┴──────────────┴──────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_657, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>y_hat</th><th>y</th><th>is_won</th><th>signal</th><th>trade_log_return</th><th>equity_curve</th><th>drawdown_log</th></tr><tr><td>f32</td><td>f32</td><td>bool</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>-0.002318</td><td>-0.006746</td><td>true</td><td>-1.0</td><td>0.006746</td><td>0.006746</td><td>0.0</td></tr><tr><td>0.00053</td><td>-0.009977</td><td>false</td><td>1.0</td><td>-0.009977</td><td>-0.003231</td><td>-0.009977</td></tr><tr><td>0.001189</td><td>0.007165</td><td>true</td><td>1.0</td><td>0.007165</td><td>0.003934</td><td>-0.002812</td></tr><tr><td>-0.000483</td><td>0.005752</td><td>false</td><td>-1.0</td><td>-0.005752</td><td>-0.001817</td><td>-0.008564</td></tr><tr><td>-0.000464</td><td>-0.015257</td><td>true</td><td>-1.0</td><td>0.015257</td><td>0.013439</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0.000955</td><td>-0.000422</td><td>false</td><td>1.0</td><td>-0.000422</td><td>1.245924</td><td>-0.094122</td></tr><tr><td>0.00015</td><td>0.005611</td><td>true</td><td>1.0</td><td>0.005611</td><td>1.251534</td><td>-0.088511</td></tr><tr><td>-0.000264</td><td>0.000919</td><td>false</td><td>-1.0</td><td>-0.000919</td><td>1.250615</td><td>-0.089431</td></tr><tr><td>0.000177</td><td>-0.01579</td><td>false</td><td>1.0</td><td>-0.01579</td><td>1.234825</td><td>-0.105221</td></tr><tr><td>0.001614</td><td>0.000479</td><td>true</td><td>1.0</td><td>0.000479</td><td>1.235304</td><td>-0.104742</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 873
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.582755Z",
     "start_time": "2025-11-07T13:51:35.577027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Max DD log\n",
    "\n",
    "max_drawdown_log = trade_results['drawdown_log'].min()\n",
    "max_drawdown_log"
   ],
   "id": "dc4d312e4393d46f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21904850006103516"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 874
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.659544Z",
     "start_time": "2025-11-07T13:51:35.653908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Putting into simple returns\n",
    "drawdown_pct = np.exp(max_drawdown_log)-1\n",
    "drawdown_pct"
   ],
   "id": "16249152c479d0b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.19671724205394092)"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 875
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.830722Z",
     "start_time": "2025-11-07T13:51:35.825415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "equity_peak = 1000\n",
    "equity_peak * drawdown_pct"
   ],
   "id": "4631e8c4e23860c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-196.71724205394094)"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 876
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.909216Z",
     "start_time": "2025-11-07T13:51:35.904166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Win rate\n",
    "win_rate = trade_results['is_won'].mean()\n",
    "win_rate"
   ],
   "id": "2d9b507adaac0064",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385773428678962"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 877
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.940537Z",
     "start_time": "2025-11-07T13:51:35.935113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Expected Value\n",
    "avg_win = trade_results.filter(pl.col('is_won')==True)['trade_log_return'].mean()\n",
    "avg_loss = trade_results.filter(pl.col('is_won')==False)['trade_log_return'].mean()\n",
    "ev= win_rate * avg_win + (1-win_rate) * avg_loss\n",
    "ev"
   ],
   "id": "d468061f8e991eff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004649241365790812"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 878
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:35.984530Z",
     "start_time": "2025-11-07T13:51:35.978097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# total log return\n",
    "total_log_return = trade_results['trade_log_return'].sum()\n",
    "total_log_return"
   ],
   "id": "2f17e20df0efa498",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2353034019470215"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 879
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.026575Z",
     "start_time": "2025-11-07T13:51:36.022318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "compound_return = np.exp(total_log_return)\n",
    "compound_return"
   ],
   "id": "56891aaf997e9185",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.439421889714994)"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 880
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.044583Z",
     "start_time": "2025-11-07T13:51:36.040404Z"
    }
   },
   "cell_type": "code",
   "source": "1000*compound_return",
   "id": "252ec1fb55cf7c37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3439.421889714994)"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 881
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.079092Z",
     "start_time": "2025-11-07T13:51:36.075265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equity trough\n",
    "\n",
    "equity_trough = trade_results['equity_curve'].min()\n",
    "equity_trough"
   ],
   "id": "5834b73f78d2269f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.029032129794359207"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 882
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.098916Z",
     "start_time": "2025-11-07T13:51:36.093661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Equity peak\n",
    "\n",
    "equity_peak = trade_results['equity_curve'].max()\n",
    "equity_peak"
   ],
   "id": "93602c49574cca65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3400459289550781"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 883
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.121599Z",
     "start_time": "2025-11-07T13:51:36.118115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# std\n",
    "std = trade_results['trade_log_return'].std()\n",
    "std"
   ],
   "id": "3160c0be5c9d61bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009646528400480747"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 884
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.144677Z",
     "start_time": "2025-11-07T13:51:36.140524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sharpe\n",
    "annualized_rate = np.sqrt(365*24/4)\n",
    "sharpe = ev / std * annualized_rate\n",
    "sharpe\n"
   ],
   "id": "fa947f0b16eac6a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.255449478072043)"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 885
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.192304Z",
     "start_time": "2025-11-07T13:51:36.164683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Highlighting itertools\n",
    "import itertools\n",
    "max_lags = 4\n",
    "benchmarks = []\n",
    "feature_pool = [f'{target}_lag_{i}' for i in range(1, max_lags + 1)]\n",
    "combos = list(itertools.combinations(feature_pool, 1))\n",
    "\n",
    "for features in combos:\n",
    "    model = LinearModel(len(features))\n",
    "    benchmarks.append()(ts,list(features),target, model, annualized_rate,no_epochs=200,loss=nn.L1Loss())\n",
    "\n",
    "    benchmarks = pl.DataFrame(benchmarks)\n",
    "\n",
    "\n"
   ],
   "id": "2e28eb9d7d5c2d6a",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list.append() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[886]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m features \u001B[38;5;129;01min\u001B[39;00m combos:\n\u001B[32m      9\u001B[39m     model = LinearModel(\u001B[38;5;28mlen\u001B[39m(features))\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     \u001B[43mbenchmarks\u001B[49m\u001B[43m.\u001B[49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m(ts,\u001B[38;5;28mlist\u001B[39m(features),target, model, annualized_rate,no_epochs=\u001B[32m200\u001B[39m,loss=nn.L1Loss())\n\u001B[32m     12\u001B[39m     benchmarks = pl.DataFrame(benchmarks)\n",
      "\u001B[31mTypeError\u001B[39m: list.append() takes exactly one argument (0 given)"
     ]
    }
   ],
   "execution_count": 886
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.197569700Z",
     "start_time": "2025-11-06T14:21:38.920474Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7c3c0b8533005d13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adding Transaction Fees",
   "id": "ce996a2972c59427"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:52:09.140688Z",
     "start_time": "2025-11-07T13:52:09.132955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2 types of fees:\n",
    "# 1: maker fee and taker fee\n",
    "\n",
    "maker_fee = 0.0001\n",
    "taker_fee = 0.0003\n",
    "\n",
    "roundtrip_fee_log = np.log(1-2*maker_fee)\n",
    "\n",
    "trade_results = trade_results.with_columns(pl.lit(roundtrip_fee_log).alias('tx_fee_log'))\n",
    "trade_results = trade_results.with_columns((pl.col('trade_log_return')+pl.col('tx_fee_log')).alias('trade_log_return_net'))\n",
    "trade_results = trade_results.with_columns(pl.col('trade_log_return_net').cum_sum().alias('equity_curve_net'))\n",
    "trade_results\n",
    "\n",
    "roundtrip_fee_log\n",
    "trade_results\n"
   ],
   "id": "61d4cfb19a2fb542",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (2_657, 10)\n",
       "┌───────────┬───────────┬────────┬────────┬───┬─────────────┬────────────┬────────────┬────────────┐\n",
       "│ y_hat     ┆ y         ┆ is_won ┆ signal ┆ … ┆ drawdown_lo ┆ tx_fee_log ┆ trade_log_ ┆ equity_cur │\n",
       "│ ---       ┆ ---       ┆ ---    ┆ ---    ┆   ┆ g           ┆ ---        ┆ return_net ┆ ve_net     │\n",
       "│ f32       ┆ f32       ┆ bool   ┆ f32    ┆   ┆ ---         ┆ f64        ┆ ---        ┆ ---        │\n",
       "│           ┆           ┆        ┆        ┆   ┆ f32         ┆            ┆ f64        ┆ f64        │\n",
       "╞═══════════╪═══════════╪════════╪════════╪═══╪═════════════╪════════════╪════════════╪════════════╡\n",
       "│ -0.002318 ┆ -0.006746 ┆ true   ┆ -1.0   ┆ … ┆ 0.0         ┆ -0.0002    ┆ 0.006546   ┆ 0.006546   │\n",
       "│ 0.00053   ┆ -0.009977 ┆ false  ┆ 1.0    ┆ … ┆ -0.009977   ┆ -0.0002    ┆ -0.010177  ┆ -0.003631  │\n",
       "│ 0.001189  ┆ 0.007165  ┆ true   ┆ 1.0    ┆ … ┆ -0.002812   ┆ -0.0002    ┆ 0.006965   ┆ 0.003334   │\n",
       "│ -0.000483 ┆ 0.005752  ┆ false  ┆ -1.0   ┆ … ┆ -0.008564   ┆ -0.0002    ┆ -0.005952  ┆ -0.002617  │\n",
       "│ -0.000464 ┆ -0.015257 ┆ true   ┆ -1.0   ┆ … ┆ 0.0         ┆ -0.0002    ┆ 0.015057   ┆ 0.012439   │\n",
       "│ …         ┆ …         ┆ …      ┆ …      ┆ … ┆ …           ┆ …          ┆ …          ┆ …          │\n",
       "│ 0.000955  ┆ -0.000422 ┆ false  ┆ 1.0    ┆ … ┆ -0.094122   ┆ -0.0002    ┆ -0.000622  ┆ 0.71527    │\n",
       "│ 0.00015   ┆ 0.005611  ┆ true   ┆ 1.0    ┆ … ┆ -0.088511   ┆ -0.0002    ┆ 0.005411   ┆ 0.720681   │\n",
       "│ -0.000264 ┆ 0.000919  ┆ false  ┆ -1.0   ┆ … ┆ -0.089431   ┆ -0.0002    ┆ -0.001119  ┆ 0.719561   │\n",
       "│ 0.000177  ┆ -0.01579  ┆ false  ┆ 1.0    ┆ … ┆ -0.105221   ┆ -0.0002    ┆ -0.01599   ┆ 0.703571   │\n",
       "│ 0.001614  ┆ 0.000479  ┆ true   ┆ 1.0    ┆ … ┆ -0.104742   ┆ -0.0002    ┆ 0.000279   ┆ 0.70385    │\n",
       "└───────────┴───────────┴────────┴────────┴───┴─────────────┴────────────┴────────────┴────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_657, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>y_hat</th><th>y</th><th>is_won</th><th>signal</th><th>trade_log_return</th><th>equity_curve</th><th>drawdown_log</th><th>tx_fee_log</th><th>trade_log_return_net</th><th>equity_curve_net</th></tr><tr><td>f32</td><td>f32</td><td>bool</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-0.002318</td><td>-0.006746</td><td>true</td><td>-1.0</td><td>0.006746</td><td>0.006746</td><td>0.0</td><td>-0.0002</td><td>0.006546</td><td>0.006546</td></tr><tr><td>0.00053</td><td>-0.009977</td><td>false</td><td>1.0</td><td>-0.009977</td><td>-0.003231</td><td>-0.009977</td><td>-0.0002</td><td>-0.010177</td><td>-0.003631</td></tr><tr><td>0.001189</td><td>0.007165</td><td>true</td><td>1.0</td><td>0.007165</td><td>0.003934</td><td>-0.002812</td><td>-0.0002</td><td>0.006965</td><td>0.003334</td></tr><tr><td>-0.000483</td><td>0.005752</td><td>false</td><td>-1.0</td><td>-0.005752</td><td>-0.001817</td><td>-0.008564</td><td>-0.0002</td><td>-0.005952</td><td>-0.002617</td></tr><tr><td>-0.000464</td><td>-0.015257</td><td>true</td><td>-1.0</td><td>0.015257</td><td>0.013439</td><td>0.0</td><td>-0.0002</td><td>0.015057</td><td>0.012439</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0.000955</td><td>-0.000422</td><td>false</td><td>1.0</td><td>-0.000422</td><td>1.245924</td><td>-0.094122</td><td>-0.0002</td><td>-0.000622</td><td>0.71527</td></tr><tr><td>0.00015</td><td>0.005611</td><td>true</td><td>1.0</td><td>0.005611</td><td>1.251534</td><td>-0.088511</td><td>-0.0002</td><td>0.005411</td><td>0.720681</td></tr><tr><td>-0.000264</td><td>0.000919</td><td>false</td><td>-1.0</td><td>-0.000919</td><td>1.250615</td><td>-0.089431</td><td>-0.0002</td><td>-0.001119</td><td>0.719561</td></tr><tr><td>0.000177</td><td>-0.01579</td><td>false</td><td>1.0</td><td>-0.01579</td><td>1.234825</td><td>-0.105221</td><td>-0.0002</td><td>-0.01599</td><td>0.703571</td></tr><tr><td>0.001614</td><td>0.000479</td><td>true</td><td>1.0</td><td>0.000479</td><td>1.235304</td><td>-0.104742</td><td>-0.0002</td><td>0.000279</td><td>0.70385</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 887
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### I tested multiple features, including varying lag and combinations thereof, but the highest yielding results remains in lag_1\n",
    "### tweaks\n",
    "* Increased time horizon from 1H to 4H and used the lag_1 feature.After scanning through all single features, lag_1 resulted in highest performance\n",
    "* We can add further features next\n",
    "* We can explore correlation next\n",
    "\n",
    "### I have adjusted the lag to 1 and put the time_interval to 4h. This has increased the sharpe and net equity."
   ],
   "id": "9b67de23ef499fc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:52:12.131093Z",
     "start_time": "2025-11-07T13:52:12.069972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = trade_results['equity_curve_net'].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(y)\n",
    "plt.title(\"Equity Curve Net\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Equity\")\n",
    "plt.show()"
   ],
   "id": "8687ebc481d14742",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 888
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:51:36.205220200Z",
     "start_time": "2025-11-06T19:09:45.003870Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), 'model_weights.pth')",
   "id": "e46a418efcc959b5",
   "outputs": [],
   "execution_count": 895
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Now to create my own research module to adjust models and their functions without changing the full model.\n",
    "### This will assist in identifying strength of model between features."
   ],
   "id": "d62229645e191fff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%sql\n",
    "# Save"
   ],
   "id": "73821151e70cad6a",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "75605fb220a9a9be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
